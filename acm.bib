@inproceedings{10.1145/3544548.3580875,
author = {Garrett, Rachael and Popova, Kristina and N\'{u}\~{n}ez-Pacheco, Claudia and Asgeirsdottir, Thorhildur and Lampinen, Airi and H\"{o}\"{o}k, Kristina},
title = {Felt Ethics: Cultivating Ethical Sensibility in Design Practice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580875},
doi = {10.1145/3544548.3580875},
abstract = {We theoretically develop the ethical positions implicit in somaesthetic interaction design and, using the case study of a water faucet, illustrate our conceptual understanding of ethical sensibilities in design. We apply four lenses – the felt self, intercorporeal self, socio-cultural and political self, and entangled self – to show how our selves and ethical sensibilities are fundamentally constituted by a socially, materially, and technologically entwined world. Further, we show how ethical sensibilities are cultivated in the practice of somaesthetic interaction design. We contribute felt ethics as an approach to cultivating ethical sensibilities in design practice. The felt ethics approach is comprised of (i) a processual cultivation of ethical sensibility through analytical, pragmatic, and practical engagement, (ii) an ongoing critical attentiveness to the limits of our own bodies and lived experiences, and (iii) the rendering visible of our ethical practices as a matter of care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {1},
numpages = {15},
keywords = {Ethics, Aesthetics, Felt Ethics, Soma Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581407,
author = {Rismani, Shalaleh and Shelby, Renee and Smart, Andrew and Jatho, Edgar and Kroll, Joshua and Moon, AJung and Rostamzadeh, Negar},
title = {From Plane Crashes to Algorithmic Harm: Applicability of Safety Engineering Frameworks for Responsible ML},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581407},
doi = {10.1145/3544548.3581407},
abstract = {Inappropriate design and deployment of machine learning (ML) systems lead to negative downstream social and ethical impacts – described here as social and ethical risks – for users, society, and the environment. Despite the growing need to regulate ML systems, current processes for assessing and mitigating risks are disjointed and inconsistent. We interviewed 30 industry practitioners on their current social and ethical risk management practices and collected their first reactions on adapting safety engineering frameworks into their practice – namely, System Theoretic Process Analysis (STPA) and Failure Mode and Effects Analysis (FMEA). Our findings suggest STPA/FMEA can provide an appropriate structure for social and ethical risk assessment and mitigation processes. However, we also find nontrivial challenges in integrating such frameworks in the fast-paced culture of the ML industry. We call on the CHI community to strengthen existing frameworks and assess their efficacy, ensuring that ML systems are safer for all people.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {2},
numpages = {18},
keywords = {Social and Ethical Risk, Safety Engineering, Machine Learning, Empirical Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580942,
author = {Hidaka, Shun and Kobuki, Sota and Watanabe, Mizuki and Seaborn, Katie},
title = {Linguistic Dead-Ends and Alphabet Soup: Finding Dark Patterns in Japanese Apps},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580942},
doi = {10.1145/3544548.3580942},
abstract = {Dark patterns are deceptive and malicious properties of user interfaces that lead the end-user to do something different from intended or expected. While now a key topic in critical computing, most work has been conducted in Western contexts. Japan, with its booming app market, is a relatively uncharted context that offers culturally- and linguistically-sensitive differences in design standards, contexts of use, values, and language, all of which could influence the presence and expression of dark patterns. In this work, we analyzed 200 popular mobile apps in the Japanese market. We found that most apps had dark patterns, with an average of 3.9 per app. We also identified a new class of dark pattern: “Linguistic Dead-Ends” in the forms of “Untranslation” and “Alphabet Soup.” We outline the implications for design and research practice, especially for future cross-cultural research on dark patterns.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {3},
numpages = {13},
keywords = {Dark patterns, Persuasive design, Deceptive design, App design, Japan, Ethical design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581160,
author = {Asgeirsdottir, Thorhildur and Comber, Rob},
title = {Making Energy Matter: Soma Design for Ethical Relations in Energy Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581160},
doi = {10.1145/3544548.3581160},
abstract = {There is a need to reframe our relationship to energy, particularly in Western energy contexts, where we have plentiful access and no meaningful barriers to use. This paper outlines a first-person engagement with energy systems and shows how somaesthetic design is one possible means to cultivate and design for new ways of ethical being with energy systems. Early autobiographical design work focused on designing for ’sustainability’ revealed a trajectory of fatalism and restriction. A turn towards enacting material relations, co-performed with others, opened into a more holistic relationship with energy. Reflecting on how this process unfolded, we argue that sustainability is not, in itself, a somaesthetic sensibility, and remains constrained within rational framings. We develop this argument to contribute to a new understanding of how we somatically relate to energy and how relational ethics in interaction design research and practice can encourage a felt sense for the materiality of energy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {4},
numpages = {14},
keywords = {somaesthetic, sustainability, soma, soma design, energy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580771,
author = {Elsayed-Ali, Salma and Berger, Sara E and Santana, Vagner Figueredo De and Becerra Sandoval, ‪Juana Catalina},
title = {Responsible &amp; Inclusive Cards: An Online Card Tool to Promote Critical Reflection in Technology Industry Work Practices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580771},
doi = {10.1145/3544548.3580771},
abstract = {Societal implications of technology are often considered after public deployment. However, broader impacts ought to be considered during the onset and throughout development to reduce potential for harmful uses, biases, and exclusions. There is a need for tools and frameworks that help technologists become more aware of broader contexts of their work and engage in more responsible and inclusive practices. In this paper, we introduce an online card tool containing questions to scaffold critical reflection about projects’ impacts on society, business, and research. We present the iterative design of the Responsible &amp; Inclusive Cards and findings from five workshops (n=21 participants) with teams distributed across a multinational technology corporation, as well as interviews with people with disabilities to assess gameplay and mental models. We found the tool promoted discussions about challenging topics, reduced power gaps through democratized turn-taking, and enabled participants to identify concrete areas to improve their practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {5},
numpages = {14},
keywords = {Card Tools, Responsible Innovation, Critical Reflection, Ethics, Reflection-in-Action, Research Through Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581147,
author = {Cosio, Laura D and Buruk, O\u{g}uz 'Oz' and Fern\'{a}ndez Galeote, Daniel and Bosman, Isak De Villiers and Hamari, Juho},
title = {Virtual and Augmented Reality for Environmental Sustainability: A Systematic Review},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581147},
doi = {10.1145/3544548.3581147},
abstract = {In recent years, extended reality (XR) technology has seen a rise in use in environmental subjects, i.e., climate change or biodiversity loss, as a potential tool to inform and engage the public with current and future environmental issues. However, research on the potential of XR technology for environmental sustainability is still in the early stages, and there is no clear synthesis of the methods studied in this field. To provide a clearer view of existing approaches and research objectives, we systematically reviewed current literature dealing with XR use in environmental topics. Although the results indicate that the volume of literature exploring XR in environmental applications is increasing, empirical evidence of its impact is limited, hindering the possibility of presently drawing significant conclusions on its potential benefits. Based on our analyses, we identified thematic, theoretical, and methodological knowledge gaps and provide a guideline to aid future research in the field.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {6},
numpages = {23},
keywords = {Extended Reality, Environmental Sustainability, Systematic Literature Review, Augmented Reality, Climate Change, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581152,
author = {Baughan, Amanda and Wang, Xuezhi and Liu, Ariel and Mercurio, Allison and Chen, Jilin and Ma, Xiao},
title = {A Mixed-Methods Approach to Understanding User Trust after Voice Assistant Failures},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581152},
doi = {10.1145/3544548.3581152},
abstract = {Despite huge gains in performance in natural language understanding via large language models in recent years, voice assistants still often fail to meet user expectations. In this study, we conducted a mixed-methods analysis of how voice assistant failures affect users’ trust in their voice assistants. To illustrate how users have experienced these failures, we contribute a crowdsourced dataset of 199 voice assistant failures, categorized across 12 failure sources. Relying on interview and survey data, we find that certain failures, such as those due to overcapturing users’ input, derail user trust more than others. We additionally examine how failures impact users’ willingness to rely on voice assistants for future tasks. Users often stop using their voice assistants for specific tasks that result in failures for a short period of time before resuming similar usage. We demonstrate the importance of low stakes tasks, such as playing music, towards building trust after failures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {7},
numpages = {16},
keywords = {trust, interview, voice assistants, survey, dataset},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580984,
author = {Alfrink, Kars and Keller, Ianus and Doorn, Neelke and Kortuem, Gerd},
title = {Contestable Camera Cars: A Speculative Design Exploration of Public AI That Is Open and Responsive to Dispute},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580984},
doi = {10.1145/3544548.3580984},
abstract = {Local governments increasingly use artificial intelligence (AI) for automated decision-making. Contestability, making systems responsive to dispute, is a way to ensure they respect human rights to autonomy and dignity. We investigate the design of public urban AI systems for contestability through the example of camera cars: human-driven vehicles equipped with image sensors. Applying a provisional framework for contestable AI, we use speculative design to create a concept video of a contestable camera car. Using this concept video, we then conduct semi-structured interviews with 17 civil servants who work with AI employed by a large northwestern European city. The resulting data is analyzed using reflexive thematic analysis to identify the main challenges facing the implementation of contestability in public AI. We describe how civic participation faces issues of representation, public AI systems should integrate with existing democratic practices, and cities must expand capacities for responsible AI development and operation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {8},
numpages = {16},
keywords = {contestability, speculative design, local government, urban AI, camera cars, public administration, automated decision-making, vehicular urban sensing, machine learning, artificial intelligence, urban sensing, public AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580652,
author = {Liao, Q. Vera and Subramonyam, Hariharan and Wang, Jennifer and Wortman Vaughan, Jennifer},
title = {Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580652},
doi = {10.1145/3544548.3580652},
abstract = {Despite the widespread use of artificial intelligence (AI), designing user experiences (UX) for AI-powered systems remains challenging. UX designers face hurdles understanding AI technologies, such as pre-trained language models, as design materials. This limits their ability to ideate and make decisions about whether, where, and how to use AI. To address this problem, we bridge the literature on AI design and AI transparency to explore whether and how frameworks for transparent model reporting can support design ideation with pre-trained models. By interviewing 23 UX practitioners, we find that practitioners frequently work with pre-trained models, but lack support for UX-led ideation. Through a scenario-based design task, we identify common goals that designers seek model understanding for and pinpoint their model transparency information needs. Our study highlights the pivotal role that UX designers can play in Responsible AI and calls for supporting their understanding of AI limitations through model transparency and interrogation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {9},
numpages = {21},
keywords = {AI design, AI documentation, pre-trained models, explainability, AI transparency},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581242,
author = {Moore, Steven and Liao, Q. Vera and Subramonyam, Hariharan},
title = {FAIlureNotes: Supporting Designers in Understanding the Limits of AI Models for Computer Vision Tasks},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581242},
doi = {10.1145/3544548.3581242},
abstract = {To design with AI models, user experience (UX) designers must assess the fit between the model and user needs. Based on user research, they need to contextualize the model’s behavior and potential failures within their product-specific data instances and user scenarios. However, our formative interviews with ten UX professionals revealed that such a proactive discovery of model limitations is challenging and time-intensive. Furthermore, designers often lack technical knowledge of AI and accessible exploration tools, which challenges their understanding of model capabilities and limitations. In this work, we introduced a failure-driven design approach to AI, a workflow that encourages designers to explore model behavior and failure patterns early in the design process. The implementation of fAIlureNotes, a designer-centered failure exploration and analysis tool, supports designers in evaluating models and identifying failures across diverse user groups and scenarios. Our evaluation with UX practitioners shows that fAIlureNotes outperforms today’s interactive model cards in assessing context-specific model performance.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {10},
numpages = {19},
keywords = {Human-Centered AI, UX design, Pre-trained Models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581555,
author = {Balayn, Agathe and Rikalo, Natasa and Yang, Jie and Bozzon, Alessandro},
title = {Faulty or Ready? Handling Failures in Deep-Learning Computer Vision Models until Deployment: A Study of Practices, Challenges, and Needs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581555},
doi = {10.1145/3544548.3581555},
abstract = {Handling failures in computer vision systems that rely on deep learning models remains a challenge. While an increasing number of methods for bug identification and correction are proposed, little is known about how practitioners actually search for failures in these models. We perform an empirical study to understand the goals and needs of practitioners, the workflows and artifacts they use, and the challenges and limitations in their process. We interview 18 practitioners by probing them with a carefully crafted failure handling scenario. We observe that there is a great diversity of failure handling workflows in which cooperations are often necessary, that practitioners overlook certain types of failures and bugs, and that they generally do not rely on potentially relevant approaches and tools originally stemming from research. These insights allow to draw a list of research opportunities, such as creating a library of best practices and more representative formalisations of practitioners’ goals, developing interfaces to exploit failure handling artifacts, as well as providing specialized training.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {11},
numpages = {20},
keywords = {explainability, machine learning testing, practices, debugging},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581045,
author = {Brown, Barry and Broth, Mathias and Vinkhuyzen, Erik},
title = {The Halting Problem: Video Analysis of Self-Driving Cars in Traffic},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581045},
doi = {10.1145/3544548.3581045},
abstract = {Using publicly uploaded videos of the Waymo and Tesla FSD self-driving cars, this paper documents how self-driving vehicles still struggle with some basics of road interaction. To drive safely self-driving cars need to interact in traffic with other road users. Yet traffic is a complex, long established social domain. We focus on one core element of road interaction: when road users yield for each other. Yielding – such as by slowing down for others in traffic – involves communication between different road users to decide who will ‘go’ and who will ‘yield’. Videos of the Waymo and Tesla FSD self-driving cars show how these systems fail to both yield for others, as well as failing to go when yielded to. In discussion, we explore how these ‘problems’ illustrate both the complexity of designing for road interaction, but also how the space of physical machine/human social interactions more broadly can be designed for.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {12},
numpages = {14},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580682,
author = {Calisto, Francisco Maria and Fernandes, Jo\~{a}o and Morais, Margarida and Santiago, Carlos and Abrantes, Jo\~{a}o Maria and Nunes, Nuno and Nascimento, Jacinto C.},
title = {Assertiveness-Based Agent Communication for a Personalized Medicine on Medical Imaging Diagnosis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580682},
doi = {10.1145/3544548.3580682},
abstract = {Intelligent agents are showing increasing promise for clinical decision-making in a variety of healthcare settings. While a substantial body of work has contributed to the best strategies to convey these agents’ decisions to clinicians, few have considered the impact of personalizing and customizing these communications on the clinicians’ performance and receptiveness. This raises the question of how intelligent agents should adapt their tone in accordance with their target audience. We designed two approaches to communicate the decisions of an intelligent agent for breast cancer diagnosis with different tones: a suggestive (non-assertive) tone and an imposing (assertive) one. We used an intelligent agent to inform about: (1) number of detected findings; (2) cancer severity on each breast and per medical imaging modality; (3) visual scale representing severity estimates; (4) the sensitivity and specificity of the agent; and (5) clinical arguments of the patient, such as pathological co-variables. Our results demonstrate that assertiveness plays an important role in how this communication is perceived and its benefits. We show that personalizing assertiveness according to the professional experience of each clinician can reduce medical errors and increase satisfaction, bringing a novel perspective to the design of adaptive communication between intelligent agents and clinicians.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {13},
numpages = {20},
keywords = {Clinical Decision Support System, Healthcare, Breast Cancer},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581393,
author = {Yang, Qian and Hao, Yuexing and Quan, Kexin and Yang, Stephen and Zhao, Yiran and Kuleshov, Volodymyr and Wang, Fei},
title = {Harnessing Biomedical Literature to Calibrate Clinicians’ Trust in AI Decision Support Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581393},
doi = {10.1145/3544548.3581393},
abstract = {Clinical decision support tools (DSTs), powered by Artificial Intelligence (AI), promise to improve clinicians’ diagnostic and treatment decision-making. However, no AI model is always correct. DSTs must enable clinicians to validate each AI suggestion, convincing them to take the correct suggestions while rejecting its errors. While prior work often tried to do so by explaining AI’s inner workings or performance, we chose a different approach: We investigated how clinicians validated each other’s suggestions in practice (often by referencing scientific literature) and designed a new DST that embraces these naturalistic interactions. This design uses GPT-3 to draw literature evidence that shows the AI suggestions’ robustness and applicability (or the lack thereof). A prototyping study with clinicians from three disease areas proved this approach promising. Clinicians’ interactions with the prototype also revealed new design and research opportunities around (1) harnessing the complementary strengths of literature-based and predictive decision supports; (2) mitigating risks of de-skilling clinicians; and (3) offering low-data decision support with literature.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {14},
numpages = {14},
keywords = {XAI, Biomedical Literature, Qualitative Method, Clinical AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581251,
author = {Burgess, Eleanor R. and Jankovic, Ivana and Austin, Melissa and Cai, Nancy and Kapuundefinedci\'{n}ska, Adela and Currie, Suzanne and Overhage, J. Marc and Poole, Erika S and Kaye, Jofish},
title = {Healthcare AI Treatment Decision Support: Design Principles to Enhance Clinician Adoption and Trust},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581251},
doi = {10.1145/3544548.3581251},
abstract = {Artificial intelligence (AI) supported clinical decision support (CDS) technologies can parse vast quantities of patient data into meaningful insights for healthcare providers. Much work is underway to determine the technical feasibility and the accuracy of AI-driven insights. Much less is known about what insights are considered useful and actionable by healthcare providers, their trust in the insights, and clinical workflow integration challenges. Our research team used a conceptual prototype based on AI-generated treatment insights for type 2 diabetes medications to elicit feedback from 41 U.S.-based clinicians, including primary care and internal medicine physicians, endocrinologists, nurse practitioners, physician assistants, and pharmacists. We contribute to the human-computer interaction (HCI) community by describing decision optimization and design objective tensions between population-level and personalized insights, and patterns of use and trust of AI systems. We also contribute a set of 6 design principles for AI-supported CDS.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {19},
keywords = {design principles, type two diabetes, Artificial intelligence, machine learning, medication prescribing, provider workflows, design objective, sociotechnical complexity, knowledge creation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581513,
author = {Bach, Anne Kathrine Petersen and N\o{}rgaard, Trine Munch and Brok, Jens Christian and van Berkel, Niels},
title = {“If I Had All the Time in the World”: Ophthalmologists’ Perceptions of Anchoring Bias Mitigation in Clinical AI Support},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581513},
doi = {10.1145/3544548.3581513},
abstract = {Clinical needs and technological advances have resulted in increased use of Artificial Intelligence (AI) in clinical decision support. However, such support can introduce new and amplify existing cognitive biases. Through contextual inquiry and interviews, we set out to understand the use of an existing AI support system by ophthalmologists. We identified concerns regarding anchoring bias and a misunderstanding of the AI’s capabilities. Following, we evaluated clinicians’ perceptions of three bias mitigation strategies as integrated into their existing decision support system. While clinicians recognised the danger of anchoring bias, we identified a concern around the impact of bias mitigation on procedure time. Our participants were divided in their expectations of any positive impact on diagnostic accuracy, stemming from varying reliance on the decision support. Our results provide insights into the challenges of integrating bias mitigation into AI decision support.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {16},
numpages = {14},
keywords = {bias mitigation, decision support, ophthalmology, anchoring bias, artificial intelligence, Cognitive bias, DSS, AI support, CDSS},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581506,
author = {Verma, Himanshu and Mlynar, Jakub and Schaer, Roger and Reichenbach, Julien and Jreige, Mario and Prior, John and Ev\'{e}quoz, Florian and Depeursinge, Adrien},
title = {Rethinking the Role of AI with Physicians in Oncology: Revealing Perspectives from Clinical and Research Workflows},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581506},
doi = {10.1145/3544548.3581506},
abstract = {Significant and rapid advancements in cancer research have been attributed to Artificial Intelligence (AI). However, AI’s role and impact on the clinical side has been limited. This discrepancy manifests due to the overlooked, yet profound, differences in the clinical and research practices in oncology. Our contribution seeks to scrutinize physicians’ engagement with AI by interviewing 7 medical-imaging experts and disentangle its future alignment across the clinical and research workflows, diverging from the existing “one-size-fits-all” paradigm within Human-Centered AI discourses. Our analysis revealed that physicians’ trust in AI is less dependent on their general acceptance of AI, but more on their contestable experiences with AI. Contestability, in clinical workflows, underpins the need for personal supervision of AI outcomes and processes, i.e., clinician-in-the-loop. Finally, we discuss tensions in the desired attributes of AI, such as explainability and control, contextualizing them within the divergent intentionality and scope of clinical and research workflows.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {17},
numpages = {19},
keywords = {Clinical Adoption of AI, Contestability, Human-Centered AI, Imaginaries, Explainability, Human-In-The-Loop AI, AI in Oncology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581503,
author = {Jo, Eunkyung and Epstein, Daniel A. and Jung, Hyunhoon and Kim, Young-Ho},
title = {Understanding the Benefits and Challenges of Deploying Conversational AI Leveraging Large Language Models for Public Health Intervention},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581503},
doi = {10.1145/3544548.3581503},
abstract = {Recent large language models (LLMs) have advanced the quality of open-ended conversations with chatbots. Although LLM-driven chatbots have the potential to support public health interventions by monitoring populations at scale through empathetic interactions, their use in real-world settings is underexplored. We thus examine the case of CareCall, an open-domain chatbot that aims to support socially isolated individuals via check-up phone calls and monitoring by teleoperators. Through focus group observations and interviews with 34 people from three stakeholder groups, including the users, the teleoperators, and the developers, we found CareCall offered a holistic understanding of each individual while offloading the public health workload and helped mitigate loneliness and emotional burdens. However, our findings highlight that traits of LLM-driven chatbots led to challenges in supporting public and personal health needs. We discuss considerations of designing and deploying LLM-driven chatbots for public health intervention, including tensions among stakeholders around system expectations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {18},
numpages = {16},
keywords = {Check-up calls, Public health, Social isolation, Open-domain dialog system, Large language model, Chatbot},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581226,
author = {Evirgen, Noyan and Chen, Xiang 'Anthony},
title = {GANravel: User-Driven Direction Disentanglement in Generative Adversarial Networks},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581226},
doi = {10.1145/3544548.3581226},
abstract = {Generative adversarial networks (GANs) have many application areas including image editing, domain translation, missing data imputation, and support for creative work. However, GANs are considered ‘black boxes’. Specifically, the end-users have little control over how to improve editing directions through disentanglement. Prior work focused on new GAN architectures to disentangle editing directions. Alternatively, we propose GANravel—a user-driven direction disentanglement tool that complements the existing GAN architectures and allows users to improve editing directions iteratively. In two user studies with 16 participants each, GANravel users were able to disentangle directions and outperformed the state-of-the-art direction discovery baselines in disentanglement performance. In the second user study, GANravel was used in a creative task of creating dog memes and was able to create high-quality edited images and GIFs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {19},
numpages = {15},
keywords = {Disentanglement, Explainable-AI, Generative Adversarial Networks, Interactive Systems},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581063,
author = {P\"{o}hlmann, Katharina Margareta Theresa and Maior, Horia A. and F\"{o}cker, Julia and O'Hare, Louise and Parke, Adrian and Ladowska, Aleksandra and Dickinson, Patrick},
title = {I Think I Don’t Feel Sick: Exploring the Relationship Between Cognitive Demand and Cybersickness in Virtual Reality Using FNIRS},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581063},
doi = {10.1145/3544548.3581063},
abstract = {Virtual Reality (VR) applications commonly use the illusion of self-motion (vection) to simulate experiences such as running, driving, or flying. However, this can lead to cybersickness, which diminishes the experience of users, and can even lead to disengagement with this platform. In this paper we present a study in which we show that users performing a cognitive task while experiencing a VR rollercoaster reported reduced symptoms of cybersickness. Furthermore, we collected and analysed brain activity data from our participants during their experience using functional near infra-red spectroscopy (fNIRS): preliminary analysis suggests the possibility that this technology may be able to detect the experience of cybersickness. Together, these results can assist the creators of VR experiences, both through mitigation of cybersickness in the design process, and by better understanding the experiences of their users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {16},
keywords = {cybersickness, virtual reality, HMD, cognitive demand, fNIRS},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580927,
author = {Fender, Andreas Rene and Roberts, Thomas and Luong, Tiffany and Holz, Christian},
title = {InfinitePaint: Painting in Virtual Reality with Passive Haptics Using Wet Brushes and a Physical Proxy Canvas},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580927},
doi = {10.1145/3544548.3580927},
abstract = {Digital painting interfaces require an input fidelity that preserves the artistic expression of the user. Drawing tablets allow for precise and low-latency sensing of pen motions and other parameters like pressure to convert them to fully digitized strokes. A drawback is that those interfaces are rigid. While soft brushes can be simulated in software, the haptic sensation of the rigid pen input device is different compared to using a soft wet brush on paper. We present InfinitePaint, a system that supports digital painting in Virtual Reality on real paper with a real wet brush. We use special paper that turns black wherever it comes into contact with water and turns blank again upon drying. A single camera captures those temporary strokes and digitizes them while applying properties like color or other digital effects. We tested our system with artists and compared the subjective experience with a drawing tablet.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {21},
numpages = {13},
keywords = {traditional art, virtual reality, Digital painting, brush input, mixed reality, passive haptics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581402,
author = {Wang, Yunlong and Shen, Shuyuan and Lim, Brian Y},
title = {RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581402},
doi = {10.1145/3544548.3581402},
abstract = {Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {22},
numpages = {29},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581377,
author = {Wu, Di and Yu, Zhiwang and Ma, Nan and Jiang, Jianan and Wang, Yuetian and Zhou, Guixiang and Deng, Hanhui and Li, Yi},
title = {StyleMe: Towards Intelligent Fashion Generation with Designer Style},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581377},
doi = {10.1145/3544548.3581377},
abstract = {Hand-drawn sketches and sketch colourization are the most laborious but necessary steps for fashion designers to design exquisite clothes, especially when the fashion design requires distinctive and personal characteristics from designer style. This paper presents an artificial intelligent aided fashion design system, namely StyleMe, to support the automatic generation of clothing sketches with designer style. Given the clothing pictures specified by the designer, StyleMe can use deep learning based generative model to generate clothing sketches that are consistent with the designer style. The system also supports intelligent colourization on clothing sketch by style transfer, according to specified styles from the real fashion images. Through a series of performance evaluations and user studies, we found that our system can generate effective clothing sketches as good as fashion designers’ human work, and significantly improve the efficiency of fashion design with its sketch colourization method.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {16},
keywords = {generative adversarial network, sketch colourization, sketch generalization, Fashion design, generative AI tool.},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581477,
author = {Yilma, Bereket A. and Leiva, Luis A.},
title = {The Elements of Visual Art Recommendation: Learning Latent Semantic Representations of Paintings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581477},
doi = {10.1145/3544548.3581477},
abstract = {Artwork recommendation is challenging because it requires understanding how users interact with highly subjective content, the complexity of the concepts embedded within the artwork, and the emotional and cognitive reflections they may trigger in users. In this paper, we focus on efficiently capturing the elements (i.e., latent semantic relationships) of visual art for personalized recommendation. We propose and study recommender systems based on textual and visual feature learning techniques, as well as their combinations. We then perform a small-scale and a large-scale user-centric evaluation of the quality of the recommendations. Our results indicate that textual features compare favourably with visual ones, whereas a fusion of both captures the most suitable hidden semantic relationships for artwork recommendation. Ultimately, this paper contributes to our understanding of how to deliver content that suitably matches the user’s interests and how they are perceived.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {24},
numpages = {17},
keywords = {Artwork, Personalization, User Experience, Machine Learning, Recommendation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580794,
author = {Pinski, Marc and Adam, Martin and Benlian, Alexander},
title = {AI Knowledge: Improving AI Delegation through Human Enablement},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580794},
doi = {10.1145/3544548.3580794},
abstract = {When collaborating with artificial intelligence (AI), humans can often delegate tasks to leverage complementary AI competencies. However, humans often delegate inefficiently. Enabling humans with knowledge about AI can potentially improve inefficient AI delegation. We conducted a between-subjects experiment (two groups, n = 111) to examine how enabling humans with AI knowledge can improve AI delegation in human-AI collaboration. We find that AI knowledge-enabled humans align their delegation decisions more closely with their assessment of how suitable a task is for humans or AI (i.e., task appraisal). We show that delegation decisions closely aligned with task appraisal increase task performance. However, we also find that AI knowledge lowers future intentions to use AI, suggesting that AI knowledge is not strictly positive for human-AI collaboration. Our study contributes to HCI design guidelines with a new perspective on AI features, educating humans regarding general AI functioning and their own (human) performance and biases.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {25},
numpages = {17},
keywords = {AI literacy, AI education, Cognitive appraisal theory, AI delegation, AI skill},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580905,
author = {Xu, Songlin and Zhang, Xinyu},
title = {Augmenting Human Cognition with an AI-Mediated Intelligent Visual Feedback},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580905},
doi = {10.1145/3544548.3580905},
abstract = {In this paper, we introduce an AI-mediated framework that can provide intelligent feedback to augment human cognition. Specifically, we leverage deep reinforcement learning (DRL) to provide adaptive time pressure feedback to improve user performance in a math arithmetic task. Time pressure feedback could either improve or deteriorate user performance by regulating user attention and anxiety. Adaptive time pressure feedback controlled by a DRL policy according to users’ real-time performance could potentially solve this trade-off problem. However, the DRL training and hyperparameter tuning may require large amounts of data and iterative user studies. Therefore, we propose a dual-DRL framework that trains a regulation DRL agent to regulate user performance by interacting with another simulation DRL agent that mimics user cognition behaviors from an existing dataset. Our user study demonstrates the feasibility and effectiveness of the dual-DRL framework in augmenting user performance, in comparison to the baseline group.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {26},
numpages = {16},
keywords = {human-AI integration, deep reinforcement learning, time pressure, cognition regulation, machine learning, Human augmentation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580917,
author = {Boonprakong, Nattapat and Chen, Xiuge and Davey, Catherine and Tag, Benjamin and Dingler, Tilman},
title = {Bias-Aware Systems: Exploring Indicators for the Occurrences of Cognitive Biases When Facing Different Opinions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580917},
doi = {10.1145/3544548.3580917},
abstract = {Cognitive biases have been shown to play a critical role in creating echo chambers and spreading misinformation. They undermine our ability to evaluate information and can influence our behaviour without our awareness. To allow the study of occurrences and effects of biases on information consumption behaviour, we explore indicators for cognitive biases in physiological and interaction data. Therefore, we conducted two experiments investigating how people experience statements that are congruent or divergent from their own ideological stance. We collected interaction data, eye tracking data, hemodynamic responses, and electrodermal activity while participants were exposed to ideologically tainted statements. Our results indicate that people spend more time processing statements that are incongruent with their own opinion. We detected differences in blood oxygenation levels between congruent and divergent opinions, a first step towards building systems to detect and quantify cognitive biases.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {27},
numpages = {19},
keywords = {Cognitive biases, fNIRS, Electrodermal activity, Eye tracking, Bias-aware systems, Cognition-aware systems},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581529,
author = {Tretter, Stefan and Platz, Axel and Diefenbach, Sarah},
title = {Matching Mind and Method: Augmented Decision-Making with Digital Companions Based on Regulatory Mode Theory},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581529},
doi = {10.1145/3544548.3581529},
abstract = {Digital companions shall augment complex human processes like extensive decision-making. However, their acceptance may depend upon their ability to adapt to individuals’ psychological states and preferred decision strategies. Regulatory Mode Theory divides human self-regulation into assessment (i.e., making comparisons) and locomotion (i.e., movement from state to state). These regulatory modes are more or less compatible with different decision strategies. In an experimental study (N=81, 2x2-between-subjects design) we explored whether digital companions can gain higher acceptance by considering these compatibilities. Participants were confronted with a decision task. The assisting digital companion first induced a regulatory mode (assessment vs. locomotion) and subsequently presented information according to one of two decision strategies (full evaluation vs. progressive elimination). We show that a fit between regulatory mode and decision strategy (assessment/full evaluation or locomotion/progressive elimination) leads to a favorable evaluation of decisions and the digital companion. No differences regarding decision accuracy and speed were observed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {28},
numpages = {10},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581340,
author = {Kim, Taenyun and Molina, Maria D. and Rheu, Minjin (MJ) and Zhan, Emily S. and Peng, Wei},
title = {One AI Does Not Fit All: A Cluster Analysis of the Laypeople’s Perception of AI Roles},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581340},
doi = {10.1145/3544548.3581340},
abstract = {Artificial intelligence (AI) applications have become an integral part of our society. However, studying AI as one entity or studying idiosyncratic applications separately both have limitations. Thus, this study used computational methods to categorize ten different AI roles prevalent in our everyday life and compared laypeople’s perceptions of them using online survey data (N = 727). Based on theoretical factors related to the fundamental nature of AI, the principal component analysis revealed two dimensions that categorize AI: human involvement and AI autonomy. K-means clustering identified four AI role clusters: tools (low in both dimensions), servants (high human involvement and low AI autonomy), assistants (low human involvement and high AI autonomy), and mediators (high in both dimensions). Multivariate analyses of covariances revealed that people assessed AI mediators the most and AI tools the least favorably. Demographics also influenced laypeople’s assessments of AI. The implications of these results are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {20},
keywords = {Social Approval, Artificial Intelligence (AI), AI Autonomy, Clustering Analysis, Attitude, Human Involvement, Credibility, Human-AI Interaction (HAII)},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580778,
author = {Chiossi, Francesco and Haliburton, Luke and Ou, Changkun and Butz, Andreas Martin and Schmidt, Albrecht},
title = {Short-Form Videos Degrade Our Capacity to Retain Intentions: Effect of Context Switching On Prospective Memory},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580778},
doi = {10.1145/3544548.3580778},
abstract = {Social media platforms use short, highly engaging videos to catch users’ attention. While the short-form video feeds popularized by TikTok are rapidly spreading to other platforms, we do not yet understand their impact on cognitive functions. We conducted a between-subjects experiment (N = 60) investigating the impact of engaging with TikTok, Twitter, and YouTube while performing a Prospective Memory task (i.e., executing a previously planned action). The study required participants to remember intentions over interruptions. We found that the TikTok condition significantly degraded the users’ performance in this task. As none of the other conditions (Twitter, YouTube, no activity) had a similar effect, our results indicate that the combination of short videos and rapid context-switching impairs intention recall and execution. We contribute a quantified understanding of the effect of social media feed format on Prospective Memory and outline consequences for media technology designers to not harm the users’ memory and wellbeing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {30},
numpages = {15},
keywords = {TikTok, Social Media, Digital Wellbeing, Prospective Memory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580681,
author = {Inoue, Maakito and Takashima, Kazuki and Fujita, Kazuyuki and Kitamura, Yoshifumi},
title = {BirdViewAR: Surroundings-Aware Remote Drone Piloting Using an Augmented Third-Person Perspective},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580681},
doi = {10.1145/3544548.3580681},
abstract = {We propose BirdViewAR, a surroundings-aware remote drone-operation system that provides significant spatial awareness to pilots through an augmented third-person view (TPV) from an autopiloted secondary follower drone. The follower drone responds to the main drone’s motions and directions using our optimization-based autopilot, allowing the pilots to clearly observe the main drone and its imminent destination without extra input. To improve their understanding of the spatial relationships between the main drone and its surroundings, the TPV is visually augmented with AR-overlay graphics, where the main drone’s spatial statuses are highlighted: its heading, altitude, ground position, camera field-of-view (FOV), and proximity areas. We discuss BirdViewAR’s design and implement its proof-of-concept prototype using programmable drones. Finally, we conduct a preliminary outdoor user study and find that BirdViewAR effectively increased spatial awareness and piloting performance.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {31},
numpages = {19},
keywords = {visualization, spatial awareness, Teleportation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581442,
author = {Liu, Ziyi and Zhu, Zhengzhe and Jiang, Enze and Huang, Feichi and Villanueva, Ana M and Qian, Xun and Wang, Tianyi and Ramani, Karthik},
title = {InstruMentAR: Auto-Generation of Augmented Reality Tutorials for Operating Digital Instruments Through Recording Embodied Demonstration},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581442},
doi = {10.1145/3544548.3581442},
abstract = {Augmented Reality tutorials, which provide necessary context by directly superimposing visual guidance on the physical referent, represent an effective way of scaffolding complex instrument operations. However, current AR tutorial authoring processes are not seamless as they require users to continuously alternate between operating instruments and interacting with virtual elements. We present InstruMentAR, a system that automatically generates AR tutorials through recording user demonstrations. We design a multimodal approach that fuses gestural information and hand-worn pressure sensor data to detect and register the user’s step-by-step manipulations on the control panel. With this information, the system autonomously generates virtual cues with designated scales to respective locations for each step. Voice recognition and background capture are employed to automate the creation of text and images as AR content. For novice users receiving the authored AR tutorials, we facilitate immediate feedback through haptic modules. We compared InstruMentAR with traditional systems in the user study.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {32},
numpages = {17},
keywords = {Immersive Authoring, Embodied Demonstration, Tangible Interaction, Haptic Feedback, wearable Devices, Augmented Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580978,
author = {Li, Wanwan and Li, Changyang and Kim, Minyoung and Huang, Haikun and Yu, Lap-Fai},
title = {Location-Aware Adaptation of Augmented Reality Narratives},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580978},
doi = {10.1145/3544548.3580978},
abstract = {The recent popularity of augmented reality (AR) devices has enabled players to participate in interactive narratives through virtual events and characters populated in a real-world environment, where different actions may lead to different story branches. In this paper, we propose a novel approach to adapt narratives to real spaces for AR experiences. Our optimization-based approach automatically assigns contextually compatible locations to story events, synthesizing a navigation graph to guide players through different story branches while considering their walking experiences. We validated the effectiveness of our approach for adapting AR narratives to different scenes through experiments and user studies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {33},
numpages = {15},
keywords = {augmented reality, storytelling, interactive narratives, path generation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580776,
author = {Wang, Zeyu and Nguyen, Cuong and Asente, Paul and Dorsey, Julie},
title = {PointShopAR: Supporting Environmental Design Prototyping Using Point Cloud in Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580776},
doi = {10.1145/3544548.3580776},
abstract = {We present PointShopAR, a novel tablet-based system for AR environmental design using point clouds as the underlying representation. It integrates point cloud capture and editing in a single AR workflow to help users quickly prototype design ideas in their spatial context. We hypothesize that point clouds are well suited for prototyping, as they can be captured more rapidly than textured meshes and then edited immediately in situ on the capturing device. We based the design of PointShopAR on the practical needs of six architects in a formative study. Our system supports a variety of point cloud editing operations in AR, including selection, transformation, hole filling, drawing, morphing, and animation. We evaluate PointShopAR through a remote study on usability and an in-person study on environmental design support. Participants were able to iterate design rapidly, showing the merits of an integrated capture and editing workflow with point clouds in AR environmental design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {34},
numpages = {15},
keywords = {AR design, capture and editing, point cloud},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580873,
author = {Niyazov, Aziz and Ens, Barrett and Satriadi, Kadek Ananta and Mellado, Nicolas and Barthe, Loic and Dwyer, Tim and Serrano, Marcos},
title = {User-Driven Constraints for Layout Optimisation in Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580873},
doi = {10.1145/3544548.3580873},
abstract = {Automatic layout optimisation allows users to arrange augmented reality content in the real-world environment without the need for tedious manual interactions. This optimisation is often based on modelling the intended content placement as constraints, defined as cost functions. Then, applying a cost minimization algorithm leads to a desirable placement. However, such an approach is limited by the lack of user control over the optimisation results. In this paper we explore the concept of user-driven constraints for augmented reality layout optimisation. With our approach users can define and set up their own constraints directly within the real-world environment. We first present a design space composed of three dimensions: the constraints, the regions of interest and the constraint parameters. Then we explore which input gestures can be employed to define the user-driven constraints of our design space through a user elicitation study. Using the results of the study, we propose a holistic system design and implementation demonstrating our user-driven constraints, which we evaluate in a final user study where participants had to create several constraints at the same time to arrange a set of virtual contents.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {35},
numpages = {16},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581136,
author = {Zhang, Lei and Agrawal, Ashutosh and Oney, Steve and Guo, Anhong},
title = {VRGit: A Version Control System for Collaborative Content Creation in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581136},
doi = {10.1145/3544548.3581136},
abstract = {Immersive authoring tools allow users to intuitively create and manipulate 3D scenes while immersed in Virtual Reality (VR). Collaboratively designing these scenes is a creative process that involves numerous edits, explorations of design alternatives, and frequent communication with collaborators. Version Control Systems (VCSs) help users achieve this by keeping track of the version history and creating a shared hub for communication. However, most VCSs are unsuitable for managing the version history of VR content because their underlying line differencing mechanism is designed for text and lacks the semantic information of 3D content; and the widely adopted commit model is designed for asynchronous collaboration rather than real-time awareness and communication in VR. We introduce VRGit, a new collaborative VCS that visualizes version history as a directed graph composed of 3D miniatures, and enables users to easily navigate versions, create branches, as well as preview and reuse versions directly in VR. Beyond individual uses, VRGit also facilitates synchronous collaboration in VR by providing awareness of users’ activities and version history through portals and shared history visualizations. In a lab study with 14 participants (seven groups), we demonstrate that VRGit enables users to easily manage version history both individually and collaboratively in VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {36},
numpages = {14},
keywords = {Collaboration, Version Control System, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581315,
author = {Oliveira, Alberto Dumont Alves and Dos Santos, Paulo S\'{e}rgio Henrique and Marc\'{\i}lio J\'{u}nior, Wilson Est\'{e}cio and Aljedaani, Wajdi M and Eler, Danilo Medeiros and Eler, Marcelo Medeiros},
title = {Analyzing Accessibility Reviews Associated with Visual Disabilities or Eye Conditions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581315},
doi = {10.1145/3544548.3581315},
abstract = {Accessibility reviews collected from app stores may contain valuable information for improving apps accessibility. Recent studies have presented insightful information on accessibility reviews, but they were based on small datasets and focused on general accessibility concerns. In this paper, we analyzed accessibility reviews that report issues affecting users with visual disabilities or conditions. Such reviews were identified based on selection criteria applied over 179,519,598 reviews of popular apps on the Google Play Store. Our results show that only 0,003% of user reviews mention visual disabilities or conditions; accessibility reviews are associated with 36 visual disabilities or eye conditions; many users do not give precise feedback and refer to their disability using generic terms; accessibility reviews can be grouped into general topics of concerns related to different types of disabilities; and positive reviews are generally associated with high scores and negative feedback with lower scores.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {14},
keywords = {visual disability, user review, evaluation, mobile application, accessibility, app store},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581083,
author = {S\o{}ndergaard, Marie Louise Juul and Campo Woytuk, Nadia},
title = {Feminist Posthumanist Design of Menstrual Care for More-than-Human Bodies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581083},
doi = {10.1145/3544548.3581083},
abstract = {Social stigma and human exceptionalism have contributed to unsustainable menstrual products and a neglect for the nutrients in menstrual blood that can enrich soil. In a Research-through-Design project, we explored how menstrual care can extend to caring for non-human species and the environment. We describe our design process and insights from three workshops with 20 participants, where we designed tools and technologies and worked with biomaterials to create biodegradable menstrual artifacts that can be composted and bring the nutrients in menstrual blood into soil. By drawing on feminist HCI’s quality of ecology and bringing more-than-human design into the domain of intimate care, our research affirms the fertile relations between feminist HCI and posthumanist HCI through the concept of more-than-human bodies. We discuss how our work contributes to inclusive understandings of technology, and to a feminist posthumanist design methodology that centers more-than-human bodies in intimate care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {38},
numpages = {18},
keywords = {feminist HCI, more-than-human design, menstrual care, biomaterials, posthumanism, research through design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581478,
author = {Tuli, Anupriya and Ismail, Azra and Bhat, Karthik S and Singh, Pushpendra and Kumar, Neha},
title = {“Information-Backward but Sex-Forward”: Navigating Masculinity towards Intimate Wellbeing and Heterosexual Relationships},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581478},
doi = {10.1145/3544548.3581478},
abstract = {There has been a growing interest in reproductive health and intimate wellbeing in Human-Computer Interaction, increasingly from an ecological perspective. Much of this work is centered around women’s experiences across diverse settings, emphasizing men’s limited engagement and need for greater participation on these topics. Our research responds to this gap by investigating cisgender men’s experiences of cultivating sexual health literacies in an urban Indian context. We leverage media probes to stimulate focus group discussions, using popular media references on men’s fertility to elicit shared reflection. Our findings uncover the role that humor and masculinity play in shaping men’s perceptions of their sexual health and how this influences their sense of agency and participation in heterosexual intimate relationships. We further discuss how technologies might be designed to support men’s participation in these relationships as supportive partners and allies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {39},
numpages = {16},
keywords = {Heterosexual relationships, Sexual health and wellbeing, Taboo, Media probes, Men},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580673,
author = {Barros Pena, Bel\'{e}n and Koteyko, Nelya and Van Driel, Martine and Delgado, Andrea and Vines, John},
title = {"My Perfect Platform Would Be Telepathy" - Reimagining the Design of Social Media with Autistic Adults},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580673},
doi = {10.1145/3544548.3580673},
abstract = {In this paper, we critically examine the design of mainstream social media platforms from the point of view of autistic experiences and perspectives, drawing inspiration from the neurodiversity movement, the notion of autism as neurodivergence, and the concept of autistic sociality. We conducted 12 participatory design sessions with 20 autistic adult collaborators. Through thematic analysis of qualitative data, we identify seven challenges our participants experienced when using social media, and a set of imagined features that represent their vision of how design could better support their social media use. We discuss how mainstream social media platforms are primarily designed to address neurotypical sensitivities, and fail autistic adults through lack of user control, inadequate mechanisms for expressing tone and intention, and an orientation towards phatic interactions. To close, we outline how autistic sociality can inspire the design of kinder and more considerate social media platforms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {40},
numpages = {16},
keywords = {participatory design, social media, autistic adults, autistic sociality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580687,
author = {Kuribayashi, Masaki and Ishihara, Tatsuya and Sato, Daisuke and Vongkulbhisal, Jayakorn and Ram, Karnik and Kayukawa, Seita and Takagi, Hironobu and Morishima, Shigeo and Asakawa, Chieko},
title = {PathFinder: Designing a Map-Less Navigation System for Blind People in Unfamiliar Buildings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580687},
doi = {10.1145/3544548.3580687},
abstract = {Indoor navigation systems with prebuilt maps have shown great potential in navigating blind people even in unfamiliar buildings. However, blind people cannot always benefit from them in every building, as prebuilt maps are expensive to build. This paper explores a map-less navigation system for blind people to reach destinations in unfamiliar buildings, which is implemented on a robot. We first conducted a participatory design with five blind people, which revealed that intersections and signs are the most relevant information in unfamiliar buildings. Then, we prototyped PathFinder, a navigation system that allows blind people to determine their way by detecting and conveying information about intersections and signs. Through a participatory study, we improved the interface of PathFinder, such as the feedback for conveying the detection results. Finally, a study with seven blind participants validated that PathFinder could assist users in navigating unfamiliar buildings with increased confidence compared to their regular aid.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {41},
numpages = {16},
keywords = {sign recognition, visual impairment, orientation and mobility, intersection detection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581553,
author = {Karusala, Naveena and G, Victoria and Yan, Shirley and Anderson, Richard},
title = {Unsettling Care Infrastructures: From the Individual to the Structural in a Digital Maternal and Child Health Intervention},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581553},
doi = {10.1145/3544548.3581553},
abstract = {Information services for maternal and child health are increasingly being implemented at scale and integrated into public health infrastructures in Global South countries. These services often disseminate tailored health information and provide channels for families to ask questions to health workers. With increasing uptake, these services are intervening into a highly gendered space and shaping care work and information-seeking in new ways. We present a study of a patient education program and associated WhatsApp-based information service deployed across multiple states in India, drawing on observations, interviews, and analysis of chat records. Building on notions of “unsettling care” [63], we examine what it means to deploy such an intervention in inequitable, fragmented health systems. We find that even as the intervention focuses on individual behavior change, it also runs up against structural issues, such as the overburden of health workers, an illegible health system, and gendered power dynamics that extend beyond the realm of the home. We use our findings to unsettle notions of how the intervention provides care, and to reframe how we might think about the design and implementation of health information services to also engage with structural issues.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {16},
keywords = {care, maternal and child health, chat, future of work, India},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581400,
author = {Islam, Md Touhidul and Porter, Donald E and Billah, Syed Masum},
title = {A Probabilistic Model and Metrics for Estimating Perceived Accessibility of Desktop Applications in Keystroke-Based Non-Visual Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581400},
doi = {10.1145/3544548.3581400},
abstract = {Perceived accessibility of an application is a subjective measure of how well an individual with a particular disability, skills, and goals experiences the application via assistive technology. This paper first presents a study with 11 blind users to report how they perceive the accessibility of desktop applications while interacting via assistive technology such as screen readers and a keyboard. The study identifies the low navigational complexity of the user interface (UI) elements as the primary contributor to higher perceived accessibility of different applications. Informed by this study, we develop a probabilistic model that accounts for the number of user actions needed to navigate between any two arbitrary UI elements within an application. This model contributes to the area of computational interaction for non-visual interaction. Next, we derive three metrics from this model: complexity, coverage, and reachability, which reveal important statistical characteristics of an application indicative of its perceived accessibility. The proposed metrics are appropriate for comparing similar applications and can be fine-tuned for individual users to cater to their skills and goals. Finally, we present five use cases, demonstrating how blind users, application developers, and accessibility practitioners can benefit from our model and metrics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {43},
numpages = {20},
keywords = {Perceived accessibility, blind users, probabilistic model, keyboards, desktops., usability, computational interaction, screen readers},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580840,
author = {Takaki, Ken and Nozaki, Etsushi and Kanai, Tomomi and Hautasaari, Ari and Kashio, Akinori and Sato, Daisuke and Kamogashira, Teru and Uranaka, Tsukasa and Urata, Shinji and Koyama, Hajime and Yamasoba, Tatsuya and Kawahara, Yoshihiro},
title = {AsEars: Designing and Evaluating the User Experience of Wearable Assistive Devices for Single-Sided Deafness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580840},
doi = {10.1145/3544548.3580840},
abstract = {Single-sided deafness (SSD) significantly restricts social participation in hearing/speaking cultures due to the person’s difficulty hearing conversations on their deaf side. Although hearing aids for SSD are effective in social situations, the acceptance rate remains low at 4%. To address this problem, we designed and developed a bone conduction-based device to be worn with eyeglasses, involving 53 individuals with SSD including two authors. We conducted a four-week diary study comparing our proposed device with traditional Contralateral Routing of Signals (CROS) hearing aids and explored the factors that might affect the acceptance rate of assistive devices for SSD. The findings indicated that our design was more acceptable for users with SSD due to its effectiveness, social acceptability, and the ability for wearers to use other devices simultaneously, such as earbuds. Based on our results, we discuss implications for designing wearable assistive devices to promote greater acceptance among the target population.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {44},
numpages = {17},
keywords = {user experience, bone conduction, assistive technology, social acceptance, self-stigma, hearing aids, single-sided deafness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580749,
author = {Chiou, Paul T. and Alotaibi, Ali S. and Halfond, William G.J.},
title = {BAGEL: An Approach to Automatically Detect Navigation-Based Web Accessibility Barriers for Keyboard Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580749},
doi = {10.1145/3544548.3580749},
abstract = {The Web has become an essential part of many people’s daily lives, enabling them to complete everyday and essential tasks online and access important information resources. The ability to navigate the Web via the keyboard interface is critical to people with various types of disabilities. However, modern websites often violate web accessibility guidelines for keyboard navigability. In this paper, we present a novel approach for automatically detecting web accessibility barriers that prevent or hinder keyboard users’ ability to navigate web pages. An extensive evaluation of our technique on real-world subjects showed that our technique was able to detect navigation-based keyboard accessibility barriers in web applications with high precision and recall.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {45},
numpages = {17},
keywords = {Keyboard Navigation, Web Accessibility, WCAG, Software Testing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580770,
author = {Rakhmetulla, Gulnar and Arif, Ahmed Sabbir},
title = {Crownboard: A One-Finger Crown-Based Smartwatch Keyboard for Users with Limited Dexterity},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580770},
doi = {10.1145/3544548.3580770},
abstract = {Mobile text entry is difficult for people with motor impairments due to limited access to smartphones and the need for precise target selection on touchscreens. Text entry on smartwatches, on the other hand, has not been well explored for the population. Crownboard enables people with limited dexterity enter text on a smartwatch using its crown. It uses an alphabetical layout divided into eight zones around the bezel. The zones are scanned either automatically or manually by rotating the crown, then selected by pressing the crown. Crownboard decodes zone sequences into words and displays word suggestions. We validated its design in multiple studies. First, a comparison between manual and automated scanning revealed that manual scanning is faster and more accurate. Second, a comparison between clockwise and shortest-path scanning identified the former to be faster and more accurate. In the final study with representative users, only 30% participants could use the default Qwerty. They were 9% and 23% faster with manual and automated Crownboard, respectively. All participants were able to use both variants of Crownboard.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {46},
numpages = {22},
keywords = {wristwatch, text entry, virtual keyboard, crown, smartwatch, motor impairments, accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581367,
author = {Niklaus, Aleena Gertrudes and Cai, Tianyuan and Bylinskii, Zoya and Wallace, Shaun},
title = {Digital Reading Rulers: Evaluating Inclusively Designed Rulers for Readers With Dyslexia and Without},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581367},
doi = {10.1145/3544548.3581367},
abstract = {Physical reading rulers are simple yet effective interventions that help readers with dyslexia. Digital reading rulers may offer similar benefits. Given their potential value, we provide the following contributions: (1) We host focus group sessions including people with dyslexia to build upon their lived experiences, (2) We provide evidence for designs that are effective and preferred, (3) We measure reading gains of rulers for readers with and without dyslexia. Using inclusive design principles, we arrive at four digital ruler designs - Grey Bar, Lightbox, Shade, and Underline. For the first time, we offer a comprehensive evaluation of digital ruler effectiveness on 91 crowdsourced readers with dyslexia and 86 without. Considering reading speed, comprehension, and preference, many readers benefit from these rulers, with the largest gains among readers with dyslexia. Rulers designed by readers with dyslexia increased the reading speeds of readers with dyslexia, supporting the need for inclusive design practices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {47},
numpages = {17},
keywords = {Highlighting, Readability, Human-Computer Interaction, ADHD, Color Overlay, Reading Ruler, Ability-Based Design., Dyslexia, User Sensitive Inclusive Design, Inclusive Design, Accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581105,
author = {Kuang, Emily and Chen, Ruihuan and Fan, Mingming},
title = {Enhancing Older Adults’ Gesture Typing Experience Using the T9 Keyboard on Small Touchscreen Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581105},
doi = {10.1145/3544548.3581105},
abstract = {Older adults increasingly adopt small-screen devices, but limited motor dexterity hinders their ability to type effectively. While a 9-key (T9) keyboard allocates larger space to each key, it is shared by multiple consecutive letters. Consequently, users must interrupt their gestures when typing consecutive letters, leading to inefficiencies and poor user experience. Thus, we proposed a novel keyboard that leverages the currently unused key 1 to duplicate letters from the previous key, allowing the entry of consecutive letters without interruptions. A user study with 12 older adults showed that it significantly outperformed the T9 with wiggle gesture in typing speed, KSPC, insertion errors, and deletes per word while achieving comparable performance as the conventional T9. Repeating the typing tasks with 12 young adults found that the advantages of the novel T9 were consistent or enhanced. We also provide error analysis and design considerations for improving gesture typing on T9 for older adults.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {48},
numpages = {14},
keywords = {Older Adults, Small Touchscreen Devices, Gesture Typing, T9 Keyboard, Text Entry},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580710,
author = {Mott, Martez E and Tang, John and Cutrell, Edward},
title = {Accessibility of Profile Pictures: Alt Text and Beyond to Express Identity Online},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580710},
doi = {10.1145/3544548.3580710},
abstract = {Profile pictures can convey rich social signals that are often inaccessible to blind and low vision screen reader users. Although there have been efforts to understand screen reader users’ preferences for alternative (alt) text descriptions when encountering images online, profile pictures evoke distinct information needs. We conducted semi-structured interviews with 16 screen reader users to understand their preferences for various styles of profile picture image descriptions in different social contexts. We also interviewed seven sighted individuals to explore their thoughts on authoring alt text for profile pictures. Our findings suggest that detailed image descriptions and user narrated alt text can provide screen reader users enjoyable and informative experiences when exploring profile pictures. We also identified mismatches between how sighted individuals would author alt text with what screen reader users prefer to know about profile pictures. We discuss the implications of our findings for social applications that support profile pictures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {49},
numpages = {13},
keywords = {profile pictures, avatars, screen reader, blind, image description, Accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581286,
author = {Tang, Xinru and Chang, Xiang and Chen, Nuoran and Ni, Yingjie (MaoMao) and LC, RAY and Tong, Xin},
title = {Community-Driven Information Accessibility: Online Sign Language Content Creation within d/Deaf Communities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581286},
doi = {10.1145/3544548.3581286},
abstract = {Information access is one of the most significant challenges faced by d/Deaf signers due to a lack of sign language information. Given the challenges in machine-driven solutions, we seek to understand how d/Deaf communities can support the growth of sign language content. Based on interviews with 12 d/Deaf people in China, we found that d/Deaf videos, i.e., sign language videos created by and for d/Deaf people, can be crucial information sources and educational materials. Combining content analysis of 360 d/Deaf videos to better understand this type of video, we show how d/Deaf communities co-create information accessibility through collaboration in content creation online. We uncover two major challenges that creators need to address, e.g., difficulties in interpretation and inconsistent content qualities. We propose potential design opportunities and future research directions to support d/Deaf people’s needs for sign language content through collaboration within d/Deaf communities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {50},
numpages = {24},
keywords = {sign language content creation, accessibility, online collaboration, information access, sign language, online content creation and sharing, d/Deaf, Deaf, d/Deaf community, sign language interpretation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580922,
author = {Sharma, Tanusree and Stangl, Abigale and Zhang, Lotus and Tseng, Yu-Yun and Xu, Inan and Findlater, Leah and Gurari, Danna and Wang, Yang},
title = {Disability-First Design and Creation of A Dataset Showing Private Visual Information Collected With People Who Are Blind},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580922},
doi = {10.1145/3544548.3580922},
abstract = {We present the design and creation of a disability-first dataset, “BIV-Priv,” which contains 728 images and 728 videos of 14 private categories captured by 26 blind participants to support downstream development of artificial intelligence (AI) models. While best practices in dataset creation typically attempt to eliminate private content, some applications require such content for model development. We describe our approach in creating this dataset with private content in an ethical way, including using props rather than participants’ own private objects and balancing multi-disciplinary perspectives (e.g., accessibility, privacy, computer vision) to meet the tangible metrics (e.g., diversity, category, amount of content) to support AI innovations. We observed challenges that our participants encountered during the data collection, including accessibility issues (e.g., understanding foreground vs. background object placement) and issues due to the sensitive nature of the content (e.g., discomfort in capturing some props such as condoms around family members).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {51},
numpages = {15},
keywords = {visual assistance, visual impairments, visual interpretation, private visual content, accessibility, dataset, blind, computer vision, image description, personal visual data, privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580936,
author = {Curtis, Humphrey and You, Zihao and Deary, William and Tudoreanu, Miruna-Ioana and Neate, Timothy},
title = {Envisioning the (In)Visibility of Discreet and Wearable AAC Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580936},
doi = {10.1145/3544548.3580936},
abstract = {High-tech augmentative and alternative communication (AAC) devices can offer vital communication support for those with complex communication needs (CCNs). Unfortunately, these devices are rarely adopted. Abandonment has been linked to many factors – commonly, stigma resulting from the visibility of the device and its intrusion into other essential modes of communication like body language. However, visible AAC is strategically useful for setting conversational expectations. In this work, we explore how we might envision AAC to address these tensions directly. We conduct user-centred design activities to build three high-fidelity AAC prototypes with different communities with CCNs, specialists and stakeholders. The prototypes demonstrate different form factors, visibility and modes of input/output. Subsequently, we conduct two qualitative focus groups using convergent and divergent co-design methods with people with the language impairment aphasia – supporting ideation of seven discreet and wearable low-fidelity AAC prototypes and critique of the three high-fidelity prototypes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {19},
keywords = {Accessibility, Discreet and Wearable Devices, Alternative and Augmentative Communication, AAC, Focus Groups},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581341,
author = {Choi, Dasom and Kim, Sung-In and Lee, Sunok and Lim, Hyunseung and Yoo, Hee Jeong and Hong, Hwajung},
title = {Love on the Spectrum: Toward Inclusive Online Dating Experience of Autistic Individuals},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581341},
doi = {10.1145/3544548.3581341},
abstract = {Online dating is a space where autistic individuals can find romantic partners with reduced social demands. Autistic individuals are often expected to adapt their behaviors to the social norms underlying the online dating platform to appear as desirable romantic partners. However, given that their autistic traits can lead them to different expectations of dating, it is uncertain whether conforming their behaviors to the norm will guide them to the person they truly want. In this paper, we explored the perceptions and expectations of autistic adults in online dating through interviews and workshops. We found that autistic people desired to know whether they behaved according to the platform’s norms. Still, they expected to keep their unique characteristics rather than unconditionally conform to the norm. We conclude by providing suggestions for designing inclusive online dating experiences that could foster self-guided decisions of autistic users and embrace their unique characteristics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {53},
numpages = {15},
keywords = {online dating, participatory design workshop, autism, inclusive design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581130,
author = {Kim, JooYeong and Ahn, SooYeon and Hong, Jin-Hyuk},
title = {Visible Nuances: A Caption System to Visualize Paralinguistic Speech Cues for Deaf and Hard-of-Hearing Individuals},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581130},
doi = {10.1145/3544548.3581130},
abstract = {Captions help deaf and hard-of-hearing (DHH) individuals visually communicate voice information to better understand video content. In speech, the literal content and paralinguistic cues (e.g., pitch and nuance) work together to create real intention. However, current captions are limited in their capacity to deliver fine nuances because they cannot fully convey these paralinguistic cues. This paper proposes an audio-visualized caption system that automatically visualizes paralinguistic cues into various caption elements (thickness, height, font type and motion). A comparative study with 20 DHH participants demonstrates how our system supports DHH individuals to be better accessible to paralinguistic cues while watching videos. Particularly in the case of formal talks, they could accurately identify the speaker’s nuance more often compared to current captions, without any practice or training. Addressing some issues on legibility and familiarity, the proposed caption system has potentials to enrich DHH individuals’ video watching experience more as hearing people enjoy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {54},
numpages = {15},
keywords = {Paralinguistic cues, Speech accessibility, Caption design, Deaf and hard-of-hearing individuals},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580655,
author = {Zhang, Zhuohao (Jerry) and Wobbrock, Jacob O.},
title = {A11yBoard: Making Digital Artboards Accessible to Blind and Low-Vision Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580655},
doi = {10.1145/3544548.3580655},
abstract = {Digital artboards, which hold objects rather than pixels (e.g., Microsoft PowerPoint and Google Slides), remain largely inaccessible for blind and low-vision (BLV) users. Building on prior findings about the experiences of BLV users with digital artboards, we present a novel tool called A11yBoard, an interactive multimodal system that makes interpreting and authoring digital artboards accessible. A11yBoard combines a web-based drawing canvas paired with a mobile touch screen device such as a tablet. The mobile device displays the same canvas and enables risk-free spatial exploration of the artboard via touch and gesture. Speech recognition, non-speech audio, and keyboard-based commands are also used for input and output. Through a series of pilot studies and formal task-based user studies with BLV participants, we show that A11yBoard provides (1) intuitive spatial reasoning about two-dimensional objects, (2) multimodal access to objects’ properties and relationships, and (3) eyes-free creating and editing of objects to establish their desired properties and positions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {55},
numpages = {17},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581285,
author = {Ivanyi, Balazs Andras and Tjemsland, Truls Bendik and Tsalidis de Zabala, Christian Vasileios and Toth, Lilla Julia and Dyrholm, Marcus Alexander and Naylor, Scott James and Paradiso, Ann and Lamb, Dwayne and Chudge, Jarnail and Adjorlu, Ali and Serafin, Stefania},
title = {DuoRhythmo: Design and Remote User Experience Evaluation (UXE) of a Collaborative Accessible Digital Musical Interface (CADMI) for People with ALS (PALS)},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581285},
doi = {10.1145/3544548.3581285},
abstract = {We present DuoRhythmo, a collaborative accessible digital musical interface (CADMI) that gives people living with Amyotrophic Lateral Sclerosis (PALS) the experience of remotely and collaboratively creating music in real-time. We designed DuoRhythmo specifically to be utilized for eye tracking and optimized it for head- and computer mouse interaction, as well using a user-centered design approach. Together with five PALS, we completed a mixed-methods evaluation to assess the accessibility of DuoRhythmo. Participants described the CADMI using the Microsoft Desirability Toolkit (MDT) as fun, empowering, accessible, easy to use, engaging, and stimulating and gave an average System Usability Scale (SUS) score of 79.5. We suggest further research on remote collaboration within the field of accessible digital musical instruments (ADMIs) using the term CADMI to explore the positive effects of collaborative music-making on the quality of life of PALS.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {56},
numpages = {13},
keywords = {accessibility, people living with ALS, user-centered design, musical co-creation, eye tracking, remote user experience evaluation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581249,
author = {Herskovitz, Jaylin and Xu, Andi and Alharbi, Rahaf and Guo, Anhong},
title = {Hacking, Switching, Combining: Understanding and Supporting DIY Assistive Technology Design by Blind People},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581249},
doi = {10.1145/3544548.3581249},
abstract = {Existing assistive technologies (AT) often fail to support the unique needs of blind and visually impaired (BVI) people. Thus, BVI people have become domain experts in customizing and ‘hacking’ AT, creatively suiting their needs. We aim to understand this behavior in depth, and how BVI people envision creating future DIY personalized AT. We conducted a multi-part qualitative study with 12 blind participants: an interview on unique uses of AT, a two-week diary study to log use cases, and a scenario-based design session to imagine creating future technologies. We found that participants work to design new AT both implicitly through creative use cases, and explicitly through regular ideation and development. Participants envisioned creating a variety of new technologies, and we summarize expected benefits and concerns of using a DIY technology approach. From our results, we present design considerations for future DIY technology systems to support existing customization and ‘hacking’ behaviors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {57},
numpages = {17},
keywords = {Do-It-Yourself, Accessibility, Design, Interview, Assistive technology, Visual impairment, Blind},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581053,
author = {Cao, Beiyan and He, Changyang and Zhou, Muzhi and Fan, Mingming},
title = {Sparkling Silence: Practices and Challenges of Livestreaming Among Deaf or Hard of Hearing Streamers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581053},
doi = {10.1145/3544548.3581053},
abstract = {Understanding livestream platforms’ accessibility challenges for minority groups, such as people with disabilities, is critical to increasing the diversity and inclusion of those platforms. While prior work investigated the experiences of streamers with vision or motor loss, little is known about the experiences of deaf or hard of hearing (DHH) streamers who must work with livestreaming platforms that heavily depend on audio. We conducted semi-structured interviews with DHH streamers to learn why they livestream, how they navigate livestream platforms and related challenges. Our findings revealed their desire to break the stereotypes towards the DHH groups via livestream and the intense interplay between interaction methods, such as sign language, texts, lip language, background music, and viewer characteristics. Major accessibility challenges include the lack of real-time captioning, the small sign language reading window, and misinterpretation of sign language. We present design considerations for improving the accessibility of the livestream platforms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {58},
numpages = {15},
keywords = {deaf or hard of hearing (DHH), livestreaming, social media/online communities, accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581287,
author = {Yoo, Suhyeon and Lin, Georgianna and Byeon, Hyeon Jeong and Hwang, Amy S. and Truong, Khai Nhut},
title = {Understanding Tensions in Music Accessibility through Song Signing for and with d/Deaf and Non-d/Deaf Persons},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581287},
doi = {10.1145/3544548.3581287},
abstract = {Song signing is a method practiced by people who are d/Deaf and non-d/Deaf individuals to visually represent music and make music accessible through sign language and body movements. Although there is growing interest in song signing, there is a lack of understanding on what d/Deaf people value about song signing and how to make song signing productions that they would consider acceptable. We conducted semi-structured interviews with 12 d/Deaf participants to gain a deeper understanding of what they value in music and song signing. We then interviewed 14 song signers to understand their experiences and processes in creating song signing performances. From this study, we identify three complex, interrelated layers of the song signing creation process and discuss how they can be supported and completed to potentially bridge the cultural divide between the d/Deaf and non-d/Deaf audiences and guide more culturally responsive creation of music.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {59},
numpages = {18},
keywords = {People who are deaf or hard of hearing, Music, Assistive technology, Accessibility, Song signing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580941,
author = {Li, Franklin Mingzhe and Zhang, Lotus and Bandukda, Maryam and Stangl, Abigale and Shinohara, Kristen and Findlater, Leah and Carrington, Patrick},
title = {Understanding Visual Arts Experiences of Blind People},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580941},
doi = {10.1145/3544548.3580941},
abstract = {Visual arts play an important role in cultural life and provide access to social heritage and self-enrichment, but most visual arts are inaccessible to blind people. Researchers have explored different ways to enhance blind people’s access to visual arts (e.g., audio descriptions, tactile graphics). However, how blind people adopt these methods remains unknown. We conducted semi-structured interviews with 15 blind visual arts patrons to understand how they engage with visual artwork and the factors that influence their adoption of visual arts access methods. We further examined interview insights in a follow-up survey (N=220). We present: 1) current practices and challenges of accessing visual artwork in-person and online (e.g., Zoom tour), 2) motivation and cognition of perceiving visual arts (e.g., imagination), and 3) implications for designing visual arts access methods. Overall, our findings provide a roadmap for technology-based support for blind people’s visual arts experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {60},
numpages = {21},
keywords = {Visual arts, Mixed-methods study, Blind people, Assistive technology, Accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581112,
author = {Chen, Yingting and Kanno, Taro and Furuta, Kazuo},
title = {Cognition-Oriented Facilitation and Guidelines for Collaborative Problem-Solving Online and Face-to-Face: An in-Depth Examination of Format and Facilitation Influence on Problem-Solving Performance},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581112},
doi = {10.1145/3544548.3581112},
abstract = {During the Covid-19 pandemic, more guidelines were created to teach people how to facilitate meetings online, but few were designed from a cognition-oriented perspective. Additionally, solving complex problems is essential in many occupations. However, the influence of online and face-to-face discussion formats on the performance in complex problem-solving tasks is unclear, even though remote working has become common over the past several few years. Hence, this study aims to answer two research questions: (a) Does problem-solving performance differ between online and face-to-face meetings? and (b) Does facilitation improve problem-solving performance when different formats are used? We conducted experiments with 40 groups using a 2 \texttimes{} 2 factorial design, which were controlled for both facilitation and format. Each group comprised two randomly selected participants, and each problem-solving discussion lasted between 1.5–2 h. The obtained evidence showed that format can influence the performance of balancing intercorrelated factors in a complex scenario, but it does not affect the performance of achieving a predefined goal. Instead, it we found that facilitation is helpful for achieving a predefined goal. Based on the results obtained, we propose future design directions for problem-solving centric computer-supported cooperative work systems from a cognition-oriented perspective.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {61},
numpages = {15},
keywords = {Meeting facilitation, Remote collaboration, Cognition-oriented guidelines, Face-to-face meeting, Complex problem solving},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581556,
author = {Williams, Rua Mae and Park, Chorong},
title = {Cyborg Assemblages: How Autistic Adults Construct Sociotechnical Networks to Support Cognitive Function},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581556},
doi = {10.1145/3544548.3581556},
abstract = {Autism has become a popular context for accessible technology researchers, yet a majority of HCI projects for autism and ADHD do not engage in participatory methods or otherwise involve disabled stakeholders in the project and research design. Prior inquiry has identified executive function as a common difficulty for which technologies may provide novel benefits. In this study, we explore how autistic adults currently use technologies, broadly defined, to augment executive function and support themselves in day-to-day tasks. We collect qualitative data from narratives elicited during informal asynchronous interviews to conduct a digital ethnomethodology. Following from principles of Design Justice, crip technoscience, and cyborg assemblage theory, we investigate how autistic adults articulate their own sociotechnical environments into technologically mediated assemblages of executive function and interpersonal webs of care. These patterns of sociotechnical formation inform future work in research and design for tools that can mediate executive function for all users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {62},
numpages = {15},
keywords = {disability in adulthood, digital ethnomethodology, critical disability studies, executive function, contextual inquiry},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580824,
author = {Huber, Stephan and Rath\ss{}, Natalie},
title = {Empathic Accuracy and Mental Effort During Remote Assessments of Emotions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580824},
doi = {10.1145/3544548.3580824},
abstract = {Observing users in remote settings is unfavorable because it adds filters altering the information that underlie judgement. Still, the COVID pandemic led to an unprecedented popularity of remote user experience tests. In this work, we revisited the question, which information is most important for evaluators to assess users’ emotions successfully and efficiently. In an online study, we asked N=55 participants to assess users’ emotions from short videos of 30 interaction situations. As independent variable, we manipulated the combination of the information channels video of users, video of the interactive technology, and audio within subjects. Our findings indicate that empathic accuracy is highest and mental effort is lowest when all stimuli are present. Surprisingly, empathic accuracy was lowest and mental effort highest, when only video of users was available. We discuss these findings in the light of emotion literature focusing on persons’ facial expressions and derive practical implications for remote observations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {63},
numpages = {13},
keywords = {observations, meta-evaluation, emotion, Remote user research, empathy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580742,
author = {Son, Seoyun and Choi, Junyoug and Lee, Sunjae and Song, Jean Y and Shin, Insik},
title = {It is Okay to Be Distracted: How Real-Time Transcriptions Facilitate Online Meeting with Distraction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580742},
doi = {10.1145/3544548.3580742},
abstract = {Online meetings are indispensable in collaborative remote work environments, but they are vulnerable to distractions due to their distributed and location-agnostic nature. While distraction often leads to a decrease in online meeting quality due to loss of engagement and context, natural multitasking has positive tradeoff effects, such as increased productivity within a given time unit. In this study, we investigate the impact of real-time transcriptions (i.e., full-transcripts, summaries, and keywords) as a solution to help facilitate online meetings during distracting moments while still preserving multitasking behaviors. Through two rounds of controlled user studies, we qualitatively and quantitatively show that people can better catch up with the meeting flow and feel less interfered with when using real-time transcriptions. The benefits of real-time transcriptions were more pronounced after distracting activities. Furthermore, we reveal additional impacts of real-time transcriptions (e.g., supporting recalling contents) and suggest design implications for future online meeting platforms where these could be adaptively provided to users with different purposes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {64},
numpages = {19},
keywords = {real-time transcriptions, online meeting, multitasking, distraction, Video-conferencing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581485,
author = {Villa, Steeven and Niess, Jasmin and Nakao, Takuro and Lazar, Jonathan and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {Understanding Perception of Human Augmentation: A Mixed-Method Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581485},
doi = {10.1145/3544548.3581485},
abstract = {Technologies that help users overcome their limitations and integrate with the human body are often termed “human augmentations”. Such technologies are now available on the consumer market, potentially supporting people in their everyday activities. To date, there is no systematic understanding of the perception of human augmentations yet. To address this gap and build an understanding of how to design positive experiences with human augmentations, we conducted a mixed-method study of the perception of augmented humans (AHs). We conducted two scenario-based studies: interviews (n = 16) and an online study (n = 506) with participants from four countries. The scenarios include one out of three augmentation categories (sensory, motor, and cognitive) and specify if the augmented person has a disability or not. Overall, results show that the type of augmentation and disability impacted user attitudes towards AHs. We derive design dimensions for creating technological augmentations for a diverse and global audience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {65},
numpages = {16},
keywords = {social attitudes, augmented human, human augmentation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581355,
author = {Lee, Ken Jen and Davila, Adrian and Cheng, Hanlin and Goh, Joslin and Nilsen, Elizabeth and Law, Edith},
title = {“We Need to Do More... I Need to Do More”: Augmenting Digital Media Consumption via Critical Reflection to Increase Compassion and Promote Prosocial Attitudes and Behaviors},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581355},
doi = {10.1145/3544548.3581355},
abstract = {Much HCI research on prompting prosocial behaviors focuses on methods for increasing empathy. However, increased empathy may have unintended negative consequences. Our work offers an alternative solution that encourages critical reflection for nurturing compassion, which involves motivation and action to help others. In a between-subject experiment, participants (N=60) viewed a climate change documentary while receiving no prompts (CON), reflective prompts to focus on their emotions (RE) or surprises (RS). State compassion, critical reflection, and motivation to act or learn were measured at the end of the session (post-video) and two weeks later (follow-up). Despite participants’ condition not affecting compassion, critical reflection was positively correlated with post-video state compassion. RE and RS participants demonstrated deeper reflection and reported higher motivation to learn post-video, and more prosocial behavioral changes during follow-up. RS participants reported better follow-up recall than RE participants. We conclude by discussing implications on designing technology to support compassion and longer-term critical reflection.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {66},
numpages = {20},
keywords = {Critical Reflection, Compassion, Prosocial Behaviors, Prosocial Attitudes, Digital Media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581360,
author = {Alshehri, Ahmed and Pahk, Eugin and Spielman, Joseph and Parker, Jacob T and Gilbert, Benjamin and Yue, Chuan},
title = {Exploring the Negotiation Behaviors of Owners and Bystanders over Data Practices of Smart Home Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581360},
doi = {10.1145/3544548.3581360},
abstract = {Bystanders (i.e., visiting friends, visiting family members, or domestic workers) are often not aware of the data practices in other people’s (i.e., owners’) smart homes, exposing them to privacy risks. One solution to avoid violating bystanders’ privacy is to increase the data practice transparency and facilitate negotiation. In this paper, we designed a negotiation interaction study to explore the behaviors of owners (n1=238 participants assigned with the owner role) and bystanders (n2=222 participants assigned with the bystander role) when negotiating about smart home data practices with the corresponding bystander and owner digital agents. We also asked questions to explore factors that may potentially correlate with or affect the observed negotiation behaviors and outcomes. We found that owner and bystander participants differ in behaviors regarding numbers of rounds of negotiation, final reached preferences, and total number of agreements. We analyzed the correlating factors and predictability of reaching agreements.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {67},
numpages = {27},
keywords = {privacy, negotiation behaviors., data practices, Smart home devices},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580993,
author = {W\"{u}rsching, Leon and Putz, Florentin and Haesler, Steffen and Hollick, Matthias},
title = {FIDO2 the Rescue? Platform vs. Roaming Authentication on Smartphones},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580993},
doi = {10.1145/3544548.3580993},
abstract = {Modern smartphones support FIDO2 passwordless authentication using either external security keys or internal biometric authentication, but it is unclear whether users appreciate and accept these new forms of web authentication for their own accounts. We present the first lab study (N=87) comparing platform and roaming authentication on smartphones, determining the practical strengths and weaknesses of FIDO2 as perceived by users in a mobile scenario. Most participants were willing to adopt passwordless authentication during our in-person user study, but closer analysis shows that participants prioritize usability, security, and availability differently depending on the account type. We identify remaining adoption barriers that prevent FIDO2 from succeeding password authentication, such as missing support for contemporary usage patterns, including account delegation and usage on multiple clients.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {68},
numpages = {16},
keywords = {Accounts, Usability, User Authentication, Biometrics, Passwordless, Security},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581397,
author = {Cheon, Eunyong and Huh, Jun Ho and Oakley, Ian},
title = {GestureMeter: Design and Evaluation of a Gesture Password Strength Meter},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581397},
doi = {10.1145/3544548.3581397},
abstract = {Gestures drawn on touchscreens have been proposed as an authentication method to secure access to smartphones. They provide good usability and a theoretically large password space. However, recent work has demonstrated that users tend to select simple or similar gestures as their passwords, rendering them susceptible to dictionary based guessing attacks. To improve their security, this paper describes a novel gesture password strength meter that interactively provides security assessments and improvement suggestions based on a scoring algorithm that combines a probabilistic model, a gesture dictionary, and a set of novel stroke heuristics. We evaluate this system in both online and offline settings and show it supports creation of gestures that are significantly more resistant to guessing attacks (by up to 67%) while also maintaining performance on usability metrics such as recall success rate and time. We conclude that gesture password strength meters can help users select more secure gesture passwords.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {69},
numpages = {19},
keywords = {Password composition policy, Gesture password, Large scale study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581167,
author = {Windl, Maximiliane and Schmidt, Albrecht and Feger, Sebastian S.},
title = {Investigating Tangible Privacy-Preserving Mechanisms for Future Smart Homes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581167},
doi = {10.1145/3544548.3581167},
abstract = {Most smart home devices have multiple sensors, such as cameras and microphones; however, most cannot be controlled individually. Tangible privacy mechanisms provide control over individual sensors and instill high certainty of privacy. Yet, it remains unclear how they can be used in future smart homes. We conducted three studies to understand how tangible privacy mechanisms scale across multiple devices and respond to user needs. First, we conducted a focus group (N=8) on speculative tangible control artifacts to understand the user perspective. Second, we ran a workshop at a human-computer interaction conference (N=8) on tangible privacy. Third, we conducted a six-week in-the-wild study with a tangible, static privacy dashboard across six households. Our findings help to contrast the need for tangible privacy mechanisms on the sensor level with user needs on a smart home level. Finally, we discuss our design implications for future smart homes through the lens of inclusive privacy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {16},
keywords = {Privacy, Inclusive Privacy, Tangible Privacy Spectrum., Configurable Smart Devices, Speculative Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581558,
author = {Emami-Naeini, Pardis and Breda, Joseph and Dai, Wei and Kohno, Tadayoshi and Laine, Kim and Patel, Shwetak and Roesner, Franziska},
title = {Understanding People’s Concerns and Attitudes Toward Smart Cities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581558},
doi = {10.1145/3544548.3581558},
abstract = {Designing privacy-respecting and human-centric smart cities requires a careful investigation of people’s attitudes and concerns toward city-wide data collection scenarios. To capture a holistic view, we carried out this investigation in two phases. We first surfaced people’s understanding, concerns, and expectations toward smart city scenarios by conducting 21 semi-structured interviews with people in underserved communities. We complemented this in-depth qualitative study with a 348-participant online survey of the general population to quantify the significance of smart city factors (e.g., type of collected data) on attitudes and concerns. Depending on demographics, privacy and ethics were the two most common types of concerns among participants. We found the type of collected data to have the most and the retention time to have the least impact on participants’ perceptions and concerns about smart cities. We highlight key takeaways and recommendations for city stakeholders to consider when designing inclusive and protective smart cities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {71},
numpages = {24},
keywords = {Smart City, Ethics, IoT, Privacy, Human Centered, Internet of Things},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581508,
author = {Fassl, Matthias and Krombholz, Katharina},
title = {Why I Can’t Authenticate — Understanding the Low Adoption of Authentication Ceremonies with Autoethnography},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581508},
doi = {10.1145/3544548.3581508},
abstract = {Authentication ceremonies detect and mitigate Man-in-the-Middle (MitM) attacks on end-to-end encrypted messengers, such as Signal, WhatsApp, or Threema. However, prior work found that adoption remains low as non-expert users have difficulties using them correctly. Anecdotal evidence suggests that security researchers also have trouble authenticating others. Since their issues are probably unrelated to user comprehension or usability, the root causes may lie deeper. This work explores these root causes using autoethnography. The first author kept a five-month research diary of their experience with authentication ceremonies. The results uncover points of failure while planning and conducting authentication ceremonies. They include cognitive load, forgetfulness, social awkwardness, and explanations required by a communication partner. Additionally, this work identifies and discusses how sociocultural aspects affect authentication ceremonies. Lastly, this work discusses a design approach for cooperative security that employs cultural transcoding to improve sociocultural aspects of security by design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {72},
numpages = {15},
keywords = {End-to-End-Encrypted Messaging, Autoethnography, Authentication Ceremonies, Social Cybersecurity, MitM Attacks},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580679,
author = {Salehnamadi, Navid and He, Ziyao and Malek, Sam},
title = {Assistive-Technology Aided Manual Accessibility Testing in Mobile Apps, Powered by Record-and-Replay},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580679},
doi = {10.1145/3544548.3580679},
abstract = {Billions of people use smartphones on a daily basis, including 15% of the world’s population with disabilities. Mobile platforms encourage developers to manually assess their apps’ accessibility in the way disabled users interact with phones, i.e., through Assistive Technologies (AT) like screen readers. However, most developers only test their apps with touch gestures and do not have enough knowledge to use AT properly. Moreover, automated accessibility testing tools typically do not consider AT. This paper introduces a record-and-replay technique that records the developers’ touch interactions, replays the same actions with an AT, and generates a visualized report of various ways of interacting with the app using ATs. Empirical evaluation of this technique on real-world apps revealed that while user study is the most reliable way of assessing accessibility, our technique can aid developers in detecting complex accessibility issues at different stages of development.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {73},
numpages = {20},
keywords = {Android, Accessibility, Software Testing, AssistiveTechnology, TalkBack},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580762,
author = {Fink, Paul D. S. and Dimitrov, Velin and Yasuda, Hiroshi and Chen, Tiffany L. and Corey, Richard R. and Giudice, Nicholas A. and Sumner, Emily S.},
title = {Autonomous is Not Enough: Designing Multisensory Mid-Air Gestures for Vehicle Interactions Among People with Visual Impairments},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580762},
doi = {10.1145/3544548.3580762},
abstract = {Should fully autonomous vehicles (FAVs) be designed inclusively and accessibly, independence will be transformed for millions of people experiencing transportation-limiting disabilities worldwide. Although FAVs hold promise to improve efficient transportation without intervention, a truly accessible experience must enable user input, for all people, in many driving scenarios (e.g., to alter a route or pull over during an emergency). Therefore, this paper explores desires for control in FAVs among (n=23) people who are blind and visually impaired. Results indicate strong support for control across a battery of driving tasks, as well as the need for multimodal information. These findings inspired the design and evaluation of a novel multisensory interface leveraging mid-air gestures, audio, and haptics. All participants successfully navigated driving scenarios using our gestural-audio interface, reporting high ease-of-use. Contributions include the first inclusively designed gesture set for FAV control and insight regarding supplemental haptic and audio cues.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {74},
numpages = {13},
keywords = {Situational awareness, Interfaces for blind or visually impaired individuals, Gestures, Accessible design, Spatial audio, Autonomous vehicles},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581124,
author = {Barbareschi, Giulia and Kawaguchi, Midori and Kato, Hiroaki and Nagahiro, Masato and Takeuchi, Kazuaki and Shiiba, Yoshifumi and Kasahara, Shunichi and Kunze, Kai and Minamizawa, Kouta},
title = {“I Am Both Here and There” Parallel Control of Multiple Robotic Avatars by Disabled Workers in a Caf\'{e}},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581124},
doi = {10.1145/3544548.3581124},
abstract = {Robotic avatars can help disabled people extend their reach in interacting with the world. Technological advances make it possible for individuals to embody multiple avatars simultaneously. However, existing studies have been limited to laboratory conditions and did not involve disabled participants. In this paper, we present a real-world implementation of a parallel control system allowing disabled workers in a caf\'{e} to embody multiple robotic avatars at the same time to carry out different tasks. Our data corpus comprises semi-structured interviews with workers, customer surveys, and videos of caf\'{e} operations. Results indicate that the system increases workers’ agency, enabling them to better manage customer journeys. Parallel embodiment and transitions between avatars create multiple interaction loops where the links between disabled workers and customers remain consistent, but the intermediary avatar changes. Based on our observations, we theorize that disabled individuals possess specific competencies that increase their ability to manage multiple avatar bodies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {75},
numpages = {17},
keywords = {telework, caf\'{e}, disability, avatar},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581302,
author = {Nair, Vishnu and Zhu, Hanxiu 'Hazel' and Smith, Brian A.},
title = {ImageAssist: Tools for Enhancing Touchscreen-Based Image Exploration Systems for Blind and Low Vision Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581302},
doi = {10.1145/3544548.3581302},
abstract = {Blind and low vision (BLV) users often rely on alt text to understand what a digital image is showing. However, recent research has investigated how touch-based image exploration on touchscreens can supplement alt text. Touchscreen-based image exploration systems allow BLV users to deeply understand images while granting a strong sense of agency. Yet, prior work has found that these systems require a lot of effort to use, and little work has been done to explore these systems’ bottlenecks on a deeper level and propose solutions to these issues. To address this, we present ImageAssist, a set of three tools that assist BLV users through the process of exploring images by touch — scaffolding the exploration process. We perform a series of studies with BLV users to design and evaluate ImageAssist, and our findings reveal several implications for image exploration tools for BLV users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {76},
numpages = {17},
keywords = {touchscreen-based image exploration tools, smartphone-based accessibility tools, visual impairments, alt text},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581023,
author = {Natalie, Rosiana and Tseng, Joshua and Kacorri, Hernisa and Hara, Kotaro},
title = {Supporting Novices Author Audio Descriptions via Automatic Feedback},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581023},
doi = {10.1145/3544548.3581023},
abstract = {Audio descriptions (AD) make videos accessible to those who cannot see them. But many videos lack AD and remain inaccessible as traditional approaches involve expensive professional production. We aim to lower production costs by involving novices in this process. We present an AD authoring system that supports novices to write scene descriptions (SD)—textual descriptions of video scenes—and convert them into AD via text-to-speech. The system combines video scene recognition and natural language processing to review novice-written SD and feeds back what to mention automatically. To assess the effectiveness of this automatic feedback in supporting novices, we recruited 60 participants to author SD with no feedback, human feedback, and automatic feedback. Our study shows that automatic feedback improves SD’s descriptiveness, objectiveness, and learning quality, without affecting qualities like sufficiency and clarity. Though human feedback remains more effective, automatic feedback can reduce production costs by 45%.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {77},
numpages = {18},
keywords = {Accessibility, AI-supported Writing, Individuals with Disabilities and Assistive Technologies},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580929,
author = {Bilius, Laura-Bianca and Ungurean, Ovidiu-Ciprian and Vatavu, Radu-Daniel},
title = {Understanding Wheelchair Users’ Preferences for On-Body, In-Air, and On-Wheelchair Gestures},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580929},
doi = {10.1145/3544548.3580929},
abstract = {We present empirical results from a gesture elicitation study conducted with eleven wheelchair users that proposed on-body, in-air, and on-wheelchair gestures to effect twenty-one referents representing common actions, types of digital content, and navigation commands for interactive systems. We report a large preference for on-body (47.6%) and in-air (40.7%) compared to on-wheelchair (11.7%) gestures, mostly represented by touch input on different parts of the body and hand poses performed in mid-air with one hand. Following an agreement analysis that revealed low consensus (≤ 5.5%) between users, although high perceived gesture ease, goodness, and social acceptability within users, we examine our participants’ gesture characteristics in relation to their self-reported motor impairments, e.g., low strength, rapid fatigue, etc. We highlight the need for personalized gesture sets, tailored to and reflective of both users’ preferences and specific motor abilities, an implication that we examine through the lenses of ability-based design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {78},
numpages = {16},
keywords = {study, motor symptoms, mid-air gestures, Gesture input, wheelchair users, on-body input, mobility impairments, gesture analysis, on-wheelchair gestures, motor impairments, gesture elicitation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581473,
author = {Tran, Peter Khoa Duc and Gadepalli, Purna Valli Anusha and Lee, Jaeyeon and Nittala, Aditya Shekhar},
title = {Augmenting On-Body Touch Input with Tactile Feedback Through Fingernail Haptics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581473},
doi = {10.1145/3544548.3581473},
abstract = {The key assumption attributed to on-body touch input is that the skin being touched provides natural tactile feedback. In this paper, we for the first time systematically explore augmenting on-body touch input with computer-generated tactile feedback. We employ vibrotactile actuation on the fingernail to couple on-body touch input with tactile feedback. Results from our first experiment show that users prefer tactile feedback for on-body touch input. In our second experiment, we determine the frequency thresholds for rendering realistic tactile “click” sensations for on-body touch buttons on three different body locations. Finally, in our third experiment, we dig deeper to render highly expressive tactile effects with a single actuator. Our non-metric multi-dimensional analysis shows that haptic augmentation of on-body buttons enhances the expressivity of on-body touch input. Overall, results from our experiments reinforce the need for tactile feedback for on-body touch input and show that actuation on the fingernail is a promising approach.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {79},
numpages = {13},
keywords = {Vibrotactile Actuation, Haptics, On-Body Interaction, Wearables, Epidermal Interfaces, Fingernail devices},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581382,
author = {Tanaka, Yudai and Shen, Alan and Kong, Andy and Lopes, Pedro},
title = {Full-Hand Electro-Tactile Feedback without Obstructing Palmar Side of Hand},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581382},
doi = {10.1145/3544548.3581382},
abstract = {We present a technique to render tactile feedback to the palmar side of the hand while keeping it unobstructed and, thus, preserving manual dexterity during interactions with physical objects. We implement this by applying electro-tactile stimulation only to the back of the hand and to the wrist. In our approach, there are no electrodes on the palmar side, yet that is where tactile sensations are felt. While we place electrodes outside the user's palm, we do so in strategic locations that conduct the electrical currents to the median/ulnar nerves, causing tactile sensations on the palmar side of the hand. In our user studies, we demonstrated that our approach renders tactile sensations to 11 different locations on the palmar side while keeping users’ palms free for dexterous manipulations. Our approach enables new applications such as tactile notifications during dexterous activities or VR experiences that rely heavily on physical props.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {80},
numpages = {15},
keywords = {Electro-tactile, Virtual Reality, Haptics, Mixed Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580727,
author = {Han, Sangyoon and Park, Jaejun and Choi, Seungmoon},
title = {Generating Haptic Motion Effects for Multiple Articulated Bodies for Improved 4D Experiences: A Camera Space Approach},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580727},
doi = {10.1145/3544548.3580727},
abstract = {Motion effects are indispensable for improving 4D experiences in highly interactive applications, such as amusement parks, 4D theaters, and virtual reality games. Their recent emergence calls for effective algorithms generating motion effects synchronized with audiovisual content. This paper presents an automatic algorithm for synthesizing the object-based motion effects that express the movements of multiple articulated bodies inclusively when the objects’ motion trajectories are available in the 3D camera space. By taking the visual velocities and sizes of all object parts, our method computes a motion proxy that represents the objects’ movements by one point and converts the motion proxy to a motion command through a motion cueing algorithm. The motion proxy is determined by linearly combining the velocities, and its best combination was selected from several candidates by user studies. The results of user studies indicate that our algorithm can produce compelling object-based motion effects that enhance the multisensory experience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {17},
keywords = {articulated body, mulsemedia, motion cueing, multiple sensorial media, vestibular sense, automatic generation, motion effects, 4D, virtual reality, haptics, synthesis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580764,
author = {Nith, Romain and Serfaty, Jacob and Shatzkin, Samuel G and Shen, Alan and Lopes, Pedro},
title = {JumpMod: Haptic Backpack That Modifies Users’ Perceived Jump},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580764},
doi = {10.1145/3544548.3580764},
abstract = {Vertical force-feedback is extremely rare in mainstream interactive experiences. This happens because existing haptic devices capable of sufficiently strong forces that would modify a user's jump require grounding (e.g., motion platforms or pulleys) or cumbersome actuators (e.g., large propellers attached or held by the user). To enable interactive experiences to feature jump-based haptics without sacrificing wearability, we propose JumpMod, an untethered backpack that modifies one's sense of jumping. JumpMod achieves this by moving a weight up/down along the user's back, which modifies perceived jump momentum—creating accelerated &amp; decelerated jump sensations. In our second study, we empirically found that our device can render five effects: jump higher, land harder/softer, pulled higher/lower. Based on these, we designed four jumping experiences for VR &amp; sports. Finally, in our third study, we found that participants preferred wearing our device in an interactive context, such as one of our jump-based VR applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {82},
numpages = {15},
keywords = {wearable, full-body, virtual reality, haptics, backpack, jumping},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580641,
author = {Shen, Zhouyang and Vasudevan, Madhan Kumar and Ku\v{c}era, Jan and Obrist, Marianna and Martinez Plasencia, Diego},
title = {Multi-Point STM: Effects of Drawing Speed and Number of Focal Points on Users’ Responses Using Ultrasonic Mid-Air Haptics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580641},
doi = {10.1145/3544548.3580641},
abstract = {Spatiotemporal modulation (STM) is used to render tactile patterns with ultrasound arrays. Previous research only explored the effects of single-point STM parameters, such as drawing speed (Vd). Here we explore the effects of multi-point STM on both perceptual (intensity) and emotional (valence/arousal) responses. This introduces a new control parameter for STM - the number of focal points (Nfp) – on top of conventional STM parameter (Vd). Our results from a study with 30 participants showed a negative effect of Nfp on perceived intensity and arousal, but no significant effects on valence. We also found the effects of Vd still aligned with prior results for single-point, even when different Nfp were used, suggesting that effects observed from single-point also apply to multi-point STM. We finally derive recommendations, such as using single-point STM to produce stimuli with higher intensity and/or arousal, or using multi-point STM for milder and more relaxing (less arousing) experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {83},
numpages = {11},
keywords = {perception, emotion, mid-air haptics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580738,
author = {Sehrt, Jessica and Wi\ss{}mann, Tim and Breitenbach, Jan and Schwind, Valentin},
title = {The Effects of Body Location and Biosignal Feedback Modality on Performance and Workload Using Electromyography in Virtual&nbsp;Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580738},
doi = {10.1145/3544548.3580738},
abstract = {Using biosignals through electromyography (EMG) and rendering them as feedback for hands-free interaction finally migrates to engaging virtual reality (VR) experiences for health and fitness-related applications. Previous work proposes various body locations as input sources and different output modalities for creating effective biofeedback loops. However, it is currently unknown which muscles and sensory modalities can provide optimal real-time interaction regarding the performance and perceived workload of the users. In two VR studies (N=18 and N=40) based on a Fitts’ law target selection task, we explored sensor placement at different body locations and investigate auditory, tactile, and visual feedback modalities. Objective and subjective results indicate that input performance can be improved by presenting muscle tension as simultaneous tactile and visual feedback. We contribute with recommendations for registration of isometric muscle contraction at different body locations and conclude that reproducing physiological feedback through multimodal channels can assist users interacting with EMG devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {84},
numpages = {16},
keywords = {Virtual Reality, Physiological Sensing, Electromyography, Biofeedback, Accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581221,
author = {Anuyah, Oghenemaro and Badillo-Urquiola, Karla and Metoyer, Ronald},
title = {Characterizing the Technology Needs of Vulnerable Populations for Participation in Research and Design by Adopting Maslow’s Hierarchy of Needs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581221},
doi = {10.1145/3544548.3581221},
abstract = {While various frameworks and heuristics exist within the HCI community to guide research and design for vulnerable populations, most are centered on the researcher’s involvement. In this work, we developed a conceptual framework for supporting the participation of vulnerable populations in the research and design of technologies. Building upon Maslow’s hierarchy of needs, we synthesized 84 research articles that focus on vulnerable populations and technology to develop our framework. This framework conceptualizes both the barriers, such as lack of technology access and digital literacy, and assets, like social relationships, that impact effective participation in research and design. Using our framework can guide researchers in identifying and fulfilling the technology-related needs of vulnerable populations, leading to more empowering research participation for these groups. The framework’s guiding questions offer researchers the opportunity to reflect on their approach prior to and during their collaboration with vulnerable populations in technology research and design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {85},
numpages = {20},
keywords = {Motivation Theories, Vulnerable Populations, Research and Design, Conceptual Framework, Systematic Review, Marginalized Communities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581031,
author = {Manni, Simona and Ursu, Marian F and Gray, John and Markeviciute, Migle and Walter, Andrew and Hook, Jonathan},
title = {Designing Structural Participation in an Interactive Film on Mental Health},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581031},
doi = {10.1145/3544548.3581031},
abstract = {The practice of interactive documentary can provide participatory opportunities thanks to its capacity for making space for audiences to leave their marks in a film. However, participants’ inclusion has often been limited to an a-posteriori contribution of materials rather than a structural involvement in the film design. What happens when we treat participants as authors and let them imagine and design their own interactive film? This paper explores how design processes from participatory filmmaking can be adapted to achieve this goal by presenting the design process that led to the production of an interactive participatory film on mental health, Stepping Through Interactive. Five participants with lived experience of mental health problems explored, designed, and produced a non-linear film form to effectively represent their personal accounts of mental health. We review the challenges faced and the strategies deployed in the design process in view of supporting similar forms of production in other contexts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {86},
numpages = {13},
keywords = {Participatory filmmaking, Participatory design, Mental health, Interactive filmmaking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581312,
author = {Smout, Anna and Chandrasekara, Dharshani Tharanga and Wu, Ling and Melvin, Glenn and Seguin, Joshua Paolo and Olivier, Patrick and Cardamone-Breen, Mairead Claire and Bartindale, Tom and Mcnaney, Roisin and Yap, Marie B H},
title = {Enabling Digital Parenting Interventions to Promote Empathic Partnerships among Parents, Educators, and Adolescents Targeting School Refusal},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581312},
doi = {10.1145/3544548.3581312},
abstract = {School refusal is a complex issue which typically develops in adolescence, often in the context of anxiety and depressive disorders. While parents and educators play a critical role in supporting these adolescents, they need guidance to work together to overcome the problem. Our study explores how technology can be designed to help parents and educators work together in supporting adolescents who refuse school. We first conducted 14 interviews with parents which highlighted that empathic understanding and communication between parents and the educators is key to supporting adolescents with school refusal. Subsequently, we conducted co-design workshops with three parents, three adolescents and five educators. Our workshop findings show that reactive and problem-focused communication can undermine trust-building and progress towards supporting the adolescent. Drawing on these findings, we formulate design implications that can enable empathic parent-adolescent-educator partnerships, provide holistic support for parents, and facilitate individual tailoring for diverse parent-adolescent journeys.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {87},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581209,
author = {Kruzan, Kaylee Payne and Ng, Ada and Stiles-Shields, Colleen and Lattie, Emily G and Mohr, David C. and Reddy, Madhu},
title = {The Perceived Utility of Smartphone and Wearable Sensor Data in Digital Self-Tracking Technologies for Mental Health},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581209},
doi = {10.1145/3544548.3581209},
abstract = {Mental health symptoms are commonly discovered in primary care. Yet, these settings are not set up to provide psychological treatment. Digital interventions can play a crucial role in stepped care management of patients’ symptoms where patients are offered a low intensity intervention, and treatment evolves to incorporate providers if needed. Though digital interventions often use smartphone and wearable sensor data, little is known about patients’ desires to use these data to manage mental health symptoms. In 10 interviews with patients with symptoms of depression and anxiety, we explored their: symptom self-management, current and desired use of sensor data, and comfort sharing such data with providers. Findings support the use digital interventions to manage mental health, yet they also highlight a misalignment in patient needs and current efforts to use sensors. We outline considerations for future research, including extending design thinking to wraparound services that may be necessary to truly reduce healthcare burden.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {88},
numpages = {16},
keywords = {mobile phone app, sensing, primary care, digital mental health, depression, self-management, tracking, anxiety},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581155,
author = {Falk, Jeanette and Kubesch, Moritz and Blumenkranz, Anna and Frauenberger, Christopher},
title = {Three Design Directions for a Diversity Computing Design Space},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581155},
doi = {10.1145/3544548.3581155},
abstract = {We present the insights from participatory design work that explores notions of Diversity Computing (DivComp) and how HCI can meaningfully engage with designing technology around diversity without resorting to tokenistic approaches. A future goal overarching the initial findings in this paper is to design technologically mediated, physical spaces (DivComp Spaces) within a school context where children meet, experiment and learn the complex dynamics of othering. We report on a series of nine workshops with 48 children. Based on a thematic analysis, we present four themes — Technology as Utility and Authority, Individual and Collective Place-Making, Staged and Emerging Conflicts, Belonging to the Group and Self-Expression — which we use to inform three design directions for developing DivComp Spaces specifically in the context of school. Finally, we critically reflect on our design practice and the difficulties of designing not only for, but also with diversity meaningfully embedded into design processes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {89},
numpages = {16},
keywords = {participatory design, interaction design, diversity, design directions},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581316,
author = {Silva, Lucas M. and Cibrian, Franceli L. and Monteiro, Elissa and Bhattacharya, Arpita and Beltran, Jesus A. and Bonang, Clarisse and Epstein, Daniel A. and Schuck, Sabrina E. B. and Lakes, Kimberley D. and Hayes, Gillian R.},
title = {Unpacking the Lived Experiences of Smartwatch Mediated Self and Co-Regulation with ADHD Children},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581316},
doi = {10.1145/3544548.3581316},
abstract = {Challenges associated with ADHD affect children’s daily routines and response to environmental stimuli, and support from parents is helpful in managing and overcoming behavior regulation challenges. Positive reinforcement is increasingly integrated into family technologies for teaching regulation skills, but typically support specific co-located activities. To better understand how technology can support co-regulation within families with ADHD children, we deployed CoolTaco, a smartwatch and phone system to support collaboration in creating tasks, gaining points for achieving them, and redeeming rewards. Ten families with ADHD children used CoolTaco in their daily routines. By qualitatively analyzing family interviews and usage logs, we find that smartwatches can help provide pervasive regulation support to children, but the division across devices and parent-child roles interfere with developing independence. We discuss how technology should support co-regulation while also fostering future self-regulation, such as by guiding children in goal setting and helping them reflect on progress and achievements.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {90},
numpages = {19},
keywords = {ADHD, Smartwatch, children, co-regulation, wearable},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580935,
author = {Wang, Ge and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = {12 Ways to Empower: Designing for Children’s Digital Autonomy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580935},
doi = {10.1145/3544548.3580935},
abstract = {In recent years, growing research has been made on supporting children to become more autonomous in the digital environment around them. However, there has been little consensus regarding the conceptualisation of digital autonomy for children in the HCI community and how best they can be supported. Through a systematic review of autonomy-supportive designs within HCI research, this paper makes three contributions: a landscape overview of the existing conceptualisation of Digital Autonomy for children within HCI; a framework of 12 distinct design mechanisms for supporting children’s digital autonomy, clustered into 5 categories by their common mechanisms; and an identification of 5 critical design considerations for future support of children’s digital autonomy. Our findings provide a critical understanding of current support for children’s digital autonomy in HCI. We highlight the importance of considering children’s digital autonomy from multi-perspectives and suggest critical factors and gaps to be considered for future autonomy-supportive designs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {91},
numpages = {27},
keywords = {Systematic Literature Review, Children, Autonomy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580667,
author = {Yu, Junnan and Widman, Sari and Roque, Ricarose},
title = {Family Negotiation in Joint Media Engagement with Creative Computing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580667},
doi = {10.1145/3544548.3580667},
abstract = {HCI researchers have been investigating family dynamics with new and emerging technologies during joint media engagement (JME) experiences. However, most studies describe family dynamics from parents’ perspectives, such as their roles and mediation practices, while the roles and agency of other family members are less understood. In this paper, we examine family dynamics through the lens of negotiation between family members. Our study is located within an informal learning program called Family Creative Learning, where families from non-dominant groups were invited to participate in a series of workshops to create with a programming app called ScratchJr. Through analysis of data that included process, artifact, and reflective data, we identify negotiation practices of family members as they advocate for device and creative control. We further discuss how the lens of negotiation expands the meaning of productive JME in family contexts and highlight design considerations to facilitate engaging joint family experiences with educational technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {92},
numpages = {15},
keywords = {family, joint media engagement, negotiation, creative making},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581043,
author = {Xu, Wenjie and Ma, Jiayi and Yao, Jiayu and Lin, Weijia and Zhang, Chao and Xia, Xuanhe and Zhuang, Nan and Weng, Shitong and Xie, Xiaoqian and Feng, Shuyue and Ying, Fangtian and Hansen, Preben and Yao, Cheng},
title = {MathKingdom: Teaching Children Mathematical Language Through Speaking at Home via a Voice-Guided Game},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581043},
doi = {10.1145/3544548.3581043},
abstract = {The amount and quality of mathematical language in the family are positively associated with promoting children’s mathematical abilities. However, mathematical language in many families is poor. Through need-finding investigation, we developed MathKingdom, a voice-agent-based game that helps children aged 4–7 learn and use rich, accurate mathematical language (e.g., mathematical expressions related to measurement, sequence, patterns). The game has four flows, in which users can wake up, transform, decorate, and perform as their avatars, as well as practice basic mathematical vocabulary, mathematical single sentences, coherent mathematical statements, and free expression. We refined the system design through wizard-of-oz testing and then evaluated it with 18 families. The results showed that MathKingdom effectively engaged children, enhanced their mathematical language skills and mathematical abilities, and encouraged parent-child conversations about math.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {93},
numpages = {14},
keywords = {Voice agent, Embodied game, Children, Mathematical language},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580720,
author = {Jin, Qiao and Yuan, Ye and Yarosh, Svetlana},
title = {Socio-Technical Opportunities in Long-Distance Communication Between Siblings with a Large Age Difference},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580720},
doi = {10.1145/3544548.3580720},
abstract = {Siblings play a crucial and long-lasting role in family connections and relationships. However, with the older sibling transitioning out of their parental home, maintaining a close sibling relationship can be challenging, especially if siblings have a large age difference. We conducted a diary and interview study with nine families in China which have spaced siblings, to identify design opportunities for technology to better support their communication and connection needs. We contribute to the HCI community in three aspects. First, we contribute an empirical understanding of current communication patterns from distributed families with large age gap siblings in China. Second, we identify current facilitation roles, practices, and challenges regarding sibling relationships from different stakeholders’ perspectives. Last but not least, we present technological opportunities for supporting the large-gap sibling relationship, informing directions for future research and design for distributed families.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {94},
numpages = {15},
keywords = {computer-mediated communication, non-Western, children, distributed families, siblings},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580933,
author = {Wang, Ge and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = {‘Treat Me as Your Friend, Not a Number in Your Database’: Co-Designing with Children to Cope with Datafication Online},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580933},
doi = {10.1145/3544548.3580933},
abstract = {Datafication refers to the practices through which children’s online actions are pervasively recorded, tracked, aggregated, analysed, and exploited by online services in ways including behavioural engineering and monetisation. Previous research has shown that not only do children care significantly about various aspects of datafication, but they demand a chance to take action. Through 10 co-design sessions with 53 children, we examined how children in the UK want to be supported to cope with the datafication practices. Our findings provide insights for creating age-appropriate support for children’s algorithmic literacy development, highlighting and unpacking the importance of no one-size-fitting-all designs to support children’s coping with datafication. We contribute a first understanding of how children aged 7–14 would like to be supported with datafication and what future data-driven digital experiences should be like for them, who demand a shift of the current data ecosystem towards a more humane-by-design and autonomy-supportive future.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {95},
numpages = {21},
keywords = {Online Platforms, Children, Co-design, Data Inference, Datafication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580981,
author = {Dietz, Griffin and Tamer, Nadin and Ly, Carina and Le, Jimmy K and Landay, James A.},
title = {Visual StoryCoder: A Multimodal Programming Environment for Children’s Creation of Stories},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580981},
doi = {10.1145/3544548.3580981},
abstract = {Computational thinking (CT) education reaches only a fraction of young children, in part because CT learning tools often require expensive hardware or fluent literacy. Block-based programming environments address these challenges through symbolic graphical interfaces, but users often need instructor support to advance. Alternatively, voice-based tools provide direct instruction on CT concepts but can present memory and navigation challenges to users. In this work, we present Visual StoryCoder, a multimodal tablet application that combines the strengths of each of these approaches to overcome their respective weaknesses. Visual StoryCoder introduces children ages 5–8 to CT through creative storytelling, offers direct instruction via a pedagogical voice agent, and eases use through a block-like graphical interface. In a between-subjects evaluation comparing Visual StoryCoder to a leading block-based programming app for this age group (N = 24), we show that Visual StoryCoder is more understandable to independent learners, leads to higher-quality code after app familiarization, and encourages personally meaningful projects.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {96},
numpages = {16},
keywords = {multimodal interface, computational thinking, children, storytelling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580879,
author = {Schr\"{o}der, Jan-Henrik and Schacht, Daniel and Peper, Niklas and Hamurculu, Anita Marie and Jetter, Hans-Christian},
title = {Collaborating Across Realities: Analytical Lenses for Understanding Dyadic Collaboration in Transitional Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580879},
doi = {10.1145/3544548.3580879},
abstract = {Transitional Interfaces are a yet underexplored, emerging class of cross-reality user interfaces that enable users to freely move along the reality-virtuality continuum during collaboration. To analyze and understand how such collaboration unfolds, we propose four analytical lenses derived from an exploratory study of transitional collaboration with 15 dyads. While solving a complex spatial optimization task, participants could freely switch between three contexts, each with different displays (desktop screens, tablet-based augmented reality, head-mounted virtual reality), input techniques (mouse, touch, handheld controllers), and visual representations (monoscopic and allocentric 2D/3D maps, stereoscopic egocentric views). Using the rich qualitative and quantitative data from our study, we evaluated participants’ perceptions of transitional collaboration and identified commonalities and differences between dyads. We then derived four lenses including metrics and visualizations to analyze key aspects of transitional collaboration: (1) place and distance, (2) temporal patterns, (3) group use of contexts, (4) individual use of contexts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {97},
numpages = {16},
keywords = {user study, analytical lenses, transitional interfaces, transitional collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581089,
author = {Rajaram, Shwetha and Chen, Chen and Roesner, Franziska and Nebeling, Michael},
title = {Eliciting Security &amp; Privacy-Informed Sharing Techniques for Multi-User Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581089},
doi = {10.1145/3544548.3581089},
abstract = {The HCI community has explored new interaction designs for collaborative AR interfaces in terms of usability and feasibility; however, security &amp; privacy (S&amp;P) are often not considered in the design process and left to S&amp;P professionals. To produce interaction proposals with S&amp;P in mind, we extend the user-driven elicitation method with a scenario-based approach that incorporates a threat model involving access control in multi-user AR. We conducted an elicitation study in two conditions, pairing AR/AR experts in one condition and AR/S&amp;P experts in the other, to investigate the impact of each pairing. We contribute a set of expert-elicited interactions for sharing AR content enhanced with access control provisions, analyze the benefits and tradeoffs of pairing AR and S&amp;P experts, and present recommendations for designing future multi-user AR interactions that better balance competing design goals of usability, feasibility, and S&amp;P in collaborative AR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {98},
numpages = {17},
keywords = {threat modeling, elicitation studies},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580752,
author = {James, Rapha\"{e}l and Bezerianos, Anastasia and Chapuis, Olivier},
title = {Evaluating the Extension of Wall Displays with AR for Collaborative Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580752},
doi = {10.1145/3544548.3580752},
abstract = {Wall displays are well suited for collaborative work and are often placed in rooms with ample space in front of them that remains largely unused. Augmented Reality (AR) headsets can seamlessly extend the collaboration space around the Wall. Nevertheless, it is unclear if extending Walls with AR is effective and how it may affect collaboration. We first present a prototype combining a Wall and AR headsets to extend the Wall workspace. We then use this prototype to study how users utilize the virtual space created in AR. In an experiment with 24 participants, we compare how pairs solve collaborative tasks with the Wall alone and with Wall+AR. Our qualitative and quantitative results highlight that with Wall+AR, participants use the physical space in front and around the Wall extensively, and while this creates interaction overhead, it does not impact performance and improves the user experience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {99},
numpages = {17},
keywords = {Wall Display, Empirical Study, Augmented Reality, Collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581103,
author = {Deighan, Mairi Therese and Ayobi, Amid and O'Kane, Aisling Ann},
title = {Social Virtual Reality as a Mental Health Tool: How People Use VRChat to Support Social Connectedness and Wellbeing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581103},
doi = {10.1145/3544548.3581103},
abstract = {Social virtual reality (VR) platforms have increased in popularity with many people turning to these platforms to experience social connection, including a rapid influx of users during the COVID-19 pandemic. However, there is limited understanding of how people appropriate and use emerging social VR applications to actively support their mental health and wellbeing in daily life. Through an online questionnaire and exploratory interviews conducted within the social VR app VRChat during the COVID-19 pandemic, we document how social VR is being used explicitly as a mental health support tool. Participants reported positive wellbeing benefits, mostly attributed to the anonymity provided by avatars and perceived safety within digital worlds and communities of practice. We also report how people use social VR to practice social interaction, reduce negative thoughts and form strong social bonds and connections with others.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {100},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581277,
author = {Irlitti, Andrew and Latifoglu, Mesut and Zhou, Qiushi and Reinoso, Martin N and Hoang, Thuong and Velloso, Eduardo and Vetere, Frank},
title = {Volumetric Mixed Reality Telepresence for Real-Time Cross Modality Collaboration},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581277},
doi = {10.1145/3544548.3581277},
abstract = {Mixed-reality telepresence allows local and remote users feel as if they are present together in the same space. In this paper we report on a mixed-reality volumetric telepresence system that is adaptable, multi-user and cross-modal, i.e. combining augmented and virtual reality technologies with face-to-face interactions. The system extends state-of-art by creating full-body and environmental volumetric renderings in real-time over local enterprise networks. We report findings of an evaluation in a training scenario which was adapted for remote delivery and led by an industry professional. Analysis of interviews and observed behaviours identify varying attitudes towards virtually mediated full-body experiences and highlight the impact of volumetric mixed-reality telepresence to facilitate personal experiences of co-presence and to ground communication with interlocutors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {101},
numpages = {14},
keywords = {telepresence, virtual reality, volumetric capture, Extended reality, avatars, augmented reality, collaboration, conversational grounding},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581162,
author = {Schlagowski, Ruben and Nazarenko, Dariia and Can, Yekta and Gupta, Kunal and Mertes, Silvan and Billinghurst, Mark and Andr\'{e}, Elisabeth},
title = {Wish You Were Here: Mental and Physiological Effects of Remote Music Collaboration in Mixed Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581162},
doi = {10.1145/3544548.3581162},
abstract = {With face-to-face music collaboration being severely limited during the recent pandemic, mixed reality technologies and their potential to provide musicians a feeling of "being there" with their musical partner can offer tremendous opportunities. In order to assess this potential, we conducted a laboratory study in which musicians made music together in real-time while simultaneously seeing their jamming partner’s mixed reality point cloud via a head-mounted display and compared mental effects such as flow, affect, and co-presence to an audio-only baseline. In addition, we tracked the musicians’ physiological signals and evaluated their features during times of self-reported flow. For users jamming in mixed reality, we observed a significant increase in co-presence. Regardless of the condition (mixed reality or audio-only), we observed an increase in positive affect after jamming remotely. Furthermore, we identified heart rate and HF/LF as promising features for classifying the flow state musicians experienced while making music together.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {102},
numpages = {16},
keywords = {Remote Collaboration, Head-mounted Displays, Physiological Signal Processing, Mixed Reality, Psychophysiology, Networked Music Performance, Augmented Reality, Co-Presence, Social Presence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581351,
author = {Fu, Liye and Newman, Benjamin and Jakesch, Maurice and Kreps, Sarah},
title = {Comparing Sentence-Level Suggestions to Message-Level Suggestions in AI-Mediated Communication},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581351},
doi = {10.1145/3544548.3581351},
abstract = {Traditionally, writing assistance systems have focused on short or even single-word suggestions. Recently, large language models like GPT-3 have made it possible to generate significantly longer natural-sounding suggestions, offering more advanced assistance opportunities. This study explores the trade-offs between sentence- vs. message-level suggestions for AI-mediated communication. We recruited 120 participants to act as staffers from legislators’ offices who often need to respond to large volumes of constituent concerns. Participants were asked to reply to emails with different types of assistance. The results show that participants receiving message-level suggestions responded faster and were more satisfied with the experience, as they mainly edited the suggested drafts. In addition, the texts they wrote were evaluated as more helpful by others. In comparison, participants receiving sentence-level assistance retained a higher sense of agency, but took longer for the task as they needed to plan the flow of their responses and decide when to use suggestions. Our findings have implications for designing task-appropriate communication assistance systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {103},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581569,
author = {Laban, Philippe and Wu, Chien-Sheng and Murakhovs'Ka, Lidiya and Chen, Xiang 'Anthony' and Xiong, Caiming},
title = {Designing and Evaluating Interfaces That Highlight News Coverage Diversity Using Discord Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581569},
doi = {10.1145/3544548.3581569},
abstract = {Modern news aggregators do the hard work of organizing a large news stream, creating collections for a given news story with tens of source options. This paper shows that navigating large source collections for a news story can be challenging without further guidance. In this work, we design three interfaces – the Annotated Article, the Recomposed Article, and the Question Grid – aimed at accompanying news readers in discovering coverage diversity while they read. A first usability study with 10 journalism experts confirms the designed interfaces all reveal coverage diversity and determine each interface’s potential use cases and audiences. In a second usability study, we developed and implemented a reading exercise with 95 novice news readers to measure exposure to coverage diversity. Results show that Annotated Article users are able to answer questions 34% more completely than with two existing interfaces while finding the interface equally easy to use.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {104},
numpages = {21},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581219,
author = {Jahanbakhsh, Farnaz and Katsis, Yannis and Wang, Dakuo and Popa, Lucian and Muller, Michael},
title = {Exploring the Use of Personalized AI for Identifying Misinformation on Social Media},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581219},
doi = {10.1145/3544548.3581219},
abstract = {This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user’s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users’ judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {27},
keywords = {Fact Checking, Misinformation, Artificial Intelligence, Democratized Content Moderation, Social Media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581339,
author = {Li, Daniel and Chen, Thomas and Zadikian, Alec and Tung, Albert and Chilton, Lydia B},
title = {Improving Automatic Summarization for Browsing Longform Spoken Dialog},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581339},
doi = {10.1145/3544548.3581339},
abstract = {Longform spoken dialog delivers rich streams of informative content through podcasts, interviews, debates, and meetings. While production of this medium has grown tremendously, spoken dialog remains challenging to consume as listening is slower than reading and difficult to skim or navigate relative to text. Recent systems leveraging automatic speech recognition (ASR) and automatic summarization allow users to better browse speech data and forage for information of interest. However, these systems intake disfluent speech which causes automatic summarization to yield readability, adequacy, and accuracy problems. To improve navigability and browsability of speech, we present three training agnostic post-processing techniques that address dialog concerns of readability, coherence, and adequacy. We integrate these improvements with user interfaces which communicate estimated summary metrics to aid user browsing heuristics. Quantitative evaluation metrics show a 19% improvement in summary quality. We discuss how summarization technologies can help people browse longform audio in trustworthy and readable ways.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {106},
numpages = {20},
keywords = {machine learning applications, summarization, information retrieval, automatic speech recognition, natural language interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581057,
author = {Song, Jean Y. and Lee, Sangwook and Lee, Jisoo and Kim, Mina and Kim, Juho},
title = {ModSandbox: Facilitating Online Community Moderation Through Error Prediction and Improvement of Automated Rules},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581057},
doi = {10.1145/3544548.3581057},
abstract = {Despite the common use of rule-based tools for online content moderation, human moderators still spend a lot of time monitoring them to ensure they work as intended. Based on surveys and interviews with Reddit moderators who use AutoModerator, we identified the main challenges in reducing false positives and false negatives of automated rules: not being able to estimate the actual effect of a rule in advance and having difficulty figuring out how the rules should be updated. To address these issues, we built ModSandbox, a novel virtual sandbox system that detects possible false positives and false negatives of a rule and visualizes which part of the rule is causing issues. We conducted a comparative, between-subject study with online content moderators to evaluate the effect of ModSandbox in improving automated rules. Results show that ModSandbox can support quickly finding possible false positives and false negatives of automated rules and guide moderators to improve them to reduce future errors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {107},
numpages = {20},
keywords = {automated moderation bots, sociotechnical systems, online communities, moderation, human-AI collaboration, virtual sandbox},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581566,
author = {Liu, Xingyu "Bruce" and Kirilyuk, Vladimir and Yuan, Xiuxiu and Olwal, Alex and Chi, Peggy and Chen, Xiang "Anthony" and Du, Ruofei},
title = {Visual Captions: Augmenting Verbal Communication with On-the-Fly Visuals},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581566},
doi = {10.1145/3544548.3581566},
abstract = {Video conferencing solutions like Zoom, Google Meet, and Microsoft Teams are becoming increasingly popular for facilitating conversations, and recent advancements such as live captioning help people better understand each other. We believe that the addition of visuals based on the context of conversations could further improve comprehension of complex or unfamiliar concepts. To explore the potential of such capabilities, we conducted a formative study through remote interviews (N=10) and crowdsourced a dataset of over 1500 sentence-visual pairs across a wide range of contexts. These insights informed Visual Captions, a real-time system that integrates with a video conferencing platform to enrich verbal communication. Visual Captions leverages a fine-tuned large language model to proactively suggest relevant visuals in open-vocabulary conversations. We present findings from a lab study (N=26) and an in-the-wild case study (N=10), demonstrating how Visual Captions can help improve communication through visual augmentation in various scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {108},
numpages = {20},
keywords = {text-to-visual, video-mediated communication, online meeting, augmented reality, dataset, AI agent, large language models, augmented communication, collaborative work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581357,
author = {Wenzel, Kimi and Devireddy, Nitya and Davison, Cam and Kaufman, Geoff},
title = {Can Voice Assistants Be Microaggressors? Cross-Race Psychological Responses to Failures of Automatic Speech Recognition},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581357},
doi = {10.1145/3544548.3581357},
abstract = {Language technologies have a racial bias, committing greater errors for Black users than for white users. However, little work has evaluated what effect these disparate error rates have on users themselves. The present study aims to understand if speech recognition errors in human-computer interactions may mirror the same effects as misunderstandings in interpersonal cross-race communication. In a controlled experiment (N=108), we randomly assigned Black and white participants to interact with a voice assistant pre-programmed to exhibit a high versus low error rate. Results revealed that Black participants in the high error rate condition, compared to Black participants in the low error rate condition, exhibited significantly higher levels of self-consciousness, lower levels of self-esteem and positive affect, and less favorable ratings of the technology. White participants did not exhibit this disparate pattern. We discuss design implications and the diverse research directions to which this initial study aims to contribute.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {109},
numpages = {14},
keywords = {Microaggressions, Race, Harm, Wizard-of-Oz, Automated Speech Recognition, Voice Assistants, Language Technology, Individual Differences, Quantitative Methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581457,
author = {Park, Eunji and Jung, Yugyeong and Kim, Inyeop and Lee, Uichin},
title = {Charlie and the Semi-Automated Factory: Data-Driven Operator Behavior and Performance Modeling for Human-Machine Collaborative Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581457},
doi = {10.1145/3544548.3581457},
abstract = {A semi-automated manufacturing system that entails human intervention in the middle of the process is a representative collaborative system that requires active interaction between humans and machines. User behavior induced by the operator’s decision-making process greatly impacts system operation and performance in such an environment that requires human-machine collaboration. There has been room for utilizing machine-generated data for a fine-grained understanding of the relationship between the behavior and performance of operators in the industrial domain, while multiple streams of data have been collected from manufacturing machines. In this study, we propose a large-scale data-analysis methodology that comprises data contextualization and performance modeling to understand the relationship between operator behavior and performance. For a case study, we collected machine-generated data over 6-months periods from a highly automated machine in a large tire manufacturing facility. We devised a set of metrics consisting of six human-machine interaction factors and four work environment factors as independent variables, and three performance factors as dependent variables. Our modeling results reveal that the performance variations can be explained by the interaction and work environment factors (R2 = 0.502, 0.356, and 0.500 for the three performance factors, respectively). Finally, we discuss future research directions for the realization of context-aware computing in semi-automated systems by leveraging machine-generated data as a new modality in human-machine collaboration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {110},
numpages = {16},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581196,
author = {Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and Zalmanson, Lior and Naaman, Mor},
title = {Co-Writing with Opinionated Language Models Affects Users’ Views},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581196},
doi = {10.1145/3544548.3581196},
abstract = {If large language models like GPT-3 preferably produce a particular point of view, they may influence people’s opinions on an unknown scale. This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write – and what they think. In an online experiment, we asked participants (N=1,506) to write a post discussing whether social media is good for society. Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society. Participants then completed a social media attitude survey, and independent judges (N=500) evaluated the opinions expressed in their writing. Using the opinionated language model affected the opinions expressed in participants’ writing and shifted their opinions in the subsequent attitude survey. We discuss the wider implications of our results and argue that the opinions built into AI language technologies need to be monitored and engineered more carefully.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {111},
numpages = {15},
keywords = {risks of large language models, Co-writing, GPT-3, opinion change},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581252,
author = {Xiao, Ziang and Li, Tiffany Wenting and Karahalios, Karrie and Sundaram, Hari},
title = {Inform the Uninformed: Improving Online Informed Consent Reading with an AI-Powered Chatbot},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581252},
doi = {10.1145/3544548.3581252},
abstract = {Informed consent is a core cornerstone of ethics in human subject research. Through the informed consent process, participants learn about the study procedure, benefits, risks, and more to make an informed decision. However, recent studies showed that current practices might lead to uninformed decisions and expose participants to unknown risks, especially in online studies. Without the researcher’s presence and guidance, online participants must read a lengthy form on their own with no answers to their questions. In this paper, we examined the role of an AI-powered chatbot in improving informed consent online. By comparing the chatbot with form-based interaction, we found the chatbot improved consent form reading, promoted participants’ feelings of agency, and closed the power gap between the participant and the researcher. Our exploratory analysis further revealed the altered power dynamic might eventually benefit study response quality. We discussed design implications for creating AI-powered chatbots to offer effective informed consent in broader settings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {112},
numpages = {17},
keywords = {informed consent, human-AI interaction, conversational agents, AI-powered chatbot, power dynamic},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581025,
author = {He, Gaole and Kuiper, Lucie and Gadiraju, Ujwal},
title = {Knowing About Knowing: An Illusion of Human Competence Can Hinder Appropriate Reliance on AI Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581025},
doi = {10.1145/3544548.3581025},
abstract = {The dazzling promises of AI systems to augment humans in various tasks hinge on whether humans can appropriately rely on them. Recent research has shown that appropriate reliance is the key to achieving complementary team performance in AI-assisted decision making. This paper addresses an under-explored problem of whether the Dunning-Kruger Effect (DKE) among people can hinder their appropriate reliance on AI systems. DKE is a metacognitive bias due to which less-competent individuals overestimate their own skill and performance. Through an empirical study (N = 249), we explored the impact of DKE on human reliance on an AI system, and whether such effects can be mitigated using a tutorial intervention that reveals the fallibility of AI advice, and exploiting logic units-based explanations to improve user understanding of AI advice. We found that participants who overestimate their performance tend to exhibit under-reliance on AI systems, which hinders optimal team performance. Logic units-based explanations did not help users in either improving the calibration of their competence or facilitating appropriate reliance. While the tutorial intervention was highly effective in helping users calibrate their self-assessment and facilitating appropriate reliance among participants with overestimated self-assessment, we found that it can potentially hurt the appropriate reliance of participants with underestimated self-assessment. Our work has broad implications on the design of methods to tackle user cognitive biases while facilitating appropriate reliance on AI systems. Our findings advance the current understanding of the role of self-assessment in shaping trust and reliance in human-AI decision making. This lays out promising future directions for relevant HCI research in this community.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {113},
numpages = {18},
keywords = {XAI, Appropriate Reliance, Dunning-Kruger Effect, Human-AI Decision Making},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581066,
author = {Hou, Yoyo Tsung-Yu and Lee, Wen-Ying and Jung, Malte},
title = {“Should I Follow the Human, or Follow the Robot?” — Robots in Power Can Have More Influence Than Humans on Decision-Making},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581066},
doi = {10.1145/3544548.3581066},
abstract = {Artificially intelligent (AI) agents such as robots are increasingly delegated power in work settings, yet it remains unclear how power functions in interactions with both humans and robots, especially when they directly compete for influence. Here we present an experiment where every participant was matched with one human and one robot to perform decision-making tasks. By manipulating who has power, we created three conditions: human as leader, robot as leader, and a no-power-difference control. The results showed that the participants were significantly more influenced by the leader, regardless of whether the leader was a human or a robot. However, they generally held a more positive attitude toward the human than the robot, although they considered whichever was in power as more competent. This study illustrates the importance of power for future Human-Robot Interaction (HRI) and Human-AI Interaction (HAI) research, as it addresses pressing concerns of society about AI-powered intelligent agents.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {114},
numpages = {13},
keywords = {artificial agent, robot, intelligent agent, influence, authority, social power, power, human-robot interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580995,
author = {Rapp, Amon and Boldi, Arianna and Curti, Lorenzo and Perrucci, Alessandro and Simeoni, Rossana},
title = {Collaborating with a Text-Based Chatbot: An Exploration of Real-World Collaboration Strategies Enacted during Human-Chatbot Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580995},
doi = {10.1145/3544548.3580995},
abstract = {A central problem for chatbots in the customer care domain revolves around how people collaborate with the agent to achieve their own situated goals. The majority of the previous research, however, relied on experiments within artificial settings, rather than on observation of real-world interactions. Moreover, such research mostly analyzed users’ responses to communication breakdowns, rather than the wider collaboration strategies utilized during a conversation. In this paper, we qualitatively analyzed 12,477 real-world exchanges with a task-based chatbot using a Grounded Theory approach as a rigorous coding method to analyze the data. We identified two main aspects of collaboration, behavioral and conversational, and for each aspect we highlighted the different strategies that users perform to “work together” with the agent. These strategies may be utilized from the very beginning of the conversation or in response to misunderstandings in the course of ongoing interactions and may show different evolving dynamics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {115},
numpages = {17},
keywords = {chatbots, human-machine cooperation, Conversational agents, human-AI cooperation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581247,
author = {Kuang, Emily and Jahangirzadeh Soure, Ehsan and Fan, Mingming and Zhao, Jian and Shinohara, Kristen},
title = {Collaboration with Conversational AI Assistants for UX Evaluation: Questions and How to Ask Them (Voice vs. Text)},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581247},
doi = {10.1145/3544548.3581247},
abstract = {AI is promising in assisting UX evaluators with analyzing usability tests, but its judgments are typically presented as non-interactive visualizations. Evaluators may have questions about test recordings, but have no way of asking them. Interactive conversational assistants provide a Q&amp;A dynamic that may improve analysis efficiency and evaluator autonomy. To understand the full range of analysis-related questions, we conducted a Wizard-of-Oz design probe study with 20 participants who interacted with simulated AI assistants via text or voice. We found that participants asked for five categories of information: user actions, user mental model, help from the AI assistant, product and task information, and user demographics. Those who used the text assistant asked more questions, but the question lengths were similar. The text assistant was perceived as significantly more efficient, but both were rated equally in satisfaction and trust. We also provide design considerations for future conversational AI assistants for UX evaluation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {116},
numpages = {15},
keywords = {Conversational assistants, Human-AI collaboration, Usability testing, UX evaluation, User experience (UX)},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581346,
author = {Phinnemore, Rachel and Reza, Mohi and Lewis, Blaine and Mahadevan, Karthik and Wang, Bryan and Annett, Michelle and Wigdor, Daniel},
title = {Creepy Assistant: Development and Validation of a Scale to Measure the Perceived Creepiness of Voice Assistants},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581346},
doi = {10.1145/3544548.3581346},
abstract = {Voice assistants have afforded users rich interaction opportunities to access information and issue commands in a variety of contexts. However, some users feel uneasy or creeped out by voice assistants, leading to a decreased desire to use them. As there has yet to be a comprehensive understanding of the factors that cause users to perceive voice assistants as being creepy, this research developed an empirical scale to measure the creepiness inherent in various voice assistants. Utilizing prior scale creation methodologies, a 7-item Perceived Creepiness of Voice Assistants Scale (PCAS) was created and validated. The scale measures how creepy a new voice assistant would be for users of voice assistants. The scale was developed to ensure that researchers and designers can evaluate the next generation of voice assistants before such voice assistants are released to the wider public.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {117},
numpages = {18},
keywords = {voice assistants, evaluation, questionnaire, empirical scale, creepiness, perceived creepiness of voice assistants},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581145,
author = {Pucci, Emanuele and Possaghi, Isabella and Cutrupi, Claudia Maria and Baez, Marcos and Cappiello, Cinzia and Matera, Maristella},
title = {Defining Patterns for a Conversational Web},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581145},
doi = {10.1145/3544548.3581145},
abstract = {Conversational agents are emerging as channels for a natural and accessible interaction with digital services. Their benefits span across a wide range of usage scenarios and address visual impairments and any situational impairments that may take advantage of voice-based interactions. A few works highlighted the potential and the feasibility of adopting conversational agents for making the Web truly accessible for everyone. Yet, there is still a lack of concrete guidance in designing conversational experiences for browsing the Web. This paper illustrates a human-centered process that involved 26 blind and visually impaired people to investigate their difficulties when using assistive technology for accessing the Web, and their attitudes and preferences on adopting conversational agents. In response to the identified challenges, the paper introduces patterns for conversational Web browsing. It also discusses design implications that can promote Conversational AI as a technology to enhance Web accessibility.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {118},
numpages = {17},
keywords = {Conversational UIs, Conversational Web Browsing, Conversational Patterns},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581427,
author = {Cai, Wanling and Jin, Yucheng and Zhao, Xianglin and Chen, Li},
title = {“Listen to Music, Listen to Yourself”: Design of a Conversational Agent to Support Self-Awareness While Listening to Music},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581427},
doi = {10.1145/3544548.3581427},
abstract = {Music can affect the human brain and cognition. Melodies and lyrics that resonate with us can awaken our inner feelings and thoughts; being in touch with these feelings and expressing them allow us to understand ourselves better and increase our self-awareness. To support self-awareness elicited by music, we designed a novel conversational agent (CA) that guides users to become self-aware and express their thoughts when they listen to music. Moreover, we investigated two prominent design factors in the CA, proactive guidance and social information. We then conducted a 2x2 between-subjects experiment (N = 90) to investigate how the two design factors affect self-awareness, user acceptance, and mental well-being. The results of a five-day user study reveal that high proactive guidance and social information increased self-awareness, but high proactive guidance tended to influence perceived autonomy and usefulness negatively. Further, users’ subjective feedback revealed the CA’s potential to support mental well-being.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {119},
numpages = {19},
keywords = {self-determination theory, emotional well-being, Listening to music, user engagement, chatbot},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580719,
author = {Harrington, Christina N. and Egede, Lisa},
title = {Trust, Comfort and Relatability: Understanding Black Older Adults’ Perceptions of Chatbot Design for Health Information Seeking},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580719},
doi = {10.1145/3544548.3580719},
abstract = {Conversational agents such as chatbots have emerged as a useful resource to access real-time health information online. Perceptions of trust and credibility among chatbots have been attributed to the anthropomorphism and humanness of the chatbot design, with gender and race influencing their reception. Few existing studies have looked specifically at the diversity of chatbot avatar design related to both race, age, and gender, which may have particular significance for racially minoritized users like Black older adults. In this paper, we explored perceptions of chatbots with varying identities for health information seeking in a diary and interview study with 30 Black older adults. Our findings suggest that while racial and age likeness influence feelings of trust and comfort with chatbots, constructs such as professionalism and likeability and overall familiarity also influence reception. Based on these findings, we provide implications for designing text-based chatbots that consider Black older adults.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {18},
keywords = {older adults, relatability, race, trust, embodied conversational assistants, chatbots, health information, diary study, identity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580683,
author = {Mcnutt, Andrew M and Outkine, Anton and Chugh, Ravi},
title = {A Study of Editor Features in a Creative Coding Classroom},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580683},
doi = {10.1145/3544548.3580683},
abstract = {Creative coding is a rapidly expanding domain for both artistic expression and computational education. Numerous libraries and IDEs support creative coding, however there has been little consideration of how the environments themselves might be designed to serve these twin goals. To investigate this gap, we implemented and used an experimental editor to teach a sequence of college and high-school creative coding courses. In the first year, we conducted a log analysis of student work (n=39) and surveys regarding prospective features (n=25). These guided our implementation of common enhancements (e.g. color pickers) as well as uncommon ones (e.g. bidirectional shape editing). In the second year, we studied the effects of these features through logging (n=39+) and survey (n=23) studies. Reflecting on the results, we identify opportunities to improve creativity- and novice-focused IDEs and highlight tensions in their design—as in tools that augment artistry or efficiency but may be perceived as hindering learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {121},
numpages = {15},
keywords = {Introductory programming, p5, Creative coding, Code editors},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581070,
author = {Shi, Xinyu and Zhou, Ziqi and Zhang, Jing Wen and Neshati, Ali and Tyagi, Anjul Kumar and Rossi, Ryan and Guo, Shunan and Du, Fan and Zhao, Jian},
title = {De-Stijl: Facilitating Graphics Design with Interactive 2D Color Palette Recommendation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581070},
doi = {10.1145/3544548.3581070},
abstract = {Selecting a proper color palette is critical in crafting a high-quality graphic design to gain visibility and communicate ideas effectively. To facilitate this process, we propose De-Stijl, an intelligent and interactive color authoring tool to assist novice designers in crafting harmonic color palettes, achieving quick design iterations, and fulfilling design constraints. Through De-Stijl, we contribute a novel 2D color palette concept that allows users to intuitively perceive color designs in context with their proportions and proximities. Further, De-Stijl implements a holistic color authoring system that supports 2D palette extraction, theme-aware and spatial-sensitive color recommendation, and automatic graphical elements (re)colorization. We evaluated De-Stijl through an in-lab user study by comparing the system with existing industry standard tools, followed by in-depth user interviews. Quantitative and qualitative results demonstrate that De-Stijl is effective in assisting novice design practitioners to quickly colorize graphic designs and easily deliver several alternatives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {122},
numpages = {19},
keywords = {Graphics design, 2D color palette., AI-assisted design, color palette recommendation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580642,
author = {Hashim, Sonia and H\"{o}llerer, Tobias and Jacobs, Jennifer},
title = {Drawing Transforms: A Unifying Interaction Primitive to Procedurally Manipulate Graphics across Style, Space, and Time},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580642},
doi = {10.1145/3544548.3580642},
abstract = {Procedural functionality enables visual creators to rapidly edit, explore alternatives, and fine-tune artwork in many domains including illustration, motion graphics, and interactive animation. Symbolic procedural tools, such as textual programming languages, are highly expressive but often limit directly manipulating concrete artwork; whereas direct manipulation tools support some procedural expression but limit creators to pre-defined behaviors and inputs. Inspired by visions of using geometric input to create procedural relationships, we identify an opportunity to use vector geometry from artwork to specify expressive user-defined procedural functions. We present Drawing Transforms (DTs), a technique that enables the use of any drawing to procedurally transform the stylistic, spatial, and temporal properties of target artwork. We apply DTs in a prototype motion graphics system to author continuous and discrete transformations, modify multiple elements in a composition simultaneously, create animations, and control fine-grained procedural instantiation. We discuss how DTs can unify procedural authoring through direct manipulation across visual media domains.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {123},
numpages = {15},
keywords = {creativity support tools, direct manipulation, procedural art},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580931,
author = {Kato, Jun and Goto, Masataka},
title = {Lyric App Framework: A Web-Based Framework for Developing Interactive Lyric-Driven Musical Applications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580931},
doi = {10.1145/3544548.3580931},
abstract = {Lyric videos have become a popular medium to convey lyrical content to listeners, but they present the same content whenever they are played and cannot adapt to listeners’ preferences. Lyric apps, as we name them, are a new form of lyric-driven visual art that can render different lyrical content depending on user interaction and address the limitations of static media. To open up this novel design space for programmers and musicians, we present Lyric App Framework, a web-based framework for building interactive graphical applications that play musical pieces and show lyrics synchronized with playback. We designed the framework to provide a streamlined development experience for building production-ready lyric apps with creative coding libraries of choice. We held programming contests twice and collected 52 examples of lyric apps, enabling us to reveal eight representative categories, confirm the framework’s effectiveness, and report lessons learned.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {124},
numpages = {18},
keywords = {toolkit, music synchronization, multimedia control},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581338,
author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Miles, Scott and Kleiner, Maria and Yuan, Xiuxiu and Zhang, Yinda and Kulkarni, Anuva and Liu, Xingyu and Sabie, Ahmed and Orts-Escolano, Sergio and Kar, Abhishek and Yu, Ping and Iyengar, Ram and Kowdle, Adarsh and Olwal, Alex},
title = {Rapsai: Accelerating Machine Learning Prototyping of Multimedia Applications through Visual Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581338},
doi = {10.1145/3544548.3581338},
abstract = {In recent years, there has been a proliferation of multimedia applications that leverage machine learning (ML) for interactive experiences. Prototyping ML-based applications is, however, still challenging, given complex workflows that are not ideal for design and experimentation. To better understand these challenges, we conducted a formative study with seven ML practitioners to gather insights about common ML evaluation workflows. The study helped us derive six design goals, which informed Rapsai1, a visual programming platform for rapid and iterative development of end-to-end ML-based multimedia applications. Rapsai features a node-graph editor to facilitate interactive characterization and visualization of ML model performance. Rapsai streamlines end-to-end prototyping with interactive data augmentation and model comparison capabilities in its no-coding environment. Our evaluation of Rapsai in four real-world case studies (N=15) suggests that practitioners can accelerate their workflow, make more informed decisions, analyze strengths and weaknesses, and holistically evaluate model behavior with real-world input.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {125},
numpages = {23},
keywords = {Data Augmentation, Node-graph Editor, Deep Learning, Visual Analytics, Deep Neural Networks, Visual Programming, Model Comparison},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581394,
author = {Rawn, Eric and Li, Jingyi and Paulos, Eric and Chasins, Sarah E.},
title = {Understanding Version Control as Material Interaction with Quickpose},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581394},
doi = {10.1145/3544548.3581394},
abstract = {Whether a programmer with code or a potter with clay, practitioners engage in an ongoing process of working and reasoning with materials. Existing discussions in HCI have provided rich accounts of these practices and processes, which we synthesize into three themes: (1) reciprocal discovery of goals and materials, (2) local knowledge of materials, and (3) annotation for holistic interpretation. We then apply these design principles generatively to the domain of version control to present Quickpose: a version control system for creative coding. In an in-situ, longitudinal study of Quickpose guided by our themes, we collected usage data, version history, and interviews. Our study explored our participants’ material interaction behaviors and the initial promise of our proposed measures for recognizing these behaviors. Quickpose is an exploration of version control as material interaction, using existing discussions to inform domain-specific concepts, measures, and designs for version control systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {18},
keywords = {Materiality, End-User Programming, Creative Coding, Variations, Version Control Systems (VCS)},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581571,
author = {Devendorf, Laura and Walters, Kathryn and Fairbanks, Marianne and Sandry, Etta and Goodwill, Emma R},
title = {AdaCAD: Parametric Design as a New Form of Notation for Complex Weaving},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581571},
doi = {10.1145/3544548.3581571},
abstract = {Woven textiles are increasingly a medium through which HCI is inventing new technologies. Key challenges in integrating woven textiles in HCI include the high level of textile knowledge required to make effective use of the new possibilities they afford and the need for tools that bridge the concerns of textile designers and concerns of HCI researchers. This paper presents AdaCAD, a parametric design tool for designing woven textile structures. Through our design and evaluation of AdaCAD we found that parametric design helps weavers notate and explain the logics behind the complex structures they generate. We discuss these finding in relation to prior work in integrating craft and/or weaving in HCI, histories of woven notation, and boundary object theory to illuminate further possibilities for collaboration between craftspeople and HCI practitioners.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {127},
numpages = {18},
keywords = {computer-aided design, open-source, parametric design, weaving, textile fabrication, smart textiles, first-person methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580803,
author = {Zhou, Feng and Benford, Steven D and Whatley, Sarah and Marsh, Kate and Ashcroft, Ian and Erhart, Tanja and O’Brien, Welly and Tennent, Paul},
title = {Beyond Skin Deep: Generative Co-Design for Aesthetic Prosthetics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580803},
doi = {10.1145/3544548.3580803},
abstract = {There is a trend for handcrafting bespoke prostheses that embody their wearers’ aesthetic tastes and identities. We explore how this might be extended by enabling users to co-design with algorithms. We report a design-led exploration (Figure 1) in which professional disabled dancers danced with a generative design algorithm to create personalised designs called aesthetic seeds. Further algorithms applied these to prosthetic greaves, rendering them in various materials before optimising for additive manufacture. Interviews with our dancers revealed that the aesthetics of prosthetics reach beyond visual decoration to encompass form, function, bodily experience, body image, and identity; that interactions with generative design algorithms can harness people’s expressive and aesthetic skills; and that we must redesign supporting technologies for diverse bodies. We generalise our findings into a process for how people may co-design 3D printable products with algorithms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {128},
numpages = {19},
keywords = {disabled dance artists, additive manufacture, assistive technologies, personalisation, aesthetics, embodied interaction, design methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581051,
author = {Zhou, Tongyu and Liu, Connie and Yang, Joshua Kong and Huang, Jeff},
title = {Filtered.Ink: Creating Dynamic Illustrations with SVG Filters},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581051},
doi = {10.1145/3544548.3581051},
abstract = {Vector illustrations are object-based, meaning they are composed of strokes that can be filtered individually through textures or animations and transformed without loss of quality. These filters are typically difficult to specify without programming prerequisites. We propose filtered.ink , a full-featured illustration application to construct and explore filters via a node graph interface with a live preview. This turns vector graphics and their filters into a form of vector hypermedia that can be shared and remixed with new users. By examining interactions that occur when crafting, remixing, and using filters for dynamic illustrations through a task-based usability study, we expose new workflow patterns and avenues of expression. The observations result in a user model supported by filtered.ink: see, want, rewant, and remix. In this model, the artist breaks away from traditional notions of illustration, taking advantage of the inherent remixability of the strokes and filters in the vector graphics format.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {129},
numpages = {15},
keywords = {SVG, dynamic textures, vector illustration, animation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581446,
author = {Jing, Qianzhi and Zhou, Tingting and Tsang, Yixin and Chen, Liuqing and Sun, Lingyun and Zhen, Yankun and Du, Yichun},
title = {Layout Generation for Various Scenarios in Mobile Shopping Applications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581446},
doi = {10.1145/3544548.3581446},
abstract = {Layout is essential for the product listing pages (PLPs) in mobile shopping applications. To clearly convey the information that consumers require and to achieve specific functions, PLPs layouts often have many variations driven by scenarios. In this work, we study the PLPs layout design for different scenarios and propose a design space to guide the large-scale creation of PLPs. We propose LayoutVQ-VAE, a novel model specialized in generating layouts with internal and external constraints. LayoutVQ-VAE differs from previous methods as it learns a discrete latent representation of layout and can model the relationship between layout representation and scenarios without applying heuristics. Experiments on publicly available benchmarks for different layout types validate that our method performs comparably or favorably against the state-of-the-art methods. Case studies show that the proposed approach including the design space and model is effective in producing large-scale high-quality PLPs layouts for mobile shopping platforms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {130},
numpages = {18},
keywords = {layout generation, deep generative model, product listing pages, mobile application user interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581429,
author = {Haoran, Xu and Shuyao, Chen and Zhang, Ying},
title = {Magical Brush: A Symbol-Based Modern Chinese Painting System for Novices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581429},
doi = {10.1145/3544548.3581429},
abstract = {Modern Chinese painting is a new type of painting inherited from ancient Chinese painting. Drawing modern Chinese painting is time-consuming and laborious, which is difficult for novices to start. Symbols are fundamental components of Chinese cultural works both materially and mentally. We introduce a symbol-based modern Chinese painting system termed Magical Brush. Magical Brush combines symbolic cultural factors with AI generative models, with the attempt to help novices create a complete modern Chinese painting, learn basic ideas of Chinese paintings and obtain co-creation engagement. In user study, we compare Magical Brush to other AI and non-AI digital painting tools. Results indicate that by combining cultural factors, Magical Brush can help novices easily create modern Chinese paintings and experience the cultural connotations in the process.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {131},
numpages = {14},
keywords = {Digital painting, artificial intelligence, cultural prior},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581047,
author = {Das, Maitraye and Gergle, Darren and Piper, Anne Marie},
title = {Simphony: Enhancing Accessible Pattern Design Practices among Blind Weavers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581047},
doi = {10.1145/3544548.3581047},
abstract = {The maker movement has garnered significant attention as democratizing design; yet, recent work has called attention to the challenges disabled people encounter in making. Although researchers have built systems to improve accessibility of maker technologies, limited studies have centered disabled people’s engagement in traditional forms of making like fiber arts. We examine the practice of fabric pattern design among a community of blind weavers who create hand-woven products with sighted instructors. Grounded in seventeen interviews with blind weavers and sighted instructors, we built Simphony, an audio-tactile system that aims to support blind weavers in creating and perceiving patterns. Findings from eight design exploration sessions at the community studio reveal how blind weavers used Simphony to learn the process of pattern design and generate patterns with sighted instructors. We reflect on collaborative understanding of pattern design among blind and sighted individuals and discuss opportunities for integrating technological augmentations into traditional craftwork.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {132},
numpages = {19},
keywords = {Disability, accessibility, blind, design, making, weaving},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580645,
author = {Kapania, Shivani and Taylor, Alex S and Wang, Ding},
title = {A Hunt for the Snark: Annotator Diversity in Data Practices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580645},
doi = {10.1145/3544548.3580645},
abstract = {Diversity in datasets is a key component to building responsible AI/ML. Despite this recognition, we know little about the diversity among the annotators involved in data production. We investigated the approaches to annotator diversity through 16 semi-structured interviews and a survey with 44 AI/ML practitioners. While practitioners described nuanced understandings of annotator diversity, they rarely designed dataset production to account for diversity in the annotation process. The lack of action was explained through operational barriers: from the lack of visibility in the annotator hiring process, to the conceptual difficulty in incorporating worker diversity. We argue that such operational barriers and the widespread resistance to accommodating annotator diversity surface a prevailing logic in data practices—where neutrality, objectivity and ‘representationalist thinking’ dominate. By understanding this logic to be part of a regime of existence, we explore alternative ways of accounting for annotator subjectivity and diversity in data practices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {133},
numpages = {15},
keywords = {data annotation, ML datasets, data production, machine learning, annotator diversity, data work, diversity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581161,
author = {Yurrita, Mireia and Draws, Tim and Balayn, Agathe and Murray-Rust, Dave and Tintarev, Nava and Bozzon, Alessandro},
title = {Disentangling Fairness Perceptions in Algorithmic Decision-Making: The Effects of Explanations, Human Oversight, and Contestability},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581161},
doi = {10.1145/3544548.3581161},
abstract = {Recent research claims that information cues and system attributes of algorithmic decision-making processes affect decision subjects’ fairness perceptions. However, little is still known about how these factors interact. This paper presents a user study (N = 267) investigating the individual and combined effects of explanations, human oversight, and contestability on informational and procedural fairness perceptions for high- and low-stakes decisions in a loan approval scenario. We find that explanations and contestability contribute to informational and procedural fairness perceptions, respectively, but we find no evidence for an effect of human oversight. Our results further show that both informational and procedural fairness perceptions contribute positively to overall fairness perceptions but we do not find an interaction effect between them. A qualitative analysis exposes tensions between information overload and understanding, human involvement and timely decision-making, and accounting for personal circumstances while maintaining procedural consistency. Our results have important design implications for algorithmic decision-making processes that meet decision subjects’ standards of justice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {134},
numpages = {21},
keywords = {fairness perceptions, human oversight, algorithmic decision-making, contestability, explanations},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581463,
author = {Lewicki, Kornel and Lee, Michelle Seng Ah and Cobbe, Jennifer and Singh, Jatinder},
title = {Out of Context: Investigating the Bias and Fairness Concerns of “Artificial Intelligence as a Service”},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581463},
doi = {10.1145/3544548.3581463},
abstract = {“AI as a Service” (AIaaS) is a rapidly growing market, offering various plug-and-play AI services and tools. AIaaS enables its customers (users)—who may lack the expertise, data, and/or resources to develop their own systems—to easily build and integrate AI capabilities into their applications. Yet, it is known that AI systems can encapsulate biases and inequalities that can have societal impact. This paper argues that the context-sensitive nature of fairness is often incompatible with AIaaS’ ‘one-size-fits-all’ approach, leading to issues and tensions. Specifically, we review and systematise the AIaaS space by proposing a taxonomy of AI services based on the levels of autonomy afforded to the user. We then critically examine the different categories of AIaaS, outlining how these services can lead to biases or be otherwise harmful in the context of end-user applications. In doing so, we seek to draw research attention to the challenges of this emerging area.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {135},
numpages = {17},
keywords = {AIaaS, artificial intelligence, MLaaS, fairness, cloud, algorithmic supply chains, data-driven, machine learning, bias, accountability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581527,
author = {Engelbutzeder, Philip and Bollmann, Yannick and Berns, Katie and Landwehr, Marvin and Sch\"{a}fer, Franka and Randall, Dave and Wulf, Volker},
title = {(Re-)Distributional Food Justice: Negotiating Conflicting Views of Fairness within a Local Grassroots Community},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581527},
doi = {10.1145/3544548.3581527},
abstract = {Sustainable HCI and Human-Food-Interaction research have developing interest in preventing food waste through food sharing. Sustainability requires attention to both the opportunities and challenges associated with the building of food sharing groups engaged in the redistribution of food but also in developing a wider agenda which includes, for instance, the local production of food resources. In this paper, we argue for a better understanding of the different conceptions of ‘fairness’ which inform volunteer and guest practice and in turn mediate community-building efforts. We examine the practices surrounding ‘SharingEvent’ and challenges faced to sustainability by the heterogenous, and sometimes contested, commitments of the people involved. We further consider how ICT provided opportunities for explicit examination of ideological differences concerning what ‘sharing’ might mean. Our findings show that community building is dependent on the negotiation of different values and purposes identified. We derive recommendations for action-oriented researchers ultimately concerned with systemic transformation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {136},
numpages = {16},
keywords = {Grassroots, Fairness, Surplus, Justice, Community, Food Sharing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580863,
author = {Kopeinik, Simone and Mara, Martina and Ratz, Linda and Krieg, Klara and Schedl, Markus and Rekabsaz, Navid},
title = {Show Me a "Male Nurse"! How Gender Bias is Reflected in the Query Formulation of Search Engine Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580863},
doi = {10.1145/3544548.3580863},
abstract = {Biases in algorithmic systems have led to discrimination against historically disadvantaged groups, including the reinforcement of outdated gender stereotypes. While a substantial body of research addresses biases in algorithms and underlying data, in this work, we study if and how users themselves reflect these biases in their interactions with systems, which expectedly leads to the further manifestation of biases. More specifically, we investigate the replication of stereotypical gender representations by users in formulating online search queries. Following prototype theory, we define the disproportionate mention of the gender that does not conform to the prototypical representative of a searched domain (e.g., “male nurse”) as an indication of bias. In a pilot study with 224 US participants and a main study with 400 UK participants, we find clear evidence of gender biases in formulating search queries. We also report the effects of an educative text on user behaviour and highlight the wish of users to learn about bias-mitigating strategies in their interactions with search engines.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {137},
numpages = {15},
keywords = {search queries, user study, gender bias, information retrieval, prototype effect},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581017,
author = {Seaborn, Katie and Chandra, Shruti and Fabre, Thibault},
title = {Transcending the “Male Code”: Implicit Masculine Biases in NLP Contexts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581017},
doi = {10.1145/3544548.3581017},
abstract = {Critical scholarship has elevated the problem of gender bias in data sets used to train virtual assistants (VAs). Most work has focused on explicit biases in language, especially against women, girls, femme-identifying people, and genderqueer folk; implicit associations through word embeddings; and limited models of gender and masculinities, especially toxic masculinities, conflation of sex and gender, and a sex/gender binary framing of the masculine as diametric to the feminine. Yet, we must also interrogate how masculinities are “coded” into language and the assumption of “male” as the linguistic default: implicit masculine biases. To this end, we examined two natural language processing (NLP) data sets. We found that when gendered language was present, so were gender biases and especially masculine biases. Moreover, these biases related in nuanced ways to the NLP context. We offer a new dictionary called AVA that covers ambiguous associations between gendered language and the language of VAs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {138},
numpages = {19},
keywords = {Machine learning bias, Gender bias, Data sets, Implicit gendered language, Natural language processing, Feminist HCI, Masculinities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581521,
author = {Kim, Nari and Jang, Sangsu and Kim, Hansol and Lee, Jaeyeon and Park, Young-Woo},
title = {Design and Field Trial of Tunee in Shared Houses: Exploring Experiences of Sharing Individuals’ Current Noise-Level Preferences with Housemates},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581521},
doi = {10.1145/3544548.3581521},
abstract = {Being a little more careful about the sound that people produce is difficult in shared houses because individuals can generate several unintended living noises and sounds. We designed Tunee to help each housemate better understand the others’ context and desired noise-level. It is an interactive speaker that allows people to share noise-level preferences through the position change of nodes. Our three-week in-field study with four groups of participants revealed that expressing noise-level preference through nodes reduced the burden of verbally delivering issues about the trivial noises of everyday life, and the intentions of the lowered preference were referred to and deemed significant. We also identified how participants figured out what behavior was acceptable for others according to each noise-level. Our findings imply considerations in designing interfaces to support coordinating behaviors and awareness of social contexts in shared spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {15},
keywords = {Social information, Mediated communication, Noise, Shared houses},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581433,
author = {Rossmy, Beat and Terzimehi\'{c}, Na\textcrd{}a and D\"{o}ring, Tanja and Buschek, Daniel and Wiethoff, Alexander},
title = {Point of No Undo: Irreversible Interactions as a Design Strategy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581433},
doi = {10.1145/3544548.3581433},
abstract = {Despite irreversibility being omnipresent in the lifeworld, research on interactions making use of irreversibility in computing systems is still in the early stages. User freedom – provided by the undo functionality – is considered to be a pillar of “usable” computer systems, overcoming irreversibility. Within this paper, we set up a thought experiment, challenging the “undo feature” and instead take advantage of irreversibility in the interaction with physical computing systems (tangibles, robots, etc). First, we present three material speculations, each inherently utilizing irreversibility. Second, we elaborate on the concept of irreversible interactions by contextualizing our work with critical HCI discourses and deducing three design strategies. Finally, we discuss irreversibility as a design element for self-reflection, meaningful acting, and a sustainable relationship with technology. While previously individual aspects of irreversibility have been explored, we contribute a comprehensive discussion of irreversible interactions in HCI presenting artifacts, a conceptualization, design strategies, and application purposes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {140},
numpages = {18},
keywords = {Robotic Interfaces, Design Strategies, Speculative Design, Tangible User Interfaces, Irreversibility, Reality-Based Interaction, Causality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581491,
author = {Biggs, Heidi and Suttles, Shellye and Bardzell, Shaowen},
title = {Redlining Maps and Terrains of Sustainability: Interdisciplinary Mapping of Racialized Redlining to Present-Day Sustainability Agendas in HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581491},
doi = {10.1145/3544548.3581491},
abstract = {We ask how historic redlining, a US government run, racially discriminatory practice of assessing and mapping property values for federally subsidized home loan eligibility in the 1930s, is tied to current issues of sustainability. We frame redlining as a historic data practice, tied to ongoing exposure to environmental harms and difficulty building generational wealth in African American communities in Indianapolis. To address this, we made maps to ground interdisciplinary discourse between the authors: two who research sustainable human computer interaction (SHCI) and one who researches sustainable food systems, including issues of food security. Our maps, which combine historical redlining maps and contemporary sustainability issues facing Indianapolis, helped us explore the ongoing impacts of redlining across our disciplines. We develop the term ‘sustainability’ for HCI across racial, socioeconomic, and environmental tensions and reflect on how SHCI's emerging posthuman emphasis on human/non-human relations are associated with human/human challenges like redlining.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {141},
numpages = {18},
keywords = {Sustainable HCI, Redlining, Sustainability, Ecological Posthumanism, Socioeconomic Sustainability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581228,
author = {Cornelio, Patricia and Hughes, Stephen and Georgiou, Orestis and Frier, William and Maunsbach, Martin and Vasudevan, Madhan Kumar and Obrist, Marianna},
title = {Responsible Innovation of Touchless Haptics: A Prospective Design Exploration in Social Interaction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581228},
doi = {10.1145/3544548.3581228},
abstract = {The rapid development of touchless systems has introduced many innovations in social interaction scenarios in recent years. People now can interact with touchless systems in social applications that are aimed to be used in everyday situations in the future. This accelerated development makes us ask, what will the next generation of touchless systems be like? How can we responsibly develop new touchless technologies in the future? To answer the first question, we brought together 20 experts to ideate, speculate, and evaluate possible touchless applications for social interactions. A total of 48 ideas were generated from two consecutive workshops. Then, to answer the second question, we critically analyzed those ideas through a thematic analysis using a responsible innovation (RI) framework, and identified key ethical considerations to guide developers, practitioners when designing future touchless systems. We argue that the social scenarios described, and the RI framework proposed in this paper are a useful starting point for responsibly designing the next generation of touchless systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {142},
numpages = {16},
keywords = {mid-air haptics, responsible innovation, ethics, social interaction, touchless interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580842,
author = {Yao, Yuan and Huang, Li and He, Yi and Ma, Zhijun and Xu, Xuhai and Mi, Haipeng},
title = {Reviewing and Reflecting on Smart Home Research from the Human-Centered Perspective},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580842},
doi = {10.1145/3544548.3580842},
abstract = {While there has been rapid growth in smart home research from a technical perspective– focusing on home automation, devices, software, and protocols– few review papers examine the human-centered perspective. A human-centered focus is crucial for achieving the goals of providing natural, convenient, comfortable, friendly, and safe user experiences in the smart home. To understand key innovations in human-centered smart home research, we analyzed keyword changes over time via 19,091 papers from 2000 to 2022, then selected 55 papers from high-impact venues in the last five years, and summarized them through a combination of qualitative and quantitative methods. Our analysis revealed five research trends with unique characteristics and interdependence. Drawing on this review, we elaborate on the future of smart home design research with respect to multidisciplinary development, stakeholder involvement, and the shift of design implications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {143},
numpages = {21},
keywords = {literature analysis, smart home, research trends, human-centered design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581445,
author = {Choi, Yunjae J. and Lee, Minha and Lee, Sangsu},
title = {Toward a Multilingual Conversational Agent: Challenges and Expectations of Code-Mixing Multilingual Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581445},
doi = {10.1145/3544548.3581445},
abstract = {Multilingual speakers tend to interleave two or more languages when communicating. This communication strategy is called code-mixing, and it has surged with today’s ever-increasing linguistic and cultural diversity. Because of their communication style, multilinguals who use conversational agents have specific needs and expectations which are currently not being met by conversational systems. While research has been undertaken on code-mixing conversational systems, previous works have rarely focused on the code-mixing users themselves to discover their genuine needs. This work furthers our understanding of the challenges faced by code-mixing users in conversational agent interaction, unveils the key factors that users consider in code-mixing scenarios, and explores expectations that users have for future conversational agents capable of code-mixing. This study discusses the design implications of our findings and provides a guide on how to alleviate the challenges faced by multilingual users and how to improve the conversational agent user experience for multilingual users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {144},
numpages = {17},
keywords = {Code-switching, Conversational Agent, Multilingual Users, User Study, Code-mixing, User Experience, Language Mixing, User Centered Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580962,
author = {Eddy, Ethan and Scheme, Erik J and Bateman, Scott},
title = {A Framework and Call to Action for the Future Development of EMG-Based Input in HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580962},
doi = {10.1145/3544548.3580962},
abstract = {Electromyography (EMG) has been explored as an HCI input modality following a long history of success for prosthesis control. While EMG has the potential to address a range of hands-free interaction needs, it has yet to be widely accepted outside of prosthetics due to a perceived lack of robustness and intuitiveness. To understand how EMG input systems can be better designed, we sampled the ACM digital library to identify limitations in the approaches taken. Leveraging these works in combination with our research group’s extensive interdisciplinary experience in this field, four themes emerged (1) interaction design, (2) model design, (3) system evaluation, and (4) reproducibility. Using these themes, we provide a step-by-step framework for designing EMG-based input systems to strengthen the foundation on which EMG-based interactions are built. Additionally, we provide a call-to-action for researchers to unlock the hidden potential of EMG as a widely applicable and highly usable input modality.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {145},
numpages = {23},
keywords = {emg, static contractions, electromyography, dynamic gestures, emg control, design framework},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581091,
author = {Masson, Damien and Malacria, Sylvain and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Charagraph: Interactive Generation of Charts for Realtime Annotation of Data-Rich Paragraphs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581091},
doi = {10.1145/3544548.3581091},
abstract = {Documents often have paragraphs packed with numbers that are difficult to extract, compare, and interpret. To help readers make sense of data in text, we introduce the concept of Charagraphs: dynamically generated interactive charts and annotations for in-situ visualization, comparison, and manipulation of numeric data included within text. Three Charagraph characteristics are defined: leveraging related textual information about data; integrating textual and graphical representations; and interacting at different contexts. We contribute a document viewer to select in-text data; generate and customize Charagraphs; merge and refine a Charagraph using other in-text data; and identify, filter, compare, and sort data synchronized between text and visualization. Results of a study show participants can easily create Charagraphs for diverse examples of data-rich text, and when answering questions about data in text, participants were more correct compared to only reading text.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {146},
numpages = {18},
keywords = {data-rich documents, in-text data, active reading, interactive documents, visualization, reading interfaces, annotation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581113,
author = {Masson, Damien and Malacria, Sylvain and Vogel, Daniel and Lank, Edward and Casiez, G\'{e}ry},
title = {ChartDetective: Easy and Accurate Interactive Data Extraction from Complex Vector Charts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581113},
doi = {10.1145/3544548.3581113},
abstract = {Extracting underlying data from rasterized charts is tedious and inaccurate; values might be partially occluded or hard to distinguish, and the quality of the image limits the precision of the data being recovered. To address these issues, we introduce a semi-automatic system leveraging vector charts to extract the underlying data easily and accurately. The system is designed to make the most of vector information by relying on a drag-and-drop interface combined with selection, filtering, and previsualization features. A user study showed that participants spent less than 4 minutes to accurately recover data from charts published at CHI with diverse styles, thousands of data points, a combination of different encodings, and elements partially or completely occluded. Compared to other approaches relying on raster images, our tool successfully recovered all data, even when hidden, with a 78% lower relative error.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {147},
numpages = {17},
keywords = {vector graphics, chart reverse-engineering, data extraction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580726,
author = {Sarma, Abhraneel and Kale, Alex and Moon, Michael Jongho and Taback, Nathan and Chevalier, Fanny and Hullman, Jessica and Kay, Matthew},
title = {Multiverse: Multiplexing Alternative Data Analyses in R Notebooks},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580726},
doi = {10.1145/3544548.3580726},
abstract = {There are myriad ways to analyse a dataset. But which one to trust? In the face of such uncertainty, analysts may adopt multiverse analysis: running all reasonable analyses on the dataset. Yet this is cognitively and technically difficult with existing tools—how does one specify and execute all combinations of reasonable analyses of a dataset?—and often requires discarding existing workflows. We present multiverse, a tool for implementing multiverse analyses in R with expressive syntax supporting existing computational notebook workflows. multiverse supports building up a multiverse through local changes to a single analysis and optimises execution by pruning redundant computations. We evaluate how multiverse supports programming multiverse analyses using (a) principles of cognitive ergonomics to compare with two existing multiverse tools; and (b) case studies based on semi-structured interviews with researchers who have successfully implemented an end-to-end analysis using multiverse. We identify design tradeoffs (e.g. increased flexibility versus learnability), and suggest future directions for multiverse tool design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {148},
numpages = {15},
keywords = {Multiverse Analysis, cognitive dimensions of notations, robust statistical analysis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581099,
author = {Gu, Ken and Jun, Eunice and Althoff, Tim},
title = {Understanding and Supporting Debugging Workflows in Multiverse Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581099},
doi = {10.1145/3544548.3581099},
abstract = {Multiverse analysis—a paradigm for statistical analysis that considers all combinations of reasonable analysis choices in parallel—promises to improve transparency and reproducibility. Although recent tools help analysts specify multiverse analyses, they remain difficult to use in practice. In this work, we identify debugging as a key barrier due to the latency from running analyses to detecting bugs and the scale of metadata processing needed to diagnose a bug. To address these challenges, we prototype a command-line interface tool, Multiverse Debugger, which helps diagnose bugs in the multiverse and propagate fixes. In a qualitative lab study (n=13), we use Multiverse Debugger as a probe to develop a model of debugging workflows and identify specific challenges, including difficulty in understanding the multiverse’s composition. We conclude with design implications for future multiverse analysis authoring systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {149},
numpages = {19},
keywords = {statistical analysis, analysis authoring, workflows, debugging, Multiverse analysis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581422,
author = {Waghmare, Anandghan and Ben Taleb, Youssef and Chatterjee, Ishan and Narendra, Arjun and Patel, Shwetak},
title = {Z-Ring: Single-Point Bio-Impedance Sensing for Gesture, Touch, Object and User Recognition},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581422},
doi = {10.1145/3544548.3581422},
abstract = {We present Z-Ring, a wearable ring that enables gesture input, object detection, user identification, and interaction with passive user interface (UI) elements using a single sensing modality and a single point of instrumentation on the finger. Z-Ring uses active electrical field sensing to detect changes in the hand’s electrical impedance caused by finger motions or contact with external surfaces. We develop a diverse set of interactions and evaluate them with 21 users. We demonstrate: (1) Single- and two-handed gesture recognition with up to 93% accuracy (2) Tangible input with a set of passive touch UI elements, including buttons, a continuous 1D slider, and a continuous 2D trackpad with 91.8% accuracy, &lt;4.4 cm MAE, and &lt;4.1cm MAE, respectively (3) Object recognition across six household objects with 94.5% accuracy (4) User identification among 14 users with 99% accuracy. Z-Ring’s sensing methodology uses only a single co-located electrode pair for both receiving and sensing, lending itself well to future miniaturization for use in on-the-go scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {150},
numpages = {18},
keywords = {user identification, passive user interface, rings, gesture recognition, bio-impedance, sensing, interaction, tangible user interface, object identification},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580902,
author = {Kinnee, Brian and Desjardins, Audrey and Rosner, Daniela},
title = {Autospeculation: Reflecting on the Intimate and Imaginative Capacities of Data Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580902},
doi = {10.1145/3544548.3580902},
abstract = {Given decades of Human computer interaction (HCI) research focused on scientific empiricism, it can be hard for the field to acknowledge that data analysis is both an emotional and speculative process. But what does it mean for this process of data analysis to embrace its situated and speculative nature? In this paper, we explore this possibility by building on decades of HCI mixed methods that root data analysis in design. Drawing on an autoethnographic design inquiry, we examine how data analysis can work as an implicating process, one that is not only critically grounded in a designer’s own situation but also offers modes of imagining the world otherwise. In this analysis, we find that autobiographical design can help HCI scholars to respond to current critiques of speculative design by grounding and rendering more personal certain kinds of speculation, opening a space for diverse voices to emerge.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {151},
numpages = {10},
keywords = {Autoethnography, Data Analysis, Speculative Design, Autobiographical Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580831,
author = {Boone, Ashley and Disalvo, Carl and Le Dantec, Christopher A},
title = {Data Practice for a Politics of Care: Food Assistance as a Site of Careful Data Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580831},
doi = {10.1145/3544548.3580831},
abstract = {As data plays an increasing role in civic decision making, diverse organizations are facing pressure to engage in data work. The HCI community has explored both the potential of and challenges to integrating robust data practices in mission-driven organizations. At each step – from collection, to storage, to analysis, to maintenance – these organizations need to develop tools and practices that balance internal operational needs and external community priorities. This work reports on an 11 month-long collaboration with a mission-driven hybrid organization that has designed tools and procedures for collecting data that enact an ethic of care. This caring data practice is characterized by defining success through relationships, attending to the social and cultural community context, and protecting vulnerable populations through non-collection. We share the organization’s practices, analyze how they support the organization in providing care, and offer recommendations for building caring data systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {152},
numpages = {13},
keywords = {digital civics, data, design, politics of measurement, care},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581495,
author = {J\o{}rgensen, Michael N\o{}rgaard and Jenkins, Tom},
title = {Designing Anekdota: Investigating Personal Metadata for Legacy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581495},
doi = {10.1145/3544548.3581495},
abstract = {This project uses research through design to explore how metadata could be used as a design material to create inheritable artefacts that make personal legacy experiential. Metadata is produced as traces of life, and by designing artifacts that capture and represent these traces, interaction design offers the possibility to experience the everyday practices of someone else as they are passed on and inherited. We use interviews with people interested in data practices, memorializing, and who have experienced grief to find themes and insights for designing with metadata as well as for legacy. Based on these, we developed the prototype Anekdota, a handheld metadata detector that lets an inheritor experience bequeathed location metadata. From a series of think-aloud walks, Anekdota was tested with participants to reveal sensitizing concepts for designing for metadata, and imaginative leaps for how this metadata may become a part of future legacy practices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {153},
numpages = {14},
keywords = {Metadata, Research through Design, Prototyping, Legacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581426,
author = {White, Jordan and Odom, William and Brand, Nico and Zhong, Ce},
title = {Memory Tracer &amp; Memory Compass: Investigating Personal Location Histories as a Design Material for Everyday Reminiscence},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581426},
doi = {10.1145/3544548.3581426},
abstract = {With the massive adoption of smartphones, location trackers, and GPS-based applications, data is being generated that captures people's geographic locations in more precise detail than ever before. Personal location history archives offer a potentially valuable and overlooked resource for supporting reminiscence and recollection of the past. Yet, little design research has explored how location histories can be used as a material in designing such experiences. To investigate this space, we engaged in a practice-based design research process that resulted in two design artifacts. Memory Tracer is a tangible device that occasionally, yet perpetually surfaces locations from the past bound to today's date. Memory Compass is a smartwatch application that uses a ‘casting’ interaction enabling a user to retrieve and explore locations from their past, across space and time. We unpack and reflect on key decisions in our design process and conclude with opportunities for future HCI research and practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {19},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581323,
author = {Desjardins, Audrey and McWhirter, Jena and Petelka, Justin and Simon, Chandler and Shin, Yuna and Peven, Ruby K and Widjaja, Philbert},
title = {On the Making of Alternative Data Encounters: The Odd Interpreters},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581323},
doi = {10.1145/3544548.3581323},
abstract = {While data are the backbone for home Internet of Things’ (IoT) functional and economic model, data remain elusive and abstract for home dwellers. In response, we present the Odd Interpreters (OIs): a collection of three artifacts that materialize alternative ways of engaging with IoT data in home environments. The OIs recast home data as imaginative sounds (Broadcast), fading fabric (Soft Fading), and cookie recipes (Data Bakery) with the intent to reveal the hidden human labor and material infrastructures of data and to critique data's assumed objectivity. Following a Research-through-Design approach, we unpack design events that mark our process for making the Odd Interpreters. We conclude with a discussion around the need for pluralizing data encounters, the tactic of designing between illusion and precision, and a reflection on living with the prototypes while designing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {155},
numpages = {20},
keywords = {Interpretation, Data physicalization, Speculative, Home, Internet of Things, Data, Research-through-Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581417,
author = {Kim, Raphael and Risseeuw, Clarice and Groutars, Eduard Georges and Karana, Elvin},
title = {Surfacing Livingness in Microbial Displays: A Design Taxonomy for HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581417},
doi = {10.1145/3544548.3581417},
abstract = {In recent years, there has been a notable proliferation and diversification of works in HCI, that integrate living microorganisms; an imperative lifeform dominating ecosystems of our planet. Yet despite the growing interest, there is a lack of structured lenses with which designers can strategize their processes of surfacing livingness; a material quality inherent in living artefacts with a potential to enrich user experiences and to initiate mutualistic care between humans and microorganisms. Through a systematic artefacts review and a case study on Flavobacteria, we have developed and instantiated a Taxonomy of Surfacing Livingness in Microbial Displays, consisting of six microbe-sensitive, tuneable mechanisms for human noticing of microorganisms: 1) Canvassing, 2) Marking, 3) Magnifying, 4) Translating, 5) Nudging, and 6) Molecular Programming. The taxonomy invites diverse and adaptable ways of generating and crafting microbial displays; towards overcoming microbe-specific surfacing constraints, integrating diverse stakeholders’ values, and enabling nuanced address of microbial welfare.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {156},
numpages = {21},
keywords = {livingness, biological-HCI, biodesign, taxonomy, living aesthetics, Microbes},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581133,
author = {Arakawa, Riku and Yakura, Hiromu and Goto, Masataka},
title = {CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581133},
doi = {10.1145/3544548.3581133},
abstract = {CatAlyst uses generative models to help workers’ progress by influencing their task engagement instead of directly contributing to their task outputs. It prompts distracted workers to resume their tasks by generating a continuation of their work and presenting it as an intervention that is more context-aware than conventional (predetermined) feedback. The prompt can function by drawing their interest and lowering the hurdle for resumption even when the generated continuation is insufficient to substitute their work, while recent human-AI collaboration research aiming at work substitution depends on a stable high accuracy. This frees CatAlyst from domain-specific model-tuning and makes it applicable to various tasks. Our studies involving writing and slide-editing tasks demonstrated CatAlyst’s effectiveness in helping workers swiftly resume tasks with a lowered cognitive load. The results suggest a new form of human-AI collaboration where large generative models publicly available but imperfect for each individual domain can contribute to workers’ digital well-being.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {157},
numpages = {19},
keywords = {task engagement, procrastination, behavior change, large generative models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581198,
author = {Bentvelzen, Marit and Dominiak, Julia and Niess, Jasmin and Henraat, Frederique and Wo\'{z}niak, Pawe\l{} W.},
title = {How Instructional Data Physicalisation Fosters Reflection in Personal Informatics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581198},
doi = {10.1145/3544548.3581198},
abstract = {The ever-increasing number of devices quantifying our lives offers a perspective of high awareness of one’s wellbeing, yet it remains a challenge for personal informatics (PI) to effectively support data-based reflection. Effective reflection is recognised as a key factor for PI technologies to foster wellbeing. Here, we investigate whether building tangible representations of health data can offer engaging and reflective experiences. We conducted a between-subjects study where n = 60 participants explored their immediate blood pressure data in relation to medical norms. They either used a standard mobile app, built a data representation from LEGO® bricks based on instructions, or completed a free-form brick build. We found that building with instructions fostered more comparison and using bricks fostered focused attention. The free-form condition required extra time to complete, and lacked usability. Our work shows that designing instructional physicalisation experiences for PI is a means of improving engagement and understanding of personal data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {158},
numpages = {15},
keywords = {personal informatics, reflection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581299,
author = {Chen, Yuchen and Sun, Yuling and Lindtner, Silvia},
title = {Maintainers of Stability: The Labor of China’s Data-Driven Governance and Dynamic Zero-COVID},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581299},
doi = {10.1145/3544548.3581299},
abstract = {This paper examines the social, technological, and emotional labor of maintaining China’s data-driven governance broadly, and dynamic zero-COVID management in particular. Drawing on ethnographic research in China, we examine the sociotechnical work of maintenance during the 2022 Shanghai lockdown. This labor included coordinating mass testing, quarantine, and lockdown procedures as well as implementing ad-hoc technological workarounds and managing public sentiments. We demonstrate that, far from being effected from the top down, China’s data-driven governance relies on the circumscribed participation of citizens. During Shanghai’s lockdown, citizens with relevant expertise helped to maintain technological stability by fixing or programming data systems, but also to ensure the ongoing production of“positive feelings” about social stability through data-driven governance. In so doing, such citizens simultaneously enacted an ambivalent and circumscribed form of agency, and maintained social and by extension political stability. This article sheds light on data-driven governance and political processes of maintenance.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {159},
numpages = {16},
keywords = {data-driven, maintenance, China, affect, labor, data work, COVID, governance, data},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581240,
author = {Singh, Anubha and Garcia, Patricia and Lindtner, Silvia},
title = {Old Logics, New Technologies: Producing a Managed Workforce on On-Demand Service Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581240},
doi = {10.1145/3544548.3581240},
abstract = {We examine how two prominent food delivery platforms in India, Swiggy and Zomato, produce a managed digital workforce using a combination of algorithmic control and traditional labor management strategies. Our findings draw from interviews conducted with 13 food delivery workers and a critical discourse analysis of news media coverage. We found that the two platforms combine piece wage restructuring, granular datafication practices, and the use of benevolent language as neoliberal social control mechanisms. We find that this combination of technological governance and strategic managerial practices is a mutually constitutive method of control that restructures labor processes, extracts workers’ compliance and consent, and prevents work disruption. We show that contemporary platform companies draw from strategies that have historically been deployed in industrial labor management. By examining how older and newer regimes of social control and exploitation are strategically intertwined in contemporary platform design, we contribute a historically situated understanding of platform labor that moves beyond dualistic interpretations of “traditional” labor management practices and more recent algorithmic modes of control. Our findings contribute to recent debates in tech labor and algorithmic control by examining how contemporary conditions of precarious work reactivate certain past forms of control and in doing so normalize extreme overwork, exhaustion, speedups, and injuries.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {160},
numpages = {15},
keywords = {piecework, managed workforce, food delivery, gig work, digital labor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580780,
author = {Ebert, Nico and Scheppler, Bj\"{o}rn and Ackermann, Kurt Alexander and Geppert, Tim},
title = {QButterfly: Lightweight Survey Extension for Online User Interaction Studies for Non-Tech-Savvy Researchers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580780},
doi = {10.1145/3544548.3580780},
abstract = {We provide a user-friendly, flexible, and lightweight open-source HCI toolkit (github.com/QButterfly) that allows non-tech-savvy researchers to conduct online user interaction studies using the widespread Qualtrics and LimeSurvey platforms. These platforms already provide rich functionality (e.g., for experiments or usability tests) and therefore lend themselves to an extension to display stimulus web pages and record clickstreams. The toolkit consists of a survey template with embedded JavaScript, a JavaScript library embedded in the HTML web pages, and scripts to analyze the collected data. No special programming skills are required to set up a study or match survey data and user interaction data after data collection. We empirically validated the software in a laboratory and a field study. We conclude that this extension, even in its preliminary version, has the potential to make online user interaction studies (e.g., with crowdsourced participants) accessible to a broader range of researchers.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {161},
numpages = {8},
keywords = {Qualtrics, HCI toolkit, open source, online experiments, LimeSurvey, online user interaction studies},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581283,
author = {Bovo, Riccardo and Giunchi, Daniele and Sidenmark, Ludwig and Newn, Joshua and Gellersen, Hans and Costanza, Enrico and Heinis, Thomas},
title = {Speech-Augmented Cone-of-Vision for Exploratory Data Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581283},
doi = {10.1145/3544548.3581283},
abstract = {Mutual awareness of visual attention is crucial for successful collaboration. Previous research has explored various ways to represent visual attention, such as field-of-view visualizations and cursor visualizations based on eye-tracking, but these methods have limitations. Verbal communication is often utilized as a complementary strategy to overcome such disadvantages. This paper proposes a novel method that combines verbal communication with the Cone of Vision to improve gaze inference and mutual awareness in VR. We conducted a within-group study with pairs of participants who performed a collaborative analysis of data visualizations in VR. We found that our proposed method provides a better approximation of eye gaze than the approximation provided by head direction. Furthermore, we release the first collaborative head, eyes, and verbal behaviour dataset. The results of this study provide a foundation for investigating the potential of verbal communication as a tool for enhancing visual cues for joint attention.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {162},
numpages = {18},
keywords = {eye-tracking, multi-modal visual attention cues, VR collaborative analytics, Field of View},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580725,
author = {Bouma-Sims, Elijah Robert and Li, Megan and Lin, Yanzi and Sakura-Lemessy, Adia and Nisenoff, Alexandra and Young, Ellie and Birrell, Eleanor and Cranor, Lorrie Faith and Habib, Hana},
title = {A US-UK Usability Evaluation of Consent Management Platform Cookie Consent Interface Design on Desktop and Mobile},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580725},
doi = {10.1145/3544548.3580725},
abstract = {Websites implement cookie consent interfaces to obtain users’ permission to use non-essential cookies, as required by privacy regulations. We extend prior research evaluating the impact of interface design on cookie consent through an online behavioral experiment (n = 1359) in which we prompted mobile and desktop users from the UK and US to make cookie consent decisions using one of 14 interfaces implemented with the OneTrust consent management platform (CMP). We found significant effects on user behavior and sentiment for multiple explanatory variables, including more negative sentiment towards the consent process among UK participants and lower comprehension of interface information among mobile users. The design factor that had the largest effect on user behavior was the initial set of options displayed in the cookie banner. In addition to providing more evidence of the inadequacy of current cookie consent processes, our results have implications for website operators and CMPs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {163},
numpages = {36},
keywords = {CCPA, privacy notice, privacy choice, cookie consent, GDPR, consent management platforms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580791,
author = {Sarathy, Jayshree and Song, Sophia and Haque, Audrey and Schlatter, Tania and Vadhan, Salil},
title = {Don’t Look at the Data! How Differential Privacy Reconfigures the Practices of Data Science},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580791},
doi = {10.1145/3544548.3580791},
abstract = {Across academia, government, and industry, data stewards are facing increasing pressure to make datasets more openly accessible for researchers while also protecting the privacy of data subjects. Differential privacy (DP) is one promising way to offer privacy along with open access, but further inquiry is needed into the tensions between DP and data science. In this study, we conduct interviews with 19 data practitioners who are non-experts in DP as they use a DP data analysis prototype to release privacy-preserving statistics about sensitive data, in order to understand perceptions, challenges, and opportunities around using DP. We find that while DP is promising for providing wider access to sensitive datasets, it also introduces challenges into every stage of the data science workflow. We identify ethics and governance questions that arise when socializing data scientists around new privacy constraints and offer suggestions to better integrate DP and data science.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {164},
numpages = {19},
keywords = {data practitioners, utility, privacy, data analysis, open access},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580654,
author = {Hutton, Hannah J and Ellis, David A},
title = {Exploring User Motivations Behind IOS App Tracking Transparency Decisions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580654},
doi = {10.1145/3544548.3580654},
abstract = {Apple’s App Tracking Transparency framework allows users to decide whether they want to allow their activity to be tracked for advertising purposes. In this work we examine the tracking decisions made by 312 participants and their associations with privacy concern and personality factors, and conduct a thematic analysis on participants’ reasons for choosing to accept or reject tracking requests. Despite 51% of participants reporting that they had rejected tracking for privacy reasons, higher privacy concern scores did not correlate with a lower rate of tracking acceptance. Additionally, 43% of participants held incorrect beliefs about what tracking does, including nearly a quarter who mistakenly believed that accepting a tracking request would share their location with the requesting app. We suggest explanations for these misconceptions and provide recommendations that may improve usability of both App Tracking Transparency and future Privacy Enhancing Technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {165},
numpages = {12},
keywords = {privacy concern, iOS, privacy decision making, privacy, App Tracking Transparency, privacy salience, Apple, privacy paradox, privacy calculus},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580967,
author = {Seymour, William and Cote, Mark and Such, Jose},
title = {Legal Obligation and Ethical Best Practice: Towards Meaningful Verbal Consent for Voice Assistants},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580967},
doi = {10.1145/3544548.3580967},
abstract = {To improve user experience, Alexa now allows users to consent to data sharing via voice rather than directing them to the companion smartphone app. While verbal consent mechanisms for voice assistants (VAs) can increase usability, they can also undermine principles core to informed consent. We conducted a Delphi study with experts from academia, industry, and the public sector on requirements for verbal consent in VAs. Candidate requirements were drawn from the literature, regulations, and research ethics guidelines that participants rated based on their relevance to the consent process, actionability by platforms, and usability by end-users, discussing their reasoning as the study progressed. We highlight key areas of (dis)agreement between experts, deriving recommendations for regulators, skill developers, and VA platforms towards crafting meaningful verbal consent mechanisms. Key themes include approaching permissions according to the user’s ability to opt-out, minimising consent decisions, and ensuring platforms follow established consent principles.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {166},
numpages = {16},
keywords = {Verbal Consent, Voice Assistants, Consent, GDPR, Alexa, Permissions, Conversational User Interfaces, Informed Consent},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581181,
author = {Terpstra, Arnout and De Rooij, Alwin and Schouten, Alexander},
title = {Online Proctoring: Privacy Invasion or Study Alleviation? Discovering Acceptability Using Contextual Integrity},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581181},
doi = {10.1145/3544548.3581181},
abstract = {Detecting fraud during online exams using proctoring software comes with substantial privacy challenges. Previous work argues students experience heightened anxiety and have privacy concerns. However, little is known about which specific aspects of online proctoring cause these concerns. This study contributes such insights by using the Contextual Integrity (CI) framework to discover how students (N = 456) rate the acceptability of 1064 proctoring information flows with varying information types, recipients, and transmission principles. We find that the acceptability varies considerably depending on the context. Besides exposing obvious privacy violations, we find that, under certain conditions, students consider it acceptable to share data with teachers - despite their lack of involvement in proctoring. Also, the acceptability of sharing highly sensitive information - which should under no circumstances be shared - sometimes increases. We discuss the implications of these and other findings and provide concrete recommendations for educational institutions using online proctoring.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {167},
numpages = {20},
keywords = {Acceptability, Information flows, Contextual integrity, Privacy, Online proctoring},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581060,
author = {Tahaei, Mohammad and Abu-Salma, Ruba and Rashid, Awais},
title = {Stuck in the Permissions With You: Developer &amp; End-User Perspectives on App Permissions &amp; Their Privacy Ramifications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581060},
doi = {10.1145/3544548.3581060},
abstract = {While the literature on permissions from the end-user perspective is rich, there is a lack of empirical research on why developers request permissions, their conceptualization of permissions, and how their perspectives compare with end-users’ perspectives. Our study aims to address these gaps using a mixed-methods approach. Through interviews with 19 app developers and a survey of 309 Android and iOS end-users, we found that both groups shared similar concerns about unnecessary permissions breaking trust, damaging the app’s reputation, and potentially allowing access to sensitive data. We also found that developer participants sometimes requested multiple permissions due to confusion about the scope of certain permissions or third-party library requirements. Additionally, most end-user participants believed they were responsible for granting a permission request, and it was their choice to do so, a belief shared by many developer participants. Our findings have implications for improving the permission ecosystem for both developers and end-users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {168},
numpages = {24},
keywords = {smartphone permissions, empirical software engineering, privacy, usable security, app users, usable privacy, programming, developers, mixed-methods research},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581149,
author = {Sultana, Sharifa and Ahmed, Syed Ishtiaque and Rzeszotarski, Jeffrey M},
title = {Communicating Consequences: Visual Narratives, Abstraction, and Polysemy in Rural Bangladesh},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581149},
doi = {10.1145/3544548.3581149},
abstract = {Information communication and visualization practices reflect two centuries of developments of conventions and best practices which may not be reflective of global audiences’ methods for conveying information. Contrasting between rural traditional visual culture and contemporary HCI and data-visualization, we argue that an understanding of traditional practices for information visualization is required for building rich data-narratives and making data-driven systems more accessible and culturally situated. Our ten-month ethnographic study investigates how rural Bangladeshi communities construct narratives through visual media. 1 Our observation, interviews, and FGDs (n=54) expose how participants convey risk management, decision-making, and monetary management practices to their peers. We find that villagers used a rich network of polysemic symbols and abstractions to manifest subjectivity, factuality, consequence, situatedness, and uncertainty; varied visual attributes for constructing narratives; and emphasized material relations among components in visuals. These findings inform the design of future systems for decision support in a culturally situated manner.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {19},
keywords = {Visual Narratives, Consequences, Bangladesh, Polysemy, Abstraction, Information Visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581470,
author = {Li, Wenchao and Wang, Zhan and Wang, Yun and Weng, Di and Xie, Liwenhan and Chen, Siming and Zhang, Haidong and Qu, Huamin},
title = {GeoCamera: Telling Stories in Geographic Visualizations with Camera Movements},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581470},
doi = {10.1145/3544548.3581470},
abstract = {In geographic data videos, camera movements are frequently used and combined to present information from multiple perspectives. However, creating and editing camera movements requires significant time and professional skills. This work aims to lower the barrier of crafting diverse camera movements for geographic data videos. First, we analyze a corpus of 66 geographic data videos and derive a design space of camera movements with a dimension for geospatial targets and one for narrative purposes. Based on the design space, we propose a set of adaptive camera shots and further develop an interactive tool called GeoCamera. This interactive tool allows users to flexibly design camera movements for geographic visualizations. We verify the expressiveness of our tool through case studies and evaluate its usability with a user study. The participants find that the tool facilitates the design of camera movements.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {170},
numpages = {15},
keywords = {authoring tools, Visual storytelling, geographic visualization, data video},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580701,
author = {Xu, Xian and Wu, Aoyu and Yang, Leni and Wei, Zheng and Huang, Rong and Yip, David and Qu, Huamin},
title = {Is It the End? Guidelines for Cinematic Endings in Data Videos},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580701},
doi = {10.1145/3544548.3580701},
abstract = {Data videos are becoming increasingly popular in society and academia. Yet little is known about how to create endings that strengthen a lasting impression and persuasion. To fulfill the gap, this work aims to develop guidelines for data video endings by drawing inspiration from cinematic arts. To contextualize cinematic endings in data videos, 111 film endings and 105 data video endings are first analyzed to identify four common styles using the framework of ending punctuation marks. &nbsp;We conducted expert interviews (N=11) and formulated 20 guidelines for creating cinematic endings in data videos. To validate our guidelines, we conducted a user study where 24 participants were invited to design endings with and without our guidelines, which are evaluated by experts and the general public. The participants praise the clarity and usability of the guidelines, and results show that the endings with guidelines are perceived to be more understandable, impressive, and reflective.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {16},
keywords = {Data Video, Storytelling, Guideline, Interview, Visualization, Lab Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581452,
author = {Li, Wenchao and Sch\"{o}ttler, Sarah and Scott-Brown, James and Wang, Yun and Chen, Siming and Qu, Huamin and Bach, Benjamin},
title = {NetworkNarratives: Data Tours for Visual Network Exploration and Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581452},
doi = {10.1145/3544548.3581452},
abstract = {This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about network exploration, and can aid the dissemination of analysis results. NetworkNarratives is available online, together with detailed illustrations for each tour.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {172},
numpages = {15},
keywords = {network visualization, Guided exploration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580965,
author = {Li, Haotian and Ying, Lu and Zhang, Haidong and Wu, Yingcai and Qu, Huamin and Wang, Yun},
title = {Notable: On-the-Fly Assistant for Data Storytelling in Computational Notebooks},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580965},
doi = {10.1145/3544548.3580965},
abstract = {Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user study with 12 data workers. The feedback from user study participants verifies its effectiveness and usability.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {173},
numpages = {16},
keywords = {computational notebooks, data storytelling, data visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581330,
author = {Markant, Douglas and Rogha, Milad and Karduni, Alireza and Wesslen, Ryan and Dou, Wenwen},
title = {When Do Data Visualizations Persuade? The Impact of Prior Attitudes on Learning about Correlations from Scatterplot Visualizations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581330},
doi = {10.1145/3544548.3581330},
abstract = {Data visualizations are vital to scientific communication on critical issues such as public health, climate change, and socioeconomic policy. They are often designed not just to inform, but to persuade people to make consequential decisions (e.g., to get vaccinated). Are such visualizations persuasive, especially when audiences have beliefs and attitudes that the data contradict? In this paper we examine the impact of existing attitudes (e.g., positive or negative attitudes toward COVID-19 vaccination) on changes in beliefs about statistical correlations when viewing scatterplot visualizations with different representations of statistical uncertainty. We find that strong prior attitudes are associated with smaller belief changes when presented with data that contradicts existing views, and that visual uncertainty representations may amplify this effect. Finally, even when participants’ beliefs about correlations shifted their attitudes remained unchanged, highlighting the need for further research on whether data visualizations can drive longer-term changes in views and behavior.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {174},
numpages = {16},
keywords = {persuasion, data visualization, uncertainty communication, attitudes, science communication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581336,
author = {Brand, Nico and Odom, William and Barnett, Samuel},
title = {Envisioning and Understanding Orientations to Introspective AI: Exploring a Design Space with Meta.Aware},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581336},
doi = {10.1145/3544548.3581336},
abstract = {Introspection is the practice of looking inward for ongoing self-examination. It involves considering one's past experiences and asking questions about the present and future. Our work investigates how AI could open new possibilities for supporting introspective experiences. Adopting a design fiction approach, we created a fictional company called Meta.Aware to contextualize 4 different Introspective AI product concepts in the form of video sketches. We used the Meta.Aware platform to conduct interviews with 17 participants, using the 4 concept videos as prompts for discussion. Participants had a range of reactions related to perceived benefits and tensions in this emerging design space. We interpret these results to outline future design directions for mobilizing AI as a resource to support introspective experiences over time, as well as to reflect on issues and dilemmas bound to this emerging design space.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {175},
numpages = {18},
keywords = {Introspection, AI, Personal Data, Research through Design, Design Fiction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580732,
author = {Carvalho, Arthur and Zavolokina, Liudmila and Bhunia, Suman and Chaudhary, Monu and Yoganathan, Nitharsan},
title = {Promoting Inclusiveness and Fairness through NFTs: The Case of Student-Athletes and NILs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580732},
doi = {10.1145/3544548.3580732},
abstract = {Recent regulatory changes have enabled NCAA student-athletes to profit from their name, image, and likeness (NIL), departing from previous policies requiring those athletes to maintain their amateur status. However, despite the changes, it is unlikely that all the approximately 500,000 NCAA student-athletes will profit from NIL contracts. Within this context, we study how to design a fair and inclusive solution that may help all student-athletes secure NIL financial resources. Following a design science approach, we define design requirements after interviewing student-athletes. Subsequently, we derive three design principles: inclusiveness, fairness, and transparency. Thereafter, we suggest a blockchain-based artifact that satisfies all design principles. Our idea lies in designing collectibles as non-fungible tokens (NFTs) that pay different royalties whenever a transaction (purchase or exchange) happens in different markets (primary or secondary). Finally, we evaluate our solution by discussing its features with current student-athletes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {176},
numpages = {9},
keywords = {inclusiveness, blockchain, NFT, fairness, design science},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581540,
author = {Boucher, Andy},
title = {Research Products at Scale: Learnings from Designing Devices in Multiples of Ones, Tens, Hundreds and Thousands},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581540},
doi = {10.1145/3544548.3581540},
abstract = {In this paper, I argue that scale is an important quality of research products [32] and reflect upon the lessons learnt from designing and producing research products at scales ranging from one-offs to those reproduced in thousands. I describe details from a body of research completed by our studio over twenty years by examining four research projects that were designed, developed, and manufactured at four distinct levels of scale. I draw out details from these projects that have not previously been reported and discuss the methodological implications of growth not just for design and production, but also for strategies for engaging with participants. In addition, I discuss particular features of research products produced at the four levels of scale and describe the benefits and trade-offs of producing research products at different scales.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {177},
numpages = {15},
keywords = {IoT, research through design, design research, self-build, research products},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581175,
author = {Benjamin, Jesse Josua and Biggs, Heidi and Berger, Arne and Rukanskaitundefined, Julija and Heidt, Michael B. and Merrill, Nick and Pierce, James and Lindley, Joseph},
title = {The Entoptic Field Camera as Metaphor-Driven Research-through-Design with AI Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581175},
doi = {10.1145/3544548.3581175},
abstract = {Artificial intelligence (AI) technologies are widely deployed in smartphone photography; and prompt-based image synthesis models have rapidly become commonplace. In this paper, we describe a Research-through-Design (RtD) project which explores this shift in the means and modes of image production via the creation and use of the Entoptic Field Camera. Entoptic phenomena usually refer to perceptions of floaters or bright blue dots stemming from the physiological interplay of the eye and brain. We use the term entoptic as a metaphor to investigate how the material interplay of data and models in AI technologies shapes human experiences of reality. Through our case study using first-person design and a field study, we offer implications for critical, reflective, more-than-human and ludic design to engage AI technologies; the conceptualisation of an RtD research space which contributes to AI literacy discourses; and outline a research trajectory concerning materiality and design affordances of AI technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {178},
numpages = {19},
keywords = {materiality, research through design, technological mediation, artificial intelligence, image synthesis, GAN},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581432,
author = {Kowalczyk, Monica and Gunawan, Johanna T. and Choffnes, David and Dubois, Daniel J and Hartzog, Woodrow and Wilson, Christo},
title = {Understanding Dark Patterns in Home IoT Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581432},
doi = {10.1145/3544548.3581432},
abstract = {Internet-of-Things (IoT) devices are ubiquitous, but little attention has been paid to how they may incorporate dark patterns despite consumer protections and privacy concerns arising from their unique access to intimate spaces and always-on capabilities. This paper conducts a systematic investigation of dark patterns in 57 popular, diverse smart home devices. We update manual interaction and annotation methods for the IoT context, then analyze dark pattern frequency across device types, manufacturers, and interaction modalities. We find that dark patterns are pervasive in IoT experiences, but manifest in diverse ways across device traits. Speakers, doorbells, and camera devices contain the most dark patterns, with manufacturers of such devices (Amazon and Google) having the most dark patterns compared to other vendors. We investigate how this distribution impacts the potential for consumer exposure to dark patterns, discuss broader implications for key stakeholders like designers and regulators, and identify opportunities for future dark patterns study.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {179},
numpages = {27},
keywords = {UX design, IoT, dark patterns, human factors},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581110,
author = {Song, Katherine Wei and Paulos, Eric},
title = {Vim: Customizable, Decomposable Electrical Energy Storage},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581110},
doi = {10.1145/3544548.3581110},
abstract = {Providing electrical power is essential for nearly all interactive technologies, yet it often remains an afterthought. Some designs handwave power altogether as an “exercise for later.” Others hastily string together batteries to meet the system’s electrical requirements, enclosing them in whatever box fits. Vim is a new approach – it elevates power as a first-class design element; it frees power from being a series of discrete elements, instead catering to exact requirements; it enables power to take on new, flexible forms; it is fabricated using low-cost, accessible materials and technologies; finally, it advances sustainability by being rechargeable, non-toxic, edible, and compostable. Vims are decomposable battery alternatives that rapidly charge and can power small applications for hours. We present Vims, detail their characteristics, offer design guidelines for their fabrication, and explore their use in applications spanning prototyping, fashion, and food, including novel systems that are entirely decomposable and edible.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {180},
numpages = {18},
keywords = {energy, DIY, decomposable materials, biodegradation, supercapacitors, sustainability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581294,
author = {Kilic Afsar, Ozgun and Luft, Yoav and Cotton, Kelsey and Stepanova, Ekaterina R. and N\'{u}\~{n}ez-Pacheco, Claudia and Kleinberger, Rebecca and Ben Abdesslem, Fehmi and Ishii, Hiroshi and H\"{o}\"{o}k, Kristina},
title = {Corsetto: A Kinesthetic Garment for Designing, Composing for, and Experiencing an Intersubjective Haptic Voice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581294},
doi = {10.1145/3544548.3581294},
abstract = {We present a novel intercorporeal experience – an intersubjective haptic voice. Through an autobiographical design inquiry, based on singing techniques from the classical opera tradition, we created Corsetto, a kinesthetic garment for transferring somatic reminiscents of vocal experience from an expert singer to a listener. We then composed haptic gestures enacted in the Corsetto, emulating upper-body movements of the live singer performing a piece by Morton Feldman named Three Voices. The gestures in the Corsetto added a haptics-based ‘fourth voice’ to the immersive opera performance. Finally, we invited audiences who were asked to wear Corsetto during live performances. Afterwards they engaged in micro-phenomenological interviews. The analysis revealed how the Corsetto managed to bridge inner and outer bodily sensations, creating a feeling of a shared intercorporeal experience, dissolving boundaries between listener, singer and performance. We propose that ‘intersubjective haptics’ can be a generative medium not only for singing performances, but other possible intersubjective experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {181},
numpages = {23},
keywords = {shape changing interfaces, micro-phenomenology, haptics, Robotic textiles, voice, machine learning, somaesthetic interaction design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580761,
author = {Nguyen, Binh Vinh Duc and Han, Jihae and Houben, Maarten and Bayoumi, Yssmin and Vande Moere, Andrew},
title = {Engaging Passers-by with Rhythm: Applying Feedforward Learning to a Xylophonic Media Architecture Facade},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580761},
doi = {10.1145/3544548.3580761},
abstract = {Media architecture exploits interactive technology to encourage passers-by to engage with an architectural environment. Whereas most media architecture installations focus on visual stimulation, we developed a permanent media facade that rhythmically knocks xylophone blocks embedded beneath 11 window sills, according to the human actions constantly traced via an overhead camera. In an attempt to overcome its apparent limitations in engaging passers-by more enduringly and purposefully, our study investigates the impact of feedforward learning, a constructive interaction method that instructs passers-by about the results of their actions. Based on a comparative (n=25) and a one-month in-the-wild (n=1877) study, we propose how feedforward learning could empower passers-by to understand the interaction of more abstract types of media architecture, and how particular quantitative indicators capturing this learning could predict how enduringly and purposefully a passer-might engage. We believe these contributions could inspire more creative integrations of non-visual modalities in future public interactive interventions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {182},
numpages = {21},
keywords = {human-building interaction, musical interface, interactive architecture, rhythm, comparative study, placemaking, media architecture, public display, feedforward learning, musical expression, in-the-wild study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580666,
author = {Zhou, Qiushi and Grebel, Louise and Irlitti, Andrew and Minaai, Julie Ann and Goncalves, Jorge and Velloso, Eduardo},
title = {Here and Now: Creating Improvisational Dance Movements with a Mixed Reality Mirror},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580666},
doi = {10.1145/3544548.3580666},
abstract = {This paper explores using mixed reality (MR) mirrors for supporting improvisational dance making. Motivated by the prevalence of mirrors in dance studios and inspired by Forsythe’s Improvisation Technologies, we conducted workshops with 13 dancers and choreographers to inform the design of future MR visualisation and annotation tools for dance. The workshops involved using a prototype MR mirror as a technology probe that reveals the spatial and temporal relationships between the reflected dancing body and its surroundings during improvisation; speed dating group interviews around future design ideas; follow-up surveys and extended interviews with a digital media dance artist and a dance educator. Our findings highlight how the MR mirror enriches dancers’ temporal and spatial perception, creates multi-layered presence, and affords appropriation by dancers. We also discuss the unique place of MR mirrors in the theoretical context of dance and in the history of movement visualisation, and distil lessons for broader HCI research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {183},
numpages = {16},
keywords = {mixed reality, augmented reality, mirror, improvisation, dance},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581523,
author = {Ryding, Karin and Tsaknaki, Vasiliki and J\o{}rgensen, Stina Marie Hasse and Fritsch, Jonas},
title = {LYDSPOR: AN URBAN SOUND EXPERIENCE WEAVING TOGETHER PAST AND PRESENT THROUGH VIBRATING BODIES},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581523},
doi = {10.1145/3544548.3581523},
abstract = {In this paper we present LYDSPOR; a site-specific sound experience, created in Elsinore, Denmark, consisting of two physical installations and an app-based soundwalk, which together allow people to feel and sense in their bodies certain narrative fragments of the history of the city. LYDSPOR is the result of a 1,5 year-long research project which had the aim of adopting soma design methods by drawing on affective interaction design and on an understanding of bodies as always multiple, relational, and never only human. Through an analysis of the design process and its outcome, the paper contributes an in-depth understanding of how to combine somatic and affective design approaches when creating site-specific sonic augmentations for historical dissemination in public space.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {184},
numpages = {16},
keywords = {design methods, cultural heritage, Sonic Interaction Design, site-specific, urban, public space, Soma design, Affective Interaction Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580700,
author = {Reed, Courtney N. and Strohmeier, Paul and McPherson, Andrew P.},
title = {Negotiating Experience and Communicating Information Through Abstract Metaphor},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580700},
doi = {10.1145/3544548.3580700},
abstract = {An implicit assumption in metaphor use is that it requires grounding in a familiar concept, prominently seen in the popular Desktop Metaphor. In human-to-human communication, however, abstract metaphors, without such grounding, are often used with great success. To understand when and why metaphors work, we present a case study of metaphor use in voice teaching. Voice educators must teach about subjective, sensory experiences and rely on abstract metaphor to express information about unseen and intangible processes inside the body. We present a thematic analysis of metaphor use by 12 voice teachers. We found that metaphor works not because of strong grounding in the familiar, but because of its ambiguity and flexibility, allowing shared understanding between individual lived experiences. We summarise our findings in a model of metaphor-based communication. This model can be used as an analysis tool within the existing taxonomies of metaphor in user interaction for better understanding why metaphor works in HCI. It can also be used as a design resource for thinking about metaphor use and abstracting metaphor strategies from both novel and existing designs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {185},
numpages = {16},
keywords = {data representations, human communication, design, sensory experience, metaphor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581178,
author = {Pl\"{o}ger, Stephan and Meier, Mischa and Smith, Matthew},
title = {A Usability Evaluation of AFL and LibFuzzer with CS Students},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581178},
doi = {10.1145/3544548.3581178},
abstract = {In top-tier companies and academia, fuzzing has established itself as a valuable tool for finding bugs. It is a tool created by experts for experts, and a lot of research is being invested into improving the power of fuzzing. However, the usability of fuzzing has not received much attention yet. To alleviate this, we evaluated the usability of two popular fuzzers: AFL and libFuzzer. In our fuzzing study, 47 computer science students each worked up to 20 hours in total. We found significant usability challenges for both fuzzers leading to only 17 participants who were able to finish all tasks. Even the successful participants struggled with some of the necessary steps and found them complex and confusing. While on the whole, AFL fared better than libFuzzer, both fuzzers have strengths and weaknesses and can be improved based on our results.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {186},
numpages = {18},
keywords = {Usable Security and Privacy, Fuzzing, Student Participants, Security Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580705,
author = {Kanei, Fumihiro and Hasegawa, Ayako A. and Shioji, Eitaro and Akiyama, Mitsuaki},
title = {Analyzing the Use of Public and In-House Secure Development Guidelines in U.S. and Japanese Industries},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580705},
doi = {10.1145/3544548.3580705},
abstract = {Secure development guidelines contribute to improving software security from the development stage by making developers aware of the risks to be assumed, the necessary security countermeasures, and how to implement them. In this study, we investigated the actual utilization of guidelines and their usability in the industry through a survey of software development professionals in the U.S. and Japan (N=396 in the U.S. and N=474 in Japan). Our quantitative analysis revealed that “in-house” guidelines not examined in most existing studies are in fact widely utilized in the industry and also clarified how they are related to the use of public guidelines. In addition, we found that the practices for implementing guidelines recommended by existing studies are difficult for software development professionals with certain attributes, e.g., those who are working on small projects. The findings demonstrate the need for lightweight recommended practices taking into account organizational issues at industrial development sites that are easy for developers to implement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {187},
numpages = {17},
keywords = {Secure programming, Survey, HCI for development, Security},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581117,
author = {Washburn, Renita and Tanni, Tangila Islam and Solihin, Yan and Kapadia, Apu and Amon, Mary Jean},
title = {Bottom-up Psychosocial Interventions for Interdependent Privacy: Effectiveness Based on Individual and Content Differences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581117},
doi = {10.1145/3544548.3581117},
abstract = {Although a great deal of research has examined interventions to help users protect their own information online, less work has examined methods for reducing interdependent privacy (IDP) violations on social media (i.e., sharing of other people's information). This study tested the effectiveness of concept-based (i.e., general information), fact-based (i.e., statistics), and narrative-based (i.e., stories) educational videos in altering IDP-relevant attitudes and multimedia sharing behaviors. Our study revealed concept and fact videos reduced sharing of social media content that portrayed people negatively. The narrative intervention backfired and increased sharing among participants who did not believe IDP violations to be especially serious; however, the narrative intervention decreased sharing for participants who rated IDP violations as more serious. Notably, our study found participants preferred narrative-based interventions with real world examples, despite other strategies more effectively reducing sharing. Implications for narrative transportation theory and advancing bottom-up (i.e., user-centered) psychosocial interventions are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {188},
numpages = {20},
keywords = {social media/online communities, psychosocial intervention, interdependent privacy, behavior change},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581484,
author = {Dev, Jayati and Rashidi, Bahman and Garg, Vaibhav},
title = {Models of Applied Privacy (MAP): A Persona Based Approach to Threat Modeling},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581484},
doi = {10.1145/3544548.3581484},
abstract = {The paradigm of Privacy by Design aims to integrate privacy early in the product development life cycle. One element of this is to conduct threat modeling with developers to identify privacy threats that engender from the architecture design of the product. In this paper, we propose a systematic lightweight privacy threat modeling framework (MAP) based on attacker personas that is both easy to operationalize and scale. MAP leverages existing privacy threat frameworks to provide an operational roadmap based on relevant threat actors, associated threats, and resulting harm to individuals as well as organizations. We implement MAP as a persona picker tool that threat modelers can use as a menu select to identify, investigate, and remediate relevant threats based on product developer’s scope of privacy risk. We conclude by testing the framework using a repository of 207 privacy breaches extracted from the VERIS Community Database.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {189},
numpages = {15},
keywords = {privacy threat modeling, framework, personas, privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581229,
author = {Wei, Miranda and Consolvo, Sunny and Kelley, Patrick Gage and Kohno, Tadayoshi and Roesner, Franziska and Thomas, Kurt},
title = {“There’s so Much Responsibility on Users Right Now:” Expert Advice for Staying Safer From Hate and Harassment},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581229},
doi = {10.1145/3544548.3581229},
abstract = {Online hate and harassment poses a threat to the digital safety of people globally. In light of this risk, there is a need to equip as many people as possible with advice to stay safer online. We interviewed 24 experts to understand what threats and advice internet users should prioritize to prevent or mitigate harm. As part of this, we asked experts to evaluate 45 pieces of existing hate-and-harassment-specific digital-safety advice to understand why they felt advice was viable or not. We find that experts frequently had competing perspectives for which threats and advice they would prioritize. We synthesize sources of disagreement, while also highlighting the primary threats and advice where experts concurred. Our results inform immediate efforts to protect users from online hate and harassment, as well as more expansive socio-technical efforts to establish enduring safety.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {190},
numpages = {17},
keywords = {hate, harassment, advice, Security and privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581128,
author = {Freed, Diana and Bazarova, Natalie N. and Consolvo, Sunny and Han, Eunice J and Kelley, Patrick Gage and Thomas, Kurt and Cosley, Dan},
title = {Understanding Digital-Safety Experiences of Youth in the U.S.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581128},
doi = {10.1145/3544548.3581128},
abstract = {The seamless integration of technology into the lives of youth has raised concerns about their digital safety. While prior work has explored youth experiences with physical, sexual, and emotional threats—such as bullying and trafficking—a comprehensive and in-depth understanding of the myriad threats that youth experience is needed. By synthesizing the perspectives of 36 youth and 65 adult participants from the U.S., we provide an overview of today’s complex digital-safety landscape. We describe attacks youth experienced, how these moved across platforms and into the physical world, and the resulting harms. We also describe protective practices the youth and the adults who support them took to prevent, mitigate, and recover from attacks, and key barriers to doing this effectively. Our findings provide a broad perspective to help improve digital safety for youth and set directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {191},
numpages = {15},
keywords = {security, Digtal safety, abuse, youth, teens, privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580695,
author = {Mildner, Thomas and Savino, Gian-Luca and Doyle, Philip R. and Cowan, Benjamin R. and Malaka, Rainer},
title = {About Engaging and Governing Strategies: A Thematic Analysis of Dark Patterns in Social Networking Services},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580695},
doi = {10.1145/3544548.3580695},
abstract = {Research in HCI has shown a growing interest in unethical design practices across numerous domains, often referred to as “dark patterns”. There is, however, a gap in related literature regarding social networking services (SNSs). In this context, studies emphasise a lack of users’ self-determination regarding control over personal data and time spent on SNSs. We collected over 16 hours of screen recordings from Facebook’s, Instagram’s, TikTok’s, and Twitter’s mobile applications to understand how dark patterns manifest in these SNSs. For this task, we turned towards HCI experts to mitigate possible difficulties of non-expert participants in recognising dark patterns, as prior studies have noticed. Supported by the recordings, two authors of this paper conducted a thematic analysis based on previously described taxonomies, manually classifying the recorded material while delivering two key findings: We observed which instances occur in SNSs and identified two strategies — engaging and governing — with five dark patterns undiscovered before.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {192},
numpages = {15},
keywords = {social networking services, social media, ethical interfaces, interface design, dark patterns, well-being, SNS},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581258,
author = {Chordia, Ishita and Tran, Lena-Phuong and Tayebi, Tala June and Parrish, Emily and Erete, Sheena and Yip, Jason and Hiniker, Alexis},
title = {Deceptive Design Patterns in Safety Technologies: A Case Study of the Citizen App},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581258},
doi = {10.1145/3544548.3581258},
abstract = {Deceptive design patterns (known as dark patterns) are interface characteristics which modify users’ choice architecture to gain users’ attention, data, and money. Deceptive design patterns have yet to be documented in safety technologies despite evidence that designers of safety technologies make decisions that can powerfully influence user behavior. To address this gap, we conduct a case study of the Citizen app, a commercially available technology which notifies users about local safety incidents. We bound our study to Atlanta and triangulate interview data with an analysis of the user interface. Our results indicate that Citizen heightens users’ anxiety about safety while encouraging the use of profit-generating features which offer security. These findings contribute to an emerging conversation about how deceptive design patterns interact with sociocultural factors to produce deceptive infrastructure. We propose the need to expand an existing taxonomy of harm to include emotional load and social injustice and offer recommendations for designers interested in dismantling the deceptive infrastructure of safety technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {193},
numpages = {18},
keywords = {safety, fear, dark infrastructure, anxiety, safety technologies, dark patterns, manipulative design, crime, deceptive design, community safety},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580729,
author = {Monge Roffarello, Alberto and Lukoff, Kai and De Russis, Luigi},
title = {Defining and Identifying Attention Capture Deceptive Designs in Digital Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580729},
doi = {10.1145/3544548.3580729},
abstract = {Many tech companies exploit psychological vulnerabilities to design digital interfaces that maximize the frequency and duration of user visits. Consequently, users often report feeling dissatisfied with time spent on such services. Prior work has developed typologies of damaging design patterns (or dark patterns) that contribute to financial and privacy harms, which has helped designers to resist these patterns and policymakers to regulate them. However, we are missing a collection of similar problematic patterns that lead to attentional harms. To close this gap, we conducted a systematic literature review for what we call ‘attention capture damaging patterns’ (ACDPs). We analyzed 43 papers to identify their characteristics, the psychological vulnerabilities they exploit, and their impact on digital wellbeing. We propose a definition of ACDPs and identify eleven common types, from Time Fog to Infinite Scroll. Our typology offers technologists and policymakers a common reference to advocate, design, and regulate against attentional harms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {194},
numpages = {19},
keywords = {digital wellbeing, damaging patterns, technology overuse, dark patterns, deceptive design, attention},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581044,
author = {Semertzidis, Nathan Arthur and Li Pin Hiung, Annaelle and Vranic-Peters, Michaela Jayne and Mueller, Florian ‘Floyd’},
title = {Dozer: Towards Understanding the Design of Closed-Loop Wearables for Sleep},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581044},
doi = {10.1145/3544548.3581044},
abstract = {Sleep plays a paramount role in maintaining healthy bodily functioning. Yet, poor sleep is an increasingly prevalent global health concern. Most current sleep technology tracks sleep, but how to design for promoting sleep is relatively underexplored. We highlight the potential of employing closed-loop systems for promoting sleep onset and explore this through the design and study of “Dozer”, a closed-loop beanie that accelerates sleep onset through auditory and electrical brain stimulation after detecting drowsiness in EEG. In an in-the-wild study, participant interviews revealed three UX themes (closed-loop neurocentric agency, awareness of hardware, and awareness of feedback), which ultimately suggested that participants fell asleep in spite of Dozer, rather than through its assistance. We interpret these results and provide actionable design tactics to inform the design of closed-loop sleep systems moving forward. We hope this work gives rise to a deeper understanding of designing closed techno-physiological loops.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {195},
numpages = {14},
keywords = {neurostimulation, tACS, closed-loop, sleep, brain-computer interface, wearable, EEG},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581187,
author = {Purohit, Aditya Kumar and Bergram, Kristoffer and Barclay, Louis and Bezen\c{c}on, Val\'{e}ry and Holzer, Adrian},
title = {Starving the Newsfeed for Social Media Detox: Effects of Strict and Self-Regulated Facebook Newsfeed Diets},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581187},
doi = {10.1145/3544548.3581187},
abstract = {Doomsurfing, doomscrolling or zombie scrolling. These new additions to the tech vocabulary have become part of our everyday routine, scrolling endlessly through social media feeds. Furthermore, some users report a sense of compulsion, a decrease in mental wellbeing and an increased sense of distraction. A common complaint among users harks back to the Facebook newsfeed. In a field experiment with real Facebook users (), we investigate the difference between a strict newsfeed diet (where the newsfeed is automatically reduced to a minimum) and self-regulated newsfeed diet (where the newsfeed is reduced, but users can then manage its content). Our results indicate that both of these newsfeed diets are effective at reducing the time spent on Facebook’s platform ( for the strict diet, % for the self-regulated diet). Our findings also suggest that these design interventions come with positive and negative user experiences such as increased self-awareness and fear of missing out (FOMO).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {196},
numpages = {16},
keywords = {Multi-device, Facebook, Unfollow mechanisms, Digital Wellbeing, Infinite newsfeed, Doomscrolling, Digital Detox, Social media, Digital Nudging, Dark patterns},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580703,
author = {Lukoff, Kai and Lyngs, Ulrik and Shirokova, Karina and Rao, Raveena and Tian, Larry and Zade, Himanshu and Munson, Sean A. and Hiniker, Alexis},
title = {SwitchTube: A Proof-of-Concept System Introducing “Adaptable Commitment Interfaces” as a Tool for Digital Wellbeing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580703},
doi = {10.1145/3544548.3580703},
abstract = {YouTube has many features, such as homepage recommendations, that encourage users to explore its vast library of videos. However, when users visit YouTube with a specific intention, e.g., learning how to program in Python, these features to encourage exploration are often distracting. Prior work has innovated ‘commitment interfaces’ that restrict social media but finds that they often indiscriminately block needed content. In this paper, we describe the design, development, and evaluation of an ‘adaptable commitment interface,’ the SwitchTube mobile app, in which users can toggle between two interfaces when watching YouTube videos: Focus Mode (search-first) and Explore Mode (recommendations-first). In a three-week field deployment with 46 US participants, we evaluate how the ability to switch between interfaces affects user experience, finding that it provides users with a greater sense of agency, satisfaction, and goal alignment. We conclude with design implications for how adaptable commitment interfaces can support digital wellbeing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {197},
numpages = {22},
keywords = {social media, digital wellbeing, adaptable interfaces, YouTube, commitment devices},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581134,
author = {Chowdhury, Ananta and Bunt, Andrea},
title = {Co-Designing with Early Adolescents: Understanding Perceptions of and Design Considerations for Tech-Based Mediation Strategies That Promote Technology Disengagement},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581134},
doi = {10.1145/3544548.3581134},
abstract = {Children's excessive use of technology is a growing concern, and despite taking various measures, parents often find it difficult to limit their children's device use. Limiting tech usage can be especially challenging with early adolescents as they start to develop a sense of autonomy. While numerous tech-based mediation solutions exist, in this paper, we aim to learn from early adolescents directly by having them contribute to co-design activities. Through a multi-session, group-based, online co-design study with 21 early adolescents (ages 11-14), we explore their perceptions towards tech overuse and what types of solutions they propose to help with disengagement. Findings from these co-design sessions contribute insights into how the participants conceptualized the problem of tech overuse, how they envisioned appropriate mediation strategies, and important design considerations. We also reflect on our study methods, which encouraged active participation from our participants and facilitated valuable contributions during the online co-design sessions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {16},
keywords = {Early Adolescents, Technology Disengagement, Tech-Based Mediation Strategies, Co-Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580987,
author = {Rusu, Marius and Mayer, Sven},
title = {Deep Learning Super-Resolution Network Facilitating Fiducial Tangibles on Capacitive Touchscreens},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580987},
doi = {10.1145/3544548.3580987},
abstract = {Over the last few years, we have seen many approaches using tangibles to address the limited expressiveness of touchscreens. Mainstream tangible detection uses fiducial markers embedded in the tangibles. However, the coarse sensor size of capacitive touchscreens makes tangibles bulky, limiting their usefulness. We propose a novel deep-learning super-resolution network to facilitate fiducial tangibles on capacitive touchscreens better. In detail, our network super-resolves the markers enabling off-the-shelf detection algorithms to track tangibles reliably. Our network generalizes to unseen marker sets, such as AprilTag, ArUco, and ARToolKit. Therefore, we are not limited to a fixed number of distinguishable objects and do not require data collection and network training for new fiducial markers. With extensive evaluation, including real-world users and five showcases, we demonstrate the applicability of our open-source approach on commodity mobile devices and further highlight the potential of tangibles on capacitive touchscreens.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {199},
numpages = {16},
keywords = {capacitive touchscreen, super resolution, deep learning, human-computer interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581092,
author = {Chen, Hong-Xian and Chiu, Shih-Kang and Wen, Chi-Ching and Tsai, Hsin-Ruey},
title = {TransPAF: Rendering Omnidirectional Impact Feedback with Dynamic Point of Application of Force All Round a Controller},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581092},
doi = {10.1145/3544548.3581092},
abstract = {Impact force is common haptic feedback on virtual reality (VR) controllers, such as hitting objects with weapons or rackets. It applies to different points of application of force (PAFs) and directions in varied scenarios. For example, using weapons with different shapes, e.g.,&nbsp;a sword and a pickaxe, using a weapon in different ways, e.g.,&nbsp;stabbing and slashing with a sword, or a ball flying and hitting a racket in different directions cause different PAFs and/or force directions. Therefore, to achieve realistic VR experiences, rendering dynamic PAF and force direction is essential. Although previous works have proposed the concept of dynamic PAF, the PAF is only in a limited space and without dynamic force direction. Therefore, we propose a controller, transPAF, to render omnidirectional impact feedback with dynamic PAF all round the controller for versatile VR scenarios. transPAF consists of a controller, a semicircular track, a linear track, and an impactor, which are all rotatable. The impactor can move to any position in a sphere, which means the whole 3D space all round the controller, and rotate in any direction. Therefore, dynamic PAF and force direction are achieved and independent to each other. We conducted a just-noticeable difference (JND) study to understand users’ distinguishability in position and direction, separately. A VR experience study was further performed to verify that feedback from transPAF with dynamic PAF and force direction enhances the VR experiences and demonstrate some applications for transPAF.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {200},
numpages = {13},
keywords = {Haptic feedback, impact force feedback, point of application of force, virtual reality.},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581301,
author = {Lee, Matthew L and Carter, Scott and Iliev, Rumen and Bravo, Nayeli Suseth and Van, Monica P and Denoue, Laurent and Kimani, Everlyne and Filipowicz, Alexandre L. S. and Shamma, David A. and Sieck, Kate A and Hogan, Candice and Wu, Charlene C.},
title = {Understanding People’s Perception and Usage of Plug-in Electric Hybrids},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581301},
doi = {10.1145/3544548.3581301},
abstract = {Electrification is an important first step toward reducing the greenhouse emissions of passenger vehicles. However, how drivers drive, charge, and operate their electrified vehicles can have a large impact on their emissions, particularly for Plug-in Hybrid Electric vehicles (PHEVs) that combine all-electric driving with an internal combustion engine. In this paper, we investigate how and why drivers use their PHEVs and uncover design opportunities for interfaces that can support the efficient use of PHEVs. We used a mixed-method approach combining quantitative, qualitative, and concept elicitation methods with PHEV owners in the US. While past findings indicate that PHEV drivers are not motivated to charge regularly, our work contradicts this with evidence of (1) regular charging with home infrastructure, (2) high cost sensitivity, and (3) preference for driving in all-electric mode. Our results indicate that the most critical problem is inadequate user support for navigating poor charging infrastructure.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {201},
numpages = {21},
keywords = {behavioral science, prototyping, phev, plug-in, carbon, automobiles, hybrid},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581500,
author = {Xu, Xuhai and Yu, Anna and Jonker, Tanya R. and Todi, Kashyap and Lu, Feiyu and Qian, Xun and Evangelista Belo, Jo\~{a}o Marcelo and Wang, Tianyi and Li, Michelle and Mun, Aran and Wu, Te-Yen and Shen, Junxiao and Zhang, Ting and Kokhlikyan, Narine and Wang, Fulton and Sorenson, Paul and Kim, Sophie and Benko, Hrvoje},
title = {XAIR: A Framework of Explainable AI in Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581500},
doi = {10.1145/3544548.3581500},
abstract = {Explainable AI (XAI) has established itself as an important component of AI-driven interactive systems. With Augmented Reality (AR) becoming more integrated in daily lives, the role of XAI also becomes essential in AR because end-users will frequently interact with intelligent services. However, it is unclear how to design effective XAI experiences for AR. We propose XAIR, a design framework that addresses when, what, and how to provide explanations of AI output in AR. The framework was based on a multi-disciplinary literature review of XAI and HCI research, a large-scale survey probing 500+ end-users’ preferences for AR-based explanations, and three workshops with 12 experts collecting their insights about XAI design in AR. XAIR’s utility and effectiveness was verified via a study with 10 designers and another study with 12 end-users. XAIR can provide guidelines for designers, inspiring them to identify new design opportunities and achieve effective XAI designs in AR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {202},
numpages = {30},
keywords = {Augmented Reality, Design Framework, Explainable AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581381,
author = {Faridan, Mehrad and Kumari, Bheesha and Suzuki, Ryo},
title = {ChameleonControl: Teleoperating Real Human Surrogates through Mixed Reality Gestural Guidance for Remote Hands-on Classrooms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581381},
doi = {10.1145/3544548.3581381},
abstract = {We present ChameleonControl, a real-human teleoperation system for scalable remote instruction in hands-on classrooms. In contrast to existing video or AR/VR-based remote hands-on education, ChameleonControl uses a real human as a surrogate of a remote instructor. Building on existing human-based telepresence approaches, we contribute a novel method to teleoperate a human surrogate through synchronized mixed reality hand gestural navigation and verbal communication. By overlaying the remote instructor’s virtual hands in the local user’s MR view, the remote instructor can guide and control the local user as if they were physically present. This allows the local user/surrogate to synchronize their hand movements and gestures with the remote instructor, effectively teleoperating a real human. We deploy and evaluate our system in classrooms of physiotherapy training, as well as other application domains such as mechanical assembly, sign language and cooking lessons. The study results confirm that our approach can increase engagement and the sense of co-presence, showing potential for the future of remote hands-on classrooms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {203},
numpages = {13},
keywords = {Human Surrogates, Mixed Reality, Telepresence, Remote Collaboration, Hands-on Training, Remote Guidance, Visual Cue},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581260,
author = {Zhang, Xiaoyu and Li, Jianping and Chi, Po-Wei and Chandrasegaran, Senthil and Ma, Kwan-Liu},
title = {ConceptEVA: Concept-Based Interactive Exploration and Customization of Document Summaries},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581260},
doi = {10.1145/3544548.3581260},
abstract = {With the most advanced natural language processing and artificial intelligence approaches, effective summarization of long and multi-topic documents—such as academic papers—for readers from different domains still remains a challenge. To address this, we introduce ConceptEVA, a mixed-initiative approach to generate, evaluate, and customize summaries for long and multi-topic documents. ConceptEVA incorporates a custom multi-task longformer encoder decoder to summarize longer documents. Interactive visualizations of document concepts as a network reflecting both semantic relatedness and co-occurrence help users focus on concepts of interest. The user can select these concepts and automatically update the summary to emphasize them. We present two iterations of ConceptEVA evaluated through an expert review and a within-subjects study. We find that participants’ satisfaction with customized summaries through ConceptEVA is higher than their own manually-generated summary, while incorporating critique into the summaries proved challenging. Based on our findings, we make recommendations for designing summarization systems incorporating mixed-initiative interactions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {204},
numpages = {16},
keywords = {Interactive Visual Analytics, Knowledge Graph, Mixed-Initiative Interfaces, Document Summarization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581307,
author = {Alhelali, Eman and Ramokapane, Kopo M. and Such, Jose},
title = {Multiuser Privacy and Security Conflicts in the Cloud},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581307},
doi = {10.1145/3544548.3581307},
abstract = {Collaborative cloud platforms make it easier and more convenient for multiple users to work together on files (GoogleDocs, Office365) and store and share them (Dropbox, OneDrive). However, this can lead to privacy and security conflicts between the users involved, for instance when a user adds someone to a shared folder or changes its permissions. Such multiuser conflicts (MCs), though known to happen in the literature, have not yet been studied in-depth. In this paper, we report a study with 1,050 participants about MCs they experienced in the cloud. We show what are the MCs that arise when multiple users work together in the cloud and how and why they arise, what is the prevalence and severity of MCs, what are their consequences on users, and how do users work around MCs. We derive recommendations for designing mechanisms to help users avoid, mitigate, and resolve MCs in the cloud.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {205},
numpages = {16},
keywords = {Cloud Security, Interdependent Privacy, Multi-party Privacy Conflicts, Multiuser Conflicts},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580713,
author = {Parayno, Richard Lance and Deja, Janna Aika and Sta. Maria, Tyrone Justin and Samson, Briane Paul V. and Deja, Jordan Aiko},
title = {Good Day Manager! Exploring Social Relationships in NFT-Based Play-to-Earn Games},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580713},
doi = {10.1145/3544548.3580713},
abstract = {Play-to-Earn (P2E) crypto-games recently emerged as a gig opportunity despite the absence of regulations. As these platforms continue to grow, there is a need to understand the interactions involved to protect vulnerable stakeholders. This paper describes how an unintended social dynamic became a strategy guiding players to navigate an unregulated space. First, we inquired through surveys (N = 69) and interviews (N = 9) to understand stakeholder motivations and practices in this space. Second, we analyzed data and then conceptualized eight themes (e.g., Management, Social, Gaming). Then, we uncovered four types of relationships (e.g., Manager-Scholar, Manager-Investor-Scholar, Coach-Mentee, Scholar-Turned-Manager) that shaped the behaviours of the different users on the platform. Lastly, we present design implications and recommendations to guide the design of P2E crypto games and the gig-focused communities that thrive around them. Our results contribute to ongoing discussions in designing digital gig economies and crypto-based games.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {206},
numpages = {11},
keywords = {cryptocurrency, NFT, wallets, Axie, perceptions},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581334,
author = {Tran O'Leary, Jasper and Benabdallah, Gabrielle and Peek, Nadya},
title = {Imprimer: Computational Notebooks for CNC Milling},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581334},
doi = {10.1145/3544548.3581334},
abstract = {Digital fabrication in industrial contexts involves standardized procedures that prioritize precision and repeatability. However, fabrication machines are now available for practitioners who focus instead on experimentation. In this paper, we reframe hobbyist CNC milling as writing literate programs which interleave documentation, interactive graphics, and source code for machine control. To test this approach, we present Imprimer, a machine infrastructure for a CNC mill and an associated library for a computational notebook. Imprimer lets makers learn experimentally, prototype new interactions for making, and understand physical processes by writing and debugging code. We demonstrate three experimental milling workflows as computational notebooks, conduct a user study with practitioners with a range of backgrounds, and discuss literate programming as a future vision for digital fabrication altogether.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {207},
numpages = {15},
keywords = {exploratory digital fabrication, computational notebooks, CNC milling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580646,
author = {George, Leya and Singh, Aneesha and Berthouze, Nadia and Hobbs, Lorna and Gibbs, Jo},
title = {Jamming-as-Exploration: Creating and Playing Games to Explore Gender Identity},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580646},
doi = {10.1145/3544548.3580646},
abstract = {Games can be powerful vehicles for gender identity exploration and self-reflection but are often subject to designers' biases including gender representation, limiting such opportunities. Using a game jam as a research-through-design method, alongside qualitative interviews with the creators, this paper explores how the process of creating games and the games themselves can facilitate exploration of and reflection on gender identity. We highlight aspects of identity people want to explore; how different game elements can support processes of exploring these, and what aspects are missing in games. Further, the process of creating and playing helped participants reflect on and reframe their understanding of gender regardless of their identity/experience. Finally, we reflect on the process of designing an inclusive jam around the topic of gender identity, which can be sensitive and divisive. Our work results in implications for the design of games and other potential tools for gender exploration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {208},
numpages = {19},
keywords = {Qualitative methods, Game design, Gender identity exploration, Game jam},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581474,
author = {Lu, Alex Jiahong and Sannon, Shruti and Moy, Cameron and Brewer, Savana and Green, Jaye and Jackson, Kisha N. and Reeder, Daivon and Wafer, Camaria and Ackerman, Mark S. and Dillahunt, Tawanna R.},
title = {Shifting from Surveillance-as-Safety to Safety-through-Noticing: A Photovoice Study with Eastside Detroit Residents},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581474},
doi = {10.1145/3544548.3581474},
abstract = {Safety has been used to justify the expansion of today’s large-scale surveillance infrastructures in American cities. Our work offers empirical and theoretical groundings on why and how the safety-surveillance conflation that reproduces harm toward communities of color must be denaturalized. In a photovoice study conducted in collaboration with a Detroit community organization and a university team, we invited 11 Black mid-aged and senior Detroiters to use photography to capture their lived experiences of navigating personal and community safety. Their photographic narratives unveil acts of “everyday noticing” in negotiating and maintaining their intricate and interdependent relations with human, non-human animals, plants, spaces, and material things, through which a multiplicity of meaning and senses of safety are produced and achieved. Everyday noticing, as simultaneously a survival skill and a more-than-human care act, is situated in residents’ lived materialities, while also serving as a site for critiquing the reductive and exclusionary vision embedded in large-scale surveillance infrastructures. By proposing an epistemological shift from surveillance-as-safety to safety-through-noticing, we invite future HCI work to attend to the fluid and relational forms of safety that emerge from local entanglement and sensibilities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {19},
keywords = {entanglement, community-based participatory research, photovoice, more-than-human intersectionality, surveillance infrastructure},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580951,
author = {Vo, Dong-Bach and Pauchet, Sylvain and Jolly, Isabelle and Simon, Florine and Brock, Anke M. and Garcia, J\'{e}r\'{e}mie},
title = {Tactilient: Turbulence Resilient Tactile Icons for Pilot Feedback},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580951},
doi = {10.1145/3544548.3580951},
abstract = {Given the high attentional demand in aircraft cockpits, tactons can be used to deliver information without overloading the visual and auditory channels. However, aircraft are subject to turbulence that interfere with vibrotactile feedback. To investigate the impact of turbulence on tacton identification, 18 participants tried to identify 9 tactons with varying intensity and rhythm, while experiencing uncomfortable and very uncomfortable levels of mechanical vibration defined in ISO 2631-1. The results show that the effectiveness of tactile communication decreases with the rhythm identification performance as the level of turbulence increases. In our study, an RMS acceleration delta of 0.70&nbsp;Grms between two consecutive tactons guaranteed near zero confusion. Based on their experience performing the study, participants built tactons that included 4 pulses, lasted for at least 350&nbsp;ms and vibrated at no less than 1.25&nbsp;Grms to be comfortably perceived. Our results will support practitioners for designing tactons that can be more resilient to turbulence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {210},
numpages = {13},
keywords = {aviation, turbulence, haptics, tactile feedback},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580783,
author = {Lu, Qiuyu and Xu, Haiqing and Guo, Yijie and Wang, Joey Yu and Yao, Lining},
title = {Fluidic Computation Kit: Towards Electronic-Free Shape-Changing Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580783},
doi = {10.1145/3544548.3580783},
abstract = {Although fluidic computation has been utilized to develop interactive devices in the field of Human-Computer Interaction (HCI), the limited computation complexity of previous work hinders the exploration of richer interaction modalities. Based on the Fluidic Computation Kit we developed, this paper explores how unconventional mechanical computing can be leveraged to design shape-changing interfaces that integrate input sensing, output, and complex computation. After introducing the design space enabled by the Kit, we explain how to design four types of elementary computational components and six categories of operators. We end by providing several application scenarios which illustrate the Fluidic Computation Kit’s potential to build sophisticated circuits (e.g., a parallel processor) for use in the field of HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {211},
numpages = {21},
keywords = {pneumatic, fabrication, mechanical computation, logic, shape-changing interfaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581353,
author = {Morita, Takafumi and Jiang, Ziyuan and Aoyama, Kanon and Minaminosono, Ayato and Kuwajima, Yu and Hosoya, Naoki and Maeda, Shingo and Kakehi, Yasuaki},
title = {InflatableMod: Untethered and Reconfigurable Inflatable Modules for Tabletop-Sized Pneumatic Physical Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581353},
doi = {10.1145/3544548.3581353},
abstract = {Inflatable systems have been attracting attention in the field of interaction design. Conventional tabletop-sized pneumatic systems tend to be complex because they require bulky and noisy equipment. Therefore, several liquid-to-gas phase change actuators that use vaporization have been proposed. But these actuators have problems with controllability, reusability, and reconfigurability. In this study, we propose InflatableMod, novel inflatable modules based on the efficient control of liquid-to-gas phase change actuators. These are designed with a compact circuit that has a liquid transfer function to feed the required amount of low-boiling-point liquid into the pouch and a heating function to inflate the pouch by the volume change. This approach allows for a compact, silent, and untethered inflatable system. It is also possible to create an untethered and reconfigurable multi-inflatable system because each module is synchronized. In this paper, we propose the design of the modules, evaluate their performance, and present application scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {212},
numpages = {15},
keywords = {Programmable Materials, Multi-inflatables, Electrohydrodynamics., Inflatables, Pneumatic, Liquid-to-gas Phase Change Actuators},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581411,
author = {Yadav, Deepika and Balaam, Madeline and Lampinen, Airi},
title = {Invisibility or Visibility in Intimate Care at the Workplace? Examining the Use of Breast Pumps},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581411},
doi = {10.1145/3544548.3581411},
abstract = {Advances in intimate care technologies and on-body wearables are disrupting how and where we think about and care for our bodies. The boundaries between private and public are increasingly porous. This offers new sites for studying intimate care as technology-use-in-practice. We present a qualitative study on the use of breast pumps in the workplace, based on semi-structured interviews with 19 individuals. Through this, we contribute an illustration of the complexities in carrying out intimate care work at the workplace and what it means to be pumping at the workplace. Our analysis unpacks (in)visibility as a crucial tension in the use of breast pumps in the workplace. We discuss how (in)visibility of personal medical devices plays a mediating role in how individuals exercise bodily rights, and the norms of who fits into professional settings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {213},
numpages = {15},
keywords = {Body, breastfeeding, breast pumps, intimate care, invisibility, visibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581157,
author = {Ramakers, Raf and Leen, Danny and Kim, Jeeeun and Luyten, Kris and Houben, Steven and Veuskens, Tom},
title = {Measurement Patterns: User-Oriented Strategies for Dealing with Measurements and Dimensions in Making Processes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581157},
doi = {10.1145/3544548.3581157},
abstract = {The majority of errors in making processes can be tracked back to errors in dimensional specifications. While technical aspects of measurement, such as precision and speed have been extensively studied in metrology, the user aspects of measurement received significantly less attention. While little research exists that specifically addresses the user aspects of handling dimensions, various systems have been built that embed new interactive modalities, processes, and techniques which significantly impact how users deal with dimensions or conduct measurements. However, these features are mostly hidden in larger system contributions. To uncover and articulate these techniques, we conducted a holistic literature survey on measurement practices in crafting techniques and systems for rapid prototyping. Based on this survey, we contribute &nbsp;10&nbsp;measurement patterns, which describe reusable elements and solutions for common difficulties when dealing with dimensions throughout workflows for making physical artifacts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {214},
numpages = {17},
keywords = {Fabrication, Making, Measurement, Patterns},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581466,
author = {Wen, Xiaolin and Wang, Yong and Yue, Xuanwu and Zhu, Feida and Zhu, Min},
title = {NFTDisk: Visual Detection of Wash Trading in NFT Markets},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581466},
doi = {10.1145/3544548.3581466},
abstract = {With the growing popularity of Non-Fungible Tokens (NFT), a new type of digital assets, various fraudulent activities have appeared in NFT markets. Among them, wash trading has become one of the most common frauds in NFT markets, which attempts to mislead investors by creating fake trading volumes. Due to the sophisticated patterns of wash trading, only a subset of them can be detected by automatic algorithms, and manual inspection is usually required. We propose NFTDisk, a novel visualization for investors to identify wash trading activities in NFT markets, where two linked visualization modules are presented: a radial visualization module with a disk metaphor to overview NFT transactions and a flow-based visualization module to reveal detailed NFT flows at multiple levels. We conduct two case studies and an in-depth user interview with 14 NFT investors to evaluate NFTDisk. The results demonstrate its effectiveness in exploring wash trading activities in NFT markets.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {215},
numpages = {15},
keywords = {Wash Trading, Fintech, Visual Analytics, Non-Fungible Token},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581298,
author = {Del Valle, Ashley and Toka, Mert and Aponte, Alejandro and Jacobs, Jennifer},
title = {PunchPrint: Creating Composite Fiber-Filament Craft Artifacts by Integrating Punch Needle Embroidery and 3D Printing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581298},
doi = {10.1145/3544548.3581298},
abstract = {New printing strategies have enabled 3D-printed materials that imitate traditional textiles. These filament-based textiles are easy to fabricate but lack the look and feel of fiber textiles. We seek to augment 3D-printed textiles with needlecraft to produce composite materials that integrate the programmability of additive fabrication with the richness of traditional textile craft. We present PunchPrint: a technique for integrating fiber and filament in a textile by combining punch needle embroidery and 3D printing. Using a toolpath that imitates textile weave structure, we print a flexible fabric that provides a substrate for punch needle production. We evaluate our material’s robustness through tensile strength and needle compatibility tests. We integrate our technique into a parametric design tool and produce functional artifacts that show how PunchPrint broadens punch needle craft by reducing labor in small, detailed artifacts, enabling the integration of openings and multiple yarn weights, and scaffolding soft 3D structures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {216},
numpages = {15},
keywords = {Punch Needle Embroidery, 3D Printing, Textile Craft},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581455,
author = {Huq, Syed Fatiul and Alshayban, Abdulaziz and He, Ziyao and Malek, Sam},
title = {#A11yDev: Understanding Contemporary Software Accessibility Practices from Twitter Conversations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581455},
doi = {10.1145/3544548.3581455},
abstract = {It is crucial to make software, with its ever-growing influence on everyday lives, accessible to all, including people with disabilities. Despite promoting software accessibility through government regulations, development guidelines, tools and frameworks, investigations reveal a marketplace of inaccessible web and mobile applications. To better understand the limitations of contemporary software industry in adopting accessibility practices, it is necessary to construct a holistic view that combines the perspectives of software practitioners, stakeholders and end users. In this paper, we collect 637 conversations from Twitter to synthesize and qualitatively analyze discussions posted about software accessibility. Our findings observe an active community that provides feedback on inaccessible software, shares personal accounts of development practices and advocates for inclusivity. By perceiving software accessibility from process, profession and people viewpoints, we present current conventions, challenges and possible resolutions with four emergent themes: cost and incentives, awareness and advocacy, technology and resources, and integration and inclusion.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {217},
numpages = {18},
keywords = {human factors of software engineering, software accessibility, qualitative study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580844,
author = {Lang, Florian and Pues, Verena and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {BrailleBuddy: A Tangible User Interface to Support Children with Visual Impairment in Learning Braille},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580844},
doi = {10.1145/3544548.3580844},
abstract = {Learning to read Braille is crucial to academic success for people with blindness or severe visual impairment. In our work, we investigate how we can support early learning of Braille with tangible computing. In a human-centered inclusive design process with interviews, six design iterations with prototypes, and feedback from experts, students, and teachers, we created BrailleBuddy. BrailleBuddy is a tangible user interface supporting children with visual impairments in learning Braille. We evaluated BrailleBuddy in a user study with children with blindness. Our results show that BrailleBuddy provides intrinsic motivation for learning Braille and can be used by children without supervision. BrailleBuddy complements the educational program as it allows children to play with and explore Braille characters at their own pace, thus lowering the challenge of learning to read Braille. In addition, an open-source toolkit is provided to enable educators and researchers to support individual requirements.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {218},
numpages = {14},
keywords = {Tangible User Interface, Learning, Children, Braille, Blind, Visual Impairment, Low Vision},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581401,
author = {Ellis, Kirsten and Kruesi, Lisa and Ananthanarayan, Swamy and Senaratne, Hashini and Lindsay, Stephen},
title = {"Piece It Together": Insights from One Year of Engagement with Electronics and Programming for People with Intellectual Disabilities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581401},
doi = {10.1145/3544548.3581401},
abstract = {We present the results of one year spent engaging people living with intellectual disabilities with an electronics and programming package. The program was run in collaboration with a disability support organization and delivered by support workers. We evaluate key qualities of the package at three sites via ongoing communication and reflective interviews with five support workers, along with observation of sessions and contextual inquiry with eleven people with a range of disabilities. Our findings demonstrate the importance of physicality in enabling experiences by creating real-world analogues and supporting diverse group interactions; how groups support members’ attention, motivating each other, and allow space for coping mechanisms; and participants’ growing confidence and creativity in problem solving, and the emergence of self-directed activities. We discuss the importance of diverse repetition for skill development, how skills develop over the year, and pragmatic lessons for conducting a long-term research program with a disability support organization.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {219},
numpages = {17},
keywords = {making, intellectual disability, toolkits, Accessibility, tangibles},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580698,
author = {Saha, Abir and McHugh, Thomas Barlow and Piper, Anne Marie},
title = {Tutoria11y: Enhancing Accessible Interactive Tutorial Creation by Blind Audio Producers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580698},
doi = {10.1145/3544548.3580698},
abstract = {Audio production is a skilled practice that requires mastery in highly complex software and hardware tools. Blind audio producers face a steep learning curve where they must learn multiple inaccessible audio production tools in conjunction with workarounds for screen reader support. Learning audio production is made even more challenging due to a scarcity of educational resources geared towards blind people. Grounded in formative interviews and observations with seven blind audio production instructors, we developed Tutoria11y, an extension for GarageBand to support blind audio producers in creating accessible, interactive tutorials that screen reader users can follow to receive step-by-step guidance and confirmation of their actions. Findings from design exploration sessions with five blind instructors highlight how Tutoria11y can support tutorial creation and augment tutorial playback for blind audio producers. We discuss how we can rethink technology’s role as a means to amplify, rather than replace, the knowledge of disabled experts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {220},
numpages = {14},
keywords = {interactive tutorial, blind, screen reader, vision impairment, audio production, accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581533,
author = {Nourian, Laleh and Shinohara, Kristen and Tigwell, Garreth W.},
title = {Understanding Discussions Around Culture Within Courses Covering Topics on Accessibility and Disability at U.S. Universities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581533},
doi = {10.1145/3544548.3581533},
abstract = {Teaching accessibility is essential in training technologists and designers. However, the topics of accessibility and disability are vast and intersect with culture (social constructions). Since cultural background is an influential factor in design decisions, which could have implications for accessible design, we wanted to understand whether and how courses at U.S. institutions address the importance of cultural influences when teaching accessibility and disability topics. We surveyed 72 students from U.S. institutions and ran 14 follow-up interviews with students who took technical and non-technical courses. Using reflexive thematic analysis, we found similarities and differences in how technical and non-technical courses approach accessibility teaching. We found a lack of cultural focus in accessibility teaching in the technical courses, which can be improved by adopting teaching approaches from non-technical courses. We also make recommendations to improve course design, such as including people from different cultures and disabilities to help develop courses.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {221},
numpages = {14},
keywords = {Culture, Disability Studies, Accessibility Education},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581213,
author = {Wang, Ru and Zeng, Linxiu and Zhang, Xinyong and Mondal, Sanbrita and Zhao, Yuhang},
title = {Understanding How Low Vision People Read Using Eye Tracking},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581213},
doi = {10.1145/3544548.3581213},
abstract = {While being able to read with screen magnifiers, low vision people have slow and unpleasant reading experiences. Eye tracking has the potential to improve their experience by recognizing fine-grained gaze behaviors and providing more targeted enhancements. To inspire gaze-based low vision technology, we investigate the suitable method to collect low vision users’ gaze data via commercial eye trackers and thoroughly explore their challenges in reading based on their gaze behaviors. With an improved calibration interface, we collected the gaze data of 20 low vision participants and 20 sighted controls who performed reading tasks on a computer screen; low vision participants were also asked to read with different screen magnifiers. We found that, with an accessible calibration interface and data collection method, commercial eye trackers can collect gaze data of comparable quality from low vision and sighted people. Our study identified low vision people’s unique gaze patterns during reading, building upon which, we propose design implications for gaze-based low vision technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {222},
numpages = {17},
keywords = {low vision, gaze pattern, eye tracking, reading, Accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580658,
author = {McConvey, Kelly and Guha, Shion and Kuzminykh, Anastasia},
title = {A Human-Centered Review of Algorithms in Decision-Making in Higher Education},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580658},
doi = {10.1145/3544548.3580658},
abstract = {The use of algorithms for decision-making in higher education is steadily growing, promising cost-savings to institutions and personalized service for students but also raising ethical challenges around surveillance, fairness, and interpretation of data. To address the lack of systematic understanding of how these algorithms are currently designed, we reviewed an extensive corpus of papers proposing algorithms for decision-making in higher education. We categorized them based on input data, computational method, and target outcome, and then investigated the interrelations of these factors with the application of human-centered lenses: theoretical, participatory, or speculative design. We found that the models are trending towards deep learning, and increased use of student personal data and protected attributes, with the target scope expanding towards automated decisions. However, despite the associated decrease in interpretability and explainability, current development predominantly fails to incorporate human-centered lenses. We discuss the challenges with these trends and advocate for a human-centered approach.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {223},
numpages = {15},
keywords = {Literature Review, Higher Education, Human-Centered Machine Learning, Artificial Intelligence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581129,
author = {Angelucci, Margherita and Marshall, Harrison and Tebourbi, Meriem and Seguin, Joshua Paolo and Varghese, Delvin and Olivier, Patrick and Bartindale, Tom},
title = {Action Translate: Supporting Students in Translation Volunteering},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581129},
doi = {10.1145/3544548.3581129},
abstract = {University students are well known for volunteering within non-governmental organisations (NGOs). A significant part of NGO practice is the production of documents that communicate their work to local communities and international stakeholders. However, organisations often struggle to resource translations of these documents, resulting in the exclusion of the very same communities that they want to reach. Although many students are multilingual and are willing to volunteer their time and language skills, there are few structured opportunities configured for such non-professional translation of content in the short-term mode that would fit into the student pattern of availability. We developed Action Translate to specifically support these motivated, non-professional translators within the volunteering constraints of university life. Action Translate leverages machine translation post-editing to support teams of volunteers working on NGO translation projects online. Through analysis of a real-world deployment, we discuss how digital systems can be developed to better support student volunteer translators, specifically in building collegiate interaction and identity as translators for a cause.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {224},
numpages = {14},
keywords = {machine translation, volunteering, translation, post-editing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580907,
author = {Petridis, Savvas and Diakopoulos, Nicholas and Crowston, Kevin and Hansen, Mark and Henderson, Keren and Jastrzebski, Stan and Nickerson, Jeffrey V and Chilton, Lydia B},
title = {AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580907},
doi = {10.1145/3544548.3580907},
abstract = {News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {225},
numpages = {16},
keywords = {Ideation, Large Language Models, Generative AI, Journalism, Brainstorming},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580999,
author = {Gmeiner, Frederic and Yang, Humphrey and Yao, Lining and Holstein, Kenneth and Martelaro, Nikolas},
title = {Exploring Challenges and Opportunities to Support Designers in Learning to Co-Create with AI-Based Manufacturing Design Tools},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580999},
doi = {10.1145/3544548.3580999},
abstract = {AI-based design tools are proliferating in professional software to assist engineering and industrial designers in complex manufacturing and design tasks. These tools take on more agentic roles than traditional computer-aided design tools and are often portrayed as “co-creators.” Yet, working effectively with such systems requires different skills than working with complex CAD tools alone. To date, we know little about how engineering designers learn to work with AI-based design tools. In this study, we observed trained designers as they learned to work with two AI-based tools on a realistic design task. We find that designers face many challenges in learning to effectively co-create with current systems, including challenges in understanding and adjusting AI outputs and in communicating their design goals. Based on our findings, we highlight several design opportunities to better support designer-AI co-creation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {226},
numpages = {20},
keywords = {team learning, think-aloud study, computational co-creation, generative AI, group cognition, human-AI collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581118,
author = {Bartle, Vince and Albright, Liam and Dell, Nicola},
title = {"This Machine is for the Aides": Tailoring Voice Assistant Design to Home Health Care Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581118},
doi = {10.1145/3544548.3581118},
abstract = {This paper explores how the design of interactive voice assistants (IVAs) might be tailored to support home health aides’ important work in complex home care contexts. We designed two custom IVAs: one that looks like an aide’s medical kit and one that blends into the home environment. We also designed a voice-based application that provides aides with guidance for day-to-day tasks and for performing a medical assessment. Via a lab-based study with 25 aides and seven patients, we explore how tailoring the IVAs’ design to home health care might impact its acceptability as a work device, enabling cooperative work among aides and clients, while potentially causing conflict that will require IVA designers to decide whose values to prioritize. We also highlight limits in aides’ power to control IVAs in clients’ homes. Finally, we discuss implications for designing privacy-preserving IVAs, including leveraging IVAs’ physical design to enact privacy mechanisms and opportunities to build ‘always on’ IVAs for privacy-sensitive contexts like home health care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {227},
numpages = {19},
keywords = {Interactive Voice Assistant, Home Care Context, Digital Health, Technology Probes, Internet of Things},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581542,
author = {Atreja, Shubham and Srinath, Shruthi and Jain, Mohit and Pal, Joyojeet},
title = {Understanding Journalists’ Workflows in News Curation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581542},
doi = {10.1145/3544548.3581542},
abstract = {With the increasing dominance of internet as a source of news consumption, there has been a rise in the production and popularity of email newsletters compiled by individual journalists. However, there is little research on the processes of aggregation, and how these differ between expert journalists and trained machines. In this paper, we interviewed journalists who curate newsletters from around the world. Through an in-depth understanding of journalists’ workflows, our findings lay out the role of their prior experience in the value they bring into the curation process, their own use of algorithms in finding stories for their newsletter, and their internalization of their readers’ interests and the context they are curating for. While identifying the role of human expertise, we highlight the importance of hybrid curation and provide design insights on how technology can support the work of these experts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {228},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580735,
author = {Vyas, Preeti and Desai, Unma Mayur and Yamakawa, Karin and Maclean, Karon},
title = {A Descriptive Analysis of a Formative Decade of Research in Affective Haptic System Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580735},
doi = {10.1145/3544548.3580735},
abstract = {The global pandemic exposed serious drawbacks in relying on communication modalities in which social touch, however important, is absent. Considerable research has explored haptic technologies for sensing or displaying social touch and influencing affective state, for wellness, social communication, emotion regulation, and affect therapy. However, this Affective Haptic System design (AHSD)&nbsp;work varies widely in purpose and origin discipline, making it difficult to perceive overall progress and identify primary obstacles to practical deployment. We conducted a scoping review and conceptual analysis with a design lens, identifying 110 papers from the last decade in 11 ACM and IEEE venues that regularly attract AHSD&nbsp;work. Our analysis identified 38 dimensions within 8 facets: demographic, theoretical grounding, impact, system specification, usage specification, ethical consideration, technology, and evaluation. We visualize trends, disciplinary mixing, and topical focus over time, and highlight major advances while pinning down crucial gaps that can be addressed in the future.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {229},
numpages = {23},
keywords = {Emotion/Affective Computing, Touch/Haptic/Pointing/Gesture, Content Analysis, Meta-Analysis/Literature Survey, Affective Haptics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581467,
author = {Gupta, Aakar and Sendhilnathan, Naveen and Hartcher-O'Brien, Jess and Pezent, Evan and Benko, Hrvoje and Jonker, Tanya R.},
title = {Investigating Eyes-Away Mid-Air Typing in Virtual Reality Using Squeeze Haptics-Based Postural Reinforcement},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581467},
doi = {10.1145/3544548.3581467},
abstract = {In this paper, we investigate postural reinforcement haptics for mid-air typing using squeeze actuation on the wrist. We propose and validate eye-tracking based objective metrics that capture the impact of haptics on the user’s experience, which traditional performance metrics like speed and accuracy are not able to capture. To this end, we design four wrist-based haptic feedback conditions: no haptics, vibrations on keypress, squeeze+vibrations on keypress, and squeeze posture reinforcement + vibrations on keypress. We conduct a text input study with 48 participants to compare the four conditions on typing and gaze metrics. Our results show that for expert qwerty users, posture reinforcement haptics significantly benefit typing by reducing the visual attention on the keyboard by up to 44% relative to no haptics, thus enabling eyes-away behaviors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {230},
numpages = {11},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580668,
author = {Kocur, Martin and Jackermeier, Lukas and Schwind, Valentin and Henze, Niels},
title = {The Effects of Avatar and Environment on Thermal Perception and Skin Temperature in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580668},
doi = {10.1145/3544548.3580668},
abstract = {Humans’ thermal regulation and subjective perception of temperature is highly plastic and depends on the visual appearance of the surrounding environment. Previous work shows that an environment’s color temperature affects the experienced temperature. As virtual reality (VR) enables visual immersion, recent work suggests that a VR scene’s color temperature also affects experienced temperature. It is, however, unclear if an avatar’s appearance also affects users’ thermal perception and if a change in thermal perception even influences the body temperature. Therefore, we conducted a study with 32 participants performing a task in an ice or fire world while having ice or fire hands. We show that being in a fire world or having fire hands increases the perceived temperature. We even show that having fire hands decreases the hand temperature compared to having ice hands. We discuss the implications for the design of VR systems and future research directions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {231},
numpages = {15},
keywords = {virtual reality, embodiment, skin temperature, thermal perception},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581079,
author = {Medeiros, Daniel and Wilson, Graham and Mcgill, Mark and Brewster, Stephen Anthony},
title = {The Benefits of Passive Haptics and Perceptual Manipulation for Extended Reality Interactions in Constrained Passenger Spaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581079},
doi = {10.1145/3544548.3581079},
abstract = {Extended Reality (XR) technology brings exciting possibilities for aeroplane passengers, allowing them to escape their limited cabin space. Using nearby physical surfaces enables a connection with the real world while improving the XR experience through touch. However, available surfaces may be located in awkward positions, reducing comfort and input performance and thus limiting their long-term use. We explore the usability of passive haptic surfaces in different orientations, assessing their effects on input performance, user experience and comfort. We then overcome ergonomic issues caused by the confined space by using perceptual manipulation techniques that remap the position and rotation of physical surfaces and user movements, assessing their effects on task workload, comfort and presence. Our results show that the challenges posed by constrained seating environments can be overcome by a combination of passive haptics and remapping the workspace with moderate translation and rotation manipulations. These manipulations allow for good input performance, low workload and comfortable interaction, opening up XR use while in transit.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {232},
numpages = {19},
keywords = {aeroplane, selection, 3D User Interfaces, passive haptics, airplane, Virtual Reality, confined spaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581165,
author = {Buruk, O\u{g}uz 'Oz' and Matjeka, Louise Petersen and Mueller, Florian ‘Floyd’},
title = {Towards Designing Playful Bodily Extensions: Learning from Expert Interviews},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581165},
doi = {10.1145/3544548.3581165},
abstract = {Interactive technologies offer novel opportunities for physically extending our bodies, with the most prominent examples being prosthetics along with systems emerging from the wearables community. However, most such systems appear to focus on instrumental benefits, missing out on the opportunity to use bodily extensions for play and its associated benefits (including a lower adoption barrier and the potential to reveal a broader understanding of such technologies). To begin understanding the design of playful bodily extensions, we interviewed five designers of bodily extensions that have been showcased in prestigious academic venues or turned into commercial products. Here we present themes and actionable advice from these interviews for the design of playful bodily extensions through a thematic analysis. Our work aims to support the design of future playful bodily extensions while promoting the experiential qualities of bodily extension design, with the ultimate goal of bringing more playful experiences to people’s lives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {233},
numpages = {20},
keywords = {Thematic Analysis, Transhuman, Bodily Extensions, Expert Interviews, Cyborg, Wearables, Posthuman, Play, Games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581557,
author = {M\"{u}ller, Florian and Ye, Arantxa and Sch\"{o}n, Dominik and Rasch, Julian},
title = {UndoPort: Exploring the Influence of Undo-Actions for Locomotion in Virtual Reality on the Efficiency, Spatial Understanding and User Experience},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581557},
doi = {10.1145/3544548.3581557},
abstract = {When we get lost in Virtual Reality (VR) or want to return to a previous location, we use the same methods of locomotion for the way back as for the way forward. This is time-consuming and requires additional physical orientation changes, increasing the risk of getting tangled in the headsets’ cables. In this paper, we propose the use of undo actions to revert locomotion steps in VR. We explore eight different variations of undo actions as extensions of point&amp;teleport, based on the possibility to undo position and orientation changes together with two different visualizations of the undo step (discrete and continuous). We contribute the results of a controlled experiment with 24 participants investigating the efficiency and orientation of the undo techniques in a radial maze task. We found that the combination of position and orientation undo together with a discrete visualization resulted in the highest efficiency without increasing orientation errors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {234},
numpages = {15},
keywords = {Virtual Reality, Teleport, Undo, Locomotion},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581437,
author = {Yu, Lilith and Gao, Chenfeng and Wu, David and Nakagaki, Ken},
title = {AeroRigUI: Actuated TUIs for Spatial Interaction Using Rigging Swarm Robots on Ceilings in Everyday Space},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581437},
doi = {10.1145/3544548.3581437},
abstract = {We present AeroRigUI, an actuated tangible UI for 3D spatial embodied interaction. Using strings controlled by self-propelled swarm robots with a reeling mechanism on ceiling surfaces, our approach enables rigging (control through strings) physical objects’ position and orientation in the air. This can be applied to novel interactions in 3D space, including dynamic physical affordances, 3D information displays, and haptics. Utilizing the ceiling, an often underused room area, AeroRigUI can be applied for a range of applications such as room organization, data physicalization, and animated expressions. We demonstrate the applications based on our proof-of-concept prototype, which includes the hardware design of the rigging robots, named RigBots, and the software design for mid-air object control via interactive string manipulation. We also introduce technical evaluation and analysis of our approach prototype to address the hardware feasibility and safety. Overall, AeroRigUI enables a novel spatial and tangible UI system with great controllability and deployability.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {235},
numpages = {18},
keywords = {Spatial User Interface Display, Actuated Tangible User Interface, Human Robot Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581081,
author = {Doggett, Olivia and Bronson, Kelly and Soden, Robert},
title = {HCI Research on Agriculture: Competing Sociotechnical Imaginaries, Definitions, and Opportunities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581081},
doi = {10.1145/3544548.3581081},
abstract = {Agriculture is foundational for food security on our planet. Considering climate change and other pressures on food production, HCI scholars have increasingly begun to examine how the field should approach agricultural innovation. We conducted a literature review of HCI research through the lens of competing future visions for good food systems : a “conventional” vision of profit-oriented production, and an “alternative” which prioritizes sustainability and community-led practices. Leveraging the concept of sociotechnical imaginaries, we provide an empirical analysis of how HCI and adjacent applied computing projects align with these competing visions for agriculture. This review reveals, amongst other findings, a prioritization of the perspectives of the Global North and a need for more careful attention to the constraints and aspirations of subsistence farmers. Finally, we note the limits of the conventional-alternative binary that shapes much of contemporary HCI research focused on agriculture and offer opportunities for transcending this framing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {236},
numpages = {24},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581493,
author = {Comber, Rob and Rossitto, Chiara},
title = {Regulating Responsibility: Environmental Sustainability, Law, and the Platformisation of Waste Management},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581493},
doi = {10.1145/3544548.3581493},
abstract = {The scope of Sustainable HCI research is expanding to include the broad sociotechnical and ecological contexts of computing. We examine the intersection of environmental sustainability, technology, and the law. By studying the legal dispute between a platform service that facilitates crowd-sourced waste disposal and the local government’s regulation of waste management, we step through an evolving debate on the meaning of care and responsibility for the environment. When faced with the municipality’s claimed monopoly on responsibility for waste management, the platform argues for the paradigms of individual responsibility, designing for user needs, and personalised and on-demand digital services. In arguing against this framing, the municipality highlights the gap between the law, its interpretation, and the idealistic values of technology-driven environmental care. We contribute to the framing of environmental care within Sustainable HCI as a locally constructed, regulated, and contested aspect of technology design and appropriation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {237},
numpages = {19},
keywords = {law, environmental sustainability, regulation, waste management, platform economy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580675,
author = {Mohanty, Vikram and Filipowicz, Alexandre L. S. and Bravo, Nayeli Suseth and Carter, Scott and Shamma, David A.},
title = {Save A Tree or 6 Kg of CO2? Understanding Effective Carbon Footprint Interventions for Eco-Friendly Vehicular Choices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580675},
doi = {10.1145/3544548.3580675},
abstract = {From ride-hailing to car rentals, consumers are often presented with eco-friendly options. Beyond highlighting a “green” vehicle and CO2 emissions, CO2 equivalencies have been designed to provide understandable amounts; we ask which equivalencies will lead to eco-friendly decisions. We conducted five ride-hailing scenario surveys where participants picked between regular and eco-friendly options, testing equivalencies, social features, and valence-based interventions. Further, we tested a car-rental embodiment to gauge how an individual (needing a car for several days) might behave versus the immediate ride-hailing context. We find that participants are more likely to choose green rides when presented with additional information about emissions; CO2 by weight was found to be the most effective. Further, we found that information framing—be it individual or collective footprint, positive or negative valence—had an impact on participants’ choices. Finally, we discuss how our findings inform the design of effective interventions for reducing car-based carbon-emissions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {238},
numpages = {24},
keywords = {Eco-Feedback, Ride Hailing, Design Interventions, CO2 Emissions, Electric Vehicles, Carbon Neutrality, Carbon Emissions, Behavioral Science, Ridesharing, Automobiles},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581568,
author = {Dillahunt, Tawanna R and Sawwan, Michelle and Wood, Danielle and Wimer, Brianna L and Conrado, Ann-Marie and Eicher-Miller, Heather and Gura, Alisa Zornig and Metoyer, Ronald},
title = {Understanding Food Planning Strategies of Food Insecure Populations: Implications for Food-Agentic Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581568},
doi = {10.1145/3544548.3581568},
abstract = {To identify technological opportunities to better support nutrition security and equality among those living in low-socioeconomic situations, we conducted 33 semi-structured interviews and seven in-home visits of lower- to middle-income households from a mid-sized city in northern Indiana. Inspired by assets-based approaches to public health, we investigated technology’s role in supporting how participants selected and purchased food, planned meals, and worked through logistical barriers to obtain food. Technology helped participants identify sales and coupons, search for recipes and health-related insights to address diet and health concerns, and share information. We contribute design implications (e.g., amplifying optimization behaviors and social engagement, leveraging substitutions) in support of food agency. We further contribute three emergent archetypes to convey central shopping tendencies (i.e., inventory shoppers, menu planners, and adaptive shoppers) and identify corresponding design implications. We situate our results into nutrition decision-making and education, social psychology, food consumer studies, and HCI literature.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {239},
numpages = {22},
keywords = {nutritional equality, food planning strategies, food (in)security, agency},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580744,
author = {Halperin, Brett A. and Lukin, Stephanie M.},
title = {Envisioning Narrative Intelligence: A Creative Visual Storytelling Anthology},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580744},
doi = {10.1145/3544548.3580744},
abstract = {In this paper, we collect an anthology of 100 visual stories from authors who participated in our systematic creative process of improvised story-building based on image sequences. Following close reading and thematic analysis of our anthology, we present five themes that characterize the variations found in this creative visual storytelling process: (1) Narrating What is in Vision vs. Envisioning; (2) Dynamically Characterizing Entities/Objects; (3) Sensing Experiential Information About the Scenery; (4) Modulating the Mood; (5) Encoding Narrative Biases. In understanding the varied ways that people derive stories from images, we offer considerations for collecting story-driven training data to inform automatic story generation. In correspondence with each theme, we envision narrative intelligence criteria for computational visual storytelling as: creative, reliable, expressive, grounded, and responsible. From these criteria, we discuss how to foreground creative expression, account for biases, and operate in the bounds of visual storyworlds.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {240},
numpages = {21},
keywords = {Story Generation, Visual Storytelling, Creativity, Narrative Intelligence, Bias, Crowdsourcing, Narrative Systems, Storytelling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581414,
author = {Shin, Jae-Eun and Woo, Woontack},
title = {How Space is Told: Linking Trajectory, Narrative, and Intent in Augmented Reality Storytelling for Cultural Heritage Sites},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581414},
doi = {10.1145/3544548.3581414},
abstract = {We report on a qualitative study in which 22 participants created Augmented Reality (AR) stories for outdoor cultural heritage sites. As storytelling is a crucial strategy for AR content aimed at providing meaningful experiences, the emphasis has been on what storytelling does, rather than how it is done, the end user’s needs prioritized over the author’s. To address this imbalance, we identify how recurring patterns in the spatial trajectories and narrative compositions of AR stories for cultural heritage sites are linked to the author’s intent and creative process: While authors tend to bind story arcs tightly to confined trajectories for narrative delivery, the need for spatial exploration results in thematic content mapped loosely onto encompassing trajectories. Based on our analysis, we present design recommendations for site-specific AR storytelling tools that can support authors in delivering their intent while leveraging the placeness of cultural heritage sites as a creative resource.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {241},
numpages = {14},
keywords = {Augmented Reality, Mixed Reality, cultural heritage, authoring tools, storytelling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581106,
author = {Ma, Renkai and Gui, Xinning and Kou, Yubo},
title = {Multi-Platform Content Creation: The Configuration of Creator Ecology through Platform Prioritization, Content Synchronization, and Audience Management},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581106},
doi = {10.1145/3544548.3581106},
abstract = {Online platforms like YouTube and Instagram have enabled the platformization and monetization of creative work, allowing content creators to derive revenue and thrive in a creator economy. While much work has been done to understand content creation on single platforms, the creative practice often involves content creators’ agency and practice to interact with multiple platforms and make strategic decisions to optimize such interactions. In this paper, we use an interview study with 21 cross-platform creators to understand how they negotiate with platforms in their creative practices through the construction of creator ecology. We found that participants developed priorities among platforms based on varied criteria, paid attention to cross-platform content synchronization, and stressed managing and converting audiences across platforms to grow their fanbase. Our findings highlight the complex interplay between creator agency and labor, as well as yield implications for future design possibilities of creator empowerment and support.&nbsp;},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {242},
numpages = {19},
keywords = {Multi-platform content creation, creative labor, platformization, creator ecology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580662,
author = {Mudd, Tom},
title = {Playing with Feedback: Unpredictability, Immediacy, and Entangled Agency in the No-Input Mixing Desk},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580662},
doi = {10.1145/3544548.3580662},
abstract = {Feedback is a process that is common in both acoustic and electronic musical instruments, but rare in digital musical tools or creative digital tools more generally. This paper examines the musical use of the ’no-input mixing desk’—or ’feedback mixer’, a sound mixing desk fed back on itself—to explore how and why feedback is appealing for musicians. Twenty interviews were conducted with musicians who have used no-input mixing desk in their practice. Thematic analysis is used to explore the interview data. Results highlight the enjoyment and creative fulfilment of working with systems that can’t be fully predicted or understood, a sense of gestural immediacy, sensitivity and tactility often perceived as lacking in digital instruments, and an affinity with acoustic instruments in terms of the scope for surprise and exploration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {243},
numpages = {11},
keywords = {performance, feedback, music technology, creative interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580649,
author = {Simpson, Ellen and Semaan, Bryan},
title = {Rethinking Creative Labor: A Sociotechnical Examination of Creativity &amp; Creative Work on TikTok},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580649},
doi = {10.1145/3544548.3580649},
abstract = {Social media platform success relies on users to consume, create, and share creative content. While some creatives aspire to become influencers, this is not the goal of all creatives, particularly those with smaller audiences. Through an interview study of 15 creatives on TikTok, we explore the often overlapping intentions for creating and sharing videos, as well as the challenges to maintaining these creative intentions and routines as they are shaped by platform logic. We find platforms introduce impediments which disrupt people’s creative routines and alienate people from their overlapping creative intentions; introducing challenges which alienate people from their sense of self, and their audiences. We construct a broader definition of creative labor - the work of professionalizing and monetizing a creative product shared on social media - reflecting on how the routine enactment of creative labor is impacted by infrastructural elements of technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {244},
numpages = {16},
keywords = {Infrastructure, Creativity, TikTok, Content Creation, Creative Labor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580782,
author = {Gero, Katy Ilonka and Long, Tao and Chilton, Lydia B},
title = {Social Dynamics of AI Support in Creative Writing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580782},
doi = {10.1145/3544548.3580782},
abstract = {Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer’s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {15},
keywords = {language models, human-AI collaboration, creative writing, writing assistants, writing support tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581376,
author = {Das Swain, Vedant and Gao, Lan and Wood, William A and Matli, Srikruthi C and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Algorithmic Power or Punishment: Information Worker Perspectives on Passive Sensing Enabled AI Phenotyping of Performance and Wellbeing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581376},
doi = {10.1145/3544548.3581376},
abstract = {We are witnessing an emergence in Passive Sensing enabled AI (PSAI) to provide dynamic insights for performance and wellbeing of information workers. Hybrid work paradigms have simultaneously created new opportunities for PSAI, but have also fostered anxieties of misuse and privacy intrusions within a power asymmetry. At this juncture, it is unclear if those who are sensed can find these systems acceptable. We conducted scenario-based interviews of 28 information workers to highlight their perspectives as data subjects in PSAI. We unpack their expectations using the Contextual Integrity framework of privacy and information gathering. Participants described appropriateness of PSAI based on its impact on job consequences, work-life boundaries, and preservation of flexibility. They perceived that PSAI inferences could be shared with selected stakeholders if they could negotiate the algorithmic inferences. Our findings help envision worker-centric approaches to implementing PSAI as an empowering tool in the future of work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {246},
numpages = {17},
keywords = {passive sensing, information work, worker wellbeing, human resource management, future of work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581082,
author = {Sun, Yuan and Song, Qiurong and Gui, Xinning and Ma, Fenglong and Wang, Ting},
title = {AutoML in The Wild: Obstacles, Workarounds, and Expectations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581082},
doi = {10.1145/3544548.3581082},
abstract = {Automated machine learning (AutoML) is envisioned to make ML techniques accessible to ordinary users. Recent work has investigated the role of humans in enhancing AutoML functionality throughout a standard ML workflow. However, it is also critical to understand how users adopt existing AutoML solutions in complex, real-world settings from a holistic perspective. To fill this gap, this study conducted semi-structured interviews of AutoML users (N = 19) focusing on understanding (1) the limitations of AutoML encountered by users in their real-world practices, (2) the strategies users adopt to cope with such limitations, and (3) how the limitations and workarounds impact their use of AutoML. Our findings reveal that users actively exercise user agency to overcome three major challenges arising from customizability, transparency, and privacy. Furthermore, users make cautious decisions about whether and how to apply AutoML on a case-by-case basis. Finally, we derive design implications for developing future AutoML solutions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {247},
numpages = {15},
keywords = {Automated Machine Learning, Transparency, Privacy, User Agency, Customizability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580945,
author = {Yuan, Chien Wen (Tina) and Bi, Nanyi and Lin, Ya-Fang and Tseng, Yuen-Hsien},
title = {Contextualizing User Perceptions about Biases for Human-Centered Explainable Artificial Intelligence},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580945},
doi = {10.1145/3544548.3580945},
abstract = {Biases in Artificial Intelligence (AI) systems or their results are one important issue that demands AI explainability. Despite the prevalence of AI applications, the general public are not necessarily equipped with the ability to understand how the black-box algorithms work and how to deal with biases. To inform designs for explainable AI (XAI), we conducted in-depth interviews with major stakeholders, both end-users (n = 24) and engineers (n = 15), to investigate how they made sense of AI applications and the associated biases according to situations of high and low stakes. We discussed users’ perceptions and attributions about AI biases and their desired levels and types of explainability. We found that personal relevance and boundaries as well as the level of stake are two major dimensions for developing user trust especially during biased situations and informing XAI designs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {248},
numpages = {15},
keywords = {Transparency, Human-Computer Interaction (HCI), AI bias, Human-Centered Computing, Explainable AI (XAI), Explainability, Artificial Intelligence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581278,
author = {Wang, Qiaosi and Madaio, Michael and Kane, Shaun and Kapania, Shivani and Terry, Michael and Wilcox, Lauren},
title = {Designing Responsible AI: Adaptations of UX Practice to Meet Responsible AI Challenges},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581278},
doi = {10.1145/3544548.3581278},
abstract = {Technology companies continue to invest in efforts to incorporate responsibility in their Artificial Intelligence (AI) advancements, while efforts to audit and regulate AI systems expand. This shift towards Responsible AI (RAI) in the tech industry necessitates new practices and adaptations to roles—undertaken by a variety of practitioners in more or less formal positions, many of whom focus on the user-centered aspects of AI. To better understand practices at the intersection of user experience (UX) and RAI, we conducted an interview study with industrial UX practitioners and RAI subject matter experts, both of whom are actively involved in addressing RAI concerns throughout the early design and development of new AI-based prototypes, demos, and products, at a large technology company. Many of the specific practices and their associated challenges have yet to be surfaced in the literature, and distilling them offers a critical view into how practitioners’ roles are adapting to meet present-day RAI challenges. We present and discuss three emerging practices in which RAI is being enacted and reified in UX practitioners’ everyday work. We conclude by arguing that the emerging practices, goals, and types of expertise that surfaced in our study point to an evolution in praxis, with associated challenges that suggest important areas for further research in HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {249},
numpages = {16},
keywords = {responsible AI, industry practice, interview, UX},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581001,
author = {Kim, Sunnie S. Y. and Watkins, Elizabeth Anne and Russakovsky, Olga and Fong, Ruth and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {"Help Me Help the AI": Understanding How Explainability Can Support Human-AI Interaction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581001},
doi = {10.1145/3544548.3581001},
abstract = {Despite the proliferation of explainable AI (XAI) methods, little is understood about end-users’ explainability needs and behaviors around XAI explanations. To address this gap and contribute to understanding how explainability can support human-AI interaction, we conducted a mixed-methods study with 20 end-users of a real-world AI application, the Merlin bird identification app, and inquired about their XAI needs, uses, and perceptions. We found that participants desire practically useful information that can improve their collaboration with the AI, more so than technical system details. Relatedly, participants intended to use XAI explanations for various purposes beyond understanding the AI’s outputs: calibrating trust, improving their task skills, changing their behavior to supply better inputs to the AI, and giving constructive feedback to developers. Finally, among existing XAI approaches, participants preferred part-based explanations that resemble human reasoning and explanations. We discuss the implications of our findings and provide recommendations for future XAI design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {250},
numpages = {17},
keywords = {Human-Centered XAI, Human-AI Collaboration, Human-AI Interaction, XAI for Computer Vision, Explainable AI (XAI), Interpretability, Local Explanations},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580903,
author = {Varanasi, Rama Adithya and Goyal, Nitesh},
title = {“It is Currently Hodgepodge”: Examining AI/ML Practitioners’ Challenges during Co-Production of Responsible AI Values},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580903},
doi = {10.1145/3544548.3580903},
abstract = {Recently, the AI/ML research community has indicated an urgent need to establish Responsible AI (RAI) values and practices as part of the AI/ML lifecycle. Several organizations and communities are responding to this call by sharing RAI guidelines. However, there are gaps in awareness, deliberation, and execution of such practices for multi-disciplinary ML practitioners. This work contributes to the discussion by unpacking co-production challenges faced by practitioners as they align their RAI values. We interviewed 23 individuals, across 10 organizations, tasked to ship AI/ML based products while upholding RAI norms and found that both top-down and bottom-up institutional structures create burden for different roles preventing them from upholding RAI values, a challenge that is further exacerbated when executing conflicted values. We share multiple value levers used as strategies by the practitioners to resolve their challenges. We end our paper with recommendations for inclusive and equitable RAI value-practices, creating supportive organizational structures and opportunities to further aid practitioners.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {251},
numpages = {17},
keywords = {RAI, co-production, FAT, accountability, fairness, Responsible AI, XAI, explainability, transparency, value levers, ethical AI, collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581423,
author = {Wagner, Uta and Lystb\ae{}k, Mathias N. and Manakhov, Pavel and Gr\o{}nb\ae{}k, Jens Emil Sloth and Pfeuffer, Ken and Gellersen, Hans},
title = {A Fitts’ Law Study of Gaze-Hand Alignment for Selection in 3D User Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581423},
doi = {10.1145/3544548.3581423},
abstract = {Gaze-Hand Alignment has recently been proposed for multimodal selection in 3D. The technique takes advantage of gaze for target pre-selection, as it naturally precedes manual input. Selection is then completed when manual input aligns with gaze on the target, without need for an additional click method. In this work we evaluate two alignment techniques, Gaze&amp;Finger and Gaze&amp;Handray, combining gaze with image plane pointing versus raycasting, in comparison with hands-only baselines and Gaze&amp;Pinch as established multimodal technique. We used Fitts’ Law study design with targets presented at different depths in the visual scene, to assess effect of parallax on performance. The alignment techniques outperformed their respective hands-only baselines. Gaze&amp;Finger is efficient when targets are close to the image plane but less performant with increasing target depth due to parallax.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {252},
numpages = {15},
keywords = {gaze interaction, menu selection, augmented reality, eye-tracking, mid-air gestures, pointing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581201,
author = {Hou, Baosheng James and Newn, Joshua and Sidenmark, Ludwig and Ahmad Khan, Anam and B\ae{}kgaard, Per and Gellersen, Hans},
title = {Classifying Head Movements to Separate Head-Gaze and Head Gestures as Distinct Modes of Input},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581201},
doi = {10.1145/3544548.3581201},
abstract = {Head movement is widely used as a uniform type of input for human-computer interaction. However, there are fundamental differences between head movements coupled with gaze in support of our visual system, and head movements performed as gestural expression. Both Head-Gaze and Head Gestures are of utility for interaction but differ in their affordances. To facilitate the treatment of Head-Gaze and Head Gestures as separate types of input, we developed HeadBoost as a novel classifier, achieving high accuracy in classifying gaze-driven versus gestural head movement (F1-Score: 0.89). We demonstrate the utility of the classifier with three applications: gestural input while avoiding unintentional input by Head-Gaze; target selection with Head-Gaze while avoiding Midas Touch by head gestures; and switching of cursor control between Head-Gaze for fast positioning and Head Gesture for refinement. The classification of Head-Gaze and Head Gesture allows for seamless head-based interaction while avoiding false activation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {253},
numpages = {14},
keywords = {XGBoost, Virtual Reality, Machine Learning, Head Gestures, Eye-head Coordination, Computational Interaction, Eye Tracking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580979,
author = {Tao, Yujie and Wang, Cheng Yao and Wilson, Andrew D and Ofek, Eyal and Gonzalez-Franco, Mar},
title = {Embodying Physics-Aware Avatars in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580979},
doi = {10.1145/3544548.3580979},
abstract = {Embodiment toward an avatar in virtual reality (VR) is generally stronger when there is a high degree of alignment between the user’s and self-avatar’s motion. However, one-to-one mapping between the two is not always ideal when user interacts with the virtual environment. On these occasions, the user input often leads to unnatural behavior without physical realism (e.g., objects penetrating virtual body, body unmoved by hitting stimuli). We investigate how adding physics correction to self-avatar motion impacts embodiment. Physics-aware self-avatar preserves the physical meaning of the movement but introduces discrepancies between the user’s and self-avatar’s motion, whose contingency is a determining factor for embodiment. To understand its impact, we conducted an in-lab study (n = 20) where participants interacted with obstacles on their upper bodies in VR with and without physics correction. Our results showed that, rather than compromising embodiment level, physics-responsive self-avatar improved embodiment compared to no-physics condition in both active and passive interactions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {254},
numpages = {15},
keywords = {Virtual Reality, Physics Avatars, Embodiment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581184,
author = {Muehlhaus, Marie and Koelle, Marion and Saberpour, Artin and Steimle, J\"{u}rgen},
title = {I Need a Third Arm! Eliciting Body-Based Interactions with a Wearable Robotic Arm},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581184},
doi = {10.1145/3544548.3581184},
abstract = {Wearable robotic arms (WRA) open up a unique interaction space that closely integrates the user’s body with an embodied robotic collaborator. This space affords diverse interaction styles, including body movement, hand gestures, or gaze. Yet, it is so-far unexplored which commands are desirable from a user perspective. Contributing findings from an elicitation study (N=14), we provide a comprehensive set of interactions for basic robot control, navigation, object manipulation, and emergency situations, performed when hands are free or occupied. Our study provides insights into preferred body parts, input modalities, and the users’ underlying sources of inspiration. Comparing interaction styles between WRAs and off-body robots, we highlight how WRAs enable a range of interactions specific for on-body robots and how users use WRAs both as tools and as collaborators. We conclude by providing guidance on the design of ad-hoc interaction with WRAs informed by user behavior.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {255},
numpages = {15},
keywords = {elicitation study., supernumerary limbs, gesture, artificial limbs, augmented arms, Wearable robotic arms, human-robot interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580888,
author = {Zenner, Andr\'{e} and Ullmann, Kristin and Ariza, Oscar and Steinicke, Frank and Kr\"{u}ger, Antonio},
title = {Induce a Blink of the Eye: Evaluating Techniques for Triggering Eye Blinks in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580888},
doi = {10.1145/3544548.3580888},
abstract = {As more and more virtual reality (VR) headsets support eye tracking, recent techniques started to use eye blinks to induce unnoticeable manipulations to the virtual environment, e.g., to redirect users’ actions. However, to exploit their full potential, more control over users’ blinking behavior in VR is required. To this end, we propose a set of reflex-based blink triggers that are suited specifically for VR. In accordance with blink-based techniques for redirection, we formulate (i) effectiveness, (ii) efficiency, (iii) reliability, and (iv) unobtrusiveness as central requirements for successful triggers. We implement the soft- and hardware-based methods and compare the four most promising approaches in a user study. Our results highlight the pros and cons of the tested triggers, and show those based on the menace, corneal, and dazzle reflexes to perform best. From these results, we derive recommendations that help choosing suitable blink triggers for VR applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {256},
numpages = {12},
keywords = {virtual reality, change blindness, eye blinks, blink triggers},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580685,
author = {Sidenmark, Ludwig and Clarke, Christopher and Newn, Joshua and Lystb\ae{}k, Mathias N. and Pfeuffer, Ken and Gellersen, Hans},
title = {Vergence Matching: Inferring Attention to Objects in 3D Environments for Gaze-Assisted Selection},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580685},
doi = {10.1145/3544548.3580685},
abstract = {Gaze pointing is the de facto standard to infer attention and interact in 3D environments but is limited by motor and sensor limitations. To circumvent these limitations, we propose a vergence-based motion correlation method to detect visual attention toward very small targets. Smooth depth movements relative to the user are induced on 3D objects, which cause slow vergence eye movements when looked upon. Using the principle of motion correlation, the depth movements of the object and vergence eye movements are matched to determine which object the user is focussing on. In two user studies, we demonstrate how the technique can reliably infer gaze attention on very small targets, systematically explore how different stimulus motions affect attention detection, and show how the technique can be extended to multi-target selection. Finally, we provide example applications using the concept and design guidelines for small target and accuracy-independent attention detection in 3D environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {257},
numpages = {15},
keywords = {Motion Correlation, Virtual Reality, Selection, Small Targets, Vergence, Gaze, Attention Detection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580871,
author = {Namnakani, Omar and Abdrabou, Yasmeen and Grizou, Jonathan and Esteves, Augusto and Khamis, Mohamed},
title = {Comparing Dwell Time, Pursuits and Gaze Gestures for Gaze Interaction on Handheld Mobile Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580871},
doi = {10.1145/3544548.3580871},
abstract = {Gaze is promising for hands-free interaction on mobile devices. However, it is not clear how gaze interaction methods compare to each other in mobile settings. This paper presents the first experiment in a mobile setting that compares three of the most commonly used gaze interaction methods: Dwell time, Pursuits, and Gaze gestures. In our study, 24 participants selected one of 2, 4, 9, 12 and 32 targets via gaze while sitting and while walking. Results show that input using Pursuits is faster than Dwell time and Gaze gestures especially when there are many targets. Users prefer Pursuits when stationary, but prefer Dwell time when walking. While selection using Gaze gestures is more demanding and slower when there are many targets, it is suitable for contexts where accuracy is more important than speed. We conclude with guidelines for the design of gaze interaction on handheld mobile devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {258},
numpages = {17},
keywords = {Smooth pursuit, Gaze-based Interaction, Eye Tracking, Smartphones, Tablets},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580769,
author = {Yang, Xingyu and Zhu, Kening},
title = {Emoband: Investigating the Affective Perception towards On-Wrist Stroking and Squeezing Feedback Mediated by Different Textile Materials},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580769},
doi = {10.1145/3544548.3580769},
abstract = {This paper investigates how different textile materials on the wrist bands may mediate the affective experience of two forms of tactile icons, namely stroking and squeezing. To this end, we designed Emoband, a wrist-worn textile-based tactile display that can stroke or squeeze on wearers’ wrists through the moving fabrics. We conducted two studies on the participants’ valence and arousal ratings towards the stroking and squeezing feedback from Emoband, respectively. Results showed that the valence ratings were significantly affected by the stroking or squeezing parameters and the wristband’s material, interactively. The movement-related parameters dominated the arousal rating. Meanwhile, the valence ratings demonstrated different tendencies between the two tactile feedback, with the valence increasing and decreasing along with the strength of stroking and squeezing, respectively. Besides, the valence ratings of the stroking stimuli demonstrated varied distributions across different materials, indicating the materials’ varying affective expressiveness in the wrist-worn haptic devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {259},
numpages = {20},
keywords = {material, wearables, tactile feedback, affect, textile display},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581514,
author = {Anwar, Ahmed and Shi, Tianzheng and Schneider, Oliver},
title = {Factors of Haptic Experience across Multiple Haptic Modalities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581514},
doi = {10.1145/3544548.3581514},
abstract = {Haptic Experience (HX) is a proposed set of quality criteria useful to haptics, with prior evidence for a 5-factor model with vibrotactile feedback. We report on an ongoing process of scale development to measure HX, and explore whether these criteria hold when applied to more diverse devices, including vibrotactile, force feedback, surface haptics, and mid-air haptics. From an in-person user study with 430 participants, exploratory factor analysis (EFA), and confirmatory factor analysis (CFA), we extract an 11-item and 4-factor model (Realism, Harmony, Involvement, Expressivity) with only a partial overlap to the previous model. We compare this model to the previous vibrotactile model, finding that the new 4-factor model is more generalized and can guide attributes or applications of new haptic systems. Our findings suggest that HX may vary depending on the modalities used in an application, but these four factors are general constructs that might overlap with modality-specific concepts of HX. These factors can inform designers about the right quality criteria to use when designing or evaluating haptic experiences for multiple modalities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {260},
numpages = {12},
keywords = {Haptics, User experience design, Scale Development, HCI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580830,
author = {Steer, Cameron and Dinca, Teodora and Jicol, Crescent and Proulx, Michael J and Alexander, Jason},
title = {Feel the Force, See the Force: Exploring Visual-Tactile Associations of Deformable Surfaces with Colours and Shapes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580830},
doi = {10.1145/3544548.3580830},
abstract = {Deformable interfaces provide unique interaction potential for force input, for example, when users physically push into a soft display surface. However, there remains limited understanding of which visual-tactile design elements signify the presence and stiffness of such deformable force-input components. In this paper, we explore how people correspond surface stiffness to colours, graphical shapes, and physical shapes. We conducted a cross-modal correspondence (CC) study, where 30 participants associated different surface stiffnesses with colours and shapes. Our findings evidence the CCs between stiffness levels for a subset of the 2D/3D shapes and colours used in the study. We distil our findings in three design recommendations: (1) lighter colours should be used to indicate soft surfaces, and darker colours should indicate stiff surfaces; (2) rounded shapes should be used to indicate soft surfaces, while less-curved shapes should be used to indicate stiffer surfaces, and; (3) longer 2D drop-shadows should be used to indicate softer surfaces, while shorter drop-shadows should be used to indicate stiffer surfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {261},
numpages = {13},
keywords = {Force, Crossmodal Correspondences, Touch, Colour, Multisensory Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580924,
author = {Saad, Alia and Izadi, Kian and Ahmad Khan, Anam and Knierim, Pascal and Schneegass, Stefan and Alt, Florian and Abdelrahman, Yomna},
title = {HotFoot: Foot-Based User Identification Using Thermal Imaging},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580924},
doi = {10.1145/3544548.3580924},
abstract = {We propose a novel method for seamlessly identifying users by combining thermal and visible feet features. While it is known that users’ feet have unique characteristics, these have so far been underutilized for biometric identification, as observing those features often requires the removal of shoes and socks. As thermal cameras are becoming ubiquitous, we foresee a new form of identification, using feet features and heat traces to reconstruct the footprint even while wearing shoes or socks. We collected a dataset of users’ feet (N = 21), wearing three types of footwear (personal shoes, standard shoes, and socks) on three floor types (carpet, laminate, and linoleum). By combining visual and thermal features, an AUC between 91.1% and 98.9%, depending on floor type and shoe type can be achieved, with personal shoes on linoleum floor performing best. Our findings demonstrate the potential of thermal imaging for continuous and unobtrusive user identification.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {262},
numpages = {13},
keywords = {Thermal Imaging, Footprint, User identification},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581172,
author = {Kalus, Alexander and Kocur, Martin and Klein, Johannes and Mayer, Manuel and Henze, Niels},
title = {PumpVR: Rendering the Weight of Objects and Avatars through Liquid Mass Transfer in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581172},
doi = {10.1145/3544548.3581172},
abstract = {Perceiving objects’ and avatars’ weight in Virtual Reality (VR) is important to understand their properties and naturally interact with them. However, commercial VR controllers cannot render weight. Controllers presented by previous work are single-handed, slow, or only render a small mass. In this paper, we present PumpVR that renders weight by varying the controllers’ mass according to the properties of virtual objects or bodies. Using a bi-directional pump and solenoid valves, the system changes the controllers’ absolute weight by transferring water in or out with an average error of less than 5%. We implemented VR use cases with objects and avatars of different weights to compare the system with standard controllers. A study with 24 participants revealed significantly higher realism and enjoyment when using PumpVR to interact with virtual objects. Using the system to render body weight had significant effects on virtual embodiment, perceived exertion, and self-perceived fitness.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {263},
numpages = {13},
keywords = {haptic controllers, weight perception, virtual embodiment, virtual reality, weight interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580745,
author = {Bourgault, Samuelle and Wiley, Pilar and Farber, Avi and Jacobs, Jennifer},
title = {CoilCAM: Enabling Parametric Design for Clay 3D Printing Through an Action-Oriented Toolpath Programming System},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580745},
doi = {10.1145/3544548.3580745},
abstract = {Clay 3D printing provides the benefits of digital fabrication automation and reconfigurability through a method that evokes manual clay coiling. Existing design technologies for clay 3D printing reflect the general 3D printing workflow in which solid forms are designed in CAD and then converted into a toolpath. In contrast, in hand-coiling, form is determined by the actions taken by the artist’s hands through space in response to the material. We theorized that an action-oriented approach for clay 3D printing could allow creators to design digital fabrication toolpaths that reflect clay material properties. We present CoilCAM, a domain-specific CAM programming system that supports the integrated generation of parametric forms and surface textures through mathematically defined toolpath operations. We developed CoilCAM in collaboration with ceramics professionals and evaluated CoilCAM’s relevance to manual ceramics by reinterpreting hand-made ceramic vessels. This process revealed the importance of iterative variation and embodied experience in action-oriented workflows.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {264},
numpages = {16},
keywords = {Digital Fabrication, Artist Residency, Clay 3D Printing, Computer-Aided Machining},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581235,
author = {Kar, Pragma and Singh, Shyamvanshikumar and Mandal, Avijit and Chattopadhyay, Samiran and Chakraborty, Sandip},
title = {ExpresSense: Exploring a Standalone Smartphone to Sense Engagement of Users from Facial Expressions Using Acoustic Sensing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581235},
doi = {10.1145/3544548.3581235},
abstract = {Facial expressions have been considered a metric reflecting a person’s engagement with a task. While the evolution of expression detection methods is consequential, the foundation remains mostly on image processing techniques that suffer from occlusion, ambient light, and privacy concerns. In this paper, we propose ExpresSense, a lightweight application for standalone smartphones that relies on near-ultrasound acoustic signals for detecting users’ facial expressions. ExpresSense has been tested on different users in lab-scaled and large-scale studies for both posed as well as natural expressions. By achieving a classification accuracy of over various basic expressions, we discuss the potential of a standalone smartphone to sense expressions through acoustic sensing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {265},
numpages = {18},
keywords = {engagement, smartphone, assistive system, expressions, Acoustic sensing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580728,
author = {Seifi, Hasti and Chew, Sean and Nasc\`{e}, Antony James and Lowther, William Edward and Frier, William and Hornb\ae{}k, Kasper},
title = {Feellustrator: A Design Tool for Ultrasound Mid-Air Haptics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580728},
doi = {10.1145/3544548.3580728},
abstract = {Ultrasound mid-air haptic technology provides a large space of design possibilities, as one can modulate the ultrasound intensity in a continuous 3D space at a high speed over time. Yet, the need for programming the patterns limits rapid ideation and testing of alternatives. We present Feellustrator, a graphical design tool for quickly creating and editing ultrasound mid-air haptics. With Feellustrator, one can create custom ultrasound patterns, layer or sequence them into complex effects, project them on the user’s hand, and export them for use in external programs (e.g., Unity). To create the tool, we interviewed 13 designers who had from a few months to several years of experience with ultrasound, then derived a set of requirements for supporting ultrasound design. We demonstrate the design power of Feellustrator through example applications and an evaluation with 15 participants. Then, we outline future directions for ultrasound haptic design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {266},
numpages = {16},
keywords = {ultrasound technology, tool requirements, mid-air haptics design tool, interviews},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581499,
author = {Leake, Mackenzie and Jin, Kathryn and Davis, Abe and Mueller, Stefanie},
title = {InStitches: Augmenting Sewing Patterns with Personalized Material-Efficient Practice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581499},
doi = {10.1145/3544548.3581499},
abstract = {There is a rapidly growing group of people learning to sew online. Without hands-on instruction, these learners are often left to discover the challenges and pitfalls of sewing through trial and error, which can be a frustrating and wasteful process. We present InStitches, a software tool that augments existing sewing patterns with targeted practice tasks to guide users through the skills needed to complete their chosen project. InStitches analyzes the difficulty of sewing instructions relative to a user’s reported expertise in order to determine where practice will be helpful and then solves for a new pattern layout that incorporates additional practice steps while optimizing for efficient use of available materials. Our user evaluation indicates that InStitches can successfully identify challenging sewing tasks and augment existing sewing patterns with practice tasks that users find helpful, showing promise as a tool for helping those new to the craft.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {267},
numpages = {14},
keywords = {Deliberate practice, Personalized tutorials, Sewing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580639,
author = {Sethapakdi, Ticha and Huang, Laura and Chan, Vivian Hsinyueh and Cheng, Lung-Pan and Dall'Agnol, Fernando Fuzinatto and Leake, Mackenzie and Mueller, Stefanie},
title = {Polagons: Designing and Fabricating Polarized Light Mosaics with User-Defined Color-Changing Behaviors},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580639},
doi = {10.1145/3544548.3580639},
abstract = {Polarized light mosaics (PLMs) are color-changing structures that alter their appearance based on the orientation of incident polarized light. While a few artists have developed techniques for crafting PLMs by hand, the underlying material properties are difficult to reason about; there exist no tools to bridge the high-level design objectives with the low-level physics knowledge needed to create PLMs. In this paper, we introduce the first system for creating Polagons: machine-made PLMs crafted from cellophane with user-defined color changing behaviors. Our system includes an interface for designing and visualizing Polagons as well as a fabrication process based on laser cutting and welding that requires minimal assembly by the user. We define the design space for Polagons and demonstrate how formalizing the process for creating PLMs can enable new applications in fields such as education, data visualization, and fashion.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {14},
keywords = {optics, programmable materials, fabrication, design tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580693,
author = {Chaffangeon Caillet, Adrien and Goguey, Alix and Nigay, Laurence},
title = {µGlyph: A Microgesture Notation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580693},
doi = {10.1145/3544548.3580693},
abstract = {In the active field of hand microgestures, microgesture descriptions are typically expressed informally and are accompanied by images, leading to ambiguities and contradictions. An important step in moving the field forward is a rigorous basis for precisely describing, comparing, and analyzing microgestures. Towards this goal, we propose µGlyph, a hybrid notation based on a vocabulary of events inspired by finger biomechanics. First, we investigate the expressiveness of µGlyph by building a database of 118 microgestures extracted from the literature. Second, we experimentally explore the usability of µGlyph. Participants correctly read and wrote µGlyph descriptions 90% of the time, as compared to 46% for conventional descriptions. Third we present tools that promote µGlyph usage, including a visual editor with LaTeX export. We finally describe how µGlyph can guide research on designing, developing, and evaluating microgesture interaction. Results demonstrate the strong potential of µGlyph to establish a common ground for microgesture research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {269},
numpages = {28},
keywords = {Notation, Microgesture},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581061,
author = {Yang, Chi-Lan and Yoshida, Shigeo and Kuzuoka, Hideaki and Narumi, Takuji and Yamashita, Naomi},
title = {Affective Profile Pictures: Exploring the Effects of Changing Facial Expressions in Profile Pictures on Text-Based Communication},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581061},
doi = {10.1145/3544548.3581061},
abstract = {When receiving text messages from unacquainted colleagues in fully remote workplaces, insufficient mutual understanding and limited social cues can lead people to misinterpret the tone of the message and further influence their impression of remote colleagues. Emojis have been commonly used for supporting expressive communication; however, people seldom use emojis before they become acquainted with each other. Hence, we explored how changing facial expressions in profile pictures could be an alternative channel to communicate socio-emotional cues. By conducting an online controlled experiment with 186 participants, we established that changing facial expressions of profile pictures can influence the impression of the message receivers toward the sender and the message valence when receiving neutral messages. Furthermore, presenting incongruent profile pictures to positive messages negatively affected the interpretation of the message valence, but did not have much effect on negative messages. We discuss the implications of affective profile pictures in supporting text-based communication.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {17},
keywords = {message interpretation, impression formation, Text-based communication, affective communication, computer-mediated communication, social cues},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580932,
author = {Liu, Chengzhong and Zhou, Shixu and Liu, Dingdong and Li, Junze and Huang, Zeyu and Ma, Xiaojuan},
title = {CoArgue : Fostering Lurkers’ Contribution to Collective Arguments in Community-Based QA Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580932},
doi = {10.1145/3544548.3580932},
abstract = {In Community-Based Question Answering (CQA) platforms, people can participate in discussions about non-factoid topics by marking their stances, providing premises, or arguing for the opinions they support, which forms “collective arguments”. The sustainable development of collective arguments relies on a big contributor base, yet most of the frequent CQA users are lurkers who seldom speak out. With a formative study, we identified detailed obstacles preventing lurkers from contributing to collective arguments. We consequently designed a processing pipeline for extracting and summarizing augmentative elements from question threads. Based on this we built CoArgue, a tool with navigation and chatbot features to support CQA lurkers’ motivation and ability in making contributions. Through a within-subject study (N=24), we found that, compared to a Quora-like baseline, participants perceived CoArgue as significantly more useful in enhancing their motivation and ability to join collective arguments and found the experience to be more engaging and productive.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {17},
keywords = {Collective Arguments, Lurker Support, CQA Platforms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581325,
author = {Guo, Ge and Leshed, Gilly and Green, Keith Evan},
title = {“I Normally Wouldn’t Talk with Strangers”: Introducing a Socio-Spatial Interface for Fostering Togetherness Between Strangers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581325},
doi = {10.1145/3544548.3581325},
abstract = {Interacting with strangers can be beneficial but also challenging. Fortunately, these challenges can lead to design opportunities. In this paper, we present the design and evaluation of a socio-spatial interface, SocialStools, that leverages the human propensity for embodied interaction to foster togetherness between strangers. SocialStools is an installation of three responsive stools on caster wheels that generate sound and imagery in the near environment as three strangers sit on them, move them, and rotate them relative to each other. In our study with 12 groups of three strangers, we found a sense of togetherness emerged through interaction, evidenced by different patterns of socio-spatial movements, verbal communication, non-verbal behavior, and interview responses. We present our findings, articulate reasons for the cultivation of togetherness, consider the unique social affordances of our spatial interface in shifting attention during interpersonal communication, and provide design implications. This research contributes insights toward designing cyber-physical interfaces that foster interaction and togetherness among strangers at a time when cultivating togetherness is especially critical.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {272},
numpages = {20},
keywords = {Socio-Spatial Interface, Mixed Reality, Proxemics, Small Groups, Embodied Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581135,
author = {Zhang, Alex Wuqi and Lin, Ting-Han and Zhao, Xuan and Sebo, Sarah},
title = {Ice-Breaking Technology: Robots and Computers Can Foster Meaningful Connections between Strangers through In-Person Conversations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581135},
doi = {10.1145/3544548.3581135},
abstract = {Despite the clear benefits that social connection offers to well-being, strangers in close physical proximity regularly ignore each other due to their tendency to underestimate the positive consequences of social connection. In a between-subjects study (N = 49 pairs, 98 participants), we investigated the effectiveness of a humanoid robot, a computer screen, and a poster at stimulating meaningful, face-to-face conversations between two strangers by posing progressively deeper questions. We found that the humanoid robot facilitator was able to elicit the greatest compliance with the deep conversation questions. Additionally, participants in conversations facilitated by either the humanoid robot or the computer screen reported greater happiness and connection to their conversation partner than those in conversations facilitated by a poster. These results suggest that technology-enabled conversation facilitators can be useful in breaking the ice between strangers, ultimately helping them develop closer connections through face-to-face conversations and thereby enhance their overall well-being.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {273},
numpages = {14},
keywords = {Social Connection, Technology-Mediated Conversations, Human-Computer Interaction, Human-Robot Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581195,
author = {He, Changyang and He, Lu and Lu, Zhicong and Li, Bo},
title = {Seeking Love and Companionship through Streaming: Unpacking Livestreamer-Moderated Senior Matchmaking in China},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581195},
doi = {10.1145/3544548.3581195},
abstract = {Livestreamer-moderated matchmaking has gained wide popularity among the elderly population in China. Compared to algorithm-mediated online dating, it is characterized by (1) the mediation of matchmakers in a synchronous virtual environment and (2) the natural development of livestreaming-based matchmaking communities. Nonetheless, how these new features influence single seniors’ match-seeking remains unknown. To fill this research gap, we conduct a qualitative study consisting of observations and semi-structured interviews with 6 livestreaming matchmakers and 12 senior match-seekers (age: 50-70). We uncover matchmakers’ mediation roles during and beyond livestreaming to facilitate seniors’ match-seeking, and their additional duties to enhance seniors’ safety in this process. Livestreaming-based matchmaking communities afford multiple important values for single seniors to acquire companionship and help in seeking late-life love. We unpack the perceived benefits and challenges of livestreamer-moderated matchmaking, and discuss how to support single seniors’ match-seeking in an accessible, safe, and convenient manner.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {274},
numpages = {18},
keywords = {romantic relationships, online matchmaking technologies, live streaming, computer-mediated communication, single seniors},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581243,
author = {Maddali, Hanuma Teja and Lazar, Amanda},
title = {Understanding Context to Capture When Reconstructing Meaningful Spaces for Remote Instruction and Connecting in XR},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581243},
doi = {10.1145/3544548.3581243},
abstract = {Recent technological advances are enabling HCI researchers to explore interaction possibilities for remote XR collaboration using high-fidelity reconstructions of physical activity spaces. However, creating these reconstructions often lacks user involvement with an overt focus on capturing sensory context that does not necessarily augment an informal social experience. This work seeks to understand social context that can be important for reconstruction to enable XR applications for informal instructional scenarios. Our study involved the evaluation of an XR remote guidance prototype by 8 intergenerational groups of closely related gardeners using reconstructions of personally meaningful spaces in their gardens. Our findings contextualize physical objects and areas with various motivations related to gardening and detail perceptions of XR that might affect the use of reconstructions for remote interaction. We discuss implications for user involvement to create reconstructions that better translate real-world experience, encourage reflection, incorporate privacy considerations, and preserve shared experiences with XR as a medium for informal intergenerational activities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {18},
keywords = {Extended Reality, 3D reconstruction, gardening, intergenerational study, remote instruction, contextual capture, hobby activities, metaverse},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581309,
author = {Feng, Li and Xiong, Zeyu and Li, Xinyi and Fan, Mingming},
title = {CoPracTter: Toward Integrating Personalized Practice Scenarios, Timely Feedback and Social Support into An Online Support Tool for Coping with Stuttering in China},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581309},
doi = {10.1145/3544548.3581309},
abstract = {Stuttering is a speech disorder influencing over 70 million people worldwide, including 13 million in China. It causes low self-esteem among other detrimental effects on people who stutter (PwS). Although prior work has explored approaches to assist PwS, they primarily focused on western contexts. In our formative study, we found unique practices and challenges among Chinese PwS. We then iteratively designed an online tool, CoPracTter, to support Chinese PwS practicing speaking fluency with 1) targeted stress-inducing practice scenarios, 2) real-time speech indicators, and 3) personalized timely feedback from the community. We further conducted a seven-day deployment study (N=11) to understand how participants utilized these key features. To our knowledge, it is the first time such a prototype was designed and tested for a long time with multiple PwS participants online simultaneously. Results indicate that personalized practice with targeted scenarios and timely feedback from a supportive community assisted PwS in speaking fluently, staying positive, and facing similar real-life circumstances.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {15},
keywords = {Accessibility, People who stutter, Field Study, Assistive Technology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580980,
author = {Cruz, Stefany and Redding, Alexander and Chau, Connie W. and Lu, Claire and Persche, Julia and Hester, Josiah and Jacobs, Maia},
title = {EquityWare: Co-Designing Wearables With And For Low Income Communities In The U.S.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580980},
doi = {10.1145/3544548.3580980},
abstract = {Wearables are a potentially vital mechanism for individuals to monitor their health, track behaviors, and stay connected. Unfortunately, both price and a lack of consideration of the needs of low-SES communities have made these devices inaccessible and unusable for communities that would most substantially benefit from their affordances. To address this gap and better understand how members of low-SES communities perceive the potential benefits and barriers to using wearable devices, we conducted 19 semi-structured interviews with people from minority, high crime rate, low-SES communities. Participants emphasized a critical need for safety-related wearable devices in their communities. Still, existing tools do not yet address the specific needs of this community and are out of reach due to several barriers. We distill themes on perceived useful features and ongoing obstacles to guide a much-needed research agenda we term ’Equityware’: building wearable devices based on low-SES communities’ needs, comfortability, and limitations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {277},
numpages = {18},
keywords = {interviews, Low-socioeconomic status, Wearables, Neighborhoods, Safety, Crime, Co-design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581084,
author = {Hui, Julie and King, Jesse and Mcleod, Cynthia and Gonzales, Amy},
title = {High Risk, High Reward: Social Networking Online in Under-Resourced Communities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581084},
doi = {10.1145/3544548.3581084},
abstract = {Expanding one’s social network has been associated with greater access to resources and social support. However, little is known about how under-resourced populations decide to make new connections online and under what circumstances. We interviewed 36 low-income individuals to understand these decisions and found that people make new connections in order to seek advice and exchange support, particularly around coping with challenges more prevalent in under-resourced settings. However, participants were sometimes dissuaded from making new connections online due to fear of being scammed and hesitance around the social norms of reaching out to people outside their network. We discuss how people in under-resourced contexts grapple with ‘high risk yet high reward’ social networking and outline implications for supporting safe and purposeful network development among under-resourced SNS users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {278},
numpages = {12},
keywords = {Social networking sites, Social capital, Low-income, under-resourced, Weak ties, Social media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580934,
author = {Glick, Peter and Crivellaro, Clara},
title = {MyCareBudget: Co-Creating a Healthcare Digital Commons with and for Disabled Citizens and Their Unpaid Carers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580934},
doi = {10.1145/3544548.3580934},
abstract = {Supporting disabled populations and their unpaid carers through designing sustainable healthcare interventions and infrastructures, is an important, yet challenging, area in HCI research. We report on a collaboration with 23 disabled citizens, unpaid carers, and a care organisation, wishing to co-develop digital responses to challenges they face in the management of self-directed care budgets. We describe how leveraging participatory methods, including asynchronous and remote engagements, enabled the co-creation of a sustainable digital common-pool resource, used by over 5,000 people worldwide. This study contributes novel configurations of methods and tools for co-design with ‘seldom heard’ populations. Demonstrating how these enabled the collective articulation of what constitutes trust, governance, and responsibility, in the design of a digital commons, “MyCareBudget”, offering peer-produced care documents for use by disabled citizens and their unpaid carers. We discuss implications for HCI interested in co-designing sustainable socio-technical interventions with underserved and marginalised populations, in healthcare settings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {279},
numpages = {16},
keywords = {Action Research, Participatory Design, sustainability, self-directed care budgets, disability, healthcare, Personal Health Budgets, unpaid carers, digital commons, wiki},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581138,
author = {Reynolds-Cu\'{e}llar, Pedro and Wong-Villacres, Marisol and Badillo-Urquiola, Karla and Barrera Machuca, Mayra Donaji and Cibrian, Franceli L. and Ciolfi Felice, Marianela and Fuentes, Carolina and Gayt\'{a}n-Lugo, Laura Sanely and Genaro Motti, Vivian and Perusquia-Hernandez, Monica and Lemus, Oscar A},
title = {Para Cima y Pa’ Abajo: Building Bridges Between HCI Research in Latin America and in the Global North},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581138},
doi = {10.1145/3544548.3581138},
abstract = {The Human-computer Interaction (HCI) community has the opportunity to foster the integration of research practices across the Global South and North to begin overcoming colonial relationships. In this paper, we focus on the case of Latin America (LATAM), where initiatives to increase the representation of HCI practitioners lack a consolidated understanding of the practices they employ, the factors that influence them, and the challenges that practitioners face. To address this knowledge gap, we employ a mixed-methods approach, comprising a survey (66 respondents) and in-depth interviews (19 interviewees). Our analyses characterize a set of research perspectives on how HCI is practiced in/about LATAM; a set of driving forces and tensions with a heavy reliance on diasporic dynamics; and a set of professional demands and associated structural limitations. We also offer a roadmap towards building connections across HCI communities, in an attempt to rebuild HCI as a pluriverse.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {280},
numpages = {19},
keywords = {HCI, Latin America, social justice, development},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581114,
author = {Stein, Jake M L and Vizgirda, Vidminas and Van Kleek, Max and Binns, Reuben and Zhao, Jun and Zhao, Rui and Goel, Naman and Chalhoub, George and Albayaydh, Wael S and Shadbolt, Nigel},
title = {‘You Are You and the App. There’s Nobody Else.’: Building Worker-Designed Data Institutions within Platform Hegemony},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581114},
doi = {10.1145/3544548.3581114},
abstract = {Information asymmetries create extractive, often harmful relationships between platform workers (e.g., Uber or Deliveroo drivers) and their algorithmic managers. Recent HCI studies have put forward more equitable platform designs but leave open questions about the social and technical infrastructures required to support them without the cooperation of platforms. We conducted a participatory design study in which platform workers deconstructed and re-imagined Uber’s schema for driver data. We analyzed the data structures and social institutions participants proposed, focusing on the stakeholders, roles, and strategies for mitigating conflicting interests of privacy, personal agency, and utility. Using critical theory, we reflected on the capability of participatory design to generate bottom-up collective data infrastructures. Based on the plurality of alternative institutions participants produced and their aptitude to navigate data stewardship decisions, we propose user-configurable tools for lightweight data institution building, as an alternative to redesigning existing platforms or delegating control to centralized trusts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {281},
numpages = {26},
keywords = {Participatory Design, Empirical study that tells us about how people use a system, Workplaces, Personal Data/Tracking, Critical/Activism/Ethics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581358,
author = {Maslych, Mykola and Taranta, Eugene Matthew and Aldilati, Mostafa and Laviola, Joseph J.},
title = {Effective 2D Stroke-Based Gesture Augmentation for RNNs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581358},
doi = {10.1145/3544548.3581358},
abstract = {Recurrent neural networks (RNN) require large training datasets from which they learn new class models. This limitation prohibits their use in custom gesture applications where only one or two end user samples are given per gesture class. One common way to enhance sparse datasets is to use data augmentation to synthesize new samples. Although there are numerous known techniques, they are often treated as standalone approaches when in reality they are often complementary. We show that by intelligently chaining augmentation techniques together that simulate different gesture production variability types, such as those affecting the temporal and spatial qualities of a gesture, we can significantly increase RNN accuracy without sacrificing training time. Through experimentation on four public stroke-based 2D gesture datasets, we show that RNNs trained with our data augmentation chaining technique achieves state-of-the-art recognition accuracy in both writer-dependent and writer-independent test scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {282},
numpages = {13},
keywords = {neural networks, data augmentation, datasets, gesture recognition and customization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581042,
author = {Wei, Yushi and Shi, Rongkai and Yu, Difeng and Wang, Yihong and Li, Yue and Yu, Lingyun and Liang, Hai-Ning},
title = {Predicting Gaze-Based Target Selection in Augmented Reality Headsets Based on Eye and Head Endpoint Distributions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581042},
doi = {10.1145/3544548.3581042},
abstract = {Target selection is a fundamental task in interactive Augmented Reality (AR) systems. Predicting the intended target of selection in such systems can provide users with a smooth, low-friction interaction experience. Our work aims to predict gaze-based target selection in AR headsets with eye and head endpoint distributions, which describe the probability distribution of eye and head 3D orientation when a user triggers a selection input. We first conducted a user study to collect users’ eye and head behavior in a gaze-based pointing selection task with two confirmation mechanisms (air tap and blinking). Based on the study results, we then built two models: a unimodal model using only eye endpoints and a multimodal model using both eye and head endpoints. Results from a second user study showed that the pointing accuracy is improved by approximately 32% after integrating our models into gaze-based selection techniques.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {283},
numpages = {14},
keywords = {Augmented reality, selection modeling, eye input, target selection, error prediction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581028,
author = {Mo, George B and Kristensson, Per Ola},
title = {Relative Design Acquisition: A Computational Approach for Creating Visual Interfaces to Steer User Choices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581028},
doi = {10.1145/3544548.3581028},
abstract = {A central objective in computational design is that an optimal design is desired which optimizes a performance metric. We explore a different problem class with a computational approach we call relative design acquisition. As a motivational example, consider a user prompted to make a choice using buttons. One button may have a more visually appealing design and hence is visually optimal to steer users to click it more often than the second button. In such a design case, a relative design is acquired of a certain quality with respect to a reference design to guide a user decision. After mathematically formalizing this problem, we report the results of three experiments that demonstrate the approach’s efficacy in generating relative designs in a visual interface preference setting. The relative designs are controllable by a quality factor, which affects both comparative ratings and human decision time between the reference and relative designs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {284},
numpages = {17},
keywords = {Interface Design, Computational Interaction, Bayesian Optimization, Human-in-the-Loop},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581096,
author = {Jiang, Yue and Leiva, Luis A. and Rezazadegan Tavakoli, Hamed and R. B. Houssel, Paul and Kylm\"{a}l\"{a}, Julia and Oulasvirta, Antti},
title = {UEyes: Understanding Visual Saliency across User Interface Types},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581096},
doi = {10.1145/3544548.3581096},
abstract = {While user interfaces (UIs) display elements such as images and text in a grid-based layout, UI types differ significantly in the number of elements and how they are displayed. For example, webpage designs rely heavily on images and text, whereas desktop UIs tend to feature numerous small images. To examine how such differences affect the way users look at UIs, we collected and analyzed a large eye-tracking-based dataset, UEyes (62 participants and 1,980 UI screenshots), covering four major UI types: webpage, desktop UI, mobile UI, and poster. We analyze its differences in biases related to such factors as color, location, and gaze direction. We also compare state-of-the-art predictive models and propose improvements for better capturing typical tendencies across UI types. Both the dataset and the models are publicly available.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {285},
numpages = {21},
keywords = {Eye Tracking, Deep Learning, Computer Vision, Interaction Design, Human Perception and Cognition},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581158,
author = {Wu, Jason and Wang, Siyan and Shen, Siman and Peng, Yi-Hao and Nichols, Jeffrey and Bigham, Jeffrey P},
title = {WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581158},
doi = {10.1145/3544548.3581158},
abstract = {Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {286},
numpages = {14},
keywords = {Computer Vision, UI Modeling, Dataset, Web Semantics, Computational Interaction, Transfer Learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581279,
author = {Chu, Jeremy and An, Dongsheng and Ma, Yan and Cui, Wenzhe and Zhai, Shumin and Gu, Xianfeng David and Bi, Xiaojun},
title = {WordGesture-GAN: Modeling Word-Gesture Movement with Generative Adversarial Network},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581279},
doi = {10.1145/3544548.3581279},
abstract = {Word-gesture production models that can synthesize word-gestures are critical to the training and evaluation of word-gesture keyboard decoders. We propose WordGesture-GAN, a conditional generative adversarial network that takes arbitrary text as input to generate realistic word-gesture movements in both spatial (i.e., (x, y) coordinates of touch points) and temporal (i.e., timestamps of touch points) dimensions. WordGesture-GAN&nbsp;introduces a Variational Auto-Encoder to extract and embed variations of user-drawn gestures into a Gaussian distribution which can be sampled to control variation in generated gestures. Our experiments on a dataset with 38k gesture samples show that WordGesture-GAN&nbsp;outperforms existing gesture production models including the minimum jerk model&nbsp;[37] and the style-transfer GAN&nbsp;[31, 32] in generating realistic gestures. Overall, our research demonstrates that the proposed GAN structure can learn variations in user-drawn gestures, and the resulting WordGesture-GAN&nbsp;can generate word-gesture movement and predict the distribution of gestures. WordGesture-GAN&nbsp;can serve as a valuable tool for designing and evaluating gestural input systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {287},
numpages = {15},
keywords = {Touch/Haptic/Pointing/Gesture, Machine Learning, Word-Gesture Input, Mobile Devices: Phones/Tablets},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581510,
author = {Mella, Jon and Iacovides, Ioanna and Cox, Anna L},
title = {Gaming for Post-Work Recovery: The Role of Immersion},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581510},
doi = {10.1145/3544548.3581510},
abstract = {Playing digital games can be an effective means of recovering from daily work strain. However, limited research has examined which player experiences contribute to this process, limiting the ability of players to select games and play them in a manner which helps them recover effectively. Hence, this paper reports a mixed-methods survey study investigating how a recent post-work recovery episode was impacted by immersion: a player experience which has been implicated in theoretical accounts relating games and recovery. We found that particular dimensions of immersion, such as cognitive involvement, support specific post-work recovery needs. Moreover, participants report not only experiencing benefits in a passive manner, but actively optimising their levels of immersion to achieve recovery. This study extends previous research by improving our understanding of how digital games support post-work recovery and by demonstrating that immersion is key in determining the restorative potential of digital games.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {288},
numpages = {15},
keywords = {Immersion, Player Experience, Digital Games, Post-Work Recovery, Restorative Play},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580702,
author = {Gon\c{c}alves, David and Pi\c{c}arra, Manuel and Pais, Pedro and Guerreiro, Jo\~{a}o and Rodrigues, Andr\'{e}},
title = {"My Zelda Cane": Strategies Used by Blind Players to Play Visual-Centric Digital Games},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580702},
doi = {10.1145/3544548.3580702},
abstract = {Mainstream games are typically designed around the visual experience, with behaviors and interactions highly dependent on vision. Despite this, blind people are playing mainstream games while dealing with and overcoming inaccessible content, often together with friends and audiences. In this work, we analyze over 70 hours of YouTube videos, where blind content-creators play visual-centric games. We point out the various strategies employed by players to overcome barriers that permeate mainstream games. We reflect on ways to enable and improve blind players’ experience with these games, shedding light on the positive and negative consequences of apparently benign design choices. Our observations underline how game elements are appropriated for accessibility, the incidental consequences of audio design, and the trade-offs between accessibility, agency, and engagement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {289},
numpages = {15},
keywords = {accessibility, digital games, gaming, navigation, blind},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581441,
author = {Ashby, Trevor and Webb, Braden K and Knapp, Gregory and Searle, Jackson and Fulda, Nancy},
title = {Personalized Quest and Dialogue Generation in Role-Playing Games: A Knowledge Graph- and Language Model-Based Approach},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581441},
doi = {10.1145/3544548.3581441},
abstract = {Procedural content generation (PCG) in video games offers unprecedented opportunities for customization and user engagement. Working within the specialized context of role-playing games (RPGs), we introduce a novel framework for quest and dialogue generation that places the player at the core of the generative process. Drawing on a hand-crafted knowledge base, our method grounds generated content with in-game context while simultaneously employing a large-scale language model to create fluent, unique, accompanying dialogue. Through human evaluation, we confirm that quests generated using this method can approach the performance of hand-crafted quests in terms of fluency, coherence, novelty, and creativity; demonstrate the enhancement to the player experience provided by greater dynamism; and provide a novel, automated metric for the relevance between quest and dialogue. We view our contribution as a critical step toward dynamic, co-creative narrative frameworks in which humans and AI systems jointly collaborate to create unique and user-specific playable experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {290},
numpages = {20},
keywords = {English, MMORPG, NPC dialogue, World of Warcraft, narrative, human-AI co-creativity, language model, transformers, quest, text generation, large-scale language models, dynamic quest generation, knowledge-grounded text generation, procedural content generation, knowledge graph, GPT-2, RPG, computational creativity, natural language processing, human-computer interaction, video games, quests},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580960,
author = {Kosa, Mehmet and Bowman, Nicholas David},
title = {Replication and Extension of Video Game Demand Scale with a Turkish-Speaking Gamer Population},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580960},
doi = {10.1145/3544548.3580960},
abstract = {The current study is designed to replicate and validate the video game demand scale (VGDS) as a metric for understanding player experiences in video games, while also expanding the application space of that scale to an underrepresented population. Using available materials from prior VGDS research, we created the Video Game Demand Scale-Turkish (VGDS-T). The translated metric was administered online to a volunteer sample of self-identified Turkish-speaking gamers (N = 184), where participants answered questions about perceived cognitive, emotional, exertional, controller, and social demands of their most recent game, as well as other game evaluations (as validation checks). Confirmatory factor analysis showed that the translated five-factor scale was a strong fit to the original 26-item scale (VGDS-English) with nominally stronger fit for a 22-item scale (VGDS-Mandarin). Therefore, we both validated the five-factor VGDS on a novel population and provided a translated the metric for researcher and industry use with Turkish-speaking gamers.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {291},
numpages = {11},
keywords = {scale development, user experience, video games, demand, interactivity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581056,
author = {Laato, Samuli and Rauti, Sampsa and Hamari, Juho},
title = {Resemblance of Religion and Pervasive Games: A Study among Church Employees and Gamers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581056},
doi = {10.1145/3544548.3581056},
abstract = {Previous research suggests that the experience and practices related to gaming and extended realities, and religion and spiritualism, share similarities. In this study, we explore how both the employees of the Evangelical Lutheran Church (n=156) and pervasive game players (n=98) perceive and make sense of these connections. We approach the qualitative data from the perspective of Durkheim, who, similarly to how game theorists view games, views religion as a multi-faceted system that incorporates the rules, practices and communities that comprise the religion. From the data emerges the following prominent connection as perceived by both groups of informants: systems of (1) shared premise, (2) resilience and restoration, (3) symbolism, (4) extended reality and (5) day-to-day structuring. A numerical view of the data shows that 42,5% of the participants did not perceive similarities, and examination of these responses suggested that while religion and pervasive games share functional similarities, they are further apart from a substantive perspective.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {292},
numpages = {15},
keywords = {Augmented Reality, Video games, Pervasive games, Religion, Gamification, Techno-Spirituality, Metaverse},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580976,
author = {Freeman, Guo and Li, Lingyuan and Mcneese, Nathan and Schulenberg, Kelsea},
title = {Understanding and Mitigating Challenges for Non-Profit Driven Indie Game Development to Innovate Game Production},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580976},
doi = {10.1145/3544548.3580976},
abstract = {Non-profit driven indie game development represents a growing open and participatory game production model as an alternative to the traditional mainstream gaming industry. However, this community is also facing and coping with tensions and dilemmas brought by its focus on artistic and cultural values over economic benefits. Using 28 interviews with indie game developers with a non-profit agenda across various cultures, we investigate the challenges non-profit driven indie game developers face, which mainly emerge in their personal or collaborative labor and their endeavors to secure sustainable resources and produce quality products. Our investigation extends the current HCI knowledge of the democratization of technology and its impact on the trajectory of innovating, designing, and producing future (gaming) technologies. These insights may help increase the opportunities for and retention of previously underrepresented groups in technology production and inform effective decision/policy making to better support the creativity industry in the future.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {293},
numpages = {16},
keywords = {indie game development, developer support, game development, gaming industry, game production},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580972,
author = {Haimson, Oliver L. and Nham, Kai and Thach, Hibby and DeGuia, Aloe},
title = {How Transgender People and Communities Were Involved in Trans Technology Design Processes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580972},
doi = {10.1145/3544548.3580972},
abstract = {Trans technology – technology created to help address challenges that trans people face – is an important area for innovation that can help improve marginalized people’s lives. We conducted 104 interviews with 115 creators of trans technology to understand how they involved trans people and communities in design processes. We describe projects that used human-centered design processes, as well as design processes that involved trans people in smaller ways, including gathering feedback from users, conducting user testing, or the creators being trans themselves. We show how involving trans people and communities in design is vital for trans technologies to realize their potential for addressing trans needs. Yet we highlight a frequent gap between trans technology design and deployment, and discuss ways to bridge this gap. We argue for the importance of involving community in trans technology design to ensure that trans technology achieves its promise of helping address trans needs and challenges.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {294},
numpages = {16},
keywords = {human-centered design, trans technology, LGBTQ+, technology design processes, transgender},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580708,
author = {Tam, Hannah and Bhat, Karthik S. and Mohindra, Priyanka and Kumar, Neha},
title = {Learning to Navigate Health Taboos through Online Safe Spaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580708},
doi = {10.1145/3544548.3580708},
abstract = {Social and cultural taboos frequently prevent meaningful conversation around gendered health and wellbeing, across the globe and to varying degrees. Safe spaces can offer potential avenues to nurture non-judgmental environments for dialogue and opportunities for learning to talk through taboos. To this end, we curated an online safe space on WhatsApp—with 35 participants of Indian origin—to facilitate conversations around diverse topics related to gendered health and wellbeing. We observed participant activity for two weeks, before conducting in-depth interviews with 10 participants to better understand their experiences of engaging within the WhatsApp group. We use the lens of Legitimate Peripheral Participation to examine how peripheral and core members of the community drew on new audiences and support systems as they questioned existing structures upholding taboos. We discuss scaffolding mechanisms that could enhance learning about taboo topics in online safe spaces, and the tensions of anonymity in such learning spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {295},
numpages = {15},
keywords = {online, qualitative methods, taboo, Health, wellbeing, gender, legitimate peripheral participation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580648,
author = {Rabaan, Hawra and Dombrowski, Lynn},
title = {Survivor-Centered Transformative Justice: An Approach to Designing Alongside Domestic Violence Stakeholders in US Muslim Communities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580648},
doi = {10.1145/3544548.3580648},
abstract = {While domestic violence (DV) is prevalent in all socioeconomic settings, identity highly impacts how one experiences and recovers from abuse. This work examines US-based Muslim women’s challenges when seeking help and healing from domestic violence. Through participatory interviews with 23 participants within the DV ecosystem, we find that victim-survivors’ autonomy is compromised throughout the abuse, within their immediate communities, and when involving the criminal justice system. To address such harms, we adapt a survivor-centered transformative justice (SCTJ) approach, a framework to discern individual and systemic harm, to understand how to design alongside victim-survivors, and to focus on victim-survivors’ autonomy. We explain under what conditions an SCTJ approach may be productive for designers. We use insights from our interviews to highlight intervention areas for reducing harm, repairing harm, and promoting healing for victim-survivors. Lastly, we offer guidelines to design for harm reduction, accountability, and systemic change.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {19},
keywords = {gender-based violence, harm reduction, transformative justice, participatory design, domestic violence, social justice, Islamic HCI, restorative justice, sociotechnical systems},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581418,
author = {Wang, Yihong and Papangelis, Konstantinos and Lykourentzou, Ioanna and Saker, Michael and Chamberlain, Alan and Khan, Vassilis-Javed and Liang, Hai-Ning and Yue, Yong},
title = {Tasks of a Different Color: How Crowdsourcing Practices Differ per Complex Task Type and Why This Matters},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581418},
doi = {10.1145/3544548.3581418},
abstract = {Crowdsourcing in China is a thriving industry. Among its most interesting structures, we find crowdfarms, in which crowdworkers self-organize as small organizations to tackle macrotasks. Little, however, is known as to which practices these crowdfarms use to tackle the macrotasks, and this goes hand in hand with the current practice of the HCI research community to treat all forms of complex crowdsourcing work as practically the same. However, macrotasks differ substantially regarding structure and decomposability. Treating them under one umbrella term - macrotasking - can lead to an imprecise understanding of the workforce involved. We address this gap by examining the work practices of 31 Chinese crowdfarms on the four main macrotask types, namely: modular, interlaced, wicked, and container macrotasks. Our results confirm essential differences in how these nascent crowd organizations address different macrotasks and shed light on what platforms can do to improve the uptake of such work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {297},
numpages = {15},
keywords = {Work Practices, Crowdfarms, Crowdsourcing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581554,
author = {Chuanromanee, Tee and Metoyer, Ronald},
title = {Understanding Gender Transition Tracking Habits and Technology},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581554},
doi = {10.1145/3544548.3581554},
abstract = {Personal health tracking has long been a topic of investigation in the HCI community. There is an emerging class of apps that support gender transition, which we term transition-tracking apps. However, little work has been done examining the use and impact of such apps. We aimed to address this gap by conducting an interview study with sixteen participants who are currently undergoing different forms of gender transition. We provide an understanding of transition tracking habits, the usage and potential of transition-tracking apps in the context of transition support technologies, and provide design suggestions and open areas of research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {298},
numpages = {16},
keywords = {personal data, gender transition, transgender health and wellbeing, transition tracking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581032,
author = {Ahmadpour, Naseem and Loke, Lian and Gray, Carl and Cao, Yidan and Macdonald, Chloe and Hart, Rebecca},
title = {Understanding How Technology Can Support Social-Emotional Learning of Children: A Dyadic Trauma-Informed Participatory Design with Proxies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581032},
doi = {10.1145/3544548.3581032},
abstract = {Trauma-informed design is an important yet challenging area due to required expertise for careful engagement with the vulnerable and traumatized person, particularly with children. While technologies have the potential to generate value for the person with experience of trauma, the risk of exposing them to additional trauma due to research and design has ethical implications. We explore this space by engaging with therapists and social workers as dyads of proxies for parents and children with a history of trauma. We conducted a study as a participatory workshop with proxies to understand how technology could support parents in coaching social-emotional learning during episodes of high intensity emotion and difficult behavior by the child. Our findings identified design qualities to embed in SEL technology, and three roles that parents can play in implementing SEL strategies at home. We contribute a set of seven methodological guidelines for dyadic trauma-informed participatory design with proxies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {299},
numpages = {17},
keywords = {participatory design, mental health, proxy, pre-reflection, therapist, social emotional learning, children, trauma-informed design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581424,
author = {Ayobi, Amid and Hughes, Jacob and Duckworth, Christopher J and Dylag, Jakub J and James, Sam and Marshall, Paul and Guy, Matthew and Kumaran, Anitha and Chapman, Adriane and Boniface, Michael and O'Kane, Aisling Ann},
title = {Computational Notebooks as Co-Design Tools: Engaging Young Adults Living with Diabetes, Family Carers, and Clinicians with Machine Learning Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581424},
doi = {10.1145/3544548.3581424},
abstract = {Engaging end user groups with machine learning (ML) models can help align the design of predictive systems with people's needs and expectations. We present a co-design study investigating the benefits and challenges of using computational notebooks to inform ML models with end user groups. We used a computational notebook to engage young adults, carers, and clinicians with an example ML model that predicted health risk in diabetes care. Through co-design workshops and retrospective interviews, we found that participants particularly valued using the interactive data visualisations of the computational notebook to scaffold multidisciplinary learning, anticipate benefits and harms of the example ML model, and create fictional feature importance plots to highlight care needs. Participants also reported challenges, from running code cells to managing information asymmetries and power imbalances. We discuss the potential of leveraging computational notebooks as interactive co-design tools to meet end user needs early in ML model lifecycles.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {300},
numpages = {20},
keywords = {Machine Learning, Human-AI Interaction, Diabetes, Co-Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580759,
author = {Vyas, Dhaval and Khan, Awais Hameed and Cooper, Anabelle},
title = {Democratizing Making: Scaffolding Participation Using e-Waste to Engage Under-Resourced Communities in Technology Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580759},
doi = {10.1145/3544548.3580759},
abstract = {Maker culture and DIY practices are central to democratizing the design of technology; enabling non-designers (future end-users) to actively participate in the design process. However, little is known about how individuals from under-resourced communities and low socioeconomic status (SES) backgrounds, can practically leverage maker practices to design technology, creating value for themselves or their communities. To investigate this, we collaborated with an e-waste recycling centre, involving 24 participants (staff and low-SES volunteers) in two participatory maker workshop activities. Participants were provided with a generative e-waste toolkit, through which they repurposed e-waste materials and developed novel technology prototypes that created value from their perspectives and agendas. Our findings unpack three factors that influenced their making: balancing personal and community needs; incorporating convenience and productivity; and re-thinking sustainability and connection; and discuss strategies for scaffolding participation and engagement of under-resourced communities in making using an e-waste generative toolkit to democratize technology design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {301},
numpages = {16},
keywords = {e-Waste Recycling, Makerspaces, Under-resourced Communities, Participation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581199,
author = {Albers, Ruben and Sadeghian, Shadan and Laschke, Matthias and Hassenzahl, Marc},
title = {Dying, Death, and the Afterlife in Human-Computer Interaction. A Scoping Review.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581199},
doi = {10.1145/3544548.3581199},
abstract = {Dying is a universal experience that entails uncertainty, loss, and termination. Often, people face death unprepared and miss out on opportunities to shape their final stage of life as well as their afterlife. To better understand how thanato-technology can support the dying and the bereaved, we performed a scoping review on the current state-of-art in Human Computer Interaction. Following the PRISMA-ScR procedure, we gathered and analyzed 107 relevant papers. We categorized theoretical and conceptual contributions into three overarching themes: digital remains, remembrance, and coping. We further highlight 18 practices, such as curation, honoring and letting go. We show that technology can help to capture the identity of the deceased, to validate the life lived, and to come to terms with death. However, available approaches focus more on the bereaved than on the dying. In addition, potentially important aspects of dying (e.g., balancing involvement and autonomy, spiritual meaning-making) remain largely unexplored.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {16},
keywords = {end of life, death, dying, scoping review, thanatosensitivity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581035,
author = {Cen, Jingyao and Xu, Tian and Yu, Junnan},
title = {Examining Gender-Oriented Design Features in Computational Toys and Kits for Young Children},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581035},
doi = {10.1145/3544548.3581035},
abstract = {Computational toys and apps, or coding kits, are the primary learning media for young children to engage in Computational Thinking concepts and skills. However, how coding kits are designed to welcome children of different genders remains unclear, a critical research gap given that computing is mostly a male-dominated field. Drawing on relevant literature, we develop a framework of gender-related design features in toys (i.e., boy-oriented, girl-oriented, or gender-neutral features) and employ it to examine gender-related design features in commercially available coding kits for young children aged seven and under (N=110). The findings reveal the lopsided gender representation in coding kits, e.g., their physical forms and supported coding activities are predominantly boy-oriented. We discuss design and research implications for coding kits to welcome participation from children of different genders, especially young girls whose preferred design features are underrepresented in current designs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {303},
numpages = {19},
keywords = {young children, gendered design features, Coding kits, inclusiveness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581109,
author = {Halperin, Brett A. and Hsieh, Gary and McElroy, Erin and Pierce, James and Rosner, Daniela K.},
title = {Probing a Community-Based Conversational Storytelling Agent to Document Digital Stories of Housing Insecurity},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581109},
doi = {10.1145/3544548.3581109},
abstract = {Despite the central role that stories play in social movement-building, they are difficult to sustainably document for many reasons. To explore this challenge, this paper describes the design of a community-based conversational storytelling agent (CSA) to document digital stories of housing insecurity. Building on insights from an ongoing grassroots project, the Anti-Eviction Mapping Project, we share how a study initially focused on CSA-support opened an investigation of the role that artificial intelligence may play in housing justice movements. Drawing from 17 interviews with narrators of housing insecurity experiences and collectors of such stories, we find that collectors perceive opportunities to expand means of documentation with multimedia and multi-language support. Meanwhile, some narrators perceive potential for a CSA to offer therapeutic storytelling experiences and document otherwise unrecorded stories. Yet, CSA encounters also surface perils of machine bias, as well as reduced possibilities of human connections and relations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {18},
keywords = {Community-Based Design, Social Movements, Housing, Storytelling, Narrative Systems, City, Conversational Interface, Grassroots},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580718,
author = {Nilsson, Tommy and Rometsch, Flavie and Becker, Leonie and Dufresne, Florian and Demedeiros, Paul and Guerra, Enrico and Casini, Andrea Emanuele Maria and Vock, Anna and Gaeremynck, Florian and Cowley, Aidan},
title = {Using Virtual Reality to Shape Humanity’s Return to the Moon: Key Takeaways from a Design Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580718},
doi = {10.1145/3544548.3580718},
abstract = {Revived interest in lunar exploration is heralding a new generation of design solutions in support of human operations on the Moon. While space system design has traditionally been guided by prototype deployments in analogue studies, the resource-intensive nature of this approach has largely precluded application of proficient user-centered design (UCD) methods from human-computer interaction (HCI). This paper explores possible use of Virtual Reality (VR) to simulate analogue studies in lab settings and thereby bring to bear UCD in this otherwise engineering-dominated field. Drawing on the ongoing development of the European Large Logistics Lander, we have recreated a prospective lunar operational scenario in VR and evaluated it with a group of astronauts and space experts (n=20). Our qualitative findings demonstrate the efficacy of VR in facilitating UCD, enabling efficient contextual inquiries and improving project team coordination. We conclude by proposing future directions to further exploit VR in lunar systems design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {16},
keywords = {human factors, HCI research, lunar lander, user centered design, Virtual Reality, ergonomics, space system engineering},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581264,
author = {Xu, Chenhan and Zhou, Bing and Krishnan, Gurunandan and Nayar, Shree},
title = {AO-Finger: Hands-Free Fine-Grained Finger Gesture Recognition via Acoustic-Optic Sensor Fusing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581264},
doi = {10.1145/3544548.3581264},
abstract = {Finger gesture recognition is gaining great research interest for wearable device interactions such as smartwatches and AR/VR headsets. In this paper, we propose a hands-free fine-grained finger gesture recognition system AO-Finger based on acoustic-optic sensor fusing. Specifically, we design a wristband with a modified stethoscope microphone and two high-speed optic motion sensors to capture signals generated from finger movements. We propose a set of natural, inconspicuous and effortless micro finger gestures that can be reliably detected from the complementary signals from both sensors. We design a multi-modal CNN-Transformer model for fast gesture recognition (flick/pinch/tap), and a finger swipe contact detection model to enable fine-grained swipe gesture tracking. We built a prototype which achieves an overall accuracy of 94.83% in detecting fast gestures and enables fine-grained continuous swipe gestures tracking. AO-Finger is practical for use as a wearable device and ready to be integrated into existing wrist-worn devices such as smartwatches.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {306},
numpages = {14},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581120,
author = {Kwon, Dongjae and Abou Chahine, Ramzi and Lim, Chungman and Seifi, Hasti and Park, Gunhyuk},
title = {Can We Crowdsource Tacton Similarity Perception and Metaphor Ratings?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581120},
doi = {10.1145/3544548.3581120},
abstract = {High-fidelity vibration actuators in recent mobile phones allow designers to crowdsource user evaluation of vibrotactile (VT) Tactons. Yet, little work has examined whether online crowdsourcing platforms can provide comparable results to lab studies. To address this question, we conducted two studies with iOS devices in the lab and crowdsourced settings. In Study I, 40 users provided pairwise similarity ratings for 12 VT Tactons that varied in their parameters (e.g., duration). In Study II, 40 new users rated pairwise similarities for 14 Tactons representing different metaphors (e.g., heartbeat). They also rated the Tactons’ match to the metaphors. In both studies, the resulting similarities and perceptual spaces strongly correlated in the lab and crowdsourced settings. Furthermore, 60% of the metaphor ratings were statistically equivalent in the two settings. We discuss the results and outline directions for future work on haptic crowdsourcing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {13},
keywords = {Haptics, Vibrotactile Perception, Tacton Design, Crowdsourcing, User Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580894,
author = {Arendttorp, Emilie Maria Nybo and Winschiers-Theophilus, Heike and Rodil, Kasper and Johansen, Freja B. K. and Rosengreen J\o{}rgensen, Mads and Kjeldsen, Thomas K. K. and Magot, Samkao},
title = {Grab It, While You Can: A VR Gesture Evaluation of a Co-Designed Traditional Narrative by Indigenous People},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580894},
doi = {10.1145/3544548.3580894},
abstract = {Recent developments in Virtual Reality (VR) applications, such as hand gesture tracking, provide new opportunities to create embodied user experiences. Numerous gesture elicitation studies have been conducted. However, in most instances they lack validation of implemented gestures, as well diversity of participant groups. Our research explores the digitalization of intangible cultural heritage in collaboration with one of the San tribes in Southern Africa. The focus is on particular gestures as embodied interactions of a VR implementation of a traditional San hunting story. In this paper, we present a gesture study, which entails an in-situ elicitation of natural gestures, a co-designed integration, a VR story implementation with grasping and three mid-air gestures, and a user evaluation. Based on our findings, we discuss the anthropological value of gesture implementations determined by an indigenous community, the local usability of a grasping gesture, and in-VR gesture elicitation, as an extension of existing methods.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {308},
numpages = {13},
keywords = {Diversity, Namibia, Virtual Reality, Indigenous People, Community, Hand Gestures, Natural Interaction, User Experiences},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581027,
author = {Jiang, Yu and Li, Zhipeng and He, Mufei and Lindlbauer, David and Yan, Yukang},
title = {HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581027},
doi = {10.1145/3544548.3581027},
abstract = {We propose HandAvatar to enable users to embody non-humanoid avatars using their hands. HandAvatar leverages the high dexterity and coordination of users’ hands to control virtual avatars, enabled through our novel approach for automatically-generated joint-to-joint mappings. We contribute an observation study to understand users’ preferences on hand-to-avatar mappings on eight avatars. Leveraging insights from the study, we present an automated approach that generates mappings between users’ hands and arbitrary virtual avatars by jointly optimizing control precision, structural similarity, and comfort. We evaluated HandAvatar on static posing, dynamic animation, and creative exploration tasks. Results indicate that HandAvatar enables more precise control, requires less physical effort, and brings comparable embodiment compared to a state-of-the-art body-to-avatar control method. We demonstrate HandAvatar’s potential with applications including non-humanoid avatar based social interaction in VR, 3D animation composition, and VR scene design with physical proxies. We believe that HandAvatar unlocks new interaction opportunities, especially for usage in Virtual Reality, by letting users become the avatar in applications including virtual social interaction, animation, gaming, or education.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {17},
keywords = {gestural interaction, virtual avatar, embodiment, Mixed Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581468,
author = {Streli, Paul and Armani, Rayan and Cheng, Yi Fei and Holz, Christian},
title = {HOOV: Hand Out-Of-View Tracking for Proprioceptive Interaction Using Inertial Sensing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581468},
doi = {10.1145/3544548.3581468},
abstract = {Current Virtual Reality systems are designed for interaction under visual control. Using built-in cameras, headsets track the user’s hands or hand-held controllers while they are inside the field of view. Current systems thus ignore the user’s interaction with off-screen content—virtual objects that the user could quickly access through proprioception without requiring laborious head motions to bring them into focus. In this paper, we present HOOV, a wrist-worn sensing method that allows VR users to interact with objects outside their field of view. Based on the signals of a single wrist-worn inertial sensor, HOOV continuously estimates the user’s hand position in 3-space to complement the headset’s tracking as the hands leave the tracking range. Our novel data-driven method predicts hand positions and trajectories from just the continuous estimation of hand orientation, which by itself is stable based solely on inertial observations. Our inertial sensing simultaneously detects finger pinching to register off-screen selection events, confirms them using a haptic actuator inside our wrist device, and thus allows users to select, grab, and drop virtual content. We compared HOOV’s performance with a camera-based optical motion capture system in two folds. In the first evaluation, participants interacted based on tracking information from the motion capture system to assess the accuracy of their proprioceptive input, whereas in the second, they interacted based on HOOV’s real-time estimations. We found that HOOV’s target-agnostic estimations had a mean tracking error of 7.7&nbsp;cm, which allowed participants to reliably access virtual objects around their body without first bringing them into focus. We demonstrate several applications that leverage the larger input space HOOV opens up for quick proprioceptive interaction, and conclude by discussing the potential of our technique.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {310},
numpages = {16},
keywords = {Sensor Fusion, Virtual Reality, Proprioceptive Interaction, Inertial Tracking, Hand Tracking, Inertial Sensing, Eyes-free Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581420,
author = {Hosseini, Masoumehsadat and Ihmels, Tjado and Chen, Ziqian and Koelle, Marion and M\"{u}ller, Heiko and Boll, Susanne},
title = {Towards a Consensus Gesture Set: A Survey of Mid-Air Gestures in HCI for Maximized Agreement Across Domains},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581420},
doi = {10.1145/3544548.3581420},
abstract = {Mid-air gesture-based systems are becoming ubiquitous. Many mid-air gestures control different kinds of interactive devices, applications, and systems. They are, however, still targeted at specific devices in specific domains and are not necessarily consistent across domain boundaries. A comprehensive evaluation of the transferability of gesture vocabulary between domains is also lacking. Consequently, interaction designers cannot decide which gestures to use for which domain. In this systematic literature review, we contribute to the future research agenda in this area, based on an analysis of 172 papers. As part of our analysis, we clustered gestures according to the dimensions of an existing taxonomy to identify their common characteristics in different domains, and we investigated the extent to which existing mid-air gesture sets are consistent across different domains. We derived a consensus gesture set containing 22 gestures based on agreement rates calculation and considered their transferability across different domains.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {311},
numpages = {24},
keywords = {application domain, Mid-air gestures, systematic literature review, agreement rate},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581016,
author = {Gao, Lei and Irani, Pourang and Subramanian, Sriram and Prabhakar, Gowdham and Martinez Plasencia, Diego and Hirayama, Ryuji},
title = {DataLev: Mid-Air Data Physicalisation Using Acoustic Levitation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581016},
doi = {10.1145/3544548.3581016},
abstract = {Data physicalisation is a technique that encodes data through the geometric and material properties of an artefact, allowing users to engage with data in a more immersive and multi-sensory way. However, current methods of data physicalisation are limited in terms of their reconfigurability and the types of materials that can be used. Acoustophoresis—a method of suspending and manipulating materials using sound waves—offers a promising solution to these challenges. In this paper, we present DataLev, a design space and platform for creating reconfigurable, multimodal data physicalisations with enriched materiality using acoustophoresis. We demonstrate the capabilities of DataLev through eight examples and evaluate its performance in terms of reconfigurability and materiality. Our work offers a new approach to data physicalisation, enabling designers to create more dynamic, engaging, and expressive artefacts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {312},
numpages = {14},
keywords = {data physicalisation, Acoustic levitation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581008,
author = {Li, Zisu and Liang, Chen and Wang, Yuntao and Qin, Yue and Yu, Chun and Yan, Yukang and Fan, Mingming and Shi, Yuanchun},
title = {Enabling Voice-Accompanying Hand-to-Face Gesture Recognition with Cross-Device Sensing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581008},
doi = {10.1145/3544548.3581008},
abstract = {Gestures performed accompanying the voice are essential for voice interaction to convey complementary semantics for interaction purposes such as wake-up state and input modality. In this paper, we investigated voice-accompanying hand-to-face (VAHF) gestures for voice interaction. We targeted on hand-to-face gestures because such gestures relate closely to speech and yield significant acoustic features (e.g., impeding voice propagation). We conducted a user study to explore the design space of VAHF gestures, where we first gathered candidate gestures and then applied a structural analysis to them in different dimensions (e.g., contact position and type), outputting a total of 8 VAHF gestures with good usability and least confusion. To facilitate VAHF gesture recognition, we proposed a novel cross-device sensing method that leverages heterogeneous channels (vocal, ultrasound, and IMU) of data from commodity devices (earbuds, watches, and rings). Our recognition model achieved an accuracy of 97.3% for recognizing 3 gestures and 91.5% for recognizing 8 gestures (excluding the "empty" gesture), proving the high applicability. Quantitative analysis also shed light on the recognition capability of each sensor channel and their different combinations. In the end, we illustrated the feasible use cases and their design principles to demonstrate the applicability of our system in various scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {313},
numpages = {17},
keywords = {sensor fusion, hand gestures, acoustic sensing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580825,
author = {Zinck, Graeme and Cody, Roya and Yan, Che and Huang, Da-Yuan and Li, Wei and Vogel, Daniel},
title = {Evaluating Across-Hinge Dragging with Pen and Touch on Curved and Foldable Displays},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580825},
doi = {10.1145/3544548.3580825},
abstract = {Foldable touch screens are increasingly popular, but little research has explored how the hinge impacts usability and performance. We evaluate across- and along-hinge drag gestures on a series of prototypes emulating foldable all-screen laptops with a curved hinge radius ranging from 1mm to 24mm. Results show that using a large 24mm hinge radius instead of a small 1mm hinge radius can decrease drag time by 13% and movement variability by 7% for touch input. However, hinge radius had no effect on performance for pen input. Further, we found that dragging along the hinge was up to 30% faster than dragging across the hinge, especially when dragging across at an acute angle to the hinge. Using these results, we demonstrate use cases for across- and along-hinge gestures. Our findings provide guidance for hardware and interaction designers seeking to create foldable touchscreen devices and their accompanying software.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {12},
keywords = {interaction techniques, controlled experiments},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580787,
author = {Yun, Gyeore and Mun, Minjae and Lee, Jungeun and Kim, Dong-Geun and Tan, Hong Z and Choi, Seungmoon},
title = {Generating Real-Time, Selective, and Multimodal Haptic Effects from Sound for Gaming Experience Enhancement},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580787},
doi = {10.1145/3544548.3580787},
abstract = {We propose an algorithm that generates a vibration, an impact, or a vibration+impact haptic effect by processing a sound signal in real time. Our algorithm is selective in that it matches the most appropriate type of haptic effects to the sound using a machine-learning classifier (random forest) that is built on expert-labeled datasets. Our algorithm is tailored to enhance user experiences for video game play, and we present two examples for the RPG (role-playing game) and FPS (first-person shooter) genres. We demonstrate the effectiveness of our algorithm by a user study in comparison to other state-of-the-art (SOTA) methods for the same cross-modal conversion. Our system elicits better multisensory user experiences than the SOTA algorithms for both game genres.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {315},
numpages = {17},
keywords = {automatic generation, sound-haptic conversion, multimodal haptic effects, audio-haptic conversion, game},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581335,
author = {Hafizi, Arman and Henderson, Jay and Neshati, Ali and Zhou, Wei and Lank, Edward and Vogel, Daniel},
title = {In-Vehicle Performance and Distraction for Midair and Touch Directional Gestures},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581335},
doi = {10.1145/3544548.3581335},
abstract = {We compare the performance and level of distraction of expressive directional gesture input in the context of in-vehicle system commands. Center console touchscreen swipes and midair swipe-like movements are tested in 8-directions, with 8-button touchscreen tapping as a baseline. Participants use these input methods for intermittent target selections while performing the Lane Change Task in a virtual driving simulator. Input performance is measured with time and accuracy, cognitive load with deviation of lane position and speed, and distraction from frequency of off-screen glances. Results show midair gestures were less distracting and faster, but with lower accuracy. Touchscreen swipes and touchscreen tapping are comparable across measures. Our work provides empirical evidence for vehicle interface designers and manufacturers considering midair or touch directional gestures for centre console input.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {316},
numpages = {13},
keywords = {midair gestures, automotive interfaces, input methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580740,
author = {Yamanaka, Shota and Kinoshita, Taiki and Oba, Yosuke and Tomihari, Ryuto and Miyashita, Homei},
title = {Varying Subjective Speed-Accuracy Biases to Evaluate the Generalizability of Experimental Conclusions on Pointing-Facilitation Techniques},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580740},
doi = {10.1145/3544548.3580740},
abstract = {In typical experiments to evaluate novel pointing-facilitation techniques, participants are asked to perform a task as rapidly and accurately as possible. However, the balance can differ among participants, and the techniques’ effectiveness would change if the majority of participants give weight to either speed or accuracy. We investigated the effects of three subjective biases (emphasizing speed, neutral, and emphasizing accuracy) on the evaluation results of pointing-facilitation techniques, namely Bubble Cursor and Bayesian Touch Criterion (BTC). The results indicate that Bubble Cursor outperformed the baseline in terms of movement time and error rate under all bias conditions, while BTC underperformed a simpler target-prediction technique, which was an inconsistent outcome to the original study. Examining multiple biases enables researchers to discuss the (dis)advantages of novel or existing techniques more precisely, which can be beneficial to reach a more reliable conclusion.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {13},
keywords = {Human motor performance, Fitts’ law, target prediction, area cursor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580755,
author = {Kleinberger, Rebecca and Van Troyer, Akito Oshiro and Wang, Qian Janice},
title = {Auditory Seasoning Filters: Altering Food Perception via Augmented Sonic Feedback of Chewing Sounds},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580755},
doi = {10.1145/3544548.3580755},
abstract = {The experience of what we eat depends not only on the taste of the food, but also on other modalities of sensory feedback. Perceptual research has shown the potential of altering visual, olfactory, and textural food cues to affect flavor, texture, and satiety. Recently, the HCI community has leveraged such research to encourage healthy eating, but the resulting tools often require specialised and/or invasive devices. Ubiquitous and unobtrusive, audio feedback-based tools could alleviate those drawbacks, but research in this area has been limited to food texture. We expand on prior psychology research by exploring a wide range of auditory feedback styles to modify not only flavor attributes but also appetite-related measures. We present Auditory Seasoning, a mobile app that offers various curated audio modes to alter chewing sounds. In a Pringles-tasting experiment (N=37), this tool significantly influenced food perception and eating behavior beyond texture alone. Based on these results, we discuss design implications to create custom real-world flavor/satiety-enhancing tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {15},
keywords = {crossmodal correspondences, auditory feedback, closed-loop system, food},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581435,
author = {Kattoju, Ravi Kiran and Ghamandi, Ryan and Taranta, Eugene Matthew and Laviola, Joseph J.},
title = {Automatic Improper Loading Posture Detection and Correction Utilizing Electrical Muscle Stimulation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581435},
doi = {10.1145/3544548.3581435},
abstract = {Chronic lower back pain due to improper lifting techniques poses a major workplace safety hazard. The major risk factors for improper loading posture (ILP) include overloading, and improper loading of the lumbar muscles, ligaments, and vertebrae due to repetitive mechanical stresses exerted upon them. The current intervention technology relies on the users’ intent and willingness to self-correct ILP through alert-based feedback or involves wearing bulky lift assist devices to prevent ILP. We address these issues with a physiological feedback system that utilizes IMU sensors for ILP detection and Electrical Muscle Stimulation (EMS) for automatic dynamic ILP correction for restoring ideal lifting angles for torso inclination and knee bend. In a user study involving 36 participants, our automatic approach delivered significantly faster correction and outperformed alternative feedback mechanisms (Audio and Vibro-tactile) and was perceived to be interesting, comfortable and a potential commercial product.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {319},
numpages = {18},
keywords = {Posture correction, Lifting, Biological feedback, Electrical Muscle Stimulation, Preventive Healthcare, Wearable},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581486,
author = {Lee, Jarrett G.W. and Lee, Bongshin and Choe, Eun Kyoung},
title = {Decorative, Evocative, and Uncanny: Reactions on Ambient-to-Disruptive Health Notifications via Plant-Mimicking Shape-Changing Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581486},
doi = {10.1145/3544548.3581486},
abstract = {Ambient Information Systems (AIS) have shown some success when used as a notification towards users’ health-related activities. But in the actual busy lives of users, ambient notifications might be forgotten or even missed, nullifying the original notification. Could a system use multiple levels of noticeability to ensure its message is received, and how could this concept be effectively portrayed? To examine these questions, we took a Research through Design approach and created plant-mimicking Shape-Changing Interface (S-CI) artifacts, then conducted interviews with 10 participants who currently used a reminder system for health-related activities. We report findings on acceptable scenarios to disrupting people for health-related activities, and participants’ reactions to our design choices, including how using naturalistic aesthetics led to interpretations of the uncanny and morose, and which ways system physicality affected imagined uses. We offer design suggestions in health-related notification systems and S-CIs, and discuss future work in ambient-to-disruptive technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {320},
numpages = {16},
keywords = {Self-Tracking, Research through Design, Personal Data, Human-Plant Interaction., Notification, Ambient Information System, Shape-Changing Interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581200,
author = {Molina, Maria D. and Zhan, Emily S and Agnihotri, Devanshi and Abdullah, Saeed and Deka, Pallav},
title = {Motivation to Use Fitness Application for Improving Physical Activity Among Hispanic Users: The Pivotal Role of Interactivity and Relatedness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581200},
doi = {10.1145/3544548.3581200},
abstract = {Is the current state of fitness applications effective at motivating and satisfying the needs of Hispanic users? With most mHealth research conducted with a predominantly white population, the answer to this question is lacking. In this study, we address this question through a survey study with Hispanic users of fitness applications (N= 211) and use the Motivational Technology Model (MTM) and Self-Determination Theory (SDT) as theoretical frameworks. We found that using interactivity features is essential to inspire more autonomous forms of motivation to use fitness applications. This is because interactivity helps satisfy users’ needs for relatedness. However, interactivity also decreased autonomy and competence suggesting the need to design fitness applications that increase relatedness without compromising autonomy. Implications for the design of fitness applications for the population at large and Hispanics, in particular, are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {321},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580975,
author = {Koch, Kevin and Maritsch, Martin and Van Weenen, Eva and Feuerriegel, Stefan and Pf\"{a}ffli, Matthias and Fleisch, Elgar and Weinmann, Wolfgang and Wortmann, Felix},
title = {Leveraging Driver Vehicle and Environment Interaction: Machine Learning Using Driver Monitoring Cameras to Detect Drunk Driving},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580975},
doi = {10.1145/3544548.3580975},
abstract = {Excessive alcohol consumption causes disability and death. Digital interventions are promising means to promote behavioral change and thus prevent alcohol-related harm, especially in critical moments such as driving. This requires real-time information on a person’s blood alcohol concentration (BAC). Here, we develop an in-vehicle machine learning system to predict critical BAC levels. Our system leverages driver monitoring cameras mandated in numerous countries worldwide. We evaluate our system with n = 30 participants in an interventional simulator study. Our system reliably detects driving under any alcohol influence (area under the receiver operating characteristic curve [AUROC] 0.88) and driving above the WHO recommended limit of 0.05&nbsp;g/dL BAC (AUROC 0.79). Model inspection reveals reliance on pathophysiological effects associated with alcohol consumption. To our knowledge, we are the first to rigorously evaluate the use of driver monitoring cameras for detecting drunk driving. Our results highlight the potential of driver monitoring cameras and enable next-generation drunk driver interaction preventing alcohol-related harm.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {322},
numpages = {32},
keywords = {health, alcohol, driver monitoring, driving, eye movements, safety, head movements},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580763,
author = {Wagener, Nadine and Reicherts, Leon and Zargham, Nima and Bart\l{}omiejczyk, Natalia and Scott, Ava Elizabeth and Wang, Katherine and Bentvelzen, Marit and Stefanidi, Evropi and Mildner, Thomas and Rogers, Yvonne and Niess, Jasmin},
title = {SelVReflect: A Guided VR Experience Fostering Reflection on Personal Challenges},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580763},
doi = {10.1145/3544548.3580763},
abstract = {Reflecting on personal challenges can be difficult. Without encouragement, the reflection process often remains superficial, thus inhibiting deeper understanding and learning from past experiences. To allow people to immerse themselves in and deeply reflect on past challenges, we developed SelVReflect, a VR experience which offers active voice-based guidance and a space to freely express oneself. SelVReflect was developed in an iterative design process (N=5) and evaluated in a user study with N=20 participants. We found that SelVReflect enabled participants to approach their challenge and its (emotional) components from different perspectives and to discover new relationships between these components. By making use of the spatial possibilities in VR, participants developed a better understanding of the situation and of themselves. We contribute empirical evidence of how a guided VR experience can support reflection. We discuss opportunities and design requirements for guided VR experiences that aim to foster deeper reflection.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {323},
numpages = {17},
keywords = {Well-being, Reflection, Emotion, Virtual Reality, Guidance, Creativity, Expression, Self-care},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580660,
author = {Li, Yunzhi and Li, Franklin Mingzhe and Carrington, Patrick},
title = {Breaking the “Inescapable” Cycle of Pain: Supporting Wheelchair Users’ Upper Extremity Health Awareness and Management with Tracking Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580660},
doi = {10.1145/3544548.3580660},
abstract = {Upper extremity (UE) health issues are a common concern among wheelchair users and have a large impact on their independence, social participation, and quality of life. However, despite the well-documented prevalence and negative impacts, these issues remain unresolved. Existing solutions (e.g. surgical repair, conservative treatments) often fail to promote sustained UE health improvement in wheelchair users’ day-to-day lives. Recent HCI research has shown the effectiveness of health tracking technologies in supporting patients’ self-care for different health conditions (e.g. chronic diseases, mental health). In this work, we explore how health tracking technologies could support wheelchair users’ UE health self-care. We conducted semi-structured interviews with 12 wheelchair users and 5 therapists to understand their practices and challenges in UE health management, as well as the potential benefits of integrating health tracking technologies into self-care routines. We discuss design implications for UE health tracking technologies and outline opportunities for future investigation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {324},
numpages = {17},
keywords = {upper extremity health, wheelchair users, health tracking technologies},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581265,
author = {Ahmed, Tousif and Rahman, Md Mahbubur and Nemati, Ebrahim and Ahmed, Mohsin Yusuf and Kuang, Jilong and Gao, Alex Jun},
title = {Remote Breathing Rate Tracking in Stationary Position Using the Motion and Acoustic Sensors of Earables},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581265},
doi = {10.1145/3544548.3581265},
abstract = {Breathing rate is critical for the user’s respiratory health and is hard to track outside the clinical context, requiring specialized devices. Earables could provide a convenient solution to track the breathing rate anywhere by leveraging the user’s breathing-related motion and sound captured through the earables’ motion sensors and microphones. However, small non-breathing head movements or background noises during the assessment affect the estimation accuracy. While noise filtering improves accuracy, it can discard valid measurements. This paper presents a multimodal approach to tracking the user’s breathing rate using a signal-processing-based algorithm on motion sensors and a lightweight machine-learning algorithm on acoustic sensors from the earables that balances the accuracy and data retention. A user study with 30 participants shows that the system can accurately calculate breathing rate (Mean Absolute Error &lt; 2 breaths per minute) while retaining most breathing sessions (75%) performed in real-world settings. This work provides an essential direction for remote breathing rate monitoring.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {325},
numpages = {22},
keywords = {Breathing, Breathing Rate, Hearable, Remote Monitoring},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580906,
author = {Ning, Emma and Cladek, Andrea T. and Ross, Mindy K. and Kabir, Sarah and Barve, Amruta and Kennelly, Ellyn and Hussain, Faraz and Duffecy, Jennifer and Langenecker, Scott L. and Nguyen, Theresa and Tulabandhula, Theja and Zulueta, John and Ajilore, Olusola A. and Demos, Alexander P. and Leow, Alex},
title = {Smartphone-Derived Virtual Keyboard Dynamics Coupled with Accelerometer Data as a Window into Understanding Brain Health: Smartphone Keyboard and Accelerometer as Window into Brain Health},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580906},
doi = {10.1145/3544548.3580906},
abstract = {We examine the feasibility of using accelerometer data exclusively collected during typing on a custom smartphone keyboard to study whether typing dynamics are associated with daily variations in mood and cognition. As part of an ongoing digital mental health study involving mood disorders, we collected data from a well-characterized clinical sample (N = 85) and classified accelerometer data per typing session into orientation (upright vs. not) and motion (active vs. not). The mood disorder group showed lower cognitive performance despite mild symptoms (depression/mania). There were also diurnal pattern differences with respect to cognitive performance: individuals with higher cognitive performance typed faster and were less sensitive to time of day. They also exhibited more well-defined diurnal patterns in smartphone keyboard usage: they engaged with the keyboard more during the day and tapered their usage more at night compared to those with lower cognitive performance, suggesting a healthier usage of their phone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {326},
numpages = {15},
keywords = {Mobile Devices: Phones/Tablets, Quantitative Methods, Health - Clinical, Empirical Study that tells us about people},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580955,
author = {Gouveia, R\'{u}ben and Epstein, Daniel A.},
title = {This Watchface Fits with My Tattoos: Investigating Customisation Needs and Preferences in Personal Tracking},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580955},
doi = {10.1145/3544548.3580955},
abstract = {People engage in self-tracking with diverse data collection and visualisation needs and preferences. Customisable self-tracking tools offer the potential to support individualized preferences by letting people make changes to the aesthetics and functionality of tracker displays. In this paper, we use the customisation options offered by the displays of commercial fitness smartwatches as a lens to investigate when, why and how 386 self-trackers engage in customisations in their daily lives. We find that people largely customise their trackers’ display frequently, multiple times a day, or not at all, with frequent customisations reflecting situational data, aesthetic and personal meaning needs. We discuss implications for the design of tracking tools aiming to support customisation and discuss the utility of customisations towards goal scaffolding and maintaining interest in tracking.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {327},
numpages = {15},
keywords = {customisation, physical activity, smartwatch, personal informatics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580949,
author = {Min, Aehong and Miller, Wendy R. and Rocha, Luis M. and B\"{o}rner, Katy and Brattig Correia, Rion and Shih, Patrick C.},
title = {Understanding Contexts and Challenges of Information Management for Epilepsy Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580949},
doi = {10.1145/3544548.3580949},
abstract = {Epilepsy is a common chronic neurological disease. People with epilepsy (PWE) and their caregivers face several challenges related to their epilepsy management, including quality of care, care coordination, side effects, and stigma management. The sociotechnical issues of the information management contexts and challenges for epilepsy care may be mitigated through effective information management. We conducted 4 focus groups with 5 PWE and 7 caregivers to explore how they manage epilepsy-related information and the challenges they encountered. Primary issues include challenges of finding the right information, complexities of tracking and monitoring data, and limited information sharing. We provide a framework that encompasses three attributes — individual epilepsy symptoms and health conditions, information complexity, and circumstantial constraints. We suggest future design implications to mitigate these challenges and improve epilepsy information management and care coordination.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {328},
numpages = {15},
keywords = {Design Framework, Epilepsy, Information Management, Information Sharing, Information Monitoring, Seizure, Self-Managment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580822,
author = {Tadas, Shreya and Dickson, Jane and Coyle, David},
title = {Using Patient-Generated Data to Support Cardiac Rehabilitation and the Transition to Self-Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580822},
doi = {10.1145/3544548.3580822},
abstract = {Patient-generated data from commercially available self-tracking devices has the potential to enhance support for people transitioning from hospitalization to self-care. However, studies have revealed significant barriers to the routine use of such data in&nbsp;clinical settings. This paper explores the use of patient-generated data in the context of cardiac rehabilitation. We describe a two-stage investigation: (1) a co-design study with clinicians to design a data system that combines objective and subjective patient data; and (2) an 18-week field-study where this system was deployed as part of a hospital-based rehabilitation program. Our findings suggest the system is feasible, supported clinicians’ workflow, and helped patients to bridge the gap between supervised and self-managed care. Subjective data contextualized objective data and a structured approach data collection helped generate actionable information. The paper also provides insight on patients' attitudes towards peer data sharing and demonstrates the importance of timing when introducing self-tracking technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {16},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580733,
author = {Czech, Elaine and Soubutts, Ewan and Eardley, Rachel and O'Kane, Aisling Ann},
title = {Independence for Whom? A Critical Discourse Analysis of Onboarding a Home Health Monitoring System for Older Adult Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580733},
doi = {10.1145/3544548.3580733},
abstract = {Home health monitoring systems (HHMS) are presented as a cost-effective solution that will assist with collaborative care of older adults. However, instead of care recipients feeling like collaborators, such systems often disempower them. In this paper, we examine the dissemination, onboarding, and initial use of an HHMS to see how the discourse used by developers and participants affects users’ collaborative care efforts. We found that the textual information provided often contrasted with how our participants managed their care. Instead of providing participants with ‘independence,’ ‘safety,’ and ‘peace of mind,’ care recipients were placed in a more dependent, less proactive role, and care providers were pressured to take on more responsibilities. We position HHMS, as they are currently marketed and onboarded, as normalizing pseudo-institutionalization. As an alternative we advocate that the discourse and design of such systems should reflect and re-enforce the varied roles care recipients take in managing their care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {330},
numpages = {15},
keywords = {accessibility, older adults, onboarding, critical discourse analysis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581176,
author = {Thach, Kong Saoane and Lederman, Reeva and Waycott, Jenny},
title = {Key Considerations for The Design of Technology for Enrichment in Residential Aged Care: An Ethnographic Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581176},
doi = {10.1145/3544548.3581176},
abstract = {Technology can be valuable for providing social and emotional enrichment for people living in residential aged care, but its use is difficult to sustain because of the complexity of the aged care environment. This paper aims to advance understanding of care environments to inform the sensitive design of technologies for social benefit in those settings. We conducted an ethnographic study in which the researcher assisted a care home's leisure and lifestyle team over four weeks. This included supporting the use of video-calling for social connectedness. A decrease in the use of video-calling and an absence of other technology for enrichment in the setting were observed. This paper identifies barriers to effective use of technology for enrichment and the interplay of cultural factors. For technology to best support residents and staff, we recommend key design considerations that target cultural, psychological and physical support and that ensure technologies, when used appropriately, better fit within the environment.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {331},
numpages = {16},
keywords = {Technology for enrichment, Older adults, Ethnographic study, Aged care},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580839,
author = {Zhao, Wei and Kelly, Ryan M. and Rogerson, Melissa J. and Waycott, Jenny},
title = {Older Adults Using Technology for Meaningful Activities During COVID-19: An Analysis Through the Lens of Self-Determination Theory},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580839},
doi = {10.1145/3544548.3580839},
abstract = {Restrictions during the COVID-19 pandemic significantly affected people's opportunities to engage in activities that are meaningful to their lives. In response to these constraints, many people, including older adults, turned to digital technologies as alternative ways to pursue meaningful activities. These technology-mediated activities, however, presented new challenges for older adults’ everyday use of technology. In this paper, we investigate how older adults used digital technologies for meaningful activities during COVID-19 restrictions. We conducted in-depth interviews with 40 older adults and analyzed the interview data through the lens of self-determination theory (SDT). Our analysis shows that using digital technologies for meaningful activities can both support and undermine older people's three basic psychological needs for autonomy, competence, and relatedness. We argue that future technologies should be designed to empower older adults’ content creation, engagement in personal interests, exploration of technology, effortful communication, and participation in beneficent activities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {332},
numpages = {17},
keywords = {technology, self-determination theory, older people, meaningful activity, older adult, COVID-19},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581048,
author = {Kim, Bogoan and Kim, Sung-In and Park, Sangwon and Yoo, Hee Jeong and Hong, Hwajung and Han, Kyungsik},
title = {RoutineAid: Externalizing Key Design Elements to Support Daily Routines of Individuals with Autism},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581048},
doi = {10.1145/3544548.3581048},
abstract = {Implementing structure into our daily lives is critical for maintaining health, productivity, and social and emotional well-being. New norms for routine management have emerged during the current pandemic, and in particular, individuals with autism find it difficult to adapt to those norms. While much research has focused on the use of computer technology to support individuals with autism, little is known about ways of helping them establish and maintain “self-directed” routine structures. In this paper, we identify design requirements for an app that support four key routine components (i.e., physical activity, diet, mindfulness, and sleep) through a formative study and develop RoutineAid, a gamified smartphone app that reflects the design requirements. The results of a two-month field study on design feasibility highlight two affordances of RoutineAid—the establishment of daily routines by facilitating micro-planning and the maintenance of daily routines through celebratory interactions. We discuss salient design considerations for the future development of daily routine management tools for individuals with autism.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {333},
numpages = {18},
keywords = {user study, mobile game, daily routine management, autism},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580893,
author = {Stegner, Laura and Senft, Emmanuel and Mutlu, Bilge},
title = {Situated Participatory Design: A Method for In Situ Design of Robotic Interaction with Older Adults},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580893},
doi = {10.1145/3544548.3580893},
abstract = {We present a participatory design method to design human-robot interactions with older adults and its application through a case study of designing an assistive robot for a senior living facility. The method, called Situated Participatory Design (sPD), was designed considering the challenges of working with older adults and involves three phases that enable designing and testing use scenarios through realistic, iterative interactions with the robot. In design sessions with nine residents and three caregivers, we uncovered a number of insights about sPD that help us understand its benefits and limitations. For example, we observed how designs evolved through iterative interactions and how early exposure to the robot helped participants consider using the robot in their daily life. With sPD, we aim to help future researchers to increase and deepen the participation of older adults in designing assistive technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {334},
numpages = {15},
keywords = {accessibility, older adults, field study, assistive robots, participatory design, Human-robot interaction, design methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581222,
author = {Lim, Hajin and Kakonge, Lisa and Hu, Yaxin and Turkstra, Lyn and Duff, Melissa and Toma, Catalina and Mutlu, Bilge},
title = {So, I Can Feel Normal: Participatory Design for Accessible Social Media Sites for Individuals with Traumatic Brain Injury},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581222},
doi = {10.1145/3544548.3581222},
abstract = {Traumatic brain injury (TBI) can result in chronic sensorimotor, cognitive, psychosocial, and communication challenges that can limit social participation. Social media can be a useful outlet for social participation for individuals with TBI, but there are barriers to access. While research has drawn attention to the nature of access barriers, few studies have investigated technological solutions to address these barriers, particularly considering the perspectives of individuals with TBI. To address this gap in knowledge, we used a participatory approach to engage 10 adults with TBI in conceptualizing tools to address their challenges accessing Facebook. Participants described multifaceted challenges in using social media, including interface overload, social comparisons, and anxiety over self-presentation and communication after injury. They discussed their needs and preferences and generated ideas for design solutions. Our work contributes to designing assistive and accessibility technology to facilitate an equal access to the benefits of social media for individuals with TBI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {335},
numpages = {19},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581233,
author = {Huh-Yoo, Jina and Razi, Afsaneh and Nguyen, Diep N. and Regmi, Sampada and Wisniewski, Pamela J.},
title = {“Help Me:” Examining Youth’s Private Pleas for Support and the Responses Received from Peers via Instagram Direct Messages},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581233},
doi = {10.1145/3544548.3581233},
abstract = {Although youth increasingly communicate with peers online, we know little about how private online channels play a role in providing a supportive environment for youth. To fill this gap, we asked youth to donate their Instagram Direct Messages and filtered them by the phrase “help me.” From this query, we analyzed 82 conversations comprised of 336,760 messages that 42 participants donated. These threads often began as casual conversations among friends or lovers they met offline or online. The conversations evolved into sharing negative experiences about everyday stress (e.g., school, dating) to severe mental health disclosures (e.g., suicide). Disclosures were usually reciprocated with relatable experiences and positive peer support. We also discovered unsupport as a theme, where conversation members denied giving support, a unique finding in the online social support literature. We discuss the role of social media-based private channels and their implications for design in supporting youth’s mental health. Content Warning: This paper includes sensitive topics, including self-harm and suicide ideation. Reader discretion is advised.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {336},
numpages = {14},
keywords = {Youth, Social Support, Adolescents, Teens, Instagram Data, Mentoring},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581033,
author = {Maestre, Juan F. and Groves, Daria V. and Furness, Megan and Shih, Patrick C.},
title = {"It’s like With the Pregnancy Tests": Co-Design of Speculative Technology for Public HIV-Related Stigma and Its Implications for Social Media},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581033},
doi = {10.1145/3544548.3581033},
abstract = {Public stigma on the Human Immunodeficiency Virus (HIV) affects the physical and psychological wellbeing of those living with the condition in a severe way. There is work around the design of technology for medication adherence and HIV treatment. Yet, there is still a lack of empirical research that investigates how people could cope with stigma more effectively using technology. Thus, we obtained data from co-design workshops conducted remotely from the U.S. with 25 people living with HIV. Our findings foreground key needs and values via the discussion of features and functionality of speculative co-designed technologies that would allow people to leverage key stigma coping strategies. Based on these insights, we forward design implications for social media, which is the most common type of technology that people living with HIV currently use to cope with public stigma.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {21},
keywords = {technology for well being, stigma, remote co-design, online co-design, social media, stigmatized populations, technology for HIV-related stigma, speculative design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581559,
author = {Schaadhardt, Anastasia and Fu, Yue and Pratt, Cory Gennari and Pratt, Wanda},
title = {“Laughing so I Don’t Cry”: How TikTok Users Employ Humor and Compassion to Connect around Psychiatric Hospitalization},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581559},
doi = {10.1145/3544548.3581559},
abstract = {Today’s youth face many mental health challenges and are increasingly represented in psychiatric hospitalizations. Scholars have sought to understand social media’s role in mental health issues, but limited work has explored TikTok—the video-centric social media platform that is popular with youth—and people’s connections around psychiatric hospitalization experiences. In this study, we used qualitative content analysis to examine a random sample of 140 TikTok posts related to psychiatric hospitalization. We found that members of this population frequently utilize humor to create and maintain a positive and supportive community with each other. We also describe how TikTok’s design affords these interactions among community members, and conclude with a series of provocations for researchers and designers working at the intersections of social media and mental illness. We hope our study provides insights for how to further support rather than just censor youth in using creative outlets to connect with each other.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {338},
numpages = {13},
keywords = {social media, TikTok, humor, mental health, mental illness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580911,
author = {Zytko, Douglas and Furlo, Nicholas},
title = {Online Dating as Context to Design Sexual Consent Technology with Women and LGBTQ+ Stakeholders},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580911},
doi = {10.1145/3544548.3580911},
abstract = {This paper uses online dating as a context to explore futures for sexual consent technology: systems that mediate how partners exchange consent in order to prevent nonconsensual sex. Motivated by evidence that sexual consent is already mediated by computers in ways that challenge perceptions of sexual agency, we present a participatory design study in the United States with 17 women and LGBTQ+ stakeholders (demographics at disproportionate risk of sexual violence). Contrary to consent apps that are used right before sex to record irrevocable consent, participants envisioned alternative consent technology being used across online and offline interaction to normalize candid dialogue about sexual expectations and informed verbal consent throughout sex. Findings demonstrate opportunity for dating apps and associated technologies to foster voluntary adoption of affirmative consent, which has been widely advocated in public health for sexual violence prevention yet historically under-adopted by the general public. Content warning: graphic descriptions of sexual activity.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {339},
numpages = {17},
keywords = {consent, affirmative consent, sex, participatory design, online dating, sexual violence, dating apps},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580938,
author = {Freeman, Jaimie Lee and Curtis, Amanda Nicole},
title = {Putting the Self in Self-Tracking: The Value of a Co-Designed ‘How Might You’ Self-Tracking Guide for Teenagers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580938},
doi = {10.1145/3544548.3580938},
abstract = {Although teenagers engage with Personal Informatics tools to track their health and fitness, many do so without adequate guidance, and they express concerns regarding the potential for these practices to bring harm. Further research is needed to understand how we might leverage resources beyond these tools to support young self-trackers. We worked with 44 teenagers (aged 13-18 years) in the United Kingdom in two series of online workshops to co-design a reimagined ‘how might you’ guide to promote lifelong, healthy behaviors with self-tracking tools. Our findings emphasize the importance of flexible resources that can support teens’ self-tracking practices. For example, guidance on asking critical questions can be particularly valuable in the preparation and reflection stages of self-tracking. To better design teens’ interactions with health technologies, particularly Personal Informatics tools, we must think critically about how we design the broader information ecosystems within which these tools reside.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {340},
numpages = {16},
keywords = {co-design workshops, Self-tracking, youth, personal informatics, education},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581512,
author = {Scott, Carol F and Marcu, Gabriela and Anderson, Riana Elyse and Newman, Mark W and Schoenebeck, Sarita},
title = {Trauma-Informed Social Media: Towards Solutions for Reducing and Healing Online Harm},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581512},
doi = {10.1145/3544548.3581512},
abstract = {Social media platforms exacerbate trauma, and many users experience various forms of trauma unique to them (e.g., doxxing and swatting). Trauma is the psychological and physical response to experiencing a deeply disturbing event. Platforms’ failures to address trauma threaten users’ well-being globally, especially amongst minoritized groups. Platform policies also expose moderators and designers to trauma through content they must engage with as part of their jobs (e.g., child sexual abuse). We consider how a trauma-informed approach might help address or decrease the likelihood of (re)experiencing trauma online. A trauma-informed approach to social media recognizes that everyone likely has a trauma history and that trauma is experienced at the individual, secondary, collective, and cultural levels. This paper proceeds by detailing trauma and its impacts. We then describe how the six trauma-informed principles can be applied to social media design, content moderation, and companies. We conclude by offering recommendations that balance platform responsibility and accountability with well-being and healing for all.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {341},
numpages = {20},
keywords = {Content moderation, Online harm, Design knowledge, Trauma-informed, Sensitizing concepts, Social media, Social media companies, Trauma},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581014,
author = {Li, Brenna and Skoropad, Tetyana and Seth, Puneet and Jain, Mohit and Truong, Khai and Mariakakis, Alex},
title = {Constraints and Workarounds to Support Clinical Consultations in Synchronous Text-Based Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581014},
doi = {10.1145/3544548.3581014},
abstract = {Medical consultations over synchronous text-based platforms are becoming increasingly popular for virtual care, yet little is known about how physicians translate their training to this healthcare medium. We report the constraints, workarounds, and opportunities highlighted by eight primary care physicians who used such a platform in simulated medical scenarios with standardized patients. We found that due to the perceived inefficiency of communicating over text, the physicians made subconscious use of double-barreled questions and action multiplexing to streamline the conversation. In addition, the physicians overcame the lack of missing verbal and visual cues by adding explicit messages to convey empathy and active listening. We also identify several affordances of text-based platforms, such as the ability for users to reference the conversation history and for patients to feel a sense of privacy during sensitive disclosure. From these findings, we propose design opportunities for how future synchronous text-based platforms can better support medical consultations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {342},
numpages = {17},
keywords = {virtual care, synchronous text, non-verbal cues, clinical consultation, active listening},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581350,
author = {Han, Dongqi and Geiskkovitch, Denise Y. and Yuan, Ye and Mills, Chelsea and Zhong, Ce and Chen, Amy Yo Sue and Stuerzlinger, Wolfgang and Neustaedter, Carman},
title = {Dr.’s Eye: The Design and Evaluation of a Video Conferencing System to Support Doctor Appointments in Home Settings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581350},
doi = {10.1145/3544548.3581350},
abstract = {The spread of COVID-19 has encouraged the practice of using video conferencing for family doctor appointments. Existing applications and off-the-shelf devices face challenges in dealing with capturing the correct view of patients' bodies and supporting ease of use. We created Dr.’s Eye, a video conferencing prototype to support varying types of body exams in home settings. With our prototype, we conducted a study with participants using mock appointments to understand the simultaneous use of the camera and display and to get insights into the issues that might arise in real doctor appointments. Results show the benefits of providing more flexibility with a decoupled camera and display, and privacy protection by limiting the camera view. Yet, challenges remain in maneuvering two devices, presenting feedback for the camera view, coordinating camera work between the participant and the examiner, and reluctance towards showing private body regions. This inspires future research on how to design a video system for doctor appointments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {343},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580757,
author = {Dawson, Joshua and Kauffman, Thomas and Wiese, Jason},
title = {It Made Me Feel So Much More at Home Here: Patient Perspectives on Smart Home Technology Deployed at Scale in a Rehabilitation Hospital},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580757},
doi = {10.1145/3544548.3580757},
abstract = {Smart patient rooms are arriving; however, their value has yet to be explored. We interviewed 20 patients in a rehabilitation hospital, which has patient rooms equipped with off-the-shelf smart home technologies, so the entertainment and environment are digitally controllable. This novel implementation supports varying control abilities through touchscreen, voice command, and accessibility controllers. The smart rooms and controls are potentially transformative for patients with reduced motor function, helping them regain lost independence and control of their surroundings. Through semi-structured interviews, we explore how smart home technology deployed in patient rooms: interacts with patients’ needs, presents new challenges, and fits into the hospital context. We identify a range of considerations that inform how hospitals can integrate smart technology into their environment, including technology design considerations and adjustments to how hospital staff supports its use. These results take an important step toward understanding and improving the value of smart patient rooms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {344},
numpages = {15},
keywords = {smart hospital, smart patient room, rehabilitation hospital},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581180,
author = {Grundgeiger, Tobias and M\"{u}nz, Alea and Schlosser, Paul and Happel, Oliver},
title = {Supervising Multiple Operating Rooms Using a Head-Worn Display: A Longitudinal Evaluation of the Experience of Supervising Anesthesiologists and Their Co-Workers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581180},
doi = {10.1145/3544548.3581180},
abstract = {Research has explored head-worn displays (HWD) in various professional contexts. However, evaluations have been limited by short-term use, a focus on the person using the HWD, and on performance variables. In a field study, we evaluated a monocular, opaque HWD for multi-patient monitoring, which supervising anesthesiologists wore for 8-10 days each. We investigated the effect of prolonged HWD use on the experience of the supervising anesthesiologists and their co-workers using interviews and repeated observations. A reflexive thematic analysis showed (1) interaction and mindset changes over time, (2) information on the HWD is more than numbers, (3) the HWD affects co-workers' collaboration with supervisors, and (4) distraction depends on the point of view. Using activity theory, we discuss the fact that HWD use develops and changes over time and that even a single-user HWD influences the collaboration with co-workers. We conclude with implications for HWD design, implementation, and evaluation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {345},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580714,
author = {Maria, Sophie and Mentis, Helena M. and Canlorbe, Geoffroy and Avellino, Ignacio},
title = {Supporting Collaborative Discussions In Surgical Teleconsulting Through Augmented Reality Head Mounted Displays},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580714},
doi = {10.1145/3544548.3580714},
abstract = {Although Augmented Reality (AR) has been touted as the future of surgery, its contribution to distributed collaboration such as in surgical teleconsulting has not been articulated. We propose AR-Head Mounted Displays (AR-HMD) to tackle two previously-identified challenges: operating surgeons needing to view and interact with imaging systems that reside away from the operative field, and, their lack of gesturing tools to point and annotate on the shared images and physical environment. We report on a controlled lab experiment where 12 expert gynecology surgeons perform a tumor localisation task guided by a remote radiologist (confederate) via an AR-HMD. We find that bringing the shared images to the place of work reduces the need for clarifications and provides opportunistic access to information when required, and, that pointing and annotating provides opportunities to further support verbal instruction in deictic communication. Our results inform the design of intraoperative AR-HMD systems for surgical telecollaboration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {346},
numpages = {13},
keywords = {teleconsulting, augmented reality, remote collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580653,
author = {Bhat, Karthik S. and Kumar, Neha and Shamanna, Karthik and Kwatra, Nipun and Jain, Mohit},
title = {Towards Intermediated Workflows for Hybrid Telemedicine},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580653},
doi = {10.1145/3544548.3580653},
abstract = {The growing platformization of health has spurred new avenues for healthcare access and reinvigorated telemedicine as a viable pathway to care. Telemedicine adoption during the COVID-19 pandemic has surfaced barriers to patient-centered care that call for attention. Our work extends current Human-Computer Interaction (HCI) research on telemedicine and the challenges to remote care, and investigates the scope for enhancing remote care seeking and provision through telemedicine workflows involving intermediation. Our study, focused on the urban Indian context, involved providing doctors with videos of remote clinical examinations to aid in telemedicine. We present a qualitative evaluation of this modified telemedicine experience, highlighting how workflows involving intermediation could bridge existing gaps in telemedicine, and how their acceptance among doctors could shift interaction dynamics between doctors and patients. We conclude by discussing the implications of such telemedicine workflows on patient-centered care and the future of care work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {347},
numpages = {17},
keywords = {care work, future of work, remote care, hybrid work, Telehealth, telemedicine},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581015,
author = {Chiang, Chun-Wei and Lu, Zhuoran and Li, Zhuoyan and Yin, Ming},
title = {Are Two Heads Better Than One in AI-Assisted Decision Making? Comparing the Behavior and Performance of Groups and Individuals in Human-AI Collaborative Recidivism Risk Assessment},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581015},
doi = {10.1145/3544548.3581015},
abstract = {With the prevalence of AI assistance in decision making, a more relevant question to ask than the classical question of “are two heads better than one?’’ is how groups’ behavior and performance in AI-assisted decision making compare with those of individuals’. In this paper, we conduct a case study to compare groups and individuals in human-AI collaborative recidivism risk assessment along six aspects, including decision accuracy and confidence, appropriateness of reliance on AI, understanding of AI, decision-making fairness, and willingness to take accountability. Our results highlight that compared to individuals, groups rely on AI models more regardless of their correctness, but they are more confident when they overturn incorrect AI recommendations. We also find that groups make fairer decisions than individuals according to the accuracy equality criterion, and groups are willing to give AI more credit when they make correct decisions. We conclude by discussing the implications of our work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {348},
numpages = {18},
keywords = {Human-AI interaction, Group-AI interaction, AI-assisted decision making},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580694,
author = {Gu, Hongyan and Yang, Chunxu and Haeri, Mohammad and Wang, Jing and Tang, Shirley and Yan, Wenzhong and He, Shujin and Williams, Christopher Kazu and Magaki, Shino and Chen, Xiang 'Anthony'},
title = {Augmenting Pathologists with NaviPath: Design and Evaluation of a Human-AI Collaborative Navigation System},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580694},
doi = {10.1145/3544548.3580694},
abstract = {Artificial Intelligence (AI) brings advancements to support pathologists in navigating high-resolution tumor images to search for pathology patterns of interest. However, existing AI-assisted tools have not realized this promised potential due to a lack of insight into pathology and HCI considerations for pathologists’ navigation workflows in practice. We first conducted a formative study with six medical professionals in pathology to capture their navigation strategies. By incorporating our observations along with the pathologists’ domain knowledge, we designed NaviPath&nbsp;— a human-AI collaborative navigation system. An evaluation study with 15 medical professionals in pathology indicated that: (i)&nbsp;compared to the manual navigation, participants saw more than twice the number of pathological patterns in unit time with NaviPath, and (ii)&nbsp;participants achieved higher precision and recall against the AI and the manual navigation on average. Further qualitative analysis revealed that navigation was more consistent with NaviPath, which can improve the overall examination quality.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {349},
numpages = {19},
keywords = {navigation, digital pathology, medical AI, Human-AI collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581282,
author = {Xu, Chengyuan and Lien, Kuo-Chin and H\"{o}llerer, Tobias},
title = {Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581282},
doi = {10.1145/3544548.3581282},
abstract = {When designing an AI-assisted decision-making system, there is often a tradeoff between precision and recall in the AI’s recommendations. We argue that careful exploitation of this tradeoff can harness the complementary strengths in the human-AI collaboration to significantly improve team performance. We investigate a real-world video anonymization task for which recall is paramount and more costly to improve. We analyze the performance of 78 professional annotators working with a) no AI assistance, b) a high-precision "restrained" AI, and c) a high-recall "zealous" AI in over 3,466 person-hours of annotation work. In comparison, the zealous AI helps human teammates achieve significantly shorter task completion time and higher recall. In a follow-up study, we remove AI assistance for everyone and find negative training effects on annotators trained with the restrained AI. These findings and our analysis point to important implications for the design of AI assistance in recall-demanding scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {15},
keywords = {real-world application, human-AI team, empirical study, computer vision, AI-assisted decision making, video annotation, precision and recall, face detection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581131,
author = {Zheng, Chengbo and Wu, Yuheng and Shi, Chuhan and Ma, Shuai and Luo, Jiehui and Ma, Xiaojuan},
title = {Competent but Rigid: Identifying the Gap in Empowering AI to Participate Equally in Group Decision-Making},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581131},
doi = {10.1145/3544548.3581131},
abstract = {Existing research on human-AI collaborative decision-making focuses mainly on the interaction between AI and individual decision-makers. There is a limited understanding of how AI may perform in group decision-making. This paper presents a wizard-of-oz study in which two participants and an AI form a committee to rank three English essays. One novelty of our study is that we adopt a speculative design by endowing AI equal power to humans in group decision-making. We enable the AI to discuss and vote equally with other human members. We find that although the voice of AI is considered valuable, AI still plays a secondary role in the group because it cannot fully follow the dynamics of the discussion and make progressive contributions. Moreover, the divergent opinions of our participants regarding an “equal AI” shed light on the possible future of human-AI relations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {351},
numpages = {19},
keywords = {group decision-making, human-AI collaboration, automated essay grading, qualitative study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580672,
author = {Danry, Valdemar and Pataranutaporn, Pat and Mao, Yaoli and Maes, Pattie},
title = {Don’t Just Tell Me, Ask Me: AI Systems That Intelligently Frame Explanations as Questions Improve Human Logical Discernment Accuracy over Causal AI Explanations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580672},
doi = {10.1145/3544548.3580672},
abstract = {Critical thinking is an essential human skill. Despite the importance of critical thinking, research reveals that our reasoning ability suffers from personal biases and cognitive resource limitations, leading to potentially dangerous outcomes. This paper presents the novel idea of AI-framed Questioning that turns information relevant to the AI classification into questions to actively engage users’ thinking and scaffold their reasoning process. We conducted a study with 204 participants comparing the effects of AI-framed Questioning on a critical thinking task; discernment of logical validity of socially divisive statements. Our results show that compared to no feedback and even causal AI explanations of an always correct system, AI-framed Questioning significantly increase human discernment of logically flawed statements. Our experiment exemplifies a future style of Human-AI co-reasoning system, where the AI becomes a critical thinking stimulator rather than an information teller.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {352},
numpages = {13},
keywords = {Language Model, Human-AI Interaction, AI Explanation, Explainable AI, AI, Logic, Reasoning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580983,
author = {He, Ziyao and Song, Yunpeng and Zhou, Shurui and Cai, Zhongmin},
title = {Interaction of Thoughts: Towards Mediating Task Assignment in Human-AI Cooperation with a Capability-Aware Shared Mental Model},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580983},
doi = {10.1145/3544548.3580983},
abstract = {The existing work on task assignment of human-AI cooperation did not consider the differences between individual team members regarding their capabilities, leading to sub-optimal task completion results. In this work, we propose a capability-aware shared mental model (CASMM) with the components of task grouping and negotiation, which utilize tuples to break down tasks into sets of scenarios relating to difficulties and then dynamically merge the task grouping ideas raised by human and AI through negotiation. We implement a prototype system and a 3-phase user study for the proof of concept via an image labeling task. The result shows building CASMM boosts the accuracy and time efficiency significantly through forming the task assignment close to real capabilities within few iterations. It helps users better understand the capability of AI and themselves. Our method has the potential to generalize to other scenarios such as medical diagnoses and automatic driving in facilitating better human-AI cooperation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {353},
numpages = {18},
keywords = {shared mental model, human-AI cooperation, task assignment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581095,
author = {Cabitza, Federico and Campagner, Andrea and Angius, Riccardo and Natali, Chiara and Reverberi, Carlo},
title = {AI Shall Have No Dominion: On How to Measure Technology Dominance in AI-Supported Human Decision-Making},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581095},
doi = {10.1145/3544548.3581095},
abstract = {In this article, we propose a conceptual and methodological framework for measuring the impact of the introduction of AI systems in decision settings, based on the concept of technological dominance, i.e. the influence that an AI system can exert on human judgment and decisions. We distinguish between a negative component of dominance (automation bias) and a positive one (algorithm appreciation) by focusing on and systematizing the patterns of interaction between human judgment and AI support, or reliance patterns, and their associated cognitive effects. We then define statistical approaches for measuring these dimensions of dominance, as well as corresponding qualitative visualizations. By reporting about four medical case studies, we illustrate how the proposed methods can be used to inform assessments of dominance and of related cognitive biases in real-world settings. Our study lays the groundwork for future investigations into the effects of introducing AI support into naturalistic and collaborative decision-making.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {354},
numpages = {20},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581225,
author = {Mirowski, Piotr and Mathewson, Kory W. and Pittman, Jaylen and Evans, Richard},
title = {Co-Writing Screenplays and Theatre Scripts with Language Models: Evaluation by Industry Professionals},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581225},
doi = {10.1145/3544548.3581225},
abstract = {Language models are increasingly attracting interest from writers. However, such models lack long-range semantic coherence, limiting their usefulness for longform creative writing. We address this limitation by applying language models hierarchically, in a system we call Dramatron. By building structural context via prompt chaining, Dramatron can generate coherent scripts and screenplays complete with title, characters, story beats, location descriptions, and dialogue. We illustrate Dramatron’s usefulness as an interactive co-creative system with a user study of 15 theatre and film industry professionals. Participants co-wrote theatre scripts and screenplays with Dramatron and engaged in open-ended interviews. We report reflections both from our interviewees and from independent reviewers who critiqued performances of several of the scripts to illustrate how both Dramatron and hierarchical text generation could be useful for human-machine co-creativity. Finally, we discuss the suitability of Dramatron for co-creativity, ethical considerations—including plagiarism and bias—and participatory models for the design and deployment of such tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {355},
numpages = {34},
keywords = {natural language generation, co-creativity, computational creativity, natural language evaluation, theatre, human-computer interaction, improvisation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580900,
author = {Yildirim, Nur and Pushkarna, Mahima and Goyal, Nitesh and Wattenberg, Martin and Vi\'{e}gas, Fernanda},
title = {Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People + AI Guidebook},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580900},
doi = {10.1145/3544548.3580900},
abstract = {Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI’s design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {356},
numpages = {13},
keywords = {human-AI guidelines, human-AI interaction, people AI guidebook},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580640,
author = {Li, Zhi and Ko, Yu-Jung and Putkonen, Aini and Feiz, Shirin and Ashok, Vikas and Ramakrishnan, Iv and Oulasvirta, Antti and Bi, Xiaojun},
title = {Modeling Touch-Based Menu Selection Performance of Blind Users via Reinforcement Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580640},
doi = {10.1145/3544548.3580640},
abstract = {Although menu selection has been extensively studied in HCI, most existing studies have focused on sighted users, leaving blind users’ menu selection under-studied. In this paper, we propose a computational model that can simulate blind users’ menu selection performance and strategies, including the way they use techniques like swiping, gliding, and direct touch. We assume that selection behavior emerges as an adaptation to the user’s memory of item positions based on experience and feedback from the screen reader. A key aspect of our model is a model of long-term memory, predicting how a user recalls and forgets item position based on previous menu selections. We compare simulation results predicted by our model against data obtained in an empirical study with ten blind users. The model correctly simulated the effect of the menu length and menu arrangement on selection time, the action composition, and the menu selection strategy of the users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {357},
numpages = {18},
keywords = {boundedly optimal control, menu selection, deep reinforcement learning, accessibility, computational rationality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580926,
author = {Fruchard, Bruno and Malacria, Sylvain and Casiez, G\'{e}ry and Huot, St\'{e}phane},
title = {User Preference and Performance Using Tagging and Browsing for Image Labeling},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580926},
doi = {10.1145/3544548.3580926},
abstract = {Visual content must be labeled to facilitate navigation and retrieval, or provide ground truth data for supervised machine learning approaches. The efficiency of labeling techniques is crucial to produce numerous qualitative labels, but existing techniques remain sparsely evaluated. We systematically evaluate the efficiency of tagging and browsing tasks in relation to the number of images displayed, interaction modes, and the image visual complexity. Tagging consists in focusing on a single image to assign multiple labels (image-oriented strategy), and browsing in focusing on a single label to assign to multiple images (label-oriented strategy). In a first experiment, we focus on the nudges inducing participants to adopt one of the strategies (n=18). In a second experiment, we evaluate the efficiency of the strategies (n=24). Results suggest an image-oriented strategy (tagging task) leads to shorter annotation times, especially for complex images, and participants tend to adopt it regardless of the conditions they face.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {358},
numpages = {13},
keywords = {Human-Computer Interaction, visual complexity, image labeling, user performance, empirical studies, tagging, open science, browsing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580959,
author = {Capel, Tara and Brereton, Margot},
title = {What is Human-Centered about Human-Centered AI? A Map of the Research Landscape},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580959},
doi = {10.1145/3544548.3580959},
abstract = {The application of Artificial Intelligence (AI) across a wide range of domains comes with both high expectations of its benefits and dire predictions of misuse. While AI systems have largely been driven by a technology-centered design approach, the potential societal consequences of AI have mobilized both HCI and AI researchers towards researching human-centered artificial intelligence (HCAI). However, there remains considerable ambiguity about what it means to frame, design and evaluate HCAI. This paper presents a critical review of the large corpus of peer-reviewed literature emerging on HCAI in order to characterize what the community is defining as HCAI. Our review contributes an overview and map of HCAI research based on work that explicitly mentions the terms ‘human-centered artificial intelligence’ or ‘human-centered machine learning’ or their variations, and suggests future challenges and research directions. The map reveals the breadth of research happening in HCAI, established clusters and the emerging areas of Interaction with AI and Ethical AI. The paper contributes a new definition of HCAI, and calls for greater collaboration between AI and HCI research, and new HCAI constructs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {359},
numpages = {23},
keywords = {artificial intelligence, machine learning, human-centered machine learning, human-centered artificial intelligence, critical review},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580676,
author = {Pan, Lihang and Yu, Chun and He, Zhe and Shi, Yuanchun},
title = {A Human-Computer Collaborative Editing Tool for Conceptual Diagrams},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580676},
doi = {10.1145/3544548.3580676},
abstract = {Editing (e.g., editing conceptual diagrams) is a typical office task that requires numerous tedious GUI operations, resulting in poor interaction efficiency and user experience, especially on mobile devices. In this paper, we present a new type of human-computer collaborative editing tool (CET) that enables accurate and efficient editing with little interaction effort. CET divides the task into two parts, and the human and the computer focus on their respective specialties: the human describes high-level editing goals with multimodal commands, while the computer calculates, recommends, and performs detailed operations. We conducted a formative study (N = 16) to determine the concrete task division and implemented the tool on Android devices for the specific tasks of editing concept diagrams. The user study (N = 24 + 20) showed that it increased diagram editing speed by 32.75% compared with existing state-of-the-art commercial tools and led to better editing results and user experience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {360},
numpages = {29},
keywords = {conceptual diagram, natural content editing, multi-modal interaction, human-computer collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581224,
author = {Lea, Colin and Huang, Zifang and Narain, Jaya and Tooley, Lauren and Yee, Dianna and Tran, Dung Tien and Georgiou, Panayiotis and Bigham, Jeffrey P and Findlater, Leah},
title = {From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581224},
doi = {10.1145/3544548.3581224},
abstract = {Consumer speech recognition systems do not work as well for many people with speech differences, such as stuttering, relative to the rest of the general population. However, what is not clear is the degree to which these systems do not work, how they can be improved, or how much people want to use them. In this paper, we first address these questions using results from a 61-person survey from people who stutter and find participants want to use speech recognition but are frequently cut off, misunderstood, or speech predictions do not represent intent. In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system. Through three technical investigations, we demonstrate how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {361},
numpages = {16},
keywords = {dictation, stuttering, accessibility, speech input, voice assistants},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581352,
author = {Gebreegziabher, Simret Araya and Zhang, Zheng and Tang, Xiaohang and Meng, Yihao and Glassman, Elena L. and Li, Toby Jia-Jun},
title = {PaTAT: Human-AI Collaborative Qualitative Coding with Explainable Interactive Rule Synthesis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581352},
doi = {10.1145/3544548.3581352},
abstract = {Over the years, the task of AI-assisted data annotation has seen remarkable advancements. However, a specific type of annotation task, the qualitative coding performed during thematic analysis, has characteristics that make effective human-AI collaboration difficult. Informed by a formative study, we designed PaTAT, a new AI-enabled tool that uses an interactive program synthesis approach to learn flexible and expressive patterns over user-annotated codes in real-time as users annotate data. To accommodate the ambiguous, uncertain, and iterative nature of thematic analysis, the use of user-interpretable patterns allows users to understand and validate what the system has learned, make direct fixes, and easily revise, split, or merge previously annotated codes. This new approach also helps human users to learn data characteristics and form new theories in addition to facilitating the “learning” of the AI model. PaTAT’s usefulness and effectiveness were evaluated in a lab user study.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {362},
numpages = {19},
keywords = {data annotation, qualitative analysis, human-AI collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580699,
author = {Sakashita, Mose and Zhang, Ruidong and Li, Xiaoyi and Kim, Hyunju and Russo, Michael and Zhang, Cheng and Jung, Malte F. and Guimbreti\`{e}re, Fran\c{c}ois},
title = {ReMotion: Supporting Remote Collaboration in Open Space with Automatic Robotic Embodiment},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580699},
doi = {10.1145/3544548.3580699},
abstract = {Design activities, such as brainstorming or critique, often take place in open spaces combining whiteboards and tables to present artefacts. In co-located settings, peripheral awareness enables participants to understand each other’s locus of attention with ease. However, these spatial cues are mostly lost while using videoconferencing tools. Telepresence robots could bring back a sense of presence, but controlling them is distracting. To address this problem, we present ReMotion, a fully automatic robotic proxy designed to explore a new way of supporting non-collocated open-space design activities. ReMotion combines a commodity body tracker (Kinect) to capture a user’s location and orientation over a wide area with a minimally invasive wearable system (NeckFace) to capture facial expressions. Due to its omnidirectional platform, ReMotion embodiment can render a wide range of body movements. A formative evaluation indicated that our system enhances the sharing of attention and the sense of co-presence enabling seamless movement-in-space during a design review task.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {363},
numpages = {14},
keywords = {Remote Collaboration;, Robotic Embodiment, Telepresence Robot},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580753,
author = {Wang, Fengjie and Liu, Xuye and Liu, Oujing and Neshati, Ali and Ma, Tengfei and Zhu, Min and Zhao, Jian},
title = {Slide4N: Creating Presentation Slides from Computational Notebooks with Human-AI Collaboration},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580753},
doi = {10.1145/3544548.3580753},
abstract = {Data scientists often have to use other presentation tools (e.g., Microsoft PowerPoint) to create slides to communicate their analysis obtained using computational notebooks. Much tedious and repetitive work is needed to transfer the routines of notebooks (e.g., code, plots) to the presentable contents on slides (e.g., bullet points, figures). We propose a human-AI collaborative approach and operationalize it within Slide4N, an interactive AI assistant for data scientists to create slides from computational notebooks. Slide4N leverages advanced natural language processing techniques to distill key information from user-selected notebook cells and then renders them in appropriate slide layouts. The tool also provides intuitive interactions that allow further refinement and customization of the generated slides. We evaluated Slide4N with a two-part user study, where participants appreciated this human-AI collaborative approach compared to fully-manual or fully-automatic methods. The results also indicate the usefulness and effectiveness of Slide4N in slide creation tasks from notebooks.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {364},
numpages = {18},
keywords = {computational notebooks, slides generation, human-AI collaboration, data science., natural language processing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581148,
author = {Hu, Erzhen and Gr\o{}nb\ae{}k, Jens Emil Sloth and Ying, Wen and Du, Ruofei and Heo, Seongkook},
title = {ThingShare: Ad-Hoc Digital Copies of Physical Objects for Sharing Things in Video Meetings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581148},
doi = {10.1145/3544548.3581148},
abstract = {In video meetings, individuals may wish to share various physical objects with remote participants, such as physical documents, design prototypes, and personal belongings. However, our formative study discovered that this poses several challenges, including difficulties in referencing a remote user’s physical objects, the limited visibility of the object, and the friction of properly framing and orienting an object to the camera. To address these challenges, we propose ThingShare, a video-conferencing system designed to facilitate the sharing of physical objects during remote meetings. With ThingShare, users can quickly create digital copies of physical objects in the video feeds, which can then be magnified on a separate panel for focused viewing, overlaid on the user’s video feed for sharing in context, and stored in the object drawer for reviews. Our user study demonstrated that ThingShare made initiating object-centric conversations more efficient and provided a more stable and comprehensive view of shared objects.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {365},
numpages = {22},
keywords = {shared task space, video-mediated communication, collaborative work, object-centered meetings, augmented communication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580811,
author = {Cheng, Tingyu and Tabb, Taylor and Park, Jung Wook and Gallo, Eric M and Maheshwari, Aditi and Abowd, Gregory D. and Oh, Hyunjoo and Danielescu, Andreea},
title = {Functional Destruction: Utilizing Sustainable Materials’ Physical Transiency for Electronics Applications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580811},
doi = {10.1145/3544548.3580811},
abstract = {Today’s electronics are manufactured to provide stable functionality and fixed physical forms optimized for reliable operation over long periods and repeated use. However, even when applications don’t call for such robustness, the permanency of these electronics comes with environmental consequences. In this paper, we describe an alternative approach that utilizes sustainable transient electronics whose method of destruction is also key to their functionality. We create these electronics through three different methods: 1) by inkjet printing conductive silver traces on poly(vinyl alcohol) (PVA) substrates to create water-soluble sensors; 2) by mixing a conductive beeswax material configured as a meltable sensor; and 3) by fabricating edible electronics with 3D printed chocolate and culinary gold leaf. To enable practical applications of these devices, we implement a fully transient and sustainable chipless RF detection system.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {366},
numpages = {16},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581193,
author = {Bartkowski, Wieslaw and Nowak, Andrzej and Czajkowski, Filip Ignacy and Schmidt, Albrecht and M\"{u}ller, Florian},
title = {In Sync: Exploring Synchronization to Increase Trust Between Humans and Non-Humanoid Robots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581193},
doi = {10.1145/3544548.3581193},
abstract = {When we go for a walk with friends, we can observe an interesting effect: From step lengths to arm movements - our movements unconsciously align; they synchronize. Prior research found that this synchronization is a crucial aspect of human relations that strengthens social cohesion and trust. Generalizing from these findings in synchronization theory, we propose a dynamical approach that can be applied in the design of non-humanoid robots to increase trust. We contribute the results of a controlled experiment with 51 participants exploring our concept in a between-subjects design. For this, we built a prototype of a simple non-humanoid robot that can bend to follow human movements and vary the movement synchronization patterns. We found that synchronized movements lead to significantly higher ratings in an established questionnaire on trust between people and automation but did not influence the willingness to spend money in a trust game.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {367},
numpages = {14},
keywords = {trust, design strategy, dynamical approach, non-humanoid robot, synchronization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580680,
author = {Brooks, Jas and Lopes, Pedro},
title = {Smell &amp; Paste: Low-Fidelity Prototyping for Olfactory Experiences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580680},
doi = {10.1145/3544548.3580680},
abstract = {Low-fidelity prototyping is so foundational to Human-Computer Interaction, appearing in most early design phases. So, how do experts prototype olfactory experiences? We interviewed eight experts and found that they do not because no process supports this. Thus, we engineered Smell &amp; Paste, a low-fidelity prototyping toolkit. Designers assemble olfactory proofs-of-concept by pasting scratch-and-sniff stickers onto a paper tape. Then, they test the interaction by advancing the tape in our 3D-printed (or cardboard) cassette, which releases the smells via scratching. Our toolkit uses commodity materials; keeps iterations quick, approachable, and cheap; and circumvents electronics, programming, and chemical handling. We evaluated Smell &amp; Paste in two studies. We found that the toolkit was approachable to people of any technical background and that novices and experts appropriated and extended the toolkit, making it personalized. Novices produced prototypes quickly, and experts were excited about the kit's technical affordances and integrating it into their practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {368},
numpages = {16},
keywords = {Smell, Olfactory, Rapid prototyping, Design, Olfactory experience, Paper prototyping},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581169,
author = {Yamamura, Nahoko and Uriu, Daisuke and Muramatsu, Mitsuru and Kamiyama, Yusuke and Kashino, Zendai and Sakamoto, Shin and Tanaka, Naoki and Tanigawa, Toma and Onishi, Akiyoshi and Yoshida, Shigeo and Yamanaka, Shunji and Inami, Masahiko},
title = {Social Digital Cyborgs: The Collaborative Design Process of JIZAI ARMS},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581169},
doi = {10.1145/3544548.3581169},
abstract = {Half a century since the concept of a cyborg was introduced, digital cyborgs, enabled by the spread of wearable robotics, are the focus of much research in recent times. We introduce JIZAI ARMS, a supernumerary robotic limb system consisting of a wearable base unit with six terminals and detachable robot arms controllable by the wearer. The system was designed to enable social interaction between multiple wearers, such as an exchange of arm(s), and explore possible interactions between digital cyborgs in a cyborg society. This paper describes the JIZAI ARMS’ design process, an interdisciplinary collaboration between human augmentation researchers, product designers, a system architect, and manufacturers, to realize a technically complex system while considering the aesthetics of a digital cyborg. We also provide an autobiographical report of our first impressions of using the JIZAI ARMS and use our findings to speculate on a model of potential social interactions between digital cyborgs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {19},
keywords = {Human-robot integration, Robotics, Human Augmentation, Social Digital Cyborgs, Human-computer Integration, Cyborgs, Digital Cyborgs, Human-machine Integration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580799,
author = {Zhou, Ran and Schwemler, Zachary and Baweja, Akshay and Sareen, Harpreet and Hunt, Casey Lee and Leithinger, Daniel},
title = {TactorBots: A Haptic Design Toolkit for Out-of-Lab Exploration of Emotional Robotic Touch},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580799},
doi = {10.1145/3544548.3580799},
abstract = {Emerging research has demonstrated the viability of emotional communication through haptic technology inspired by interpersonal touch. However, the meaning-making of artificial touch remains ambiguous and contextual. We see this ambiguity caused by robotic touch’s "otherness" as an opportunity for exploring alternatives. To empower emotional haptic design in longitudinal out-of-lab exploration, we devise TactorBots, a design toolkit consisting of eight wearable hardware modules for rendering robotic touch gestures controlled by a web-based software application. We deployed TactorBots to thirteen designers and researchers to validate its functionality, characterize its design experience, and analyze what, how, and why alternative perceptions, practices, contexts, and metaphors would emerge in the experiment. We provide suggestions for designing future toolkits and field studies based on our experiences. Reflecting on the findings, we derive design implications for further enhancing the ambiguity and shifting the mindsets to expand the design space.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {370},
numpages = {19},
keywords = {Creativity Support, Wearable, Design Research, Emotional Robotic Touch, Haptic Design Toolkit, Outside of Lab Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581526,
author = {D\"{o}rrenb\"{a}cher, Judith and Ringfort-Felner, Ronda and Hassenzahl, Marc},
title = {The Intricacies of Social Robots: Secondary Analysis of Fictional Documentaries to Explore the Benefits and Challenges of Robots in Complex Social Settings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581526},
doi = {10.1145/3544548.3581526},
abstract = {In the design of social robots, the focus is often on the robot itself rather than on the intricacies of possible application scenarios. In this paper, we examine eight fictional documentaries about social robots, such as SEYNO, a robot that promotes respect between passengers in trains, or PATO, a robot to watch movies with. Overall, robots were conceptualized either (1) to substitute humans in relationships or (2) to mediate relationships (human-human-robot-interaction). While the former is basis of many current approaches to social robotics, the latter is less common, but particularly interesting. For instance, the mediation perspective fundamentally impacts the role a robot takes (e.g., role model, black sheep, ally, opponent, moralizer) and thus its potential function and form. From the substitution perspective, robots are expected to mimic human emotions; from the mediation perspective, robots can be positive precisely because they remain objective and are neither emotional nor empathic.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {371},
numpages = {13},
keywords = {design fiction, otherware, Social robots, human-robot-interaction, sociability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580953,
author = {Lima, Gabriel and Grgi\'{c}-Hla\v{c}a, Nina and Cha, Meeyoung},
title = {Blaming Humans and Machines: What Shapes People’s Reactions to Algorithmic Harm},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580953},
doi = {10.1145/3544548.3580953},
abstract = {Artificial intelligence (AI) systems can cause harm to people. This research examines how individuals react to such harm through the lens of blame. Building upon research suggesting that people blame AI systems, we investigated how several factors influence people’s reactive attitudes towards machines, designers, and users. The results of three studies (N = 1,153) indicate differences in how blame is attributed to these actors. Whether AI systems were explainable did not impact blame directed at them, their developers, and their users. Considerations about fairness and harmfulness increased blame towards designers and users but had little to no effect on judgments of AI systems. Instead, what determined people’s reactive attitudes towards machines was whether people thought blaming them would be a suitable response to algorithmic harm. We discuss implications, such as how future decisions about including AI systems in the social and moral spheres will shape laypeople’s reactions to AI-caused harm.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {372},
numpages = {26},
keywords = {Blame, Responsibility, Algorithmic Decision-Making, Harm, Explainability, Discrimination, Decision-Making, Artificial Intelligence, Algorithms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580970,
author = {Andalibi, Nazanin and Pyle, Cassidy and Barta, Kristen and Xian, Lu and Jacobs, Abigail Z. and Ackerman, Mark S.},
title = {Conceptualizing Algorithmic Stigmatization},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580970},
doi = {10.1145/3544548.3580970},
abstract = {Algorithmic systems have infiltrated many aspects of our society, mundane to high-stakes, and can lead to algorithmic harms known as representational and allocative. In this paper, we consider what stigma theory illuminates about mechanisms leading to algorithmic harms in algorithmic assemblages. We apply the four stigma elements (i.e., labeling, stereotyping, separation, status loss/discrimination) outlined in sociological stigma theories to algorithmic assemblages in two contexts : 1) "risk prediction" algorithms in higher education, and 2) suicidal expression and ideation detection on social media. We contribute the novel theoretical conceptualization of algorithmic stigmatization as a sociotechnical mechanism that leads to a unique kind of algorithmic harm: algorithmic stigma. Theorizing algorithmic stigmatization aids in identifying theoretically-driven points of intervention to mitigate and/or repair algorithmic stigma. While prior theorizations reveal how stigma governs socially and spatially, this work illustrates how stigma governs sociotechnically.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {373},
numpages = {18},
keywords = {separation, theory, discrimination, algorithmic decision-making, algorithms, stigma, representational harm, higher education, mental health, algorithmic harm, social media, risk prediction, suicide ideation, allocative harm, labeling, algorithmic stigma, stereotyping},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581296,
author = {Scott, Ava Elizabeth and Neumann, Daniel and Niess, Jasmin and Wo\'{z}niak, Pawe\l{} W.},
title = {Do You Mind? User Perceptions of Machine Consciousness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581296},
doi = {10.1145/3544548.3581296},
abstract = {The prospect of machine consciousness cultivates controversy across media, academia, and industry. Assessing whether non-experts perceive technologies as conscious, and exploring the consequences of this perception, are yet unaddressed challenges in Human Computer Interaction (HCI). To address them, we surveyed 100 people, exploring their conceptualisations of consciousness and if and how they perceive consciousness in currently available interactive technologies. We show that many people already perceive a degree of consciousness in GPT-3, a voice chat bot, and a robot vacuum cleaner. Within participant responses we identified dynamic tensions between denial and speculation, thinking and feeling, interaction and experience, control and independence, and rigidity and spontaneity. These tensions can inform future research into perceptions of machine consciousness and the challenges it represents for HCI. With both empirical and theoretical contributions, this paper emphasises the importance of HCI in an era of machine consciousness, real, perceived or denied.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {374},
numpages = {19},
keywords = {Consciousness, Machine Consciousness, Technology Consciousness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580651,
author = {Bennett, Dan and Metatla, Oussama and Roudaut, Anne and Mekler, Elisa D.},
title = {How Does HCI Understand Human Agency and Autonomy?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580651},
doi = {10.1145/3544548.3580651},
abstract = {Human agency and autonomy have always been fundamental concepts in HCI. New developments, including ubiquitous AI and the growing integration of technologies into our lives, make these issues ever pressing, as technologies increase their ability to influence our behaviours and values. However, in HCI understandings of autonomy and agency remain ambiguous. Both concepts are used to describe a wide range of phenomena pertaining to sense-of-control, material independence, and identity. It is unclear to what degree these understandings are compatible, and how they support the development of research programs and practical interventions. We address this by reviewing 30 years of HCI research on autonomy and agency to identify current understandings, open issues, and future directions. From this analysis, we identify ethical issues, and outline key themes to guide future work. We also articulate avenues for advancing clarity and specificity around these concepts, and for coordinating integrative work across different HCI communities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {375},
numpages = {18},
keywords = {mixed initiative, user experience, agency, boundary objects, theory, Autonomy, delegation, Self Determination Theory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580656,
author = {Suwanaposee, Pang and Gutwin, Carl and Chen, Zhe and Cockburn, Andy},
title = {‘Specially For You’ – Examining the Barnum Effect’s Influence on the Perceived Quality of System Recommendations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580656},
doi = {10.1145/3544548.3580656},
abstract = {The ‘Barnum effect’ is a psychological phenomenon under which people assign higher quality ratings to personality descriptions developed ‘specially for you’ than the same descriptions described as ‘generally true of people.’ This effect suggests that recommender interfaces could elevate the perceived quality of recommendations simply by indicating that they are explicitly personalised. We therefore conducted a crowd-sourced experiment (n=492) that examined the perceived quality of personalised versus non-personalised movie recommendations for good and bad movies – importantly, the actual recommendations were identical, and were merely presented as being either personalised or not. Contrary to the Barnum effect, results showed numerically lower mean quality scores for personalised recommendations, but with no significant difference. Our findings suggest that Barnum-like effects of personalisation have at most a small influence on perceived quality, and that designers should not rely on this effect to improve user experience (despite online design guidance suggesting the opposite).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {376},
numpages = {11},
keywords = {Barnum effect, subjective experience, AI recommendations},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581026,
author = {Deng, Wesley Hanwen and Guo, Boyuan and Devrio, Alicia and Shen, Hong and Eslami, Motahhare and Holstein, Kenneth},
title = {Understanding Practices, Challenges, and Opportunities for User-Engaged Algorithm Auditing in Industry Practice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581026},
doi = {10.1145/3544548.3581026},
abstract = {Recent years have seen growing interest among both researchers and practitioners in user-engaged approaches to algorithm auditing, which directly engage users in detecting problematic behaviors in algorithmic systems. However, we know little about industry practitioners’ current practices and challenges around user-engaged auditing, nor what opportunities exist for them to better leverage such approaches in practice. To investigate, we conducted a series of interviews and iterative co-design activities with practitioners who employ user-engaged auditing approaches in their work. Our findings reveal several challenges practitioners face in appropriately recruiting and incentivizing user auditors, scaffolding user audits, and deriving actionable insights from user-engaged audit reports. Furthermore, practitioners shared organizational obstacles to user-engaged auditing, surfacing a complex relationship between practitioners and user auditors. Based on these findings, we discuss opportunities for future HCI research to help realize the potential (and mitigate risks) of user-engaged auditing in industry practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {377},
numpages = {18},
keywords = {bias, responsible AI, fairness, user-engaged algorithm auditing, industry practitioners},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580760,
author = {Jansen, Pascal and Britten, Julian and H\"{a}usele, Alexander and Segschneider, Thilo and Colley, Mark and Rukzio, Enrico},
title = {AutoVis: Enabling Mixed-Immersive Analysis of Automotive User Interface Interaction Studies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580760},
doi = {10.1145/3544548.3580760},
abstract = {Automotive user interface (AUI) evaluation becomes increasingly complex due to novel interaction modalities, driving automation, heterogeneous data, and dynamic environmental contexts. Immersive analytics may enable efficient explorations of the resulting multilayered interplay between humans, vehicles, and the environment. However, no such tool exists for the automotive domain. With AutoVis, we address this gap by combining a non-immersive desktop with a virtual reality view enabling mixed-immersive analysis of AUIs. We identify design requirements based on an analysis of AUI research and domain expert interviews (N=5). AutoVis supports analyzing passenger behavior, physiology, spatial interaction, and events in a replicated study environment using avatars, trajectories, and heatmaps. We apply context portals and driving-path events as automotive-specific visualizations. To validate AutoVis against real-world analysis tasks, we implemented a prototype, conducted heuristic walkthroughs using authentic data from a case study and public datasets, and leveraged a real vehicle in the analysis process.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {378},
numpages = {23},
keywords = {automotive user interfaces, Immersive analytics, interaction analysis, virtual reality, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580827,
author = {Liu, Jiazhou and Ens, Barrett and Prouzeau, Arnaud and Smiley, Jim and Nixon, Isobel Kara and Goodwin, Sarah and Dwyer, Tim},
title = {DataDancing: An Exploration of the Design Space For Visualisation View Management for 3D Surfaces and Spaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580827},
doi = {10.1145/3544548.3580827},
abstract = {Recent studies have explored how users of immersive visualisation systems arrange data representations in the space around them. Generally, these have focused on placement centred at eye-level in absolute room coordinates. However, work in HCI exploring full-body interaction has identified zones relative to the user’s body with different roles. We encapsulate the possibilities for visualisation view management into a design space (called “DataDancing”). From this design space we extrapolate a variety of view management prototypes, each demonstrating a different combination of interaction techniques and space use. The prototypes are enabled by a full-body tracking system including novel devices for torso and foot interaction. We explore four of these prototypes, encompassing standard wall and table-style interaction as well as novel foot interaction, in depth through a qualitative user study. Learning from the results, we improve the interaction techniques and propose two hybrid interfaces that demonstrate interaction possibilities of the design space.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {17},
keywords = {visualisation view management, virtual reality, immersive analytics, design space exploration, 3D surfaces and spaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580678,
author = {Li, Ang and Liu, Jiazhou and Cordeil, Maxime and Topliss, Jack and Piumsomboon, Thammathip and Ens, Barrett},
title = {GestureExplorer: Immersive Visualisation and Exploration of Gesture Data},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580678},
doi = {10.1145/3544548.3580678},
abstract = {This paper presents the design and evaluation of GestureExplorer, an Immersive Analytics tool that supports the interactive exploration, classification and sensemaking with large sets of 3D temporal gesture data. GestureExplorer features 3D skeletal and trajectory visualisations of gestures combined with abstract visualisations of clustered sets of gestures. By leveraging the large immersive space afforded by a Virtual Reality interface our tool allows free navigation and control of viewing perspective for users to gain a better understanding of gestures. We explored a selection of classification methods to provide an overview of the dataset that was linked to a detailed view of the data that showed different visualisation modalities. We evaluated GestureExplorer with two user studies and collected feedback from participants with diverse visualisation and analytics backgrounds. Our results demonstrated the promising capability of GestureExplorer for providing a useful and engaging experience in exploring and analysing gesture data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {380},
numpages = {16},
keywords = {virtual reality, immersive analytics, gesture elicitation study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580715,
author = {Luo, Weizhou and Yu, Zhongyuan and Rzayev, Rufat and Satkowski, Marc and Gumhold, Stefan and McGinity, Matthew and Dachselt, Raimund},
title = {Pearl: Physical Environment Based Augmented Reality Lenses for In-Situ Human Movement Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580715},
doi = {10.1145/3544548.3580715},
abstract = {This paper presents Pearl, a mixed-reality approach for the analysis of human movement data in situ. As the physical environment shapes human motion and behavior, the analysis of such motion can benefit from the direct inclusion of the environment in the analytical process. We present methods for exploring movement data in relation to surrounding regions of interest, such as objects, furniture, and architectural elements. We introduce concepts for selecting and filtering data through direct interaction with the environment, and a suite of visualizations for revealing aggregated and emergent spatial and temporal relations. More sophisticated analysis is supported through complex queries comprising multiple regions of interest. To illustrate the potential of Pearl, we developed an Augmented Reality-based prototype and conducted expert review sessions and scenario walkthroughs in a simulated exhibition. Our contribution lays the foundation for leveraging the physical environment in the in-situ analysis of movement data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {381},
numpages = {15},
keywords = {In-situ visualization, Immersive Analytics, physical referents, movement data analysis, augmented/mixed reality, affordance},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580952,
author = {Satriadi, Kadek Ananta and Cunningham, Andrew and Smith, Ross T. and Dwyer, Tim and Drogemuller, Adam and Thomas, Bruce H.},
title = {ProxSituated Visualization: An Extended Model of Situated Visualization Using Proxies for Physical Referents},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580952},
doi = {10.1145/3544548.3580952},
abstract = {Existing situated visualization models assume the user is able to directly interact with the objects and spaces to which the data refers (known as physical referents). We review a growing body of work exploring scenarios where the user interacts with a proxy representation of the physical referent rather than immediately with the object itself. This introduces a complex mixture of immediate situatedness and proxies of situatedness that goes beyond the expressiveness of current models. We propose an extended model of situated visualization that encompasses Immediate Situated Visualization and ProxSituated (Proxy of Situated) Visualization. Our model describes a set of key entities involved in proxSituated scenarios and important relationships between them. From this model, we derive design dimensions and apply them to existing situated visualization work. The resulting design space allows us to describe and evaluate existing scenarios, as well as to creatively generate new conceptual scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {382},
numpages = {20},
keywords = {proxsituated visualization, situated analytics, immersive analytics, embedded visualization, situated visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581093,
author = {Saffo, David and Batch, Andrea and Dunne, Cody and Elmqvist, Niklas},
title = {Through Their Eyes and In Their Shoes: Providing Group Awareness During Collaboration Across Virtual Reality and Desktop Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581093},
doi = {10.1145/3544548.3581093},
abstract = {Many collaborative data analysis situations benefit from collaborators utilizing different platforms. However, maintaining group awareness between team members using diverging devices is difficult, not least because common ground diminishes. A person using head-mounted VR cannot physically see a user on a desktop computer even while co-located, and the desktop user cannot easily relate to the VR user’s 3D workspace. To address this, we propose the “eyes-and-shoes” principles for group awareness and abstract them into four levels of techniques. Furthermore, we evaluate these principles with a qualitative user study of 6 participant pairs synchronously collaborating across distributed desktop and VR head-mounted devices. In this study, we vary the group awareness techniques between participants and explore two visualization contexts within participants. The results of this study indicate that the more visual metaphors and views of participants diverge, the greater the level of group awareness is needed. A copy of this paper, the study preregistration, and all supplemental materials required to reproduce the study are available on OSF (link).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {383},
numpages = {15},
keywords = {ubiquitous analytics., Asymmetric collaboration, virtual reality, immersive analytics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581329,
author = {Sabri, Nazanin and Chen, Bella and Teoh, Annabelle and Dow, Steven P. and Vaccaro, Kristen and Elsherief, Mai},
title = {Challenges of Moderating Social Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581329},
doi = {10.1145/3544548.3581329},
abstract = {Recent years have seen a rise in social virtual reality (VR) platforms that allow people to interact in real-time through voice and gestures. The ephemeral nature of communication on these platforms can enable new forms of harmful behavior and new challenges for moderators. We performed virtual field research on three VR environments (AltspaceVR, Horizon Worlds, Rec Room). Based on observing 100 scheduled events, our analysis uncovered 13 distinct types of potentially harmful behaviors enabled by real-time voice, embodied interactions, and platform affordances. We witnessed potential harm at 45% of our observed events; only 24% of these incidents were addressed by moderators. To understand moderation practices, we conducted interviews with 11 moderators to investigate how they assess real-time interactions and how they operate within the current state of moderation tools. Our work sheds light on how moderation tools and practices must evolve to meet the new challenges of social VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {20},
keywords = {Content Moderation, Virtual Ethnography, Ephemeral Social Spaces, Virtual Reality, Interview},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581464,
author = {Fu, Kexue and Chen, Yixin and Cao, Jiaxun and Tong, Xin and LC, RAY},
title = {"I Am a Mirror Dweller": Probing the Unique Strategies Users Take to Communicate in the Context of Mirrors in Social Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581464},
doi = {10.1145/3544548.3581464},
abstract = {Increasingly popular social virtual reality (VR) platforms like VRChat created new ways for people to interact with each other, generating dedicated user communities with unique idioms of socializing in an alternative world. In VRChat, users frequently gather in front of mirrors en masse during online interactions. Understanding how user communities deal with the mirror’s unique interactions can generate insights for supporting communication in social VR. In this study, we investigated the mirror’s synergistic effect with avatars on behaviors and dedicated user conversational performance. Qualitative findings indicate that avatar-mediated communication through mirrors provides functions like ensuring synchronization of incarnations, increasing immersion, and enhancing idealized embodiment to express bolder behaviors anonymously. Quantitative studies show that while mirrors improve self-perception, it has a potentially adverse effect on conversational performance, similar to the role of self-viewing in video conferencing. Studying how users interact with mirrors in an immersive environment allows us to explore how digital environments affect spatialized interactions when transported from physical to digital domains.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {19},
keywords = {avatar-mediated communication, body illusion, mirror, Social VR},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580870,
author = {Fashimpaur, Jacqui and Karlson, Amy and Jonker, Tanya R. and Benko, Hrvoje and Gupta, Aakar},
title = {Investigating Wrist Deflection Scrolling Techniques for Extended Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580870},
doi = {10.1145/3544548.3580870},
abstract = {Scrolling in extended reality (XR) is currently performed using handheld controllers or vision-based arm-in-front gestures, which have the limitations of encumbering the user’s hands or requiring a specific arm posture, respectively. To address these limitations, we investigate freehand, posture-independent scrolling driven by wrist deflection. We propose two novel techniques: Wrist Joystick, which uses rate control, and Wrist Drag, which uses position control. In an empirical study of a rapid item acquisition task and a casual browsing task, both Wrist Drag and Wrist Joystick performed on par with a comparable state-of-the-art technique on one of the two tasks. Further, using a relaxed arm-at-side posture, participants retained their arm-in-front performance for both wrist techniques. Finally, we analyze behavioral and ergonomic data to provide design insights for wrist deflection scrolling. Our results demonstrate that wrist deflection provides a promising method for performant scrolling controls while offering additional benefits over existing XR interaction techniques.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {386},
numpages = {16},
keywords = {rate control, virtual reality, scrolling, user study, extended reality, wrist deflection, freehand, wristband, position control},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581238,
author = {Vasudevan, Madhan Kumar and Zhong, Shu and Ku\v{c}era, Jan and Cho, Desiree and Obrist, Marianna},
title = {MindTouch: Effect of Mindfulness Meditation on Mid-Air Tactile Perception},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581238},
doi = {10.1145/3544548.3581238},
abstract = {As we constantly seek to improve and expand upon the capabilities of technology, we frequently wonder whether we use technology to its fullest extent. Studies indicate that increasing our awareness and mindfulness of our senses may lead to a journey of unexplored experiences. In this paper, we focus on the perception of mid-air haptics stimuli and whether it can be improved through mindfulness meditation. We have conducted an experiment with 22 participants given the task to recognize digits 0 to 9 drawn on their palms using a mid-air haptic device under two conditions - with and without prior mindfulness meditation. Results show that for frequencies targeting both Meissner (40 Hz) and Pacinian (200 Hz) receptors, meditation significantly improves performance of the participants, as well as increases their confidence. This suggests that including a short meditation step in haptic user interfaces could lead to improved system performance and user satisfaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {387},
numpages = {12},
keywords = {Haptics, Tactile Experience, Mindfulness Meditation, Mid-Air Haptics, Touch, Tactile Perception},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581223,
author = {Weiss, Yannick and Villa, Steeven and Schmidt, Albrecht and Mayer, Sven and M\"{u}ller, Florian},
title = {Using Pseudo-Stiffness to Enrich the Haptic Experience in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581223},
doi = {10.1145/3544548.3581223},
abstract = {Providing users with a haptic sensation of the hardness and softness of objects in virtual reality is an open challenge. While physical props and haptic devices help, their haptic properties do not allow for dynamic adjustments. To overcome this limitation, we present a novel technique for changing the perceived stiffness of objects based on a visuo-haptic illusion. We achieved this by manipulating the hands’ Control-to-Display (C/D) ratio in virtual reality while pressing down on an object with fixed stiffness. In the first study (N=12), we determine the detection thresholds of the illusion. Our results show that we can exploit a C/D ratio from 0.7 to 3.5 without user detection. In the second study (N=12), we analyze the illusion’s impact on the perceived stiffness. Our results show that participants perceive the objects to be up to 28.1% softer and 8.9% stiffer, allowing for various haptic applications in virtual reality.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {388},
numpages = {15},
keywords = {virtual reality, pseudo-haptics, haptic illusions},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581144,
author = {Albarrak, Luluah and Metatla, Oussama and Roudaut, Anne},
title = {Using Virtual Reality and Co-Design to Study the Design of Large-Scale Shape-Changing Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581144},
doi = {10.1145/3544548.3581144},
abstract = {Large-scale shape-changing interfaces (SCIs) such as shape-changing walls offer opportunities for enhancing user experiences within buildings, e.g., for navigation. However, due to the embryonic nature of SCI technologies, designing and explaining the shape features that are beneficial to users is challenging. Previous work used virtual platforms (2D video or Projected Augmented Reality) to design SCI. This paper explores how Virtual Reality (VR) can provide an immersive experience that can help in designing large-scale SCI. We follow a co-design approach in which we use VR to obtain users’ impressions of shape-changing walls. Then, we conduct co-design sessions to understand how shape-changing walls can be designed to become ambient and blend with the environment. We report our results to guide the design of shape-changing walls as well as discuss how our approach can provide valuable insights into how a VR experience, prior to design, and can help in the design process.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {389},
numpages = {17},
keywords = {Co-design, Virtual Reality, Shape-Changing Walls, Large-Scale Interfaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581281,
author = {Danielescu, Andreea and Horowit-Hendler, Sharone A and Pabst, Alexandria and Stewart, Kenneth Michael and Gallo, Eric M and Aylett, Matthew Peter},
title = {Creating Inclusive Voices for the 21st Century: A Non-Binary Text-to-Speech for Conversational Assistants},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581281},
doi = {10.1145/3544548.3581281},
abstract = {As voice assistant usage continues to grow, their homogeneity becomes even more problematic with the UNESCO report, “I’d Blush if I could” showing that designing only feminine voice assistants encourages negative behavior, both with virtual assistants and with real people [3]. While masculine text-to-speech (TTS) voices exist, ones that cover the full range of gender presentations, such as non-binary or gender-ambiguous voices are largely missing. In this paper, we present a method of creating a non-binary TTS voice and an example voice, Sam, created with input from the non-binary and transgender communities. We have open-sourced the resulting voice, along with the process and data used to create it. Finally, we present results from a large-scale survey showing that non-binary individuals are more likely to prefer a non-binary voice assistant compared to cisgendered individuals and discuss differences across age and gender.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {390},
numpages = {17},
keywords = {text-to-speech, voice user interfaces., voice assistants, gender},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581538,
author = {Shahid, Farhana and Vashistha, Aditya},
title = {Decolonizing Content Moderation: Does Uniform Global Community Standard Resemble Utopian Equality or Western Power Hegemony?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581538},
doi = {10.1145/3544548.3581538},
abstract = {Social media platforms use content moderation to reduce and remove problematic content. However, much of the discourse on the benefits and pitfalls of moderation has so far focused on users in the West. Little is known about how users in the Global South interact with the humans and algorithms behind opaque moderation systems. To fill this gap, we conducted interviews with 19 Bangladeshi social media users who received restrictions for violating community standards on Facebook. We found that the users perceived the underlying human-AI infrastructure to imbibe coloniality in the form of amplifying power relations, centering Western norms, and perpetuating historical injustices and erasure of minoritized expressions. Based on the findings, we establish that the current moderation systems often propagate historical power relations and patterns of oppression, and discuss ways to rethink moderation in a fundamentally decolonial way.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {391},
numpages = {18},
keywords = {decoloniality, care, moderation, Global South},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581490,
author = {Petterson, Adrian and Cheng, Keith and Chandra, Priyank},
title = {Playing with Power Tools: Design Toolkits and the Framing of Equity},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581490},
doi = {10.1145/3544548.3581490},
abstract = {Design toolkits that aim to to promote equity offer designers simplified approaches to creating more equitable technology. However, it is important to understand how equity is conceptualized in practice. As a curated collection of methods, toolkits signal how equity is imagined in design. In this paper, we perform a qualitative analysis of 17 design toolkits related to equity. We explore alternative design approaches that address inequity in design. We evaluate whether equity toolkits align with calls for changes to design practice, as well as Nancy Fraser’s dimensions of justice. Finally, we find that design toolkits focus on the ‘digital divide’ rather than redistributing world-building power, and thus continue to keep design power with professional designers. We also find that ‘design thinking’ continues to influence design toolkits. Furthermore, the simplicity of toolkits does not engage with the complexities that shape equity in practice. We conclude with suggestions to help researchers and designers rethink design toolkits.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {392},
numpages = {24},
keywords = {Participatory Design, ethics, Universal Design, tool, justice, toolkits, Value Sensitive Design, equity, activism, cards, design, Inclusive Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581327,
author = {Bolesnikov, Adrian and Cochrane, Karen Anne and Girouard, Audrey},
title = {Wearable Identities: Understanding Wearables’ Potential for Supporting the Expression of Queer Identities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581327},
doi = {10.1145/3544548.3581327},
abstract = {Queer identity research largely overlooks wearable technology. Most work exploring sociocultural considerations of wearable technology determines what is “socially acceptable” based on privileged bodies, excluding queer perspectives. We address this by establishing the foundations of a knowledge base for wearables that support queer expression. We conducted a two-phase qualitative study exploring queer expressive practices and wearable technologies through 16 semi-structured interviews and 15 body mapping workshops with the queer community. We observed themes framing the queer community’s understanding of queer expression, wearable technology, and wearable technology for queer users. Providing design considerations and discussions on the potential of our methods, our work enables the creation of wearable technologies that offer meaningful user experiences for the queer community. CAUTION: This paper discusses topics that could trigger those with histories of homophobia, transphobia, gender dysphoria, racism or eating disorders. Please use caution when engaging with this work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {393},
numpages = {19},
keywords = {Inclusive design, Wearable Computing, Identity Management, Speculative Design, Somatic Design, Design Fiction, Body Mapping, Self-Presentation, Queer Interaction, Sexual and Gender Minorities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581010,
author = {Showkat, Dilruba and Smith, Angela D. R. and Lingqing, Wang and To, Alexandra},
title = {“Who is the Right Homeless Client?”: Values in Algorithmic Homelessness Service Provision and Machine Learning Research},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581010},
doi = {10.1145/3544548.3581010},
abstract = {Homelessness presents a long-standing problem worldwide. Like other welfare services, homeless services have gained increased traction in Machine Learning (ML) research. Unhoused persons are vulnerable and using their data in the ML pipeline raises serious concerns about the unintended harms and consequences of prioritizing different ML values. To address this, we conducted a critical analysis of 40 research papers identified through a systematic literature review in ML homelessness service provision research. We found that the values of novelty, performance, and identifying limitations were uplifted in these papers, whereas (in)efficiency, (low/high) cost, fast, (violated) privacy, and (homeless condition) reproducibility valuescollapse. Consequently, unhoused persons were lost (i.e., humans were deprioritized) at multi-level ML abstraction of predictors, categories, and algorithms. Our findings illuminate potential pathways forward at the intersection of data science, HCI and STS by situating humans at the center to support this vulnerable community.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {394},
numpages = {21},
keywords = {Values Collapse, Machine Learning (ML) Values, ML Values Collapse in Homelessness, Homelessness and Algorithms, Homelessness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581122,
author = {Chen, Yiqun T. and Smith, Angela D. R. and Reinecke, Katharina and To, Alexandra},
title = {Why, When, and from Whom: Considerations for Collecting and Reporting Race and Ethnicity Data in HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581122},
doi = {10.1145/3544548.3581122},
abstract = {Engaging diverse participants in HCI research is critical for creating safe, inclusive, and equitable technology. However, there is a lack of guidelines on when, why, and how HCI researchers collect study participants’ race and ethnicity. Our paper aims to take the first step toward such guidelines by providing a systematic review and discussion of the status quo of race and ethnicity data collection in HCI. Through an analysis of 2016–2021 CHI proceedings and a survey with 15 authors who published in these proceedings, we found that reporting race and ethnicity of participants is very rare (&lt;3%) and that researchers are far from consensus. Drawing from multidisciplinary literature and our findings, we devise considerations for HCI researchers to decide why, when, and from whom to collect race and ethnicity data. For truly inclusive, equitable technologies, we encourage deliberate decisions rather than default omissions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {395},
numpages = {15},
keywords = {ethnicity, race, HCI research, systematic literature review, survey},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581501,
author = {Bailey, Jakki O. and Schloss, Isabella},
title = {“Awesomely Freaky!” The Impact of Type on Children's Social-Emotional Perceptions of Virtual Reality Characters},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581501},
doi = {10.1145/3544548.3581501},
abstract = {While VR, through decades of research, has shown to successfully improve young children's lives, more research needs to examine the appropriateness of VR for children, including its design. The type of character in combination with the perceptual realism of virtual reality (VR) may influence children's perceptions of VR experiences. A within-participant experiment examined 5- to 9-year-old children's (N = 25) perceptions of three different character types in VR (i.e., human, animal, and anthropomorphized creature) based on their level of social realism. Results showed that character type impacted children's (a) social-emotional descriptions of the VR experience, (b) if VR's realism was an asset or a hindrance, and (c) primed thoughts about fantasy versus reality. However, children experienced the embodiment and personification of the characters similarly across all character types. Finally, children recalled the salient aspects of the characters they remembered and identified elements to improve the VR characters’ design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {396},
numpages = {10},
keywords = {virtual reality, child development, parasocial relationships, social-emotional, uncanny valley},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581212,
author = {Jicol, Crescent and Clarke, Christopher and Tor, Emilia and Yip, Hiu Lam and Yoon, Jinha and Bevan, Chris and Bowden, Hugh and Brann, Elisa and Cater, Kirsten and Cole, Richard and Deeley, Quinton and Eidinow, Esther and O'Neill, Eamonn and Lutteroth, Christof and Proulx, Michael J},
title = {Imagine That! Imaginative Suggestibility Affects Presence in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581212},
doi = {10.1145/3544548.3581212},
abstract = {Personality characteristics can affect how much presence an individual experiences in virtual reality, and researchers have explored how it may be possible to prime users to increase their sense of presence. A personality characteristic that has yet to be explored in the VR literature is imaginative suggestibility, the ability of an individual to successfully experience an imaginary scenario as if it were real. In this paper, we explore how suggestibility and priming affect presence when consulting an ancient oracle in VR as part of an educational experience – a common VR application. We show for the first time how imaginative suggestibility is a major factor which affects presence and emotions experienced in VR, while priming cues have no effect on participants’ (n=128) user experience, contrasting results from prior work. We consider the impacts of these findings for VR design and provide guidelines based on our results.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {397},
numpages = {11},
keywords = {priming, virtual reality, imaginative suggestibility, presence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581004,
author = {Drey, Tobias and Montag, Michael and Vogt, Andrea and Rixen, Nico and Seufert, Tina and Zander, Steffi and Rietzler, Michael and Rukzio, Enrico},
title = {Investigating the Effects of Individual Spatial Abilities on Virtual Reality Object Manipulation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581004},
doi = {10.1145/3544548.3581004},
abstract = {Object manipulation in 3D space, meaning translating, rotating, and scaling, is ubiquitous in virtual reality (VR), and several interaction techniques have been developed in the past to optimize the task performance and usability. However, preliminary research indicates that individual spatial abilities also have an impact. Yet, it was never investigated if users’ spatial abilities influence VR object manipulation. We assessed this in a user study (N=66) using 21 manipulation tasks defined in a Fitts’ law-related approach. As interaction techniques, we chose gizmos for simultaneously manipulating 1 and 3 degrees of freedom (DOF) and a handle bar metaphor for 7 DOF. Higher spatial abilities resulted in significantly shorter task completion time and more targeted manipulations, while task accuracy was unaffected. However, an optimized interaction technique could compensate individual disadvantages. We propose seven guidelines on spatial abilities in interaction technique design and research to personalize and improve VR applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {398},
numpages = {24},
keywords = {virtual reality, individual characteristics, Fitts’ law, interaction technique, docking task, mixed reality, object manipulation, spatial abilities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581448,
author = {Jicol, Crescent and Clarke, Christopher and Tor, Emilia and Dakin, Rebecca M and Lancaster, Tom Charlie and Chang, Sze Tung and Petrini, Karin and O'Neill, Eamonn and Proulx, Michael J and Lutteroth, Christof},
title = {Realism and Field of View Affect Presence in VR but Not the Way You Think},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581448},
doi = {10.1145/3544548.3581448},
abstract = {Presence is one of the most studied and most important variables in immersive virtual reality (VR) and it influences the effectiveness of many VR applications. Separate bodies of research indicate that presence is determined by (1) technical factors such as the visual realism of a virtual environment (VE) and the field of view (FoV), and (2) human factors such as emotions and agency. However, it remains unknown how technical and human factors may interact in the presence formation process. We conducted a user study (n=360) to investigate the effects of visual realism (high/low), FoV (high/low), emotions (focusing on fear) and agency (yes/no) on presence. Counter to previous assumptions, technical factors did not affect presence directly but were moderated through human factors. We propose TAP-Fear, a structural equation model that describes how design decisions, technical factors and human factors combine and interact in the formation of presence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {virtual reality, presence, level of detail, field of view, emotions, agency},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581461,
author = {Sch\"{o}n, Dominik and Kosch, Thomas and M\"{u}ller, Florian and Schmitz, Martin and G\"{u}nther, Sebastian and Bommhardt, Lukas and M\"{u}hlh\"{a}user, Max},
title = {Tailor Twist: Assessing Rotational Mid-Air Interactions for Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581461},
doi = {10.1145/3544548.3581461},
abstract = {Mid-air gestures, widely used in today’s Augmented Reality (AR) applications, are prone to the “gorilla arm” effect, leading to discomfort with prolonged interactions. While prior work has proposed metrics to quantify this effect and means to improve comfort and ergonomics, these works usually only consider simplistic, one-dimensional AR interactions, like reaching for a point or pushing a button. However, interacting with AR environments also involves far more complex tasks, such as rotational knobs, potentially impacting ergonomics. This paper advances the understanding of the ergonomics of rotational mid-air interactions in AR. For this, we contribute the results of a controlled experiment exposing the participants to a rotational task in the interaction space defined by their arms’ reach. Based on the results, we discuss how novel future mid-air gesture modalities benefit from our findings concerning ergonomic-aware rotational interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {400},
numpages = {14},
keywords = {Mid-Air Gesture, Augmented Reality, Rotational Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581443,
author = {Ke, Bo-Cheng and Li, Min-Han and Chen, Yu and Cheng, Chia-Yu and Chang, Chiao-Ju and Li, Yun-Fang and Wang, Shun-Yu and Fang, Chiao and Chen, Mike Y.},
title = {TurnAhead: Designing 3-DoF Rotational Haptic Cues to Improve First-Person Viewing (FPV) Experiences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581443},
doi = {10.1145/3544548.3581443},
abstract = {First-Person View (FPV) drone is a recently developed category of drones designed for precision flying and for capturing exhilarating experiences that could not be captured before, such as navigating through tight indoor spaces and flying extremely close to subjects of interest. FPV viewing experiences, while exhilarating, typically have frequent rotations that can lead to visually induced discomfort. We present TurnAhead, which uses 3-DoF rotational haptic cues that correspond to camera rotations to improve the comfort, immersion, and enjoyment of FPV experiences. It uses headset-mounted air jets to provide ungrounded rotational forces and is the first device to support rotation around all 3 axes: yaw, pitch, and roll. We conducted a series of perception and formative studies to explore the design space of timing and intensity of haptic cues, followed by user experience evaluation, for a combined total of 44 participants (n=12, 8, 6, 18). Results showed that TurnAhead significantly improved overall comfort, immersion, and enjoyment, and was preferred by 89% of participants.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {401},
numpages = {15},
keywords = {User Experience Design, Haptic Device, Virtual Reality, First-person Viewing Video},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581552,
author = {Palm\'{e}n, Hilary and Gilbert, Michael and Crossland, David},
title = {How Bold Can We Be? The Impact of Adjusting Font Grade on Readability in Light and Dark Polarities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581552},
doi = {10.1145/3544548.3581552},
abstract = {Variable font file technology enables adjusting fonts on scaled axes that can include weight, and grade. While making text bold increases the character width, grade achieves boldness without increasing character width or causing text reflow. Through two studies with a total of 459 participants, we examined the effect of varying grade levels on both glancing and paragraph reading tasks in light and dark modes. We show that dark text on a light background (Light Mode) is read reliably faster than its polar opposite (Dark Mode). We found an effect of mode for both glance and paragraph reading and an effect of grade for LM with heavier, increased grade levels. Paragraph readers are not choosing, or preferring, LM over DM despite fluency benefits and reported visual clarity. Software designers can vary grade across the tested font formats to influence design aesthetics and user preferences without worrying about reducing reading fluency.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {402},
numpages = {11},
keywords = {Grade, Polarity, Font, Typography, Mode, Type style, Weight, Text, Readability, Polarity. Reading fluency, Typeface, Reading, Variable font},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581246,
author = {Renom, Miguel A. and Caramiaux, Baptiste and Beaudouin-Lafon, Michel},
title = {Interaction Knowledge: Understanding the ‘Mechanics’ of Digital Tools},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581246},
doi = {10.1145/3544548.3581246},
abstract = {User interfaces typically feature tools to act on objects and rely on the ability of users to discover or learn how to interact with them. Previous work in HCI has used the Theory of Affordances to explain how users understand the possibilities for action in digital environments. A complementary theory from cognitive neuroscience, Technical Reasoning, posits that users accumulate abstract knowledge of object properties and technical principles known as mechanical knowledge, essential in tool use. Drawing from this theory, we introduce interaction knowledge as the “mechanical” knowledge of digital environments. We provide evidence of its relevance by reporting on an experiment where participants performed tasks in a digital environment with ambiguous possibilities for interaction. We analyze how interaction knowledge was transferred across two digital domains, text editing and graphical editing, and conclude that interaction knowledge models an essential type of knowledge for interacting in the digital world.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {403},
numpages = {14},
keywords = {learnability, discoverability, technical reasoning, tool use, mechanical knowledge},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581068,
author = {Wilner, Tamar and Mimizuka, Kayo and Bhimdiwala, Ayesha and Young, Jason C and Arif, Ahmer},
title = {It’s About Time: Attending to Temporality in Misinformation Interventions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581068},
doi = {10.1145/3544548.3581068},
abstract = {Recent studies in HCI have explored how we might reduce the spread of online misinformation by helping people learn how to evaluate information in more skillful ways. Unfortunately, it isn’t clear that such interventions have been meaningfully integrated into communities. To better understand why this is the case, this paper engages over thirty information professionals (educators, librarians, and journalists) who promote digital literacy in BIPOC and rural communities. Our participants describe a temporal mismatch, whereby digital literacy requires time-consuming processes that cannot be accelerated, but institutional and societal pressures demand speed. We also describe strategies that participants envisaged to cope with this mismatch. This leads us to discuss how the HCI community can better engage with the temporal aspects of digital literacy work, with a view toward expanding the range of solutions we can design to address the misinformation crisis.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {404},
numpages = {19},
keywords = {sociology of time, temporal experience, misinformation, digital literacy, emotions, temporality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581535,
author = {Jacobsen, Rune M\o{}berg and Fangel Skov, Kasper and Johansen, Stine S and Skov, Mikael B. and Kjeldskov, Jesper},
title = {Living with Sound Zones: A Long-Term Field Study of Dynamic Sound Zones in a Domestic Context},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581535},
doi = {10.1145/3544548.3581535},
abstract = {Sound zone technology enables multiple people to have personal and shared listening experiences without disturbing each other. Methods for constructing sound zones have now matured enough to allow installations outside of experimental laboratories, making it essential for further development to conduct empirical studies about how people adopt, use, and interact with sound zones in, e.g., domestic settings. To that end, we conducted a four-week field study with a sound zone system in five households. Through an inductive reflexive thematic analysis, we identify three themes relating to 1) experiencing sound zones in everyday life, 2) sound zone usage patterns in households, and 3) interacting with sound zones. Based on these themes, we discuss how sound zones can be used to manage sound in homes in new ways to allow for better social coexistence and listening experiences. We present four directions for future HCI research and interaction design to comply with user needs and considerations when using this novel technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {405},
numpages = {14},
keywords = {sound interaction, visualisation, sound visualisation, ubiquitous computing, Sound zones},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581385,
author = {Reitmaier, Thomas and Wallington, Electra and Klejch, Ond\v{r}ej and Markl, Nina and Lam-Yee-Mui, L\'{e}a-Marie and Pearson, Jennifer and Jones, Matt and Bell, Peter and Robinson, Simon},
title = {Situating Automatic Speech Recognition Development within Communities of Under-Heard Language Speakers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581385},
doi = {10.1145/3544548.3581385},
abstract = {In this paper we develop approaches to automatic speech recognition (ASR) development that suit the needs and functions of under-heard language speakers. Our novel contribution to HCI is to show how community-engagement can surface key technical and social issues and opportunities for more effective speech-based systems. We introduce a bespoke toolkit of technologies and showcase how we utilised the toolkit to engage communities of under-heard language speakers; and, through that engagement process, situate key aspects of ASR development in community contexts. The toolkit consists of (1) an information appliance to facilitate spoken-data collection on topics of community interest, (2) a mobile app to create crowdsourced transcripts of collected data, and (3) demonstrator systems to showcase ASR capabilities and to feed back research results to community members. Drawing on the sensibilities we cultivated through this research, we present a series of challenges to the orthodoxy of state-of-the-art approaches to ASR development.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {406},
numpages = {17},
keywords = {mobile devices: phones/tablets, Text/speech/language, automatic speech recognition},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581191,
author = {Clark, Logan D and El Iskandarani, Mohamad and Riggs, Sara L},
title = {The Effect of Movement Direction, Hand Dominance, and Hemispace on Reaching Movement Kinematics in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581191},
doi = {10.1145/3544548.3581191},
abstract = {When users reach their arms to different locations in physical space, they often adapt how they move (i.e., kinematic properties of their reaches) depending on the: (1) direction they move, (2) hand they use, and (3) side of the body where the movement occurs. However, it is not yet clear if and how these three properties of reaching tasks may interact to influence users’ behavior when they reach to objects in VR. To address this question, we had users perform virtual hand reaches in five different directions, on both sides of their bodies, using both their dominant and non-dominant hands. The results revealed that users adapted their virtual hand reaching movements in response to changes in all three properties. The findings provide practitioners insights on how to measure and interpret users’ movements, which has applicability in emerging contexts that include detecting VR usability issues and using VR for stroke rehabilitation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {407},
numpages = {18},
keywords = {virtual hand, reaching, virtual reality, movement kinematics, pointing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580969,
author = {Dang, Hai and Goller, Sven and Lehmann, Florian and Buschek, Daniel},
title = {Choice Over Control: How Users Write with Large Language Models Using Diegetic and Non-Diegetic Prompting},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580969},
doi = {10.1145/3544548.3580969},
abstract = {We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. “Once upon a time, I saw a fox...”), and (2) non-diegetic prompts (external, e.g. “Write about the adventures of the fox.”). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {408},
numpages = {17},
keywords = {User-centric natural language generation, Human-AI collaboration, Large language models, Co-creative systems},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580857,
author = {Pascher, Max and Gruenefeld, Uwe and Schneegass, Stefan and Gerken, Jens},
title = {How to Communicate Robot Motion Intent: A Scoping Review},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580857},
doi = {10.1145/3544548.3580857},
abstract = {Robots are becoming increasingly omnipresent in our daily lives, supporting us and carrying out autonomous tasks. In Human-Robot Interaction, human actors benefit from understanding the robot’s motion intent to avoid task failures and foster collaboration. Finding effective ways to communicate this intent to users has recently received increased research interest. However, no common language has been established to systematize robot motion intent. This work presents a scoping review aimed at unifying existing knowledge. Based on our analysis, we present an intent communication model that depicts the relationship between robot and human through different intent dimensions (intent type, intent information, intent location). We discuss these different intent dimensions and their interrelationships with different kinds of robots and human roles. Throughout our analysis, we classify the existing research literature along our intent communication model, allowing us to identify key patterns and possible directions for future research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {409},
numpages = {17},
keywords = {motion, robot, survey, cobot, drone, intent},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581431,
author = {Stureborg, Rickard and Dhingra, Bhuwan and Yang, Jun},
title = {Interface Design for Crowdsourcing Hierarchical Multi-Label Text Annotations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581431},
doi = {10.1145/3544548.3581431},
abstract = {Human data labeling is an important and expensive task at the heart of supervised learning systems. Hierarchies help humans understand and organize concepts. We ask whether and how concept hierarchies can inform the design of annotation interfaces to improve labeling quality and efficiency. We study this question through annotation of vaccine misinformation, where the labeling task is difficult and highly subjective. We investigate 6 user interface designs for crowdsourcing hierarchical labels by collecting over 18,000 individual annotations. Under a fixed budget, integrating hierarchies into the design improves crowdsource workers’ F1 scores. We attribute this to (1) Grouping similar concepts, improving F1 scores by +0.16 over random groupings, (2) Strong relative performance on high-difficulty examples (relative F1 score difference of +0.40), and (3) Filtering out obvious negatives, increasing precision by +0.07. Ultimately, labeling schemes integrating the hierarchy outperform those that do not — achieving mean F1 of 0.70.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {410},
numpages = {17},
keywords = {crowdsourcing, user experience design, text annotation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581314,
author = {Bertrand, Astrid and Viard, Tiphaine and Belloum, Rafik and Eagan, James R. and Maxwell, Winston},
title = {On Selective, Mutable and Dialogic XAI: A Review of What Users Say about Different Types of Interactive Explanations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581314},
doi = {10.1145/3544548.3581314},
abstract = {Explainability (XAI) has matured in recent years to provide more human-centered explanations of AI-based decision systems. While static explanations remain predominant, interactive XAI has gathered momentum to support the human cognitive process of explaining. However, the evidence regarding the benefits of interactive explanations is unclear. In this paper, we map existing findings by conducting a detailed scoping review of 48 empirical studies in which interactive explanations are evaluated with human users. We also create a classification of interactive techniques specific to XAI and group the resulting categories according to their role in the cognitive process of explanation: "selective", "mutable" or "dialogic". We identify the effects of interactivity on several user-based metrics. We find that interactive explanations improve perceived usefulness and performance of the human+AI team but take longer. We highlight conflicting results regarding cognitive load and overconfidence. Lastly, we describe underexplored areas including measuring curiosity or learning or perturbing outcomes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {411},
numpages = {21},
keywords = {explainability, human-grounded evaluations, interactivity, artificial intelligence, interpretability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581492,
author = {Freeman, Sophie and Gibbs, Martin and Nansen, Bjorn},
title = {Personalised But Impersonal: Listeners' Experiences of Algorithmic Curation on Music Streaming Services},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581492},
doi = {10.1145/3544548.3581492},
abstract = {The consumption of music is increasingly reliant on the personalisation, recommendation, and automated curation features of music streaming services. Using algorithm experience (AX) as a lens, we investigated the user experience of the algorithmic recommendation and automated curation features of several popular music streaming services. We conducted interviews and participant-observation with 15 daily users of music streaming services, followed by a design workshop. We found that despite the utility of increasingly algorithmic personalisation, listeners experienced these algorithmic and recommendation features as impersonal in determining their background listening, music discovery, and playlist curation. While listener desire for more control over recommendation settings is not new, we offer a number of novel insights about music listening to nuance this understanding, particularly through the notion of vibe.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {412},
numpages = {14},
keywords = {algorithmic curation, music recommendation, music interaction, vibe, music streaming},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581185,
author = {Oyshi, Marzan Tasnim and Vogt, Sebastian and Gumhold, Stefan},
title = {TmoTA: Simple, Highly Responsive Tool for Multiple Object Tracking Annotation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581185},
doi = {10.1145/3544548.3581185},
abstract = {Machine learning is applied in a multitude of sectors with very impressive results. This success is due to the availability of an ever-growing amount of data acquired by omnipresent sensor devices and platforms on the internet. But there is a scarcity of labeled data which is required for most ML methods. However, generation of labeled data requires much time and resources. In this paper, we propose a portable, Open Source, simple and responsive manual Tool for 2D multiple object Tracking Annotation (TmoTA). Besides responsiveness, our tool design provides several features like view centering and looped playback that speed up the annotation process. We evaluate our proposed tool by comparing TmoTA with the widely used manual labeling tools CVAT, Label Studio, and two semi-automated tools Supervisely and VATIC with respect to object labeling time and accuracy. The evaluation includes a user study and pre-case studies showing that the annotation time per object frame can be reduced by 20% to 40% over the first 20 annotated objects compared to the manual labeling tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {11},
keywords = {video sequence labeling, data labeling, manual labeling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580881,
author = {Poon, Anthony and Guerrero, Lourdes and Loughman, Julia and Luebke, Matthew and Lee, Ann and Sterling, Madeline and Dell, Nicola},
title = {Designing for Peer-Led Critical Pedagogies in Computer-Mediated Support Groups for Home Care Workers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580881},
doi = {10.1145/3544548.3580881},
abstract = {Home care workers (HCWs) deliver essential health services within patients’ homes and are an important part of the US healthcare system. Yet, they are a marginalized workforce, whose physical isolation and lack of access to support structures make them vulnerable to exploitation. Computer-mediated support programs may help bridge this gap and, through critical and liberatory pedagogies, foster material social change. However, such pedagogies typically assume the involvement of a professional facilitator when, in practice, support programs are often led by peers with little to no facilitation training. Based on a three-month study with HCWs, this paper explores how peers can perform critical and liberatory facilitation practice in an online support program. We illustrate the challenges peers faced learning this practice and performing this role in an online environment. Our findings can improve the design of computer-mediated support programs and how to prepare peer leadership, particularly for addressing the needs of marginalized populations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {414},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580868,
author = {Liu, Chang and Usta, Arif and Zhao, Jian and Salihoglu, Semih},
title = {Governor: Turning Open Government Data Portals into Interactive Databases},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580868},
doi = {10.1145/3544548.3580868},
abstract = {The launch of open governmental data portals (OGDPs) has popularized the open data movement of last decade. Although the amount of data in OGDPs is increasing, their functionalities are limited to finding datasets with titles/descriptions and downloading the actual files. This hinders the end users, especially those without technical skills, to find the open data tables and make use of them. We present Governor, an open-sourced[17] web application developed to make OGDPs more accessible to end users by facilitating searching actual records in the tables, previewing them directly without downloading, and suggesting joinable and unionable tables to users based on their latest working tables. Governor also manages the provenance of integrated tables allowing users and their collaborators to easily trace back to the original tables in OGDP. We evaluate Governor with a two-part user study and the results demonstrate its value and effectiveness in finding and integrating tables in OGDP.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {415},
numpages = {16},
keywords = {open data, database, user interface, data integration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581574,
author = {Pardos, Zachary A. and Tang, Matthew and Anastasopoulos, Ioannis and Sheel, Shreya K. and Zhang, Ethan},
title = {OATutor: An Open-Source Adaptive Tutoring System and Curated Content Library for Learning Sciences Research},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581574},
doi = {10.1145/3544548.3581574},
abstract = {Despite decades long establishment of effective tutoring principles, no adaptive tutoring system has been developed and open-sourced to the research community. The absence of such a system inhibits researchers from replicating adaptive learning studies and extending and experimenting with various tutoring system design directions. For this reason, adaptive learning research is primarily conducted on a small number of proprietary platforms. In this work, we aim to democratize adaptive learning research with the introduction of the first open-source adaptive tutoring system based on Intelligent Tutoring System principles. The system, we call Open Adaptive Tutor (OATutor), has been iteratively developed over three years with field trials in classrooms drawing feedback from students, teachers, and researchers. The MIT-licensed source code includes three creative commons (CC BY) textbooks worth of algebra problems, with tutoring supports authored by the OATutor project. Knowledge Tracing, an A/B testing framework, and LTI support are included.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {416},
numpages = {17},
keywords = {content authoring, Adaptive learning, intelligent tutoring systems, replicable research, OER, open source, research through design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580964,
author = {Ruoff, Marcel and Myers, Brad A and Maedche, Alexander},
title = {ONYX: Assisting Users in Teaching Natural Language Interfaces Through Multi-Modal Interactive Task Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580964},
doi = {10.1145/3544548.3580964},
abstract = {Users are increasingly empowered to personalize natural language interfaces (NLIs) by teaching how to handle new natural language (NL) inputs. However, our formative study found that when teaching new NL inputs, users require assistance in clarifying ambiguities that arise and want insight into which parts of the input the NLI understands. In this paper we introduce ONYX, an intelligent agent that interactively learns new NL inputs by combining NL programming and programming-by-demonstration, also known as multi-modal interactive task learning. To address the aforementioned challenges, ONYX provides suggestions on how ONYX could handle new NL inputs based on previously learned concepts or user-defined procedures, and poses follow-up questions to clarify ambiguities in user demonstrations, using visual and textual aids to clarify the connections. Our evaluation shows that users provided with ONYX’s new features achieved significantly higher accuracy in teaching new NL inputs (median: 93.3%) in contrast to those without (median: 73.3%).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {417},
numpages = {16},
keywords = {Natural Language Interfaces, End User Development, Interactive Task Learning, Data Visualization Tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581456,
author = {Garg, Kapil and Gergle, Darren and Zhang, Haoqi},
title = {Orchestration Scripts: A System for Encoding an Organization’s Ways of Working to Support Situated Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581456},
doi = {10.1145/3544548.3581456},
abstract = {Ill-structured problems demand that people adopt sophisticated strategies for planning, seeking support, and using available resources along their work process. These practices involve a challenging monitoring and strategizing process that existing tools cannot support since they largely lack an understanding of an organization’s processes, social structures, venues, and tools. We introduce workplace programming for situationally-aware systems–an approach for encoding work situations using computational abstractions of an organization’s ways of working and surfacing support strategies at appropriate times and settings. With this approach, we implement Orchestration Scripts, a system that supports various situated work activities in a socio-technical organization. Through a case study and field study, we show how our approach encodes different aspects of working effectively and helps people identify situations to enact effective strategies using the available support opportunities. Our results show how a programmable technology can provide situated support in today’s workplaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {418},
numpages = {17},
keywords = {Ill-Structured Problems, Organizational Objects, Orchestration Scripts, Socio-Technical Ecosystems, Situated Work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581268,
author = {Cabrera, \'{A}ngel Alexander and Fu, Erica and Bertucci, Donald and Holstein, Kenneth and Talwalkar, Ameet and Hong, Jason I. and Perer, Adam},
title = {Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581268},
doi = {10.1145/3544548.3581268},
abstract = {Machine learning models with high accuracy on test data can still produce systematic failures, such as harmful biases and safety issues, when deployed in the real world. To detect and mitigate such failures, practitioners run behavioral evaluation of their models, checking model outputs for specific types of inputs. Behavioral evaluation is important but challenging, requiring that practitioners discover real-world patterns and validate systematic failures. We conducted 18 semi-structured interviews with ML practitioners to better understand the challenges of behavioral evaluation and found that it is a collaborative, use-case-first process that is not adequately supported by existing task- and domain-specific tools. Using these findings, we designed zeno, a general-purpose framework for visualizing and testing AI systems across diverse use cases. In four case studies with participants using zeno on real-world models, we found that practitioners were able to reproduce previous manual analyses and discover new systematic failures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {14},
keywords = {testing, machine learning, evaluation, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581024,
author = {Ma, Zehua and Zhou, Hang and Zhang, Weiming},
title = {AnisoTag: 3D Printed Tag on 2D Surface via Reflection Anisotropy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581024},
doi = {10.1145/3544548.3581024},
abstract = {In the past few years, the widespread use of 3D printing technology enables the growth of the market of 3D printed products. On Esty, a website focused on handmade items, hundreds of individual entrepreneurs are selling their 3D printed products. Inspired by the positive effects of machine-readable tags, like barcodes, on daily product marketing, we propose AnisoTag, a novel tagging method to encode data on the 2D surface of 3D printed objects based on reflection anisotropy. AnisoTag has an unobtrusive appearance and much lower extraction computational complexity, contributing to a lightweight low-cost tagging system for individual entrepreneurs. On AnisoTag, data are encoded by the proposed tool as reflective anisotropic microstructures, which would reflect distinct illumination patterns when irradiating by collimated laser. Based on it, we implement a real-time detection prototype with inexpensive hardware to determine the reflected illumination pattern and decode data according to their mapping. We evaluate AnisoTag with various 3D printer brands, filaments, and printing parameters, demonstrating its superior usability, accessibility, and reliability for practical usage.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {420},
numpages = {15},
keywords = {3D printing, machine-readable tag, physical hyperlinks, fabrication, information embedding},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581030,
author = {Sareen, Harpreet and Fu, Yibo and Boulahcen, Nour and Kakehi, Yasuaki},
title = {BubbleTex: Designing Heterogenous Wettable Areas for Carbonation Bubble Patterns on Surfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581030},
doi = {10.1145/3544548.3581030},
abstract = {Materials are a key part of our daily experiences. Recently, researchers have been devising new ways to utilize materials directly from our physical world for the design of objects and interactions. We present a new fabrication technique that enables control of CO2 bubble positions and their size within carbonated liquids. Instead of soap bubbles, boiling water, or droplets, we show creation of patterns, images and text through sessile bubbles that exhibit a lifetime of several days. Surfaces with mixed wettability regions are created on glass and plastic using ceramic coatings or plasma projection leading to patterns that are relatively invisible to the human eye. Different regions react to liquids differently. Nucleation is activated after carbonated liquid is poured onto the surface with bubbles nucleating in hydrophobic regions with a strong adherence to the surface and can be controlled in size ranging from 0.5mm – 6.5mm. Bubbles go from initially popping or becoming buoyant during CO2 supersaturation to stabilizing at their positions within minutes. Technical evaluation shows stabilization under various conditions. Our design software allows users to import images and convert them into parametric pixelation forms conducive to fabrication that will result in nucleation of bubbles at required positions. Various applications are presented to demonstrate aspects that may be harnessed for a wide range of use in daily life. Through this work, we enable the use of carbonation bubbles as a new design material for designers and researchers.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {15},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580991,
author = {Iravantchi, Yasha and Zhao, Yi and Kin, Kenrick and Sample, Alanson P.},
title = {SAWSense: Using Surface Acoustic Waves for Surface-Bound Event Recognition},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580991},
doi = {10.1145/3544548.3580991},
abstract = {Enabling computing systems to understand user interactions with everyday surfaces and objects can drive a wide range of applications. However, existing vibration-based sensors (e.g., accelerometers) lack the sensitivity to detect light touch gestures or the bandwidth to recognize activity containing high-frequency components. Conversely, microphones are highly susceptible to environmental noise, degrading performance. Each time an object impacts a surface, Surface Acoustic Waves (SAWs) are generated that propagate along the air-to-surface boundary. This work repurposes a Voice PickUp Unit (VPU) to capture SAWs on surfaces (including smooth surfaces, odd geometries, and fabrics) over long distances and in noisy environments. Our custom-designed signal acquisition, processing, and machine learning pipeline demonstrates utility in both interactive and activity recognition applications, such as classifying trackpad-style gestures on a desk and recognizing 16 cooking-related activities, all with &gt;97% accuracy. Ultimately, SAWs offer a unique signal that can enable robust recognition of user touch and on-surface events.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {422},
numpages = {18},
keywords = {Surface Acoustic Wave, Activity Recognition, Sensing, Touch Detection, Acoustics, Gesture Interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581037,
author = {Ding, Yuran and Shultz, Craig and Harrison, Chris},
title = {Surface I/O: Creating Devices with Functional Surface Geometry for Haptics and User Input},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581037},
doi = {10.1145/3544548.3581037},
abstract = {Surface I/O is a novel interface approach that functionalizes the exterior surface of devices to provide haptic and touch sensing without dedicated mechanical components. Achieving this requires a unique combination of surface features spanning the macro-scale (5cm ∼ 1mm), meso-scale (1mm ∼ 200μm), and micro-scale (&lt;200μm). This approach simplifies interface creation, allowing designers to iterate on form geometry, haptic feeling, and sensing functionality without the limitations of mechanical mechanisms. We believe this can contribute to the concept of "invisible ubiquitous interactivity at scale", where the simplicity and easy implementation of the technique allows it to blend with objects around us. While we prototyped our designs using 3D printers and laser cutters, our technique is applicable to mass production methods, including injection molding and stamping, enabling passive goods with new levels of interactivity.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {423},
numpages = {22},
keywords = {haptics, input devices, design, tangible interfaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581125,
author = {Cheng, Tingyu and Zhang, Zhihan and Zong, Bingrui and Zhao, Yuhui and Chang, Zekun and Kim, Yejun and Zheng, Clement and Abowd, Gregory D. and Oh, HyunJoo},
title = {SwellSense: Creating 2.5D Interactions with Micro-Capsule Paper},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581125},
doi = {10.1145/3544548.3581125},
abstract = {In this paper, we propose SwellSense, a fabrication technique to screen print stretchable circuits onto a special micro-capsule paper, creating localized swelling patterns with sensing capabilities. This simple technique will allow users to create a wide range of paper-based tactile interactive devices, which are mostly maintaining 2D planar form factor but can also be curved or folded into 3D interactive artifacts. We frst present the design guidelines to support various tactile interaction design including basic tactile graphic geometries, patterns with directional density, or fner interactive textures with embedded sensing such as touch sensor, pressure sensor, and mechanical switch. We then provide a design editor to enable users to design more creatively using the SwellSense technique. We provide a technical evaluation and user evaluation to validate the basic performance of SwellSense. Lastly, we demonstrate several application examples and conclude with a discussion on current limitations and future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {424},
numpages = {13},
keywords = {ubiquitous computing, transient electronics, physical intelligence, sustainable unmaking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580743,
author = {Yu, Tianyu and Xu, Weiye and Xu, Haiqing and Liu, Guanhong and Liu, Chang and Wang, Guanyun and Mi, Haipeng},
title = {Thermotion: Design and Fabrication of Thermofluidic Composites for Animation Effects on Object Surfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580743},
doi = {10.1145/3544548.3580743},
abstract = {We introduce Thermotion, a novel method using thermofluidic composites to design and display thermochromic animation effects on object surfaces. With fluidic channels embedded under the object surfaces, the composites utilize thermofluidic flows to dynamically control the surface temperature as an actuator for thermochromic paints, which enables researchers and designers for the first time to create animations not only on two and three-dimensional surfaces but also on the surface made of a few flexible everyday materials. We report the design space with six animation primitives and two modification effects, and we demonstrate the design and fabrication workflow with a customized software platform for design and simulation. A range of applications is shown leveraging the objects’ dynamic displays both visually and thermally, including dynamic artifacts, teaching aids, and ambient displays. We envision an opportunity to extend thermofluidic composites to other heat-related practices for further dynamic and programmable interactions with temperature.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {425},
numpages = {19},
keywords = {Programmable Materials, Color-changing Interface, Thermal Design, Thermofluidic Composites, Human-Material Interaction, Computational Fabrication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581239,
author = {Alghamdi, Leena and Akter, Mamtaj and Kropczynski, Jess and Wisniewski, Pamela J. and Lipford, Heather},
title = {Co-Designing Community-Based Sharing of Smarthome Devices for the Purpose of Co-Monitoring In-Home Emergencies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581239},
doi = {10.1145/3544548.3581239},
abstract = {We conducted 26 co-design interviews with 50 smarthome device owners to understand the perceived benefits, drawbacks, and design considerations for developing a smarthome system that facilitates co-monitoring with emergency contacts who live outside of one’s home. Participants felt that such a system would help ensure their personal safety, safeguard from material loss, and give them peace of mind by ensuring quick response and verifying potential threats. However, they also expressed concerns regarding privacy, overburdening others, and other potential threats, such as unauthorized access and security breaches. To alleviate these concerns, participants designed flexible and granular access control and fail-safe back-up features. Our study reveals why peer-based co-monitoring of smarthomes for emergencies may be beneficial but also difficult to implement. Based on the insights gained from our study, we provide recommendations for designing technologies that facilitate such co-monitoring while mitigating its risks.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {426},
numpages = {16},
keywords = {security, privacy, peer-based, co-design, smarthome, co-monitoring, smart devices, safety},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580821,
author = {Press, Viva Sarah and Erel, Hadas},
title = {Humorous Robotic Behavior as a New Approach to Mitigating Social Awkwardness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580821},
doi = {10.1145/3544548.3580821},
abstract = {Social awkwardness is a frequent challenge to healthy social interactions and can dramatically impact how people feel, communicate and behave. It is known that humor can invoke positive feelings and enable people to modify perspective of a situation. We explored whether using a non-humanoid robotic object performing humorous behavior can reduce social awkwardness between two strangers. The robot was peripherally incorporated into the interaction to ensure the natural social flow. We compared the impact of humorous and non-humorous robotic gestures on the human-human interaction. Objective and subjective measures indicate that despite being peripheral to the human-human interaction, the humorous robotic gestures significantly reduced the intensity of awkwardness between the strangers. Our findings suggest humorous robotic behavior can be used to enhance interpersonal relationships hindered by awkwardness and still preserve natural human-human interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {427},
numpages = {16},
keywords = {Non-humanoid robots, Social robot, Social Awkwardness, HRI, HCI, Human-Human-Robot Interaction, Humor, Humor-Computer Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581000,
author = {Jiang, Yanqi and Ding, Xianghua(Sharon) and Ma, Xiaojuan and Sun, Zhida and Gu, Ning},
title = {IntimaSea: Exploring Shared Stress Display in Close Relationships},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581000},
doi = {10.1145/3544548.3581000},
abstract = {Automatic stress tracking has become increasingly available on wearable devices. Research has investigated its use for individual stress management, largely within the traditional data-as-care framing. However, its use for stress sharing in social relationships, particularly close relationships, is still under explored. Inspired by the idea of “caring-through-data”, which focuses on mediating the social and emotional experiences of the collective “us” with data, this paper presents a design study with a prototype called IntimaSea, a display featuring illustrative stress data in collective forms to be shared among close relationships. The field trials with nine groups of intimately-connected users (N=19) highlight its potential on stress awareness, interpretation and management, as well as intimacy promotion. We end by discussing sharing stress for social ways of stress management, stress data as a meaningful social cue mediating relationships, as well as design implications for caring-through-data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {428},
numpages = {19},
keywords = {Stress Tracking, Intimacy, Caring-through-data, Shared Stress Display, Close Relationships, Stress},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580707,
author = {Kimmel, Simon and Jung, Frederike and Matviienko, Andrii and Heuten, Wilko and Boll, Susanne},
title = {Let’s Face It: Influence of Facial Expressions on Social Presence in Collaborative Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580707},
doi = {10.1145/3544548.3580707},
abstract = {As the world becomes more interconnected, physical separation between people increases. Existing collaborative Virtual Reality (VR) applications, designed to bridge this distance, are not yet sufficient in providing a sense of social connection comparable to face-to-face interactions. Possible reasons are the limited multimodality of VR systems and the lack of non-verbal cues in VR avatars. We systematically investigated how facial expressions influence Social Presence in two collaborative VR tasks. We explored four types of facial expressions: eyes and mouth movements, their combination, and no expressions, for two types of explanations: verbal and graphical. To examine how these expressions influence Social Presence, we conducted a controlled VR experiment (N = 48), in which participants had to explain a specific term to their counterpart. Our results demonstrate that eye and mouth movements positively influence Social Presence in VR. Particularly, combining verbal explanations and eye movements induces the highest feeling of co-presence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {429},
numpages = {16},
keywords = {virtual reality, social presence, collaboration, facial expressions},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581094,
author = {Jones, Lee and Nousir, Alaa and Everrett, Tom and Nabil, Sara},
title = {Libraries of Things: Understanding the Challenges of Sharing Tangible Collections and the Opportunities for HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581094},
doi = {10.1145/3544548.3581094},
abstract = {“Libraries of Things” are tangible collections of borrowable objects. There are many benefits to Libraries of Things such as making objects and skill-building accessible, reducing waste through the sharing of items, and saving costs associated with purchasing rarely-used items. We introduce the first HCI study of Library of Things by interviewing 23 librarians who run a variety of collections such as handheld tools, gear, and musical instruments – within public institutions and more grass-roots efforts in the private sector. In our findings, we discuss the challenges these collections experience in changing behavioural patterns from buying to borrowing, helping individuals ‘try new things’, iterating to find sharable items, training staff, and manual intervention throughout the borrowing cycle. We present 5 opportunities for HCI research to support interactive skill-sharing, self-borrowing, maintenance recognition and cataloguing ‘things’, organizing non-uniform inventories, and creating public-awareness. Further in-the-wild studies should also consider the tensions between the values of these organizations and low-cost convenient usage.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {430},
numpages = {18},
keywords = {sustainability, thing library, tool library, Libraries of Things, library of things, sharing economy, makerspace, tangible exchanges},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580986,
author = {Haliburton, Luke and Bart\l{}omiejczyk, Natalia and Schmidt, Albrecht and Wo\'{z}niak, Pawe\l{} W. and Niess, Jasmin},
title = {The Walking Talking Stick: Understanding Automated Note-Taking in Walking Meetings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580986},
doi = {10.1145/3544548.3580986},
abstract = {While walking meetings offer a healthy alternative to sit-down meetings, they also pose practical challenges. Taking notes is difficult while walking, which limits the potential of walking meetings. To address this, we designed the Walking Talking Stick—a tangible device with integrated voice recording, transcription, and a physical highlighting button to facilitate note-taking during walking meetings. We investigated our system in a three-condition between-subjects user study with thirty pairs of participants (N=60) who conducted 15-minute outdoor walking meetings. Participants either used clip-on microphones, the prototype without the button, or the prototype with the highlighting button. We found that the tangible device increased task focus, and the physical highlighting button facilitated turn-taking and resulted in more useful notes. Our work demonstrates how interactive artifacts can incentivize users to hold meetings in motion and enhance conversation dynamics. We contribute insights for future systems which support conducting work tasks in mobile environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {431},
numpages = {16},
keywords = {Mobile Work, CSCW, Walking Meetings, Physical Activity, Office Workers, Note-taking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580895,
author = {Wang, Bryan and Li, Gang and Li, Yang},
title = {Enabling Conversational Interaction with Mobile UI Using Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580895},
doi = {10.1145/3544548.3580895},
abstract = {Conversational agents show the promise to allow users to interact with mobile devices using language. However, to perform diverse UI tasks with natural language, developers typically need to create separate datasets and models for each specific task, which is expensive and effort-consuming. Recently, pre-trained large language models (LLMs) have been shown capable of generalizing to various downstream tasks when prompted with a handful of examples from the target task. This paper investigates the feasibility of enabling versatile conversational interactions with mobile UIs using a single LLM. We designed prompting techniques to adapt an LLM to mobile UIs. We experimented with four important modeling tasks that address various scenarios in conversational interaction. Our method achieved competitive performance on these challenging tasks without requiring dedicated datasets and training, offering a lightweight and generalizable approach to enable language-based mobile interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {17},
keywords = {Mobile UI, Conversational Interaction, Large Language Models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580688,
author = {H\"{a}m\"{a}l\"{a}inen, Perttu and Tavast, Mikke and Kunnari, Anton},
title = {Evaluating Large Language Models in Generating Synthetic HCI Research Data: A Case Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580688},
doi = {10.1145/3544548.3580688},
abstract = {Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAI’s GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {433},
numpages = {19},
keywords = {User experience, User models, GPT-3, Language models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580940,
author = {Mcnutt, Andrew M and Wang, Chenglong and Deline, Robert A and Drucker, Steven M.},
title = {On the Design of AI-Powered Code Assistants for Notebooks},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580940},
doi = {10.1145/3544548.3580940},
abstract = {AI-powered code assistants, such as Copilot, are quickly becoming a ubiquitous component of contemporary coding contexts. Among these environments, computational notebooks, such as Jupyter, are of particular interest as they provide rich interface affordances that interleave code and output in a manner that allows for both exploratory and presentational work. Despite their popularity, little is known about the appropriate design of code assistants in notebooks. We investigate the potential of code assistants in computational notebooks by creating a design space (reified from a survey of extant tools) and through an interview-design study (with 15 practicing data scientists). Through this work, we identify challenges and opportunities for future systems in this space, such as the value of disambiguation for tasks like data visualization, the potential of tightly scoped domain-specific tools (like linters), and the importance of polite assistants.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {434},
numpages = {16},
keywords = {Design Probe, Code Assistant, Artificial Intelligence, Copilot, Computational Notebooks},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580948,
author = {Wang, Sitong and Petridis, Savvas and Kwon, Taeahn and Ma, Xiaojuan and Chilton, Lydia B},
title = {PopBlends: Strategies for Conceptual Blending with Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580948},
doi = {10.1145/3544548.3580948},
abstract = {Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires finding a conceptual connection between the users’ topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very different characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {435},
numpages = {19},
keywords = {applications of large language models, natural language processing, creativity support tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581318,
author = {Zhou, Jiawei and Zhang, Yixuan and Luo, Qianni and Parker, Andrea G and De Choudhury, Munmun},
title = {Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581318},
doi = {10.1145/3544548.3581318},
abstract = {Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {20},
keywords = {COVID-19, responsible AI, large language model, GPT, misinformation, generative AI, AI-generated misinformation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581388,
author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
title = {Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581388},
doi = {10.1145/3544548.3581388},
abstract = {Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {437},
numpages = {21},
keywords = {language models, end-users, design tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581519,
author = {Colarusso, Fiorenzo and Cheng, Peter C-H. and Garcia Garcia, Grecia and Stockdill, Aaron and Raggi, Daniel and Jamnik, Mateja},
title = {A Novel Interaction for Competence Assessment Using Micro-Behaviors: Extending CACHET to Graphs and Charts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581519},
doi = {10.1145/3544548.3581519},
abstract = {Competence Assessment by Chunk Hierarchy Evaluation with Transcription-tasks (CACHET) was proposed by Cheng [14]. It analyses micro-behaviors captured during cycles of stimulus viewing and copying in order to probe chunk structures in memory. This study extends CACHET by applying it to the domain of graphs and charts. Since drawing strategies are diverse, a new interactive stimulus presentation method is introduced: Transcription with Incremental Presentation of the Stimulus (TIPS). TIPS aims to reduce strategy variations that mask the chunking signal by giving users manual element-by-element control over the display of the stimulus. The potential of TIPS, is shown by the analysis of six participants transcriptions of stimuli of different levels of familiarity and complexity that reveal clear signals of chunking. To understand how the chunk size and individual differences drive TIPS measurements, a CPM-GOMS model was constructed to formalize the cognitive process involved in stimulus comprehension and chunk creation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {438},
numpages = {14},
keywords = {Task Analysis, GOMS, Chunking, Individual Differences, Competence assessment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581368,
author = {Reza, Mohi and Zavaleta Bernuy, Angela and Liu, Emmy and Li, Tong and Liang, Zhongyuan and Barber, Calista K and Williams, Joseph Jay},
title = {Exam Eustress: Designing Brief Online Interventions for Helping Students Identify Positive Aspects of Stress},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581368},
doi = {10.1145/3544548.3581368},
abstract = {Stress reappraisal interventions try to shift students’ negative perceptions towards eustress, stress that can be beneficial, and help them perform better. However, it is less clear how to present them to users as online interventions that are brief, voluntary, and scale well in real-world contexts. We explore the design of online exam eustress interventions by generating six design factors (D1-6) that reinforce a core reappraisal message (D0), and evaluate them through: (i) user interviews (N = 20) revealing six findings (F1-6) on the importance of elaboration, layout, modality, and source of intervention content; (ii) a field experiment (N = 1283) showing a significant positive effect on exam scores (p = 0.003). Subgroup analyses indicate a significant effect for first-year but not for upper-year students, and no detectable gender differences. Our work offers insight into how students interact with online mindset interventions and design considerations for incorporating them into large courses.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {439},
numpages = {13},
keywords = {exams, online interventions, eustress, stress-reappraisal, user interviews, randomized field experiments},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580671,
author = {Kim, Seoyoung and Shin, Donghoon and Kim, Jeongyeon and Kwon, Soonwoo and Kim, Juho},
title = {How Older Adults Use Online Videos for Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580671},
doi = {10.1145/3544548.3580671},
abstract = {Online videos are a promising medium for older adults to learn. Yet, few studies have investigated what, how, and why they learn through online videos. In this study, we investigated older adults’ motivation, watching patterns, and difficulties in using online videos for learning by (1) running interviews with 13 older adults and (2) analyzing large-scale video event logs (N=41.8M) from a Korean Massive Online Open Course (MOOC) platform. Our results show that older adults (1) are motivated to learn practical topics, leading to less consumption of STEM domains than non-older adults, (2) watch videos with less interaction and watch a larger portion of a single video compared to non-older adults, and (3) face various difficulties (e.g., inconvenience arisen due to their unfamiliarity with technologies) that limit their learning through online videos. Based on the findings, we propose design guidelines for online videos and platforms targeted to support older adults’ learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {440},
numpages = {16},
keywords = {older adults, video learning, online learning, MOOC},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581272,
author = {Li, Yinmiao and Nwogu, Jennifer and Buddemeyer, Amanda and Solyst, Jaemarie and Lee, Jina and Walker, Erin and Ogan, Amy and Stewart, Angela E.B.},
title = {“I Want to Be Unique From Other Robots”: Positioning Girls as Co-Creators of Social Robots in Culturally-Responsive Computing Education},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581272},
doi = {10.1145/3544548.3581272},
abstract = {Robot technologies have been introduced to computing education to engage learners. This study introduces the concept of co-creation with a robot agent into culturally-responsive computing (CRC). Co-creation with computer agents has previously focused on creating external artifacts. Our work differs by making the robot agent itself the co-created product. Through participatory design activities, we positioned adolescent girls and an agentic social robot as co-creators of the robot’s identity. Taking a thematic analysis approach, we examined how girls embody the role of creator and co-creator in this space. We identified themes surrounding who has the power to make decisions, what decisions are made, and how to maintain social relationship. Our findings suggest that co-creation with robot technology is a promising implementation vehicle for realizing CRC.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {441},
numpages = {14},
keywords = {culturally responsive computing, co-creation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581575,
author = {M\'{e}ndez, Gonzalo Gabriel and Gal\'{a}rraga, Luis and Chiluiza, Katherine and Mendoza, Patricio},
title = {Impressions and Strategies of Academic Advisors When Using a Grade Prediction Tool During Term Planning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581575},
doi = {10.1145/3544548.3581575},
abstract = {Academic advising brings numerous benefits to the mission of Higher Education Institutions. One central and challenging duty of advisors is course recommendation for term planning. This task requires both knowledge of the study programs as well as a thorough analysis of the students’ unique circumstances. Limited time and a large student population make this task overwhelming. As a result, an important body of research has sought to expedite term planning via data-oriented decision-support tools. The impact of such tools on students has been extensively studied. However, the advisors’ perspective remains largely unexplored. We contribute to redressing this gap by studying how a grade prediction tool shapes academic advisors’ approach to course recommendation. We found that while the advisors’ usual strategies tend to prevail, their recommendations largely depend on the advisee’s historical performance. That said, advisors also acknowledge the limitations of grades as a measure of academic success.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {18},
keywords = {academic advising, course recommendation, grade prediction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581567,
author = {Higgins, Erin and Posada, Jennifer and Kimble-Brown, Quinlan and Abler, Susanna and Coy, Andrew and Hamidi, Foad},
title = {Investigating an Equity-Based Participatory Approach to Technology-Rich Learning in Community Recreation Centers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581567},
doi = {10.1145/3544548.3581567},
abstract = {Understanding how to design and implement equity-based approaches to technology-rich learning can lead to increased and diversified participation in computing. Do-it-yourself (DIY) and maker approaches to interactive technology learning have been hailed as potential equalizers of science, technology, engineering, and math (STEM) education for underserved youth, a narrative challenged by scholarship that has shown that if not designed carefully, making can be exclusionary and hegemonic. Equity-based approaches to making have identified the crucial role of community educators to prioritize community assets and learner participation. We studied educators’ strategies and youth outcomes in four afterschool maker programs in urban recreation centers. Community educators used several equity-based strategies to engage youth that included: identifying their interests through direct conversation and indirect signaling, customizing program activities to respond to interests, and encouraging self-expression and authenticity. These strategies led to increased social connections among youth, and increased technology self-efficacy and project ownership.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {443},
numpages = {18},
keywords = {urban settings, afterschool youth programs, equity, technology education, informal learning, workforce readiness, underrepresented minorities, makerspaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581405,
author = {Wei, Xiaoying and Gu, Yizheng and Kuang, Emily and Wang, Xian and Cao, Beiyan and Jin, Xiaofu and Fan, Mingming},
title = {Bridging the Generational Gap: Exploring How Virtual Reality Supports Remote Communication Between Grandparents and Grandchildren},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581405},
doi = {10.1145/3544548.3581405},
abstract = {When living apart, grandparents and grandchildren often use audio-visual communication approaches to stay connected. However, these approaches seldom provide sufficient companionship and intimacy due to a lack of co-presence and spatial interaction, which can be fulfilled by immersive virtual reality (VR). To understand how grandparents and grandchildren might leverage VR to facilitate their remote communication and better inform future design, we conducted a user-centered participatory design study with twelve pairs of grandparents and grandchildren. Results show that VR affords casual and equal communication by reducing the generational gap, and promotes conversation by offering shared activities as bridges for connection. Participants preferred resemblant appearances on avatars for conveying well-being but created ideal selves for gaining playfulness. Based on the results, we contribute eight design implications that inform future VR-based grandparent-grandchild communications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {444},
numpages = {15},
keywords = {grandparents, older adults, generational gap, inter-generational communication, virtual reality, VR, grandchildren, aging},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581365,
author = {Cheng, Alan Y. and Ritchie, Jacob and Agrawal, Niki and Childs, Elizabeth and DeVeaux, Cyan and Jee, Yubin and Leon, Trevor and Maples, Bethanie and Cuadra, Andrea and Landay, James A.},
title = {Designing Immersive, Narrative-Based Interfaces to Guide Outdoor Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581365},
doi = {10.1145/3544548.3581365},
abstract = {Outdoor learning experiences, such as field trips, can improve children’s science achievement and engagement, but these experiences are often difficult to deliver without extensive support. Narrative in educational experiences can provide needed structure, while also increasing engagement. We created a narrative-based, mobile application to investigate how to guide young learners in interacting with their local, outdoor environment. In a second variant, we added augmented reality and image classification to explore the value of these features. A study (n = 44) found that participants using our system demonstrated learning gains and found the experience engaging. Our findings identified several major themes, including participant excitement for hands-on interactions with nature, curiosity about the characters, and enthusiasm toward typing their thoughts and observations. We offer a set of design implications for supporting narrative-based, outdoor learning with immersive technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {445},
numpages = {22},
keywords = {outdoor learning, machine learning, ubiquitous computing, augmented reality, mobile computing, computer vision, immersive technology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580913,
author = {Xue, Fei and Guo, Rongchen and Yao, Siyuan and Wang, Luxin and Ma, Kwan-Liu},
title = {From Artifacts to Outcomes: Comparison of HMD VR, Desktop, and Slides Lectures for Food Microbiology Laboratory Instruction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580913},
doi = {10.1145/3544548.3580913},
abstract = {Despite the value of VR (Virtual Reality) for educational purposes, the instructional power of VR in Biology Laboratory education remains under-explored. Laboratory lectures can be challenging due to students’ low motivation to learn abstract scientific concepts and low retention rate. Therefore, we designed a VR-based lecture on fermentation and compared its effectiveness with lectures using PowerPoint slides and a desktop application. Grounded in the theory of distributed cognition and motivational theories, our study examined how learning happens in each condition from students’ learning outcomes, behaviors, and perceptions. Our result indicates that VR facilitates students’ long-term retention to learn by cultivating their longer visual attention and fostering a higher sense of immersion, though students’ short-term retention remains the same across all conditions. This study extends current research on VR studies by identifying the characteristics of each teaching artifact and providing design implications for integrating VR technology into higher education.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {17},
keywords = {Educational Technology, Virtual Reality, Learning Theories, Immersive Visualization Design, Laboratory Instruction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581396,
author = {Zhu, Zhengzhe and Liu, Ziyi and Zhang, Youyou and Zhu, Lijun and Huang, Joey and Villanueva, Ana M and Qian, Xun and Peppler, Kylie and Ramani, Karthik},
title = {LearnIoTVR: An End-to-End Virtual Reality Environment Providing Authentic Learning Experiences for Internet of Things},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581396},
doi = {10.1145/3544548.3581396},
abstract = {The rapid growth of Internet-of-Things (IoT) applications has generated interest from many industries and a need for graduates with relevant knowledge. An IoT system is comprised of spatially distributed interactions between humans and various interconnected IoT components. These interactions are contextualized within their ambient environment, thus impeding educators from recreating authentic tasks for hands-on IoT learning. We propose LearnIoTVR, an end-to-end virtual reality (VR) learning environment which helps students to acquire IoT knowledge through immersive design, programming, and exploration of real-world environments empowered by IoT (e.g., a smart house). The students start the learning process by installing virtual IoT components we created in different locations inside the VR environment so that the learning will be situated in the same context where the IoT is applied. With our custom-designed 3D block-based language, students can program IoT behaviors directly within VR and get immediate feedback on their programming outcome. In the user study, we evaluated the learning outcomes among students using LearnIoTVR with a pre- and post-test to understand to what extent does engagement in LearnIoTVR lead to gains in learning programming skills and IoT competencies. Additionally, we examined what aspects of LearnIoTVR support usability and learning of programming skills compared to a traditional desktop-based learning environment. The results from these studies were promising. We also acquired insightful user feedback which provides inspiration for further expansions of this system.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {447},
numpages = {17},
keywords = {Project-based Learning, IoT, Block-based Programming, Immersive Programming, Embodied Interaction, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581041,
author = {Wu, Yudan and You, Shanhe and Guo, Zixuan and Li, Xiangyang and Zhou, Guyue and Gong, Jiangtao},
title = {MR.Brick: Designing A Remote Mixed-Reality Educational Game System for Promoting Children’s Social &amp; Collaborative Skills},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581041},
doi = {10.1145/3544548.3581041},
abstract = {Children are one of the groups most influenced by COVID-19-related social distancing, and a lack of contact with peers can limit their opportunities to develop social and collaborative skills. However, remote socialization and collaboration as an alternative approach is still a great challenge for children. This paper presents MR.Brick, a Mixed Reality (MR) educational game system that helps children adapt to remote collaboration. A controlled experimental study involving 24 children aged six to ten was conducted to compare MR.Brick with the traditional video game by measuring their social and collaborative skills and analyzing their multi-modal playing behaviours. The results showed that MR.Brick was more conducive to children’s remote collaboration experience than the traditional video game. Given the lack of training systems designed for children to collaborate remotely, this study may inspire interaction design and educational research in related fields.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {448},
numpages = {18},
keywords = {social and collaborative skill, remote collaboration, mixed reality, educational game, children, tangible user interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581069,
author = {Thanyadit, Santawat and Heintz, Matthias and Law, Effie L-C},
title = {Tutor In-Sight: Guiding and Visualizing Students’ Attention with Mixed Reality Avatar Presentation Tools},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581069},
doi = {10.1145/3544548.3581069},
abstract = {Remote conferencing systems are increasingly used to supplement or even replace in-person teaching. However, prevailing conferencing systems restrict the teacher’s representation to a webcam live-stream, hamper the teacher’s use of body-language, and result in students’ decreased sense of co-presence and participation. While Virtual Reality (VR) systems may increase student engagement, the teacher may not have the time or expertise to conduct the lecture in VR. To address this issue and bridge the requirements between students and teachers, we have developed Tutor In-sight, a Mixed Reality (MR) avatar augmented into the student’s workspace based on four design requirements derived from the existing literature, namely: integrated virtual with physical space, improved teacher’s co-presence through avatar, direct attention with auto-generated body language, and usable workflow for teachers. Two user studies were conducted from the perspectives of students and teachers to determine the advantages of Tutor In-sight in comparison to two existing conferencing systems, Zoom (video-based) and Mozilla Hubs (VR-based). The participants of both studies favoured Tutor In-sight. Among others, this main finding indicates that Tutor In-sight satisfied the needs of both teachers and students. In addition, the participants’ feedback was used to empirically determine the four main teacher requirements and the four main student requirements in order to improve the future design of MR educational tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {449},
numpages = {20},
keywords = {Augmented Reality, Remote Presentation, Virtual Avatar},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581369,
author = {Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
title = {DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children’s Why and How Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581369},
doi = {10.1145/3544548.3581369},
abstract = {Children acquire an understanding of the world by asking “why” and “how” questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children’s questions as they are more readily available than parents or teachers. However, CAs’ answers to “why” and “how” questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children’s engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children’s questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {22},
keywords = {Question Answering, Conversational Agents, Children, Dialogue, Natural Language},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581159,
author = {Lee, Sunok and Choi, Dasom and Lee, Minha and Choi, Jonghak and Lee, Sangsu},
title = {Fostering Youth’s Critical Thinking Competency About AI through Exhibition},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581159},
doi = {10.1145/3544548.3581159},
abstract = {Today’s youth lives in a world deeply intertwined with AI, which has become an integral part of everyday life. For this reason, it is important for youth to critically think about and examine AI to become responsible users in the future. Although recent attempts have educated youth on AI with focus on delivering critical perspectives within a structured curriculum, opportunities to develop critical thinking competencies that can be reflected in their lives must be provided. With this background, we designed an informal learning experience through an AI-related exhibition to cultivate critical thinking competency. To explore changes before and after the exhibition, 23 participants were invited to experience the exhibition. We found that the exhibition can support the youth in relating AI to their lives through critical thinking processes. Our findings suggest implications for designing learning experiences to foster critical thinking competency for better coexistence with AI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {451},
numpages = {22},
keywords = {AI-related exhibition, Youth learning, Critical thinking, AI education, Informal learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581378,
author = {Solyst, Jaemarie and Xie, Shixian and Yang, Ellia and Stewart, Angela E.B. and Eslami, Motahhare and Hammer, Jessica and Ogan, Amy},
title = {“I Would Like to Design”: Black Girls Analyzing and Ideating Fair and Accountable AI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581378},
doi = {10.1145/3544548.3581378},
abstract = {Artificial intelligence (AI) literacy is especially important for those who may not be well-represented in technology design. We worked with ten Black girls in fifth and sixth grade from a predominantly Black school to understand their perceptions around fair and accountable AI and how they can have an empowered role in the creation of AI. Thematic analysis of discussions and activity artifacts from a summer camp and after-school session revealed a number of findings around how Black girls: perceive AI, primarily consider fairness as niceness and equality (but may need support considering other notions, such as equity), consider accountability, and envision a just future. We also discuss how the learners can be positioned as decision-making designers in creating AI technology, as well as how AI literacy learning experiences can be empowering.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {452},
numpages = {14},
keywords = {artificial intelligence, AI literacy, AI ethics, design, Black girls},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581398,
author = {Yang, Kexin Bella and Echeverria, Vanessa and Lu, Zijing and Mao, Hongyu and Holstein, Kenneth and Rummel, Nikol and Aleven, Vincent},
title = {Pair-Up: Prototyping Human-AI Co-Orchestration of Dynamic Transitions between Individual and Collaborative Learning in the Classroom},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581398},
doi = {10.1145/3544548.3581398},
abstract = {Enabling students to dynamically transition between individual and collaborative learning activities has great potential to support better learning. We explore how technology can support teachers in orchestrating dynamic transitions during class. Working with five teachers and 199 students over 22 class sessions, we conducted classroom-based prototyping of a co-orchestration technology ecosystem that supports the dynamic pairing of students working with intelligent tutoring systems. Using mixed-methods data analysis, we study the resulting observed classroom dynamics, and how teachers and students perceived and experienced dynamic transitions as supported by our technology. We discover a potential tension between teachers’ and students’ preferred level of control: students prefer a degree of control over the dynamic transitions that teachers are hesitant to grant. Our study reveals design implications and challenges for future human-AI co-orchestration in classroom use, bringing us closer to realizing the vision of highly-personalized smart classrooms that address the unique needs of each student.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {453},
numpages = {17},
keywords = {Teacher-supported Tools, Collaborative Learning, Human-AI Collaboration, Classroom Orchestration, Educational Technology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580957,
author = {Lu, Xinyi and Fan, Simin and Houghton, Jessica and Wang, Lu and Wang, Xu},
title = {ReadingQuizMaker: A Human-NLP Collaborative System That Supports Instructors to Design High-Quality Reading Quiz Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580957},
doi = {10.1145/3544548.3580957},
abstract = {Despite that reading assignments are prevalent, methods to encourage students to actively read are limited. We propose a system ReadingQuizMaker that supports instructors to conveniently design high-quality questions to help students comprehend readings. ReadingQuizMaker adapts to instructors’ natural workflows of creating questions, while providing NLP-based process-oriented support. ReadingQuizMaker enables instructors to decide when and which NLP models to use, select the input to the models, and edit the outcomes. In an evaluation study, instructors found the resulting questions to be comparable to their previously designed quizzes. Instructors praised ReadingQuizMaker for its ease of use, and considered the NLP suggestions to be satisfying and helpful. We compared ReadingQuizMaker with a control condition where instructors were given automatically generated questions to edit. Instructors showed a strong preference for the human-AI teaming approach provided by ReadingQuizMaker. Our findings suggest the importance of giving users control and showing an immediate preview of AI outcomes when providing AI support.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {454},
numpages = {18},
keywords = {Human-AI Teaming, Active Learning, Automatic Question Generation, Reading Quiz},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580919,
author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
title = {Studying the Effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580919},
doi = {10.1145/3544548.3580919},
abstract = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {23},
keywords = {OpenAI Codex, GPT-3, AI-Assisted Pair-Programming, Introductory Programming, AI Coding Assistants, K-12 Computer Science Education, Copilot, ChatGPT, Large Language Models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581515,
author = {Gr\o{}nb\ae{}k, Jens Emil Sloth and Pfeuffer, Ken and Velloso, Eduardo and Astrup, Morten and Pedersen, Melanie Isabel S\o{}nderk\ae{}r and Kj\ae{}r, Martin and Leiva, Germ\'{a}n and Gellersen, Hans},
title = {Partially Blended Realities: Aligning Dissimilar Spaces for Distributed Mixed Reality Meetings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581515},
doi = {10.1145/3544548.3581515},
abstract = {Mixed Reality allows for distributed meetings where people’s local physical spaces are virtually aligned into blended interaction spaces. In many cases, people’s physical rooms are dissimilar, making it challenging to design a coherent blended space. We introduce the concept of Partially Blended Realities (PBR) — using Mixed Reality to support remote collaborators in partially aligning their physical spaces. As physical surfaces are central in collaborative work, PBR supports users in transitioning between different configurations of tables and whiteboard surfaces. In this paper, we 1) describe the design space of PBR, 2) present RealityBlender to explore interaction techniques for how users may configure and transition between blended spaces, and 3) provide insights from a study on how users experience transitions in a remote collaboration task. With this work, we demonstrate new potential for using partial solutions to tackle the alignment problem of dissimilar spaces in distributed Mixed Reality meetings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {456},
numpages = {16},
keywords = {mixed reality, proxemic transitions, remote collaboration, augmented and virtual reality, blended realities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580750,
author = {Ye, Hui and Leng, Jiaye and Xiao, Chufeng and Wang, Lili and Fu, Hongbo},
title = {ProObjAR: Prototyping Spatially-Aware Interactions of Smart Objects with AR-HMD},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580750},
doi = {10.1145/3544548.3580750},
abstract = {The rapid advances in technologies have brought new interaction paradigms of smart objects (e.g., digital devices) beyond digital device screens. By utilizing spatial properties, configurations, and movements of smart objects, designing spatial interaction, which is one of the emerging interaction paradigms, efficiently promotes engagement with digital content and physical facility. However, as an important phase of design, prototyping such interactions still remains challenging, since there is no ad-hoc approach for this emerging paradigm. Designers usually rely on methods that require fixed hardware setup and advanced coding skills to script and validate early-stage concepts. These requirements restrict the design process to a limited group of users in indoor scenes. To facilitate the prototyping to general usages, we aim to figure out the design difficulties and underlying needs of current design processes for spatially-aware object interactions by empirical studies. Besides, we explore the design space of the spatial interaction for smart objects and discuss the design space in an input-output spatial interaction model. Based on these findings, we present ProObjAR, an all-in-one novel prototyping system with an Augmented Reality Head Mounted Display (AR-HMD). Our system allows designers to easily obtain the spatial data of smart objects being prototyped, specify spatially-aware interactive behaviors from an input-output event triggering workflow, and test the prototyping results in situ. From the user study, we find that ProObjAR&nbsp;simplifies the design procedure and increases design efficiency to a large extent and thus advancing the development of spatially-aware applications in smart ecosystems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {457},
numpages = {15},
keywords = {smart objects, AR prototyping, spatial interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581454,
author = {Cheng, Lung-Pan and Chen, Yi and Peng, Yi-Hao and Holz, Christian},
title = {Reality Rifts: Wonder-Ful Interfaces by Disrupting Perceptual Causality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581454},
doi = {10.1145/3544548.3581454},
abstract = {Reality Rifts are interfaces between the physical and the virtual reality, where incoherent observations of physical behavior lead users to imagine comprehensive and plausible end-to-end dynamics. Reality Rifts emerge in interactive physical systems that lack one or more components that are central to their operation, yet where the physical end-to-end interaction persists with plausible outcomes. Even in the presence of a Reality Rift, users can still interact with a system—much like they would with the unaltered and complete counterpart—leading them to implicitly infer the existence and imagine the behavior of the lacking components from observable phenomena and outcomes. Therefore, dynamic systems with Reality Rifts trigger doubt, curiosity, and rumination—a sense of wonder that users experience when observing a Reality Rift due to their innate curiosity. In this paper, we explore how interactive systems can elicit and guide the user’s imagination by integrating Reality Rifts. We outline the design process for opening a Reality Rift in interactive physical systems, describe the resulting design space, and explore it through six characteristic prototypes. To understand to what extent and with which qualities these prototypes indeed induce a sense of wonder during an interaction, we evaluated Reality Rifts in the form of a field deployment with 50 participants. We discuss participants’ behavior and derive factors for the implementation of future wonder-ful experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {458},
numpages = {15},
keywords = {Mixed reality, physical displays, immersive experiences},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581449,
author = {Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo},
title = {Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581449},
doi = {10.1145/3544548.3581449},
abstract = {This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {15},
keywords = {Human-Centered Machine Learning;, Prototyping Tools, Everyday Objects, Mixed Reality, Augmented Reality, Interactive Machine Teaching, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580876,
author = {Mahadevan, Karthik and Zhou, Qian and Fitzmaurice, George and Grossman, Tovi and Anderson, Fraser},
title = {Tesseract: Querying Spatial Design Recordings by Manipulating Worlds in Miniature},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580876},
doi = {10.1145/3544548.3580876},
abstract = {New immersive 3D design tools enable the creation of spatial design recordings, capturing collaborative design activities. By reviewing captured spatial design sessions, which include user activities, workflows, and tool use, users can reflect on their own design processes, learn new workflows, and understand others’ design rationale. However, finding interesting moments in design activities can be challenging: they contain multimodal data (such as user motion and logged events) occurring over time which can be difficult to specify when searching, and are typically distributed over many sessions or recordings. We present Tesseract, a Worlds-in-Miniature-based system to expressively query VR spatial design recordings. Tesseract consists of the Search Cube interface acting as a centralized stage-to-search container, and four querying tools for specifying multimodal data to enable users to find interesting moments in past design activities. We studied ten participants who used Tesseract and found support for our miniature-based stage-to-search approach.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {460},
numpages = {16},
keywords = {Worlds-in-Miniature, Querying spatial design recordings},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580704,
author = {He, Fengming and Hu, Xiyun and Shi, Jingyu and Qian, Xun and Wang, Tianyi and Ramani, Karthik},
title = {Ubi Edge: Authoring Edge-Based Opportunistic Tangible User Interfaces in Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580704},
doi = {10.1145/3544548.3580704},
abstract = {Edges are one of the most ubiquitous geometric features of physical objects. They provide accurate haptic feedback and easy-to-track features for camera systems, making them an ideal basis for Tangible User Interfaces (TUI) in Augmented Reality (AR). We introduce Ubi Edge, an AR authoring tool that allows end-users to customize edges on daily objects as TUI inputs to control varied digital functions. We develop an integrated AR-device and an integrated vision-based detection pipeline that can track 3D edges and detect the touch interaction between fingers and edges. Leveraging the spatial-awareness of AR, users can simply select an edge by sliding fingers along it and then make the edge interactive by connecting it to various digital functions. We demonstrate four use cases including multi-function controllers, smart homes, games, and TUI-based tutorials. We also evaluated and proved our system’s usability through a two-session user study, where qualitative and quantitative results are positive.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {461},
numpages = {14},
keywords = {Augmented Reality, Tangible User Interface, immersive authoring},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581236,
author = {Guo, Grace and Karavani, Ehud and Endert, Alex and Kwon, Bum Chul},
title = {Causalvis: Visualizations for Causal Inference},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581236},
doi = {10.1145/3544548.3581236},
abstract = {Causal inference is a statistical paradigm for quantifying causal effects using observational data. It is a complex process, requiring multiple steps, iterations, and collaborations with domain experts. Analysts often rely on visualizations to evaluate the accuracy of each step. However, existing visualization toolkits are not designed to support the entire causal inference process within computational environments familiar to analysts. In this paper, we address this gap with Causalvis, a Python visualization package for causal inference. Working closely with causal inference experts, we adopted an iterative design process to develop four interactive visualization modules to support causal inference analysis tasks. The modules are then presented back to the experts for feedback and evaluation. We found that Causalvis effectively supported the iterative causal inference process. We discuss the implications of our findings for designing visualizations for causal inference, particularly for tasks of communication and collaboration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {462},
numpages = {20},
keywords = {causality, design study, causal inference},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581021,
author = {Yen, Chi-Hsien and Cheng, Haocong and Xia, Yilin and Huang, Yun},
title = {CrowdIDEA: Blending Crowd Intelligence and Data Analytics to Empower Causal Reasoning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581021},
doi = {10.1145/3544548.3581021},
abstract = {Causal reasoning is crucial for people to understand data, make decisions, or take action. However, individuals often have blind spots and overlook alternative hypotheses, and using only data is insufficient for causal reasoning. We designed and implemented CrowdIDEA, a novel tool consisting of a three-panel integration incorporating the crowd’s beliefs (Crowd Panel with two designs), data analytics (Data Panel), and user’s causal diagram (Diagram Panel) to stimulate causal reasoning. Through an experiment with 54 participants, we showed the significant effects of the Crowd Panel designs on the outcomes of causal reasoning, such as an increased number of causal beliefs generated. Participants also devised new strategies for bootstrapping, strengthening, deepening, and explaining their causal beliefs, as well as taking advantage of the unique characteristics of both qualitative and quantitative data sources to reduce potential biases in reasoning. Our work makes theoretical and design implications for exploratory causal reasoning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {463},
numpages = {17},
keywords = {Causal Reasoning, Crowd-informed Reasoning Tools, Causal Diagrams, Visualization, Crowd Intelligence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581067,
author = {Song, Sicheng and Chen, Juntong and Li, Chenhui and Wang, Changbo},
title = {GVQA: Learning to Answer Questions about Graphs with Visualizations via Knowledge Base},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581067},
doi = {10.1145/3544548.3581067},
abstract = {Graphs are common charts used to represent the topological relationship between nodes. It is a powerful tool for data analysis and information retrieval tasks involve asking questions about graphs. In formative study, we found that questions for graphs are not only about the relationship of nodes but also about the properties of graph elements. We propose a pipeline to answer natural language questions about graph visualizations and generate visual answers. We first extract the data from graphs and convert them into GML format. We design data structures to encode graph information and convert them into an knowledge base. We then extract topic entities from questions. We feed questions, entities and knowledge bases into our question-answer model to obtain the SPARQL queries for textual answers. Finally, we design a module to present the answers visually. A user study demonstrates that these visual and textual answers are useful, credible and and transparent.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {464},
numpages = {16},
keywords = {Reinforcement Learning, Question Answering, Knowledge Base, Natural Language Process, Network Graph, Visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580869,
author = {Kale, Alex and Lee, Sarah and Goan, Terrance and Tipton, Elizabeth and Hullman, Jessica},
title = {MetaExplorer : Facilitating Reasoning with Epistemic Uncertainty in Meta-Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580869},
doi = {10.1145/3544548.3580869},
abstract = {Scientists often use meta-analysis to characterize the impact of an intervention on some outcome of interest across a body of literature. However, threats to the utility and validity of meta-analytic estimates arise when scientists average over potentially important variations in context like different research designs. Uncertainty about quality and commensurability of evidence casts doubt on results from meta-analysis, yet existing software tools for meta-analysis do not provide an explicit software representation of these concerns. We present MetaExplorer, a prototype system for meta-analysis that we developed using iterative design with meta-analysis experts to provide a guided process for eliciting assessments of uncertainty and reasoning about how to incorporate them during statistical inference. Our qualitative evaluation of MetaExplorer with experienced meta-analysts shows that imposing a structured workflow both elevates the perceived importance of epistemic concerns and presents opportunities for tools to engage users in dialogue around goals and standards for evidence aggregation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {465},
numpages = {14},
keywords = {epistemic uncertainty, literature review, Meta-analysis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580808,
author = {Koonchanok, Ratanond and Tawde, Gauri Yatindra and Narayanasamy, Gokul Ragunandhan and Walimbe, Shalmali and Reda, Khairi},
title = {Visual Belief Elicitation Reduces the Incidence of False Discovery},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580808},
doi = {10.1145/3544548.3580808},
abstract = {Visualization supports exploratory data analysis (EDA), but EDA frequently presents spurious charts, which can mislead people into drawing unwarranted conclusions. We investigate interventions to prevent false discovery from visualized data. We evaluate whether eliciting analyst beliefs helps guard against the over-interpretation of noisy visualizations. In two experiments, we exposed participants to both spurious and ‘true’ scatterplots, and assessed their ability to infer data-generating models that underlie those samples. Participants who underwent prior belief elicitation made 21% more correct inferences along with 12% fewer false discoveries. This benefit was observed across a variety of sample characteristics, suggesting broad utility to the intervention. However, additional interventions to highlight counterevidence and sample uncertainty did not provide significant advantage. Our findings suggest that lightweight, belief-driven interactions can yield a reliable, if moderate, reduction in false discovery. This work also suggests future directions to improve visual inference and reduce bias.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {466},
numpages = {17},
keywords = {graphical inference., belief elicitation, False discovery},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581218,
author = {Bancilhon, Melanie and Wright, Amanda and Ha, Sunwoo and Crouser, R. Jordan and Ottley, Alvitta},
title = {Why Combining Text and Visualization Could Improve Bayesian Reasoning: A Cognitive Load Perspective},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581218},
doi = {10.1145/3544548.3581218},
abstract = {Investigations into using visualization to improve Bayesian reasoning and advance risk communication have produced mixed results, suggesting that cognitive ability might affect how users perform with different presentation formats. Our work examines the cognitive load elicited when solving Bayesian problems using icon arrays, text, and a juxtaposition of text and icon arrays. We used a three-pronged approach to capture a nuanced picture of cognitive demand and measure differences in working memory capacity, performance under divided attention using a dual-task paradigm, and subjective ratings of self-reported effort. We found that individuals with low working memory capacity made fewer errors and experienced less subjective workload when the problem contained an icon array compared to text alone, showing that visualization improves accuracy while exerting less cognitive demand. We believe these findings can considerably impact accessible risk communication, especially for individuals with low working memory capacity.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {15},
keywords = {Bayesian reasoning, Decision-making, Perception and Cognitive Load},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580659,
author = {Li, Lin and Arnold, Vitica and Piper, Anne Marie},
title = {“Any Bit of Help, Helps”: Understanding How Older Caregivers Use Carework Platforms for Caregiving Support},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580659},
doi = {10.1145/3544548.3580659},
abstract = {Older adults are increasingly acting as caregivers, given population aging and pervasive caregiver shortages. Meanwhile, gig-economy-based carework platforms have also become popular. As older adults are one of the fastest-growing groups of informal caregivers and technology users in the past decade, we conducted an online survey among older adults residing in the US (N = 193) about how they use these platforms to manage their caregiving tasks. We identified factors related to their frequency of using caregiving help and their intention to continue using caregiving help via carework platforms. We also reported how and why older adults use these platforms, their main concerns and needs related to these platforms, and their most significant positive and negative experiences. Our findings contribute to a foundational understanding of how older caregivers use carework platforms and how such platforms could be better designed to suit the needs and wants of older caregivers.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {468},
numpages = {17},
keywords = {Gig Economy, Well-being, Caregiving, Health, Carework platform, Older Adults},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580897,
author = {Jo, Hye-Young and Seidel, Laurenz and Pahud, Michel and Sinclair, Mike and Bianchi, Andrea},
title = {FlowAR: How Different Augmented Reality Visualizations of Online Fitness Videos Support Flow for At-Home Yoga Exercises},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580897},
doi = {10.1145/3544548.3580897},
abstract = {Online fitness video tutorials are an increasingly popular way to stay fit at home without a personal trainer. However, to keep the screen playing the video in view, users typically disrupt their balance and break the motion flow — two main pillars for the correct execution of yoga poses. While past research partially addressed this problem, these approaches supported only a limited view of the instructor and simple movements. To enable the fluid execution of complex full-body yoga exercises, we propose FlowAR, an augmented reality system for home workouts that shows training video tutorials as always-present virtual static and dynamic overlays around the user. We tested different overlay layouts in a study with 16 participants, using motion capture equipment for baseline performance. Then, we iterated the prototype and tested it in a furnished lab simulating home settings with 12 users. Our results highlight the advantages of different visualizations and the system’s general applicability.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {17},
keywords = {augmented reality, yoga, fitness video, home workouts},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581073,
author = {Raj, Shriti and Gupta, Toshi and Lee, Joyce and Kay, Matthew and Newman, Mark W},
title = {“It Can Bring You in the Right Direction”: Episode-Driven Data Narratives to Help Patients Navigate Multidimensional Diabetes Data to Make Care Decisions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581073},
doi = {10.1145/3544548.3581073},
abstract = {Engaging with multiple streams of personal health data to inform self-care of chronic health conditions remains a challenge. Existing informatics tools provide limited support for patients to make data actionable. To design better tools, we conducted two studies with Type 1 diabetes patients and their clinicians. In the first study, we observed data review sessions between patients and clinicians to articulate the tasks involved in assessing different types of data from diabetes devices to make care decisions. Drawing upon these tasks, we designed novel data interfaces called episode-driven data narratives and performed a task-driven evaluation. We found that as compared to the commercially available diabetes data reports, episode-driven data narratives improved engagement and decision-making with data. We discuss implications for designing data interfaces to support interaction with multidimensional health data to inform self-care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {470},
numpages = {16},
keywords = {patient-generated data, health data interface, sensemaking, diabetes, human-data interaction, personal health data, diabetes data visualization, decision-making},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581522,
author = {Cha, Yoon Jeong and Wou, Alice and Saxena, Arpita and Lee, Joyce and Newman, Mark W and Park, Sun Young},
title = {It’s Like an Educated Guessing Game: Parents’ Strategies for Collaborative Diabetes Management with Their Children},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581522},
doi = {10.1145/3544548.3581522},
abstract = {Children with Type 1 Diabetes (T1D) face many challenges with keeping their blood glucose levels within a healthy range because they cannot manage their illness by themselves. To prevent children’s blood glucose from becoming too high or too low, parents apply different strategies to avoid risky situations. To understand how parents of children with T1D manage these risks, we conducted semi-structured interviews with children with T1D (ages 6-12) and their parents (N=41). We identified four types of strategies used by parents (i.e., educated guessing game, contingency planning, experimentation, and reaching out for help) that can be categorized according to two dimensions: 1) the cause of risk (known or unknown) and 2) the occurrence of risk (predictable or unpredictable). Based on our findings, we provide design implications for collaborative health technologies that support parents in better planning for contingencies and identifying unknown causes of risks together with their children.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {471},
numpages = {15},
keywords = {child-parent collaboration, chronic illness management, collaborative healthcare technology, parent strategies for pediatric patient, type 1 diabetes},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581343,
author = {Kim, Jin Hee (Heather) and Stilling, Joan and O'Dell, Michael and Kao, Cindy Hsin-Liu},
title = {KnitDema: Robotic Textile as Personalized Edema Mobilization Device},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581343},
doi = {10.1145/3544548.3581343},
abstract = {Hand edema, defined as swelling of the hands caused by excess fluid accumulation, is a pervasive condition affecting a person’s range of motion and functional ability. However, treatment strategies remain limited to time-consuming manual massage by trained therapists, deterring a widely accessible approach. We present KnitDema, a robotic textile device that allows sequential compression from distal to proximal finger phalanges for mobilizing edema. We machine-knit the device and integrate small-scale actuators to envelop granular body locations such as fingers, catering to the shape of the hand. In addition, the device affords customizable compression levels through the enclosed fiber-like actuators. We characterize compression parameters and simulate the shunting of edema through a mock fluid system. Finally, we conduct a case study to evaluate the feasibility of the device, in which five hand edema patients assess KnitDema. Our study provides insights into the opportunities for robotic textiles to support personalized rehabilitation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {472},
numpages = {19},
keywords = {Haptics, Hand Edema, Robotic Textile, Compression Device, Wearable Computing, Rehabilitation Device, E-Textile},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580908,
author = {Ryu, Hyeyoung and Berry, Andrew B.L. and Lim, Catherine Y and Hartzler, Andrea and Hirsch, Tad and Trejo, Juanita I and Bermet, Zo\"{e} Abigail and Crawford-Gallagher, Brandi and Tran, Vi and Ferguson, Dawn and Cronkite, David J and Tiffany, Brooks and Weeks, John and Ralston, James},
title = {“You Can See the Connections”: Facilitating Visualization of Care Priorities in People Living with Multiple Chronic Health Conditions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580908},
doi = {10.1145/3544548.3580908},
abstract = {Individuals with multiple chronic health conditions (MCC) often face an overwhelming set of self-management work, resulting in a need to set care priorities. Yet, much self-management work is invisible to healthcare providers. This study aimed to understand how to support the development and sharing of connections between personal values and self-management tasks through the facilitated use of an interactive visualization system: Conversation Canvas. We conducted a field study with 13 participants with MCC, 3 caregivers, and 7 primary care providers in Washington State. Analysis of interviews with MCC participants showed that developing visualizations of connections between personal values, self-management tasks, and health conditions helped individuals make sense of connections relevant to their health and wellbeing, recognize a road map of central issues and their impacts, feel respected and understood, share priorities with providers, and support value-aligned changes. These findings demonstrated potential for the guided process and visualization to support priorities-aligned care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {473},
numpages = {17},
keywords = {patient-clinician communication, visualization, multiple chronic health conditions, sensemaking, patient priorities care, reflection, values},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580836,
author = {Zheng, Clement and Han, Bo and Liu, Xin and Devendorf, Laura and Tan, Hans and Yen, Ching Chiuan},
title = {Crafting Interactive Circuits on Glazed Ceramic Ware},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580836},
doi = {10.1145/3544548.3580836},
abstract = {Glazed ceramic is a versatile material that we use every day. In this paper, we present a new approach that instruments existing glazed ceramic ware with interactive electronic circuits. We informed this work by collaborating with a ceramics designer and connected his craft practice to our experience in physical computing. From this partnership, we developed a systematic approach that begins with the subtractive fabrication of traces on glazed ceramic surfaces via the resist-blasting technique, followed by applying conductive ink into the inlaid traces. We capture and detail this approach through an annotated flowchart for others to refer to, as well as externalize the material insights we uncovered through ceramic and circuit swatches. We then demonstrate a range of interactive home applications built with this approach. Finally, we reflect on the process we took and discuss the importance of collaborating with craftspeople for material-driven research within HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {474},
numpages = {18},
keywords = {Ceramics, Craft, Interactive Circuits},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580697,
author = {Luo, Danli and Rosner, Daniela and Peek, Nadya},
title = {Doufu, Rice Wine, And面饼: Supporting the Connections between Precision and Cultural Knowledge in Cooking},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580697},
doi = {10.1145/3544548.3580697},
abstract = {The digital codification and measurement of food preparation has made strong contributions to HCI food research, whether through ingredient manipulation, workflow management, or recipe interaction. But prior work has shown that technical developments that emphasize precise gourmet practices tend to overlook the importance of cultural knowledge. Drawing on an integrative autobiographical design approach, we describe an open-source hardware toolkit that we developed to examine the process of integrating precision techniques with ritual cooking practices across three recipes: flour skin, rice wine, and doufu. Our work points to the importance of understanding precision as a cultural process with roots in personal and familial experience. We end with a reflection on the particular knowledge-forms that come from cultivating cultural relationships to fabrication processes and their implications for reading digital fabrication processes as meaningfully relational.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {475},
numpages = {13},
keywords = {techno-culinary innovation, maker culture, critical making, design theory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581288,
author = {Xue, Jing and Petreca, Bruna Beatriz and Dawes, Christopher and Obrist, Marianna},
title = {FabTouch: A Tool to Enable Communication and Design of Tactile and Affective Fabric Experiences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581288},
doi = {10.1145/3544548.3581288},
abstract = {The tactile experience of fabric is not only a sensory experience but also an affective one. Our choice of fabric products, like clothing, is often based on how they feel. Effectively communicating such experiences is crucial for designing tactile fabric experiences. However, there remains a lack of comprehensive understanding of the fabric tactile and affective experiences, preventing the development of tools to facilitate the communication of these experiences. In this paper, we examine the fabric experiences of 27 participants towards nine cotton samples. We combine qualitative and quantitative methods to create FabTouch, a novel tool to facilitate a dialogue in the design of fabric experiences. We found six phases of fabric touch experiences including fabric touch responses, sensory associations, and emotional responses. Initial feedback from designers suggested that FabTouch could enrich design processes both in practice and in education and can create inspiration for physical and digital design explorations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {476},
numpages = {16},
keywords = {Multisensory Experiences., Touch, Diachronic and Synchronic Experiential Mapping, Fabric, Tactile Experiences: Affective Responses},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581276,
author = {Ofer, Netta and Alistar, Mirela},
title = {Felt Experiences with Kombucha Scoby: Exploring First-Person Perspectives with Living Matter},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581276},
doi = {10.1145/3544548.3581276},
abstract = {Designing with living organisms can offer new perspectives to design research and practices in HCI. In this work, we explore first-person perspectives through design research with Kombucha Scoby, a microbial biofilm. We began with a material design exploration, producing digitally fabricated and crafted samples with Scoby. As we noticed our felt experiences while growing and working with Kombucha Scoby, we shifted towards a reflective autoethnographic study. Through reflective writings, we followed sensory experiences such as hearing the Kombucha fermentation, touching the Scoby while harvesting it, and watching the slow growth of layers over time. Subsequently, we designed "sensory engagement probes”: designed experiments that bring forward new connections and communicate our process, motivations, and tensions that emerged while engaging with the organism. Lastly, we discuss how such design research can inform material design with living matter by creating space to contemplate "life as shared experience" and more-than-human design perspectives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {477},
numpages = {18},
keywords = {autoethnography, living matter, sensory engagements, kombucha scoby, design research, felt experience},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580643,
author = {Gyory, Peter and Bae, S. Sandra and Yang, Ruhan and Do, Ellen Yi-Luen and Zheng, Clement},
title = {Marking Material Interactions with Computer Vision},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580643},
doi = {10.1145/3544548.3580643},
abstract = {The electronics-centered approach to physical computing presents challenges when designers build tangible interactive systems due to its inherent emphasis on circuitry and electronic components. To explore an alternative physical computing approach we have developed a computer vision (CV) based system that uses a webcam, computer, and printed fiducial markers to create functional tangible interfaces. Through a series of design studios, we probed how designers build tangible interfaces with this CV-driven approach. In this paper, we apply the annotated portfolio method to reflect on the fifteen outcomes from these studios. We observed that CV markers offer versatile materiality for tangible interactions, afford the use of democratic materials for interface construction, and engage designers in embodied debugging with their own vision as a proxy for CV. By sharing our insights, we inform other designers and educators who seek alternative ways to facilitate physical computing and tangible interaction design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {478},
numpages = {17},
keywords = {Making, Physical Computing, Computer Vision, Materiality, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581034,
author = {Zhu, Jingwen and El Nesr, Nadine and Rettenmaier, Nola and Kao, Cindy Hsin-Liu},
title = {SkinPaper: Exploring Opportunities for Woven Paper as a Wearable Material for On-Skin Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581034},
doi = {10.1145/3544548.3581034},
abstract = {Paper circuitry has been extensively explored by HCI researchers as a means of creating interactive objects. However, these approaches focus on creating desktop or handheld objects, and paper as a wearable material remains under-explored. We present SkinPaper, a fabrication approach using silicone-treated washi paper to weave lightweight and easy-to-fabricate on-skin interactions. We adopt techniques from paper weaving and basketry weaving practices to create paper-woven structures that can conform to the body. Our approach uses off-the-shelf materials to facilitate a highly customizable fabrication process. We showcase eight case studies to illustrate our approach’s two to three-dimensional forms. To understand the expressiveness of the design space, we conducted a workshop study in which weavers created paper-woven on-skin interactions. We draw insights from the studies to understand the opportunities for paper-woven on-skin interactions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {479},
numpages = {16},
keywords = {paper circuitry, wearable computing, on-skin interfaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581489,
author = {Milton, Ashlee and Ajmani, Leah and DeVito, Michael Ann and Chancellor, Stevie},
title = {“I See Me Here”: Mental Health Content, Community, and Algorithmic Curation on TikTok},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581489},
doi = {10.1145/3544548.3581489},
abstract = {Social media platforms are a place where people look for information and social support for mental health, resulting in both positive and negative effects on users. TikTok has gained notoriety for an abundance of mental health content and discourse. We present findings from a semi-structured interview study with 16 participants about mental health content and participants’ perceptions of community on TikTok. We find that TikTok’s community structure is permeable, allowing for self-discovery and understanding not found in traditional online communities. However, participants are wary of mental health information due to conflicts between a creator’s vulnerability and credibility. Our interviews suggest that the “For You Page" is a runaway train that encourages diverse community and content engagement but also displays harmful content that participants feel they cannot escape. We propose design implications to support better mental health, as well as implications for social computing research on community in algorithmic landscapes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {480},
numpages = {17},
keywords = {Social Media, Mental Health, Community, TikTok, Interview},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581453,
author = {Randazzo, Casey and Ammari, Tawfiq},
title = {“If Someone Downvoted My Posts—That’d Be the End of the World”: Designing Safer Online Spaces for Trauma Survivors},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581453},
doi = {10.1145/3544548.3581453},
abstract = {Trauma is a common experience affecting over 70 percent of adults globally, with many survivors seeking support from online communities. Yet few studies explore the online experiences of muted groups who lack the words to name or describe their trauma. We pull from 29 in-depth interviews with muted trauma survivors who belong to online communities where trauma narratives are commonplace. Using a spinning top metaphor, we model the sociotechnical nature of the disclosure decision-making process, uncovering new affordances, such as indirect feedback and transportability in online platforms. Findings challenge prior notions of community engagement and algorithmic filter bubbles, highlighting the potential for algorithmic filters to counteract societal filters for muted groups. We conclude with design recommendations to make online spaces safer for trauma survivors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {481},
numpages = {18},
keywords = {trauma-informed computing, Disclosure, social support, nondisclosure, trauma-care tools, mental health, lurking, web sleuthing, trauma, disclosure production, true crime, disclosure decision-making},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581284,
author = {Fang, Anna and Zhu, Haiyi},
title = {Measuring the Stigmatizing Effects of a Highly Publicized Event on Online Mental Health Discourse},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581284},
doi = {10.1145/3544548.3581284},
abstract = {Media coverage has historically played an influential and often stigmatizing role in the public’s understanding of mental illness through harmful language and inaccurate portrayals of those with mental health issues. However, it is unknown how and to what extent media events may affect stigma in online discourse regarding mental health. In this study, we examine a highly publicized event – the celebrity defamation trial between Johnny Depp and Amber Heard – to uncover how stigmatizing and destigmatizing language on Twitter changed during and after the course of the trial. Using causal impact and language analysis methods, we provided a first look at how external events can lead to significantly greater levels of stigmatization and lower levels of destigmatization on Twitter towards not only particular disorders targeted in the coverage of external events but also general mental health discourse.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {482},
numpages = {18},
keywords = {online communities, mental health stigma, mental health},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581372,
author = {Wang, Tony and Shah, Haard K and Shah, Raj Sanjay and Wang, Yi-Chia and Kraut, Robert E and Yang, Diyi},
title = {Metrics for Peer Counseling: Triangulating Success Outcomes for Online Therapy Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581372},
doi = {10.1145/3544548.3581372},
abstract = {Extensive research has been published on the conversational factors of effective volunteer peer counseling on online mental health platforms (OMHPs). However, studies differ in how they define and measure success outcomes, with most prior work examining only a single success metric. In this work, we model the relationship between previously reported linguistic predictors of effective counseling with four outcomes following a peer-to-peer session on a single OMHP: retention in the community, following up on a previous session with a counselor, users’ evaluation of a counselor, and changes in users’ mood. Results show that predictors correlate negatively with community retention but positively with users following up with and giving higher evaluations to individual counselors. We suggest actionable insights for therapy platform design and outcome measurement based on findings that the relationship between predictors and outcomes of successful conversations depends on differences in measurement construct and operationalization.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {483},
numpages = {17},
keywords = {online communities, mental health, metrics triangulation, peer counseling, computational social science, regression modeling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580834,
author = {Mittal, Shravika and De Choudhury, Munmun},
title = {Moral Framing of Mental Health Discourse and Its Relationship to Stigma: A Comparison of Social Media and News},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580834},
doi = {10.1145/3544548.3580834},
abstract = {Mental health discussions on public forums influence the perceptions of people. Negative consequences may result from hostile and “othering” portrayals of people with mental disorders. Adopting the lens of Moral Foundation Theory (MFT), we study framings of mental health discourse on Twitter and News, and how moral underpinnings abate or exacerbate stigma. We adopted a large language model based representation framework to score 13,277,115 public tweets and 21,167 news articles against MFT’s five foundations. We found discussions on Twitter to demonstrate compassion, justice and equity-centered moral values for those suffering from mental illness, in contrast to those on News. That said, stigmatized discussions appeared on both Twitter and News, with news articles being more stigmatizing than tweets. We discuss implications for public health authorities to refine measures for safe reporting of mental health, and for social media platforms to design affordances that enable empathetic discourse.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {484},
numpages = {19},
keywords = {news media, BERT, mental health discourse, stigma, moral foundation theory, twitter},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581020,
author = {Schoenebeck, Sarita and Batool, Amna and Do, Giang and Darling, Sylvia and Grill, Gabriel and Wilkinson, Daricia and Khan, Mehtab and Toyama, Kentaro and Ashwell, Louise},
title = {Online Harassment in Majority Contexts: Examining Harms and Remedies across Countries},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581020},
doi = {10.1145/3544548.3581020},
abstract = {Online harassment is a global problem. This article examines perceptions of harm and preferences for remedies associated with online harassment with nearly 4000 participants in 14 countries around the world. The countries in this work reflect a range of identities and values, with a focus on those outside of North American and European contexts. Results show that perceptions of harm are higher among participants from all countries studied compared to the United States. Non-consensual sharing of sexual photos is consistently rated as harmful in all countries, while insults and rumors are perceived as more harmful in non-U.S. countries, especially harm to family reputation. Lower trust in other people and lower trust in sense of safety in one’s neighborhood correlate with increased perceptions of harm of online harassment. In terms of remedies, participants in most countries prefer monetary compensation, apologies, and publicly revealing offender’s identities compared to the U.S. Social media platform design and policy must consider regional values and norms, which may depart from U.S. centric-approaches.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {485},
numpages = {16},
keywords = {global south, social media, Non-Western, majority world, online abuse, trust, online governance, courts, online harassment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581475,
author = {Oguamanam, Vanessa O. and Hernandez, Natalie and Chandler, Rasheeta and Guillaume, Dominique and Mckeever, Kai and Allen, Morgan and Mohammed, Sabreen and Parker, Andrea G},
title = {An Intersectional Look at Use of and Satisfaction with Digital Mental Health Platforms: A Survey of Perinatal Black Women},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581475},
doi = {10.1145/3544548.3581475},
abstract = {In the United States (U.S.), Black women in the perinatal period disproportionately experience higher rates of mental health challenges like anxiety and postpartum depression. Digital platforms present promising opportunities for mental health support. However, the extent to which these tools are being adopted and satisfying the mental health needs amongst perinatal Black women is underexplored. To address this gap, we surveyed 101 pregnant and postpartum Black women in the U.S. Despite prior work showing low utilization of mental health services amongst Black women, our results show more than half of our participants using specific digital tools for mental health support (e.g., mobile apps and social media). Importantly, use and satisfaction with these tools varied by subgroups (e.g., income and education level). We use our findings to present recommendations for digital mental health intervention research that incorporates an understanding of intersectional identities during the perinatal period.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {486},
numpages = {20},
keywords = {health, digital mental health, digital health, Black women, wellbeing, pregnancy, postpartum},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581459,
author = {Sepehri, Katayoun and Holsti, Liisa and Niasati, Sara and Chan, Vita and Maclean, Karon E},
title = {Beyond the Bulging Binder: Family-Centered Design of a Digital Health Information Management System for Caregivers of Children Living with Health Complexity},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581459},
doi = {10.1145/3544548.3581459},
abstract = {Children Living with Health Complexity (CLHC), whose multiple, severe and chronic conditions differentiate them from those with “complicated” conditions, rely life-long on a vast and ever-shifting array of care providers. Their parent caregivers face a fragmented health care system, disconnected medical records, inter-stakeholder communication barriers and an impenetrable accumulation of documentation – from mundane to life-critical, and largely on paper. They must coordinate care while organizing, tracking and transmitting trends in many health parameters to myriad care providers. We engaged with parent caregivers of CLHC from 12 families through an iterative, 3-phase co-design process to understand their needs for a future digital management system. We share our deepened understanding of their information-centered challenges, a set of principles for how design best-practices need to shift when targeting this acutely high-needs group, and a medium-fidelity prototype user interface which from the ground-up prioritizes caregiver-centered data integration and humanization of the child and family, as well as integrated health record access.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {487},
numpages = {19},
keywords = {health, user study, design, personal information management},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581384,
author = {Lee, Yi-Chieh and Cui, Yichao and Jamieson, Jack and Fu, Wayne and Yamashita, Naomi},
title = {Exploring Effects of Chatbot-Based Social Contact on Reducing Mental Illness Stigma},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581384},
doi = {10.1145/3544548.3581384},
abstract = {Chatbots have been designed to provide interventions in mental healthcare. However, how chatbot-based social contact can mitigate social stigma in mental illness remains under-explored. We designed two chatbots that deliver either first-person or third-person narratives about mental illness and evaluated them using a mixed methods study. Compared to a web survey group, participants in both chatbot groups decreased their beliefs that individuals are personally responsible for their mental illnesses, and increased their intentions to help. Additionally, participants in the first-person chatbot group showed a reduced level of fear, and a lower desire for social distance from people with mental illness. Many in the first-person chatbot group also reported a feeling of relationship with the chatbot, and chose to phrase their responses empathetically. Results demonstrated that chatbot-based social contact has promising potential for mitigating mental illness stigma. Implications for designing chatbot-based social contact are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {488},
numpages = {16},
keywords = {Social Stigma, Chatbots, Mental Illness, Conversational Agents},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581040,
author = {Wilcox, Lauren and Shelby, Renee and Veeraraghavan, Rajesh and Haimson, Oliver L. and Erickson, Gabriela Cruz and Turken, Michael and Gulotta, Rebecca},
title = {Infrastructuring Care: How Trans and Non-Binary People Meet Health and Well-Being Needs through Technology},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581040},
doi = {10.1145/3544548.3581040},
abstract = {We present a cross-cultural diary study with 64 transgender (trans) and non-binary adults in Mexico, the U.S., and India, to understand experiences keeping track of and managing aspects of personal health and well-being. Based on a reflexive thematic analysis of diary data, we highlight sociotechnical interactions that shape how trans and non-binary people track and manage aspects of their health and well-being. Specifically, we surface the ways in which trans and non-binary people infrastructure forms of care, by assembling together elements of informal social ecologies, formalized knowledge sources, and self-reflective media. We examine the forms of precarity that interact with care infrastructure and shape management of health and well-being, including management of gender identity transitions. We discuss the ways in which our findings extend knowledge at the intersection of technology and marginalized health needs, and conclude by arguing for the importance of a research agenda to move toward TGNB-inclusive design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {489},
numpages = {17},
keywords = {gender, trans and non-binary health, infrastructuring, personal informatics, technology harms, marginalized health, algorithmic harms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581546,
author = {Soubutts, Ewan and Czech, Elaine and Ayobi, Amid and Eardley, Rachel and Cater, Kirsten and O'Kane, Aisling Ann},
title = {The Shifting Sands of Labour: Changes in Shared Care Work with a Smart Home Health System},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581546},
doi = {10.1145/3544548.3581546},
abstract = {Whilst the use of smart home systems has shown promise in recent years supporting older people's activities at home, there is more evidence needed to understand how these systems impact the type and the amount of shared care in the home. It is important to understand care recipients and caregivers' labour is changed with the introduction of a smart home system to efficiently and effectively support an increasingly aging population with technology. Five older households (8 participants) were interviewed before, immediately after and three months after receiving a Smart Home Health System (SHHS). We provide an identification and documentation of critical incidents and barriers that increased inter-household care work and prevented the SHHS from being successfully accepted within homes. Findings are framed within the growing body of work on smart homes for health and care, and we provide implications for designing future systems for shared home care needs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {490},
numpages = {16},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581203,
author = {Bowman, Robert and Nadal, Camille and Morrissey, Kellie and Thieme, Anja and Doherty, Gavin},
title = {Using Thematic Analysis in Healthcare HCI at CHI: A Scoping Review},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581203},
doi = {10.1145/3544548.3581203},
abstract = {CHI papers researching healthcare human-computer interaction (HCI) are increasingly reporting the use of “thematic analysis” (TA). TA refers to a range of flexible and evolving approaches for qualitative data analysis. Its increased use demonstrates a change in research practices, and with that the emergence of new local standards. We need to understand and reflect upon these emerging local practices, including departures from what is advocated as quality TA practice more generally. Toward this, we conducted a scoping review of a decade of CHI publications (2012&nbsp;–&nbsp;2021) that researched healthcare and termed their analysis approach “thematic analysis”; 78 papers reporting a total of 100 TAs were included. We contribute a description of 1) the contexts in which TA is being used, 2) the TA approaches being conducted, and 3) how TA is being reported. Drawing on this, we discuss opportunities to improve research practice when using TA in healthcare HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {18},
keywords = {thematic analysis, qualitative research, healthcare},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580918,
author = {D\"{o}llinger, Nina and Wolf, Erik and Botsch, Mario and Latoschik, Marc Erich and Wienrich, Carolin},
title = {Are Embodied Avatars Harmful to Our Self-Experience? The Impact of Virtual Embodiment on Body Awareness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580918},
doi = {10.1145/3544548.3580918},
abstract = {Virtual Reality (VR) allows us to replace our visible body with a virtual self-representation (avatar) and to explore its effects on our body perception. While the feeling of owning and controlling a virtual body is widely researched, how VR affects the awareness of internal body signals (body awareness) remains open. Forty participants performed moving meditation tasks in reality and VR, either facing their mirror image or not. Both the virtual environment and avatars photorealistically matched their real counterparts. We found a negative effect of VR on body awareness, mediated by feeling embodied in and changed by the avatar. Further, we revealed a negative effect of a mirror on body awareness. Our results indicate that assessing body awareness should be essential in evaluating VR designs and avatar embodiment aiming at mental health, as even a scenario as close to reality as possible can distract users from their internal body signals.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {492},
numpages = {14},
keywords = {body perception, Sense of embodiment, virtual reality, virtual humans, body ownership, interoception, agency},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581551,
author = {Chen, Tianying and Liu, Michael Xieyang and Ding, Emily and O'Neil, Emma and Agarwal, Mansi and Kraut, Robert E and Dabbish, Laura},
title = {Facilitating Counselor Reflective Learning with a Real-Time Annotation Tool},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581551},
doi = {10.1145/3544548.3581551},
abstract = {Experiential training, where mental health professionals practice their learned skills, remains the most costly component of therapeutic training. We introduce Pin-MI, a video-call-based tool that supports experiential learning of counseling skills used in motivational interviewing (MI)through interactive role-play as client and counselor. In Pin-MI, counselors annotate, or “pin” the important moments in their role-play sessions in real-time. The pins are then used post-session to facilitate a reflective learning process, in which both client and counselor can provide feedback about what went well or poorly during each pinned moment. We discuss the design of Pin-MI and a qualitative evaluation with a set of healthcare professionals learning MI. Our evaluation suggests that Pin-MI helped users develop empathy, be more aware of their skill usage, guaranteed immediate and targeted feedback, and helped users correct misconceptions about their performance. We discuss implications for the design of experiential training tools for learning counseling skills.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {493},
numpages = {17},
keywords = {reflective learning, psychology, clinician training},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580774,
author = {Bhattacharjee, Ananya and Williams, Joseph Jay and Meyerhoff, Jonah and Kumar, Harsh and Mariakakis, Alex and Kornfield, Rachel},
title = {Investigating the Role of Context in the Delivery of Text Messages for Supporting Psychological Wellbeing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580774},
doi = {10.1145/3544548.3580774},
abstract = {Without a nuanced understanding of users’ perspectives and contexts, text messaging tools for supporting psychological wellbeing risk delivering interventions that are mismatched to users’ dynamic needs. We investigated the contextual factors that influence young adults’ day-to-day experiences when interacting with such tools. Through interviews and focus group discussions with 36 participants, we identified that people’s daily schedules and affective states were dominant factors that shape their messaging preferences. We developed two messaging dialogues centered around these factors, which we deployed to 42 participants to test and extend our initial understanding of users’ needs. Across both studies, participants provided diverse opinions of how they could be best supported by messages, particularly around when to engage users in more passive versus active ways. They also proposed ways of adjusting message length and content during periods of low mood. Our findings provide design implications and opportunities for context-aware mental health management systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {494},
numpages = {19},
keywords = {daily schedule, mental wellbeing, contextual factors, text messages, energy, JITAI, mood},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581319,
author = {Tong, Xin and Mauriello, Matthew Louis and Mora-Mendoza, Marco Antonio and Prabhu, Nina and Kim, Jane Paik and Paredes Castro, Pablo E},
title = {Just Do Something: Comparing Self-Proposed and Machine-Recommended Stress Interventions among Online Workers with Home Sweet Office},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581319},
doi = {10.1145/3544548.3581319},
abstract = {Modern stress management techniques have been shown to be effective, particularly when applied systematically and with the supervision of an instructor. However, online workers usually lack sufficient support from therapists and learning resources to self-manage their stress. To better assist these users, we implemented a browser-based application, Home Sweet Office (HSO), to administer a set of stress micro-interventions which mimic existing therapeutic techniques, including somatic, positive psychology, meta cognitive, and cognitive behavioral categories. In a four-week field study, we compared random and machine-recommended interventions to interventions that were self-proposed by participants in order to investigate effective content and recommendation methods. Our primary findings suggest that both machine-recommended and self-proposed interventions had significantly higher momentary efficacy than random selection, whereas machine-recommended interventions offer more activity diversity compared to self-proposed interventions. We conclude with reflections on these results, discuss features and mechanisms which might improve efficacy, and suggest areas for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {495},
numpages = {20},
keywords = {Self-proposed, Stress, Self-management, Online Workers, Interventions, Machine Learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581563,
author = {Blair, Johnna and Mukherjee, Dahlia and Saunders, Erika F. H. and Abdullah, Saeed},
title = {Knowing How Long a Storm Might Last Makes It Easier to Weather: Exploring Needs and Attitudes Toward a Data-Driven and Preemptive Intervention System for Bipolar Disorder},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581563},
doi = {10.1145/3544548.3581563},
abstract = {Bipolar disorder (BD) is a serious mental illness that requires life-long management. Manic and depressive mood episodes in BD are characterized by idiosyncratic behavioral changes. Identifying these early-warning signs is critical for effective illness management. However, there are unique design constraints for technologies focusing on preemptive assessment and intervention in BD given the need for data-intensive monitoring and balancing user agency. In this paper, we aim to establish acceptance, needs, and concerns regarding a preemptive assessment and intervention system to support longitudinal BD management. We interviewed 10 individuals living with BD. To ground the findings in lived experiences, we used a hypothetical assessment and intervention system focusing on online behaviors. Based on the data, we have identified requirements for effective behavioral monitoring across illness episodes. We have also established design recommendations to support dynamic, longitudinal interventions that can address the evolving user needs for life-long BD management.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {496},
numpages = {12},
keywords = {intervention design, privacy concern, bipolar disorder},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581188,
author = {Farrall, Alexz and Taylor, Jordan and Ainsworth, Ben and Alexander, Jason},
title = {Manifesting Breath: Empirical Evidence for the Integration of Shape-Changing Biofeedback-Based Artefacts within Digital Mental Health Interventions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581188},
doi = {10.1145/3544548.3581188},
abstract = {Digital interventions are often used to support people with mental health conditions, but low engagement frequently reduces their effectiveness. We investigate the use of a Physical Artefact for Well-being Support (PAWS) to improve engagement and effectiveness of an audio-only guided well-being intervention. Through our handheld shape-changing biofeedback-based PAWS, users can synchronously feel their breath via kinaesthetic haptic feedback. By evaluating our device in a randomised-controlled experimental paradigm (N=58), we demonstrate significant reductions in physiological and subjective (self-reported) anxiety compared to an audio-only control. Our findings conclude that synchronous interactions with one‘s own physiological data via the PAWS, improves engagement and effectiveness of an intervention.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {497},
numpages = {14},
keywords = {Biofeedback, Shape-Change, Psychological Accessibility, Physicalization, Physical Artefact for Well-being Support (PAWS), Mental Health, Mental Well-being, Engagement, Breath},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580947,
author = {Yin, Michael and Xiao, Robert},
title = {Drifting Off in Paradise: Why People Sleep in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580947},
doi = {10.1145/3544548.3580947},
abstract = {Sleep is important for humans, and past research has considered methods of improving sleep through technologies such as virtual reality (VR). However, there has been limited research on how such VR technology may affect the experiential and practical aspects of sleep, especially outside of a clinical lab setting. We consider this research gap through the lens of individuals that voluntarily engage in the practice of sleeping in VR. Semi-structured interviews with 14 participants that have slept in VR reveal insights regarding the motivations, actions, and experiential factors that uniquely define this practice. We find that participant motives can be largely categorized through either the experiential or social affordances of VR. We tie these motives into findings regarding the unique customs of sleeping in VR, involving set-up both within the physical and virtual space. Finally, we identify current and future challenges for sleeping in VR, and propose prospective design directions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {498},
numpages = {13},
keywords = {sleep, social VR, VRChat},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581182,
author = {Salagean, Anca and Crellin, Eleanor and Parsons, Martin and Cosker, Darren and Stanton Fraser, Dana\"{e}},
title = {Meeting Your Virtual Twin: Effects of Photorealism and Personalization on Embodiment, Self-Identification and Perception of Self-Avatars in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581182},
doi = {10.1145/3544548.3581182},
abstract = {Embodying virtual twins – photorealistic and personalized avatars – will soon be easily achievable in consumer-grade VR. For the first time, we explored how photorealism and personalization impact self-identification, as well as embodiment, avatar perception and presence. Twenty participants were individually scanned and, in a two-hour session, embodied four avatars (high photorealism personalized, low photorealism personalized, high photorealism generic, low photorealism generic). Questionnaire responses revealed stronger mid-immersion body ownership for the high photorealism personalized avatars compared to all other avatar types, and stronger embodiment for high photorealism compared to low photorealism avatars and for personalized compared to generic avatars. In a self-other face distinction task, participants took significantly longer to pause the face morphing videos of high photorealism personalized avatars, suggesting a stronger self-identification bias with these avatars. Photorealism and personalization were perceptually positive features; how employing these avatars in VR applications impacts users over time requires longitudinal investigation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {499},
numpages = {16},
keywords = {self-identification, virtual reality, personalization, photorealism},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580853,
author = {Shimizu, Kye and Naruse, Santa and Nishida, Jun and Kasahara, Shunichi},
title = {Morphing Identity: Exploring Self-Other Identity Continuum through Interpersonal Facial Morphing Experience},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580853},
doi = {10.1145/3544548.3580853},
abstract = {We explored continuous changes in self-other identity by designing an interpersonal facial morphing experience where the facial images of two users are blended and then swapped over time. Both users’ facial images are displayed side by side, with each user controlling their own morphing facial images, allowing us to create and investigate a multifaceted interpersonal experience. To explore this with diverse social relationships, we conducted qualitative and quantitative investigations through public exhibitions. We found that there is a window of self-identification as well as a variety of interpersonal experiences in the facial morphing process. From these insights, we synthesized a Self-Other Continuum represented by a sense of agency and facial identity. This continuum has implications in terms of the social and subjective aspects of interpersonal communication, which enables further scenario design and could complement findings from research on interactive devices for remote communication.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {500},
numpages = {15},
keywords = {morphing, enfacement illusion, face, self-other identity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581305,
author = {Covaci, Alexandra and Alhasan, Khawla and Loonker, Mayank and Farrell, Bernardine and Tabbaa, Luma and Ppali, Sophia and Ang, Chee Siang},
title = {No Pie in the (Digital) Sky: Co-Imagining the Food Metaverse},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581305},
doi = {10.1145/3544548.3581305},
abstract = {Human behaviour and habits co-evolve with technology, and the metaverse is poised to become a key player in reshaping how we live our everyday life. Given the importance of food in our daily lives, we ask: how will our relationships with food be transformed by the metaverse, and what are the promises and pitfalls of this technology? To answer this, we propose a co-design study that reveals the important elements people value in their daily interactions with food. We then present a speculative catalogue of novel metaverse food experiences, and insights from discussing these ideas with food designers, anthropologists and metaverse experts. Our work aims to provide designers with inspirations for building a metaverse that: provides inclusive opportunities for the future of food; helps re-discover the forgotten or lost knowledge about food; facilitates the exploration, excitement and joy of eating; and reinvigorates the ways that food can soothe and heal.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {501},
numpages = {17},
keywords = {human food technology interaction, co-design, food, speculative design, metaverse},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581231,
author = {Von Terzi, Pia and Diefenbach, Sarah},
title = {The Attendant Perspective: Present Others in Public Technology Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581231},
doi = {10.1145/3544548.3581231},
abstract = {Technology interactions found their way into public space and present others attend what users are doing. However, in HCI research, the attendant perspective has often been neglected or considered only vaguely in the sense of “social context”. Aiming at a better understanding of different types of attendants and their experiences, we developed a typology of four types based on two differentiating criteria (conspicuousness and voluntariness of attending the user interaction). An experimental vignette study (N = 181) tested the typology and revealed typical experiential patterns (e.g., need fulfillment, emotions, desire to join the technology interaction) related to the four types based on quantitative and qualitative data. Our research provides various contributions to HCI theory and design. For example, the typology can be used analytically in UX research. Moreover, it can be used generatively to design positive technology experiences in public for all stakeholders, namely, users and attendants.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {502},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581306,
author = {Park, Hyanghee and Ahn, Daehwan and Lee, Joonhwan},
title = {Towards a Metaverse Workspace: Opportunities, Challenges, and Design Implications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581306},
doi = {10.1145/3544548.3581306},
abstract = {Both enterprises and their employees have globally experienced remote work at an unprecedented scale since the outbreak of COVID-19. As the pandemic becomes less of a threat, some companies have called their employees back to a physical office, citing issues related to working remotely, but many employees have refused to return. Thus, working in the metaverse has gained much attention as an alternative that could complement the weaknesses of completely remote work or even offline work. However, we do not know yet what benefits and drawbacks the metaverse has as a legitimate workspace, because there are few real cases of 1) working in the metaverse and 2) working remotely at such an unprecedented scale. Thus, this paper aims to identify real challenges and opportunities the metaverse workspace presents when compared to remote work by conducting semi-structured interviews and participatory workshops with various employees and company stakeholders (e.g., HR managers and CEOs) who have experienced at least two of three work types: working in a physical office, remotely, or in the metaverse. Consequently, we identified 1) advantages and disadvantages of remote work and 2) opportunities and challenges of the metaverse. We further discuss design implications that may overcome the identified challenges of working in the metaverse.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {503},
numpages = {20},
keywords = {Virtual Environment, Stakeholder-Centered Metaverse Design, Hybrid Work, Remote Work, Videoconferencing, Virtual Workspace, Metaverse, Future of Work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580670,
author = {Leqi, Liu and Zhou, Giulio and Kilinc-Karzan, Fatma and Lipton, Zachary and Montgomery, Alan},
title = {A Field Test of Bandit Algorithms for Recommendations: Understanding the Validity of Assumptions on Human Preferences in Multi-Armed Bandits},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580670},
doi = {10.1145/3544548.3580670},
abstract = {Personalized recommender systems suffuse modern life, shaping what media we read and what products we consume. Algorithms powering such systems tend to consist of supervised-learning-based heuristics, such as latent factor models with a variety of heuristically chosen prediction targets. Meanwhile, theoretical treatments of recommendation frequently address the decision-theoretic nature of the problem, including the need to balance exploration and exploitation, via the multi-armed bandits (MABs) framework. However, MAB-based approaches rely heavily on assumptions about human preferences. These preference assumptions are seldom tested using human subject studies, partly due to the lack of publicly available toolkits to conduct such studies. In this work, we conduct a study with crowdworkers in a comics recommendation MABs setting. Each arm represents a comic category, and users provide feedback after each recommendation. We check the validity of core MABs assumptions—that human preferences (reward distributions) are fixed over time—and find that they do not hold. This finding suggests that any MAB algorithm used for recommender systems should account for human preference dynamics. While answering these questions, we provide a flexible experimental framework for understanding human preference dynamics and testing MABs algorithms with human users. The code for our experimental framework and the collected data can be found at https://github.com/HumainLab/human-bandit-evaluation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {504},
numpages = {16},
keywords = {recommender systems, preference dynamics, multi-armed bandits},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580848,
author = {Salehzadeh Niksirat, Kavous and Goswami, Lahari and S. B. Rao, Pooja and Tyler, James and Silacci, Alessandro and Aliyu, Sadiq and Aebli, Annika and Wacharamanotham, Chat and Cherubini, Mauro},
title = {Changes in Research Ethics, Openness, and Transparency in Empirical Studies between CHI 2017 and CHI 2022},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580848},
doi = {10.1145/3544548.3580848},
abstract = {In recent years, various initiatives from within and outside the HCI field have encouraged researchers to improve research ethics, openness, and transparency in their empirical research. We quantify how the CHI literature might have changed in these three aspects by analyzing samples of 118 CHI 2017 and 127 CHI 2022 papers—randomly drawn and stratified across conference sessions. We operationalized research ethics, openness, and transparency into 45&nbsp; criteria and manually annotated the sampled papers. The results show that the CHI 2022 sample was better in 18 criteria, but in the rest of the criteria, it has no improvement. The most noticeable improvements were related to research transparency (10 out of 17 criteria). We also explored the possibility of assisting the verification process by developing a proof-of-concept screening system. We tested this tool with eight criteria. Six of them achieved high accuracy and F1 score. We discuss the implications for future research practices and education. This paper and all supplementary materials are freely available at&nbsp;https://doi.org/10.17605/osf.io/n25d6.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {505},
numpages = {23},
keywords = {open science, CHI, ethics, transparency, reproducibility, replicability, data availability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581190,
author = {Assi, Karim and Meegahapola, Lakmal and Droz, William and Kun, Peter and De G\"{o}tzen, Amalia and Bidoglia, Miriam and Stares, Sally and Gaskell, George and Chagnaa, Altangerel and Ganbold, Amarsanaa and Zundui, Tsolmon and Caprini, Carlo and Miorandi, Daniele and Zarza, Jos\'{e} Luis and Hume, Alethia and Cernuzzi, Luca and Bison, Ivano and Rodas Britez, Marcelo Dario and Busso, Matteo and Chenu-Abente, Ronald and Giunchiglia, Fausto and Gatica-Perez, Daniel},
title = {Complex Daily Activities, Country-Level Diversity, and Smartphone Sensing: A Study in Denmark, Italy, Mongolia, Paraguay, and UK},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581190},
doi = {10.1145/3544548.3581190},
abstract = {Smartphones enable understanding human behavior with activity recognition to support people’s daily lives. Prior studies focused on using inertial sensors to detect simple activities (sitting, walking, running, etc.) and were mostly conducted in homogeneous populations within a country. However, people are more sedentary in the post-pandemic world with the prevalence of remote/hybrid work/study settings, making detecting simple activities less meaningful for context-aware applications. Hence, the understanding of (i) how multimodal smartphone sensors and machine learning models could be used to detect complex daily activities that can better inform about people’s daily lives, and (ii) how models generalize to unseen countries, is limited. We analyzed in-the-wild smartphone data and ∼ 216K self-reports from 637 college students in five countries (Italy, Mongolia, UK, Denmark, Paraguay). Then, we defined a 12-class complex daily activity recognition task and evaluated the performance with different approaches. We found that even though the generic multi-country approach provided an AUROC of 0.70, the country-specific approach performed better with AUROC scores in [0.79-0.89]. We believe that research along the lines of diversity awareness is fundamental for advancing human behavior understanding through smartphones and machine learning, for more real-world utility across countries.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {506},
numpages = {23},
keywords = {model generalization, context-awareness, passive sensing, distributional shift, complex activities of daily living, behavior recognition, domain shift, smartphone sensing, diversity-awareness, activity recognition},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580860,
author = {Borgert, Nele and Reithmaier, Oliver D. and Jansen, Luisa and Hillemann, Larina and Hussey, Ian and Elson, Malte},
title = {Home Is Where the Smart Is: Development and Validation of the Cybersecurity Self-Efficacy in Smart Homes (CySESH) Scale},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580860},
doi = {10.1145/3544548.3580860},
abstract = {The ubiquity of devices connected to the internet raises concerns about the security and privacy of smart homes. The effectiveness of interventions to support secure user behaviors is limited by a lack of validated instruments to measure relevant psychological constructs, such as self-efficacy – the belief that one is able to perform certain behaviors. We developed and validated the Cybersecurity Self-Efficacy in Smart Homes (CySESH) scale, a 12-item unidimensional measure of domain-specific self-efficacy beliefs, across five studies (N = 1247). Three pilot studies generated and refined an item pool. We report evidence from one initial and one major, preregistered validation study for (1) excellent reliability (α = 0.90), (2) convergent validity with self-efficacy in information security (rSEIS = 0.64, p &lt; .001), and (3) discriminant validity with outcome expectations (rOE = 0.26, p &lt; .001), self-esteem (rRSE = 0.17, p &lt; .001), and optimism (rLOT-R = 0.18, p &lt; .001). We discuss CySESH’s potential to advance future HCI research on cybersecurity, practitioner user assessments, and implications for consumer protection policy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {507},
numpages = {15},
keywords = {cybersecurity, validation, self-efficacy, smart homes, scale development},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581565,
author = {Elagroudy, Passant and Khamis, Mohamed and Mathis, Florian and Irmscher, Diana and Sood, Ekta and Bulling, Andreas and Schmidt, Albrecht},
title = {Impact of Privacy Protection Methods of Lifelogs on Remembered Memories},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581565},
doi = {10.1145/3544548.3581565},
abstract = {Lifelogging is traditionally used for memory augmentation. However, recent research shows that users’ trust in the completeness and accuracy of lifelogs might skew their memories. Privacy-protection alterations such as body blurring and content deletion are commonly applied to photos to circumvent capturing sensitive information. However, their impact on how users remember memories remain unclear. To this end, we conduct a white-hat memory attack and report on an iterative experiment (N=21) to compare the impact of viewing 1) unaltered lifelogs, 2) blurred lifelogs, and 3) a subset of the lifelogs after deleting private ones, on confidently remembering memories. Findings indicate that all the privacy methods impact memories’ quality similarly and that users tend to change their answers in recognition more than recall scenarios. Results also show that users have high confidence in their remembered content across all privacy methods. Our work raises awareness about the mindful designing of technological interventions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {508},
numpages = {10},
keywords = {recognition, obfuscation, filters, recall, blurring, memory reformation, memory augmentation, privacy, lifelogging, memory implantation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581332,
author = {Stefanidi, Evropi and Bentvelzen, Marit and Wo\'{z}niak, Pawe\l{} W. and Kosch, Thomas and Wo\'{z}niak, Miko\l{}aj P. and Mildner, Thomas and Schneegass, Stefan and M\"{u}ller, Heiko and Niess, Jasmin},
title = {Literature Reviews in HCI: A Review of Reviews},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581332},
doi = {10.1145/3544548.3581332},
abstract = {This paper analyses Human-Computer Interaction (HCI) literature reviews to provide a clear conceptual basis for authors, reviewers, and readers. HCI is multidisciplinary and various types of literature reviews exist, from systematic to critical reviews in the style of essays. Yet, there is insufficient consensus of what to expect of literature reviews in HCI. Thus, a shared understanding of literature reviews and clear terminology is needed to plan, evaluate, and use literature reviews, and to further improve review methodology. We analysed 189 literature reviews published at all SIGCHI conferences and ACM Transactions on Computer-Human Interaction (TOCHI) up until August 2022. We report on the main dimensions of variation: (i) contribution types and topics; and (ii) structure and methodologies applied. We identify gaps and trends to inform future meta work in HCI and provide a starting point on how to move towards a more comprehensive terminology system of literature reviews in HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {509},
numpages = {24},
keywords = {meta-analysis, literature review, meta review, literature survey, method},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581005,
author = {Sabie, Dina and Sheta, Hala and Ferdous, Hasan Shahid and Kopalakrishnan, Vannie and Ahmed, Syed Ishtiaque},
title = {Be Our Guest: Intercultural Heritage Exchange through Augmented Reality (AR)},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581005},
doi = {10.1145/3544548.3581005},
abstract = {This paper explores how interactive applications can help mitigate the adversity of facing cultural differences between migrants and the host community, and between migrants of diverse backgrounds to foster intercultural exchange. Based on literature about situated cognition, immersive theater, and affordance, we designed and built Be Our Guest: an augmented reality application where a user is invited to the houses of people from different cultures and is asked to help with one of their cultural rituals around simple everyday objects. We detail the various phases we took to collect the cultural stories and construct the application. We then report the results of a user study with the developed application. Our findings show that participants were easily immersed in the augmented space due to the app’s narrative, visuals, and interactive nature. Moreover, they enjoyed exploring cultural rituals, including their own, and felt more confident connecting with people from other cultures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {510},
numpages = {15},
keywords = {HCI, host community, immersive theater, communication, immigrant, culture, migrant, AR, Augmented Reality, heritage, exploration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581362,
author = {Cao, Jiaxun and He, Qingyang and Wang, Zhuo and LC, RAY and Tong, Xin},
title = {DreamVR: Curating an Interactive Exhibition in Social VR Through an Autobiographical Design Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581362},
doi = {10.1145/3544548.3581362},
abstract = {Virtual exhibitions have long been regarded as an extension of information delivery for physical exhibitions. However, what virtual exhibitions can offer audiences as a novel experience independently from physical exhibitions has been largely unexplored. In this study, we aim to understand the promises and challenges of experiencing and curating exhibitions in VR by interviewing nine expert curators. Drawing from expert insights, we summarized a set of design guidelines to inform what we can learn and adapt from physical exhibitions when curating in VR. Then, using an autobiographical design approach, we curated an interactive exhibition in VRChat to explore novel interaction techniques. We also hosted an open tour guide in the user study to validate our design guidelines with thirty participants. Results show that our approach of curating an exhibition in VRChat provided the participants with engaging and novel experiences interacting with the exhibits and other audiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {511},
numpages = {18},
keywords = {virtual museum, social virtual reality, interview, autobiographical design study, Virtual exhibition},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581039,
author = {Leong, Joanne and Perteneder, Florian and Rajvee, Muhender Raj and Maes, Pattie},
title = {“Picture the Audience...”: Exploring Private AR Face Filters for Online Public Speaking},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581039},
doi = {10.1145/3544548.3581039},
abstract = {Faced with public speaking anxiety, one common piece of advice is to picture the audience in a new light, using your mind’s eye. With Augmented Reality (AR) face filters, it becomes possible to literally change how one sees oneself or others. In this paper, we explore privately applied AR filters during online public speaking. Private means that these effects are only visible to the speaker. To investigate this possibly controversial concept, we conducted an online survey with 100 respondents to gather a diverse set of initial impressions, possible boundaries, and guidelines. Following this, we built a prototype of a private AR web-based video-calling application, and pilot-tested it with 16 participants to gain more in-depth insights. Based on our results, we outline key user perspectives and opportunities for the private application of AR face filters during online public speaking and discuss them in the context of previous literature on this topic.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {512},
numpages = {13},
keywords = {video conferencing, communication, camera filters, public speaking, augmented reality, self-perception},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581292,
author = {Uhl, Jakob Carl and Schrom-Feiertag, Helmut and Regal, Georg and Gallhuber, Katja and Tscheligi, Manfred},
title = {Tangible Immersive Trauma Simulation: Is Mixed Reality the next Level of Medical Skills Training?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581292},
doi = {10.1145/3544548.3581292},
abstract = {In medical simulation training two approaches are currently rather disjunct: realistic manikins are used to teach physical skills and procedures and VR systems are used to train situation assessment and decision making. We propose a mixed reality approach, which allows trainees to use real tools and their hands when interacting with a physical manikin overlaid with a responsive virtual avatar. In close exchange with first responder organizations, we developed and evaluated an MR training scenario. In the scenario, users can talk to injured people in a car accident, assess the threat of the environment, and utilize real medical equipment. Participants experienced high levels of physical- and self-presence, increased stress levels, and reported a high technology acceptance. The proposed main requirements of first responders regarding haptic multi-sensory skill training in MR and the lessons learned from the workshop aim to guide the design of training solutions for medical training in MR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {513},
numpages = {17},
keywords = {first responder, training, presence, mixed reality, haptic feedback},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581090,
author = {Schulenberg, Kelsea and Li, Lingyuan and Freeman, Guo and Zamanifard, Samaneh and McNeese, Nathan J.},
title = {Towards Leveraging AI-Based Moderation to Address Emergent Harassment in Social Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581090},
doi = {10.1145/3544548.3581090},
abstract = {Extensive HCI research has investigated how to prevent and mitigate harassment in virtual spaces, particularly by leveraging human-based and Artificial Intelligence (AI)-based moderation. However, social Virtual Reality (VR) constitutes a novel social space that faces both intensified harassment challenges and a lack of consensus on how moderation should be approached to address such harassment. Drawing on 39 interviews with social VR users with diverse backgrounds, we investigate the perceived opportunities and limitations for leveraging AI-based moderation to address emergent harassment in social VR, and how future AI moderators can be designed to enhance such opportunities and address limitations. We provide the first empirical investigation into re-envisioning AI’s new roles in innovating content moderation approaches to better combat harassment in social VR. We also highlight important principles for designing future AI-based moderation incorporating user-human-AI collaboration to achieve safer and more nuanced online spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {514},
numpages = {17},
keywords = {social VR, artificial intelligence, online harassment, content moderation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581530,
author = {Li, Lingyuan and Freeman, Guo and Schulenberg, Kelsea and Acena, Dane},
title = {"We Cried on Each Other’s Shoulders": How LGBTQ+ Individuals Experience Social Support in Social Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581530},
doi = {10.1145/3544548.3581530},
abstract = {Although social support can be a vital component of gender and sexual identity formation, many LGBTQ+ individuals often lack offline social networks for such support. Traditional online technologies also reveal several challenges in providing LGBTQ+ individuals with effective social support. Therefore, social VR, as a unique online space for immersive and embodied experiences, is becoming popular within LGBTQ+ communities for supportive online interactions. Drawing on 29 LGBTQ+ social VR users’ experiences, we investigate the types of social support LGBTQ+ users have experienced through social VR and how they leverage unique social VR features to experience such support. We provide one of the first empirical evidence of how social VR innovates traditional online support mechanisms to empower LGBTQ+ individuals but leads to new safety and equality concerns. We also propose important principles for rethinking social VR design to provide all users, rather than just the privileged few, with supportive experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {515},
numpages = {16},
keywords = {LGBTQ+, social VR, online social support},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581174,
author = {Chen, Xiuge and Srivastava, Namrata and Jain, Rajiv and Healey, Jennifer and Dingler, Tilman},
title = {Characteristics of Deep and Skim Reading on Smartphones vs. Desktop: A Comparative Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581174},
doi = {10.1145/3544548.3581174},
abstract = {Deep reading fosters text comprehension, memory, and critical thinking. The growing prevalance of digital reading on mobile interfaces raises concerns that deep reading is being replaced by skimming and sifting through information, but this is currently unmeasured. Traditionally, reading quality is assessed using comprehension tests, which require readers to explicitly answer a set of carefully composed questions. To quantify and understand reading behaviour in natural settings and at scale, however, implicit measures are needed of deep versus skim reading across desktop and mobile devices, the most prominent digital reading platforms. In this paper, we present an approach to systematically induce deep and skim reading and subsequently train classifiers to discriminate these two reading styles based on eye movement patterns and interaction data. Based on a user study with 29 participants, we created models that detect deep reading on both devices with up to 0.82 AUC. We present the characteristics of deep reading and discuss how our models can be used to measure the effect of reading UI design and monitor long-term changes in reading behaviours.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {516},
numpages = {14},
keywords = {Deep reading, Reading mode classification, Gaze features, Eye tracking, Digital Devices},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580866,
author = {Bertrand, Jennifer K and Chapman, Craig S},
title = {Dynamics of Eye-Hand Coordination Are Flexibly Preserved in Eye-Cursor Coordination during an Online, Digital, Object Interaction Task},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580866},
doi = {10.1145/3544548.3580866},
abstract = {Do patterns of eye-hand coordination observed during real-world object interactions apply to digital, screen-based object interactions? We adapted a real-world object interaction task (physically transferring cups in sequence about a tabletop) into a two-dimensional screen-based task (dragging-and-dropping circles in sequence with a cursor). We collected gaze (with webcam eye-tracking) and cursor position data from 51 fully-remote, crowd-sourced participants who performed the task on their own computer. We applied real-world time-series data segmentation strategies to resolve the self-paced movement sequence into phases of object interaction and rigorously cleaned the webcam eye-tracking data. In this preliminary investigation, we found that: 1) real-world eye-hand coordination patterns persist and adapt in this digital context, and 2) remote, online, cursor-tracking and webcam eye-tracking are useful tools for capturing visuomotor behaviours during this ecologically-valid human-computer interaction task. We discuss how these findings might inform design principles and further investigations into natural behaviours that persist in digital environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {517},
numpages = {13},
keywords = {quantitative methods, eye-tracking, object interaction, cursor-tracking, eye-cursor coordination},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581022,
author = {Catan\u{a}, Adrian-Vasile and Vatavu, Radu-Daniel},
title = {Fingerhints: Understanding Users’ Perceptions of and Preferences for On-Finger Kinesthetic Notifications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581022},
doi = {10.1145/3544548.3581022},
abstract = {We present “fingerhints,” on-finger kinesthetic feedback represented by hyper-extension movements of the index finger, bypassing user agency, for notifications delivery. To this end, we designed a custom-made finger-augmentation device, which leverages mechanical force to deliver fingerhints as programmable hyper-extensions of the index finger. We evaluate fingerhints with 21 participants, and report good usability, low technology creepiness, and moderate to high social acceptability. In a second study with 11 new participants, we evaluate the wearable comfort of our fingerhints device against four commercial finger- and hand-augmentation devices. Finally, we present insights from the experience of one participant, who wore our device for eight hours during their daily life. We discuss the user experience of fingerhints in relation to our participants’ personality traits, finger dexterity levels, and general attitudes toward notifications, and present implications for interactive systems leveraging on-finger kinesthetic feedback for on-body computing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {518},
numpages = {17},
keywords = {kinethestic feedback, index finger, finger-augmentation devices, experiment, user experience, Kinesthesia, notifications},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581121,
author = {Yeh, Yen-Ting and Matulic, Fabrice and Vogel, Daniel},
title = {Phone Sleight of Hand: Finger-Based Dexterous Gestures for Physical Interaction with Mobile Phones},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581121},
doi = {10.1145/3544548.3581121},
abstract = {We identify and evaluate single-handed “dexterous gestures” to physically manipulate a phone using the fine motor skills of fingers. Four manipulations are defined: shift, spin (yaw axis), rotate (roll axis) and flip (pitch axis), with a formative survey showing all except flip have been performed for various reasons. A controlled experiment examines the speed, behaviour, and preference of manipulations in the form of dexterous gestures, by considering two directions and two movement magnitudes. Results show rotate is rated as easiest and most comfortable, while flip is rated lowest. Using a heuristic recognizer for spin, rotate, and flip, a one-week usability experiment finds increased practice and familiarity improve the speed and comfort of dexterous gestures. Design guidelines are developed to consider comfort, ability, and confidence when mapping dexterous gestures to interactions, and demonstrations show how such gestures can be used in smartphone applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {519},
numpages = {19},
keywords = {Interaction techniques, Mobile input, Finger dexterity, Gesture recognition},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580954,
author = {M\"{u}ller, Florian and Schmitt, Daniel and Matviienko, Andrii and Sch\"{o}n, Dominik and G\"{u}nther, Sebastian and Kosch, Thomas and Schmitz, Martin},
title = {TicTacToes: Assessing Toe Movements as an Input Modality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580954},
doi = {10.1145/3544548.3580954},
abstract = {From carrying grocery bags to holding onto handles on the bus, there are a variety of situations where one or both hands are busy, hindering the vision of ubiquitous interaction with technology. Voice commands, as a popular hands-free alternative, struggle with ambient noise and privacy issues. As an alternative approach, research explored movements of various body parts (e.g., head, arms) as input modalities, with foot-based techniques proving particularly suitable for hands-free interaction. Whereas previous research only considered the movement of the foot as a whole, in this work, we argue that our toes offer further degrees of freedom that can be leveraged for interaction. To explore the viability of toe-based interaction, we contribute the results of a controlled experiment with 18 participants assessing the impact of five factors on the accuracy, efficiency and user experience of such interfaces. Based on the findings, we provide design recommendations for future toe-based interfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {520},
numpages = {17},
keywords = {Toes, Body-Centric Interaction, Foot, Foot-Based Interaction, Input},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581534,
author = {Webber, Sarah and Kelly, Ryan M. and Wadley, Greg and Smith, Wally},
title = {Engaging with Nature through Technology: A Scoping Review of HCI Research},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581534},
doi = {10.1145/3544548.3581534},
abstract = {Technological progress has often been measured by the extent to which it shields and protects us from the harshness of nature. At the same time, it has long been recognised that our resulting disengagement from nature negatively affects our wellbeing and impedes awareness of our vital dependence on natural environments. To understand how HCI has considered the possibilities that digital technology offers for engaging with nature, we conducted a scoping review encompassing more than 20 years of HCI research on nature engagement. We compare the orientations, motivations, and methodologies of different threads within this growing body of work. We show how HCI research has enabled varied forms of direct and indirect engagement with nature, and we develop a typology of the roles proposed for technology in this work. We highlight promising and under-utilised approaches to designing for nature engagement and discuss directions for future research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {521},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580716,
author = {Sabnis, Nihar and Wittchen, Dennis and Reed, Courtney N. and Pourjafarian, Narjes and Steimle, J\"{u}rgen and Strohmeier, Paul},
title = {Haptic Servos: Self-Contained Vibrotactile Rendering System for Creating or Augmenting Material Experiences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580716},
doi = {10.1145/3544548.3580716},
abstract = {When vibrations are synchronized with our actions, we experience them as material properties. This has been used to create virtual experiences like friction, counter-force, compliance, or torsion. Implementing such experiences is non-trivial, requiring high temporal resolution in sensing, high fidelity tactile output, and low latency. To make this style of haptic feedback more accessible to non-domain experts, we present Haptic Servos: self-contained haptic rendering devices which encapsulate all timing-critical elements. We characterize Haptic Servos’ real-time performance, showing the system latency is &lt;5&nbsp;ms. We explore the subjective experiences they can evoke, highlighting that qualitatively distinct experiences can be created based on input mapping, even if stimulation parameters and algorithm remain unchanged. A workshop demonstrated that users new to Haptic Servos require approximately ten minutes to set up a basic haptic rendering system. Haptic Servos are open source, we invite others to copy and modify our design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {522},
numpages = {17},
keywords = {haptic rendering, material experiences, haptic feedback, prototyping, toolkit},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581479,
author = {Spors, Velvet and Laato, Samuli and Buruk, O\u{g}uz 'Oz' and Hamari, Juho},
title = {Longing to Be the Mountain: A Scoping Review about Nature-Centric, Health-Minded Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581479},
doi = {10.1145/3544548.3581479},
abstract = {Engaging with nature enriches people’s life greatly, and it is a particularly powerful wellbeing activity. Unsurprisingly, researchers in HCI and beyond seek to augment and extend the relationship people have with nature through technology, to positively enhance their health as a result. In this paper, we report on a scoping review that examines research exploring health, nature, and technology research. By charting 29 papers from the last five years, we produce a situated snapshot of the current research landscape and identify three trends within the paper pool: Despite the potential for rich, experiential engagements, human-nature interaction is often understood as an endeavour that is 1) universal, 2) flattened and 3) disconnected from everyday life. We reflect on our findings to outline design opportunities for human-nature interaction that extend and re-orientate it; to design for multi-dimensional caring experiences that allow for a more-than-just-human understanding of nature.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {523},
numpages = {16},
keywords = {wellness, wellbeing, climate change, scoping review, health, environmentalism, nature, sustainability, human-nature interaction, ecology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581150,
author = {Gr\"{o}newald, Laura and Weiblen, Julian and Laschke, Matthias and Christoforakos, Lara and Hassenzahl, Marc},
title = {Sustainability by Design. How to Encourage Users to Choose Energy-Saving Programs and Settings When Washing Laundry},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581150},
doi = {10.1145/3544548.3581150},
abstract = {One way to counteract anthropogenic climate change, is to reduce individual energy consumption. An especially energy-intensive everyday practice is doing the laundry. In Germany, laundry accounts for about 5% of domestic electricity consumption. In part, this is because users do not make use of the energy-saving programs offered by modern washing machines. Based on different principles of behavior change, we created four concepts for washing machine interfaces to encourage users to choose energy-saving programs and settings. These concepts were implemented as functional prototypes. An online experiment (N=400) showed that all concepts increased the choice of energy-saving programs compared to a standard machine. Especially effective was to interrupt impulsive actions and suggest alternative choices (concept B) and to restructure the entry of settings (concept E). This demonstrates how small changes in a standard interfaces can significantly increase the probability of energy conservation in a private setting.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {524},
numpages = {14},
keywords = {laundry washing, sustainability, sustainable interaction design, prototyping, empirical study, sustainable HCI, Behavior change, persuasive technology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581291,
author = {Perovich, Laura J and Titcomb, Catherine and Hirsch, Tad and Helmuth, Brian and Harteveld, Casper},
title = {Sustainable HCI Under Water: Opportunities for Research with Oceans, Coastal Communities, and Marine Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581291},
doi = {10.1145/3544548.3581291},
abstract = {Although the world’s oceans play a critical role in human well-being, they have not been a primary focus of the sustainable HCI (SHCI) community to date. In this paper, we present a scoping review to show how concerns with the oceans are threaded throughout the broader SHCI literature and to find new research opportunities. We identify several themes that could benefit from focused SHCI research, including marine food sources, culture and coastal communities, ocean conservation, and marine climate change impacts and adaptation strategies. Finally, we discuss opportunities for further work on marine human-natural systems research in SHCI and interdisciplinary collaboration with marine science and coastal communities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {525},
numpages = {16},
keywords = {marine systems, oceans, sustainable HCI, SHCI, sustainable interaction design, Sustainable Development Goal 14, environment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581289,
author = {Daepp, Madeleine I. G. and Cabral, Alex and Werner, Tiffany M and Mansour, Raed and Catlett, Charlie and Roseway, Asta and Needham, Chuck and Udeagbala, Nneka and Counts, Scott},
title = {The “Three-Legged Stool": Designing for Equitable City, Community, and Research Partnerships in Urban Environmental Sensing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581289},
doi = {10.1145/3544548.3581289},
abstract = {Urban environmental monitoring campaigns depend on expertise from city agencies, residents, and researchers. Deployment efforts rarely include all three stakeholders, typically leading to initiatives that struggle to produce credible, actionable data. We describe the implementation of a large-scale, long-term air quality sensing network in Chicago&nbsp; Illinois; detail stakeholder interviews and meetings; and present three interfaces—–a website accessible via in-situ QR codes, APIs, and a mobile, mixed-media experience. We show how a collaborative approach created a more equitable sensor distribution compared to crowdsourced or regulatory designs. We highlight shared goals of education, engagement, and empowerment despite the diversity of tool and analytics needs across stakeholder groups. Reflecting on our work, we develop a “three-legged stool” framework representing the criticality of balanced participation from three key stakeholder groups—city, community, and research—in deploying novel urban technologies. This approach can help HCI researchers facilitate more democratic technology deployments in urban spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {526},
numpages = {19},
keywords = {Design Frameworks, Collaborative Design, Smart Cities, Environmental Monitoring, User Interfaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581438,
author = {Hubenschmid, Sebastian and Zagermann, Johannes and Leicht, Daniel and Reiterer, Harald and Feuchtner, Tiare},
title = {ARound the Smartphone: Investigating the Effects of Virtually-Extended Display Size on Spatial Memory},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581438},
doi = {10.1145/3544548.3581438},
abstract = {Smartphones conveniently place large information spaces in the palms of our hands. While research has shown that larger screens positively affect spatial memory, workload, and user experience, smartphones remain fairly compact for the sake of device ergonomics and portability. Thus, we investigate the use of hybrid user interfaces to virtually increase the available display size by complementing the smartphone with an augmented reality head-worn display. We thereby combine the benefits of familiar touch interaction with the near-infinite visual display space afforded by augmented reality. To better understand the potential of virtually-extended displays and the possible issues of splitting the user’s visual attention between two screens (real and virtual), we conducted a within-subjects experiment with 24 participants completing navigation tasks using different virtually-augmented display sizes. Our findings reveal that a desktop monitor size represents a “sweet spot” for extending smartphones with augmented reality, informing the design of hybrid user interfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {527},
numpages = {15},
keywords = {augmented reality, hybrid user interfaces, spatial memory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580677,
author = {Kari, Mohamed and Holz, Christian},
title = {HandyCast: Phone-Based Bimanual Input for Virtual Reality in Mobile and Space-Constrained Settings via Pose-and-Touch Transfer},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580677},
doi = {10.1145/3544548.3580677},
abstract = {Despite the potential of Virtual Reality as the next computing platform for general purposes, current systems are tailored to stationary settings to support expansive interaction in mid-air. However, in mobile scenarios, the physical constraints of the space surrounding the user may be prohibitively small for spatial interaction in VR with classical controllers. In this paper, we present HandyCast, a smartphone-based input technique that enables full-range 3D input with two virtual hands in VR while requiring little physical space, allowing users to operate large virtual environments in mobile settings. HandyCast defines a pose-and-touch transfer function that fuses the phone’s position and orientation with touch input to derive two individual 3D hand positions. Holding their phone like a gamepad, users can thus move and turn it to independently control their virtual hands. Touch input using the thumbs fine-tunes the respective virtual hand position and controls object selection. We evaluated HandyCast in three studies, comparing its performance with that of Go-Go, a classic bimanual controller technique. In our open-space study, participants required significantly less physical motion using HandyCast with no decrease in completion time or body ownership. In our space-constrained study, participants achieved significantly faster completion times, smaller interaction volumes, and shorter path lengths with HandyCast compared to Go-Go. In our technical evaluation, HandyCast’s fully standalone inside-out 6D tracking performance again incurred no decrease in completion time compared to an outside-in tracking baseline.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {528},
numpages = {15},
keywords = {Virtual reality, bimanual interaction., 3D controller, VR input, interaction techniques},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581392,
author = {Mollyn, Vimal and Arakawa, Riku and Goel, Mayank and Harrison, Chris and Ahuja, Karan},
title = {IMUPoser: Full-Body Pose Estimation Using IMUs in Phones, Watches, and Earbuds},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581392},
doi = {10.1145/3544548.3581392},
abstract = {Tracking body pose on-the-go could have powerful uses in fitness, mobile gaming, context-aware virtual assistants, and rehabilitation. However, users are unlikely to buy and wear special suits or sensor arrays to achieve this end. Instead, in this work, we explore the feasibility of estimating body pose using IMUs already in devices that many users own — namely smartphones, smartwatches, and earbuds. This approach has several challenges, including noisy data from low-cost commodity IMUs, and the fact that the number of instrumentation points on a user’s body is both sparse and in flux. Our pipeline receives whatever subset of IMU data is available, potentially from just a single device, and produces a best-guess pose. To evaluate our model, we created the IMUPoser Dataset, collected from 10 participants wearing or holding off-the-shelf consumer devices and across a variety of activity contexts. We provide a comprehensive evaluation of our system, benchmarking it on both our own and existing IMU datasets.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {529},
numpages = {12},
keywords = {Motion capture, inertial measurement units, mobile devices, sensors},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580747,
author = {Yeo, Hui-Shyong and Wu, Erwin and Kim, Daehwa and Lee, Juyoung and Kim, Hyung-il and Oh, Seo Young and Takagi, Luna and Woo, Woontack and Koike, Hideki and Quigley, Aaron John},
title = {OmniSense: Exploring Novel Input Sensing and Interaction Techniques on Mobile Device with an Omni-Directional Camera},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580747},
doi = {10.1145/3544548.3580747},
abstract = {An omni-directional (360°) camera captures the entire viewing sphere surrounding its optical center. Such cameras are growing in use to create highly immersive content and viewing experiences. When such a camera is held by a user, the view includes the user’s hand grip, finger, body pose, face, and the surrounding environment, providing a complete understanding of the visual world and context around it. This capability opens up numerous possibilities for rich mobile input sensing. In OmniSense, we explore the broad input design space for mobile devices with a built-in omni-directional camera and broadly categorize them into three sensing pillars: i) near device ii) around device and iii) surrounding device. In addition we explore potential use cases and applications that leverage these sensing capabilities to solve user needs. Following this, we develop a working system to put these concepts into action, by leveraging these sensing capabilities to enable potential use cases and applications. We studied the system in a technical evaluation and a preliminary user study to gain initial feedback and insights. Collectively these techniques illustrate how a single, omni-purpose sensor on a mobile device affords many compelling ways to enable expressive input, while also affording a broad range of novel applications that improve user experience during mobile interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {530},
numpages = {18},
keywords = {Omni-directional, input sensing, interaction technique., 360° camera},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580696,
author = {Qin, Yue and Yu, Chun and Yao, Wentao and Yao, Jiachen and Liang, Chen and Weng, Yueting and Yan, Yukang and Shi, Yuanchun},
title = {Selecting Real-World Objects via User-Perspective Phone Occlusion},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580696},
doi = {10.1145/3544548.3580696},
abstract = {Perceiving the region of interest (ROI) and target object by smartphones from the user’s first-person perspective can enable diverse spatial interactions. In this paper, we propose a novel ROI input method and a target selecting method for smartphones by utilizing the user-perspective phone occlusion. This concept of turning the phone into real-world physical cursor benefits from the proprioception, gets rid of the constraint of camera preview, and allows users to rapidly and accurately select the target object. Meanwhile, our method can provide a resizable and rotatable rectangular ROI to disambiguate dense targets. We implemented the prototype system by positioning the user’s iris with the front camera and estimating the rectangular area blocked by the phone with the rear camera simultaneously, followed by a target prediction algorithm with the distance-weighted Jaccard index. We analyzed the behavioral models of using our method and evaluated our prototype system’s pointing accuracy and usability. Results showed that our method is well-accepted by the users for its convenience, accuracy, and efficiency.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {531},
numpages = {13},
keywords = {smartphone interaction, object selection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581419,
author = {Yi, Xin and Zhang, Shuning and Pan, Ziqi and Shi, Louisa and Han, Fengyan and Kong, Yan and Li, Hewu and Shi, Yuanchun},
title = {Squeez’In: Private Authentication on Smartphones Based on Squeezing Gestures},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581419},
doi = {10.1145/3544548.3581419},
abstract = {In this paper, we proposed Squeez’In, a technique on smartphones that enabled private authentication by holding and squeezing the phone with a unique pattern. We first explored the design space of practical squeezing gestures for authentication by analyzing the participants’ self-designed gestures and squeezing behavior. Results showed that varying-length gestures with two levels of touch pressure and duration were the most natural and unambiguous. We then implemented Squeez’In on an off-the-shelf capacitive sensing smartphone, and employed an SVM-GBDT model for recognizing gestures and user-specific behavioral patterns, achieving 99.3% accuracy and 0.93 F1-score when tested on 21 users. A following 14-day study validated the memorability and long-term stability of Squeez’In. During usability evaluation, compared with gesture and pin code, Squeez’In achieved significantly faster authentication speed and higher user preference in terms of privacy and security.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {532},
numpages = {15},
keywords = {capacitive sensing, motion-based authentication, touch pressure},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581545,
author = {Mencarini, Eleonora and Zambon, Tommaso},
title = {Becoming a Speleologist: Design Implications for Coordination in Wild Outdoor Environments},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581545},
doi = {10.1145/3544548.3581545},
abstract = {Learning outdoor sports entails acquiring physical skills, managing gear, and coordinating with others. We investigated how speleologists are trained to explore underground caves. We interviewed 15 instructors and 10 trainees to understand the main problems that may occur during training cave trips. Our findings show that stressful situations are linked to beginners’ difficulties applying new gestures and procedures - on which their progression and safety depend - and coordinating with others when they are out of sight. It emerged that group awareness and communication are pivotal for their tranquility. Yet, the underground environment makes communicating very hard. This study led to the elaboration of design implications for technology supporting awareness, communication, and coordination in speleology training, which draw from and enrich previous literature on coordination in the wild, as it may happen while performing outdoor sports or during search-and-rescue operations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {533},
numpages = {12},
keywords = {Outdoor sports, Speleology, Awareness, Team communication, Wilderness, Group coordination, Caving},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581166,
author = {Kleinberger, Rebecca and Cunha, Jennifer and Vemuri, Megha M and Hirskyj-Douglas, Ilyena},
title = {Birds of a Feather Video-Flock Together: Design and Evaluation of an Agency-Based Parrot-to-Parrot Video-Calling System for Interspecies Ethical Enrichment.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581166},
doi = {10.1145/3544548.3581166},
abstract = {Over 20 million parrots are kept as pets in the US, often lacking appropriate stimuli to meet their high social, cognitive, and emotional needs. After reviewing bird perception and agency literature, we developed an approach to allow parrots to engage in video-calling other parrots. Following a pilot experiment and expert survey, we ran a three-month study with 18 pet birds to evaluate the potential value and usability of a parrot-parrot video-calling system. We assessed the system in terms of perception, agency, engagement, and overall perceived benefits. With 147 bird-triggered calls, our results show that 1) every bird used the system, 2) most birds exhibited high motivation and intentionality, and 3) all caretakers reported perceived benefits, some arguably life-transformative, such as learning to forage or even to fly by watching others. We report on individual insights and propose considerations regarding ethics and the potential of parrot video-calling for enrichment.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {534},
numpages = {16},
keywords = {Parrots, Animal Internet, Animal Enrichment, Animal-Computer Interactions, Avian, Video Call, Interspecies Interaction, Enrichment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580886,
author = {Crosby, Alison and Orenstein, Eric Coughlin and Poulton, Susan E and Bell, Katherine L.C. and Woodward, Benjamin and Ruhl, Henry and Katija, Kakani and Forbes, Angus G.},
title = {Designing Ocean Vision AI: An Investigation of Community Needs for Imaging-Based Ocean Conservation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580886},
doi = {10.1145/3544548.3580886},
abstract = {Ocean scientists studying diverse organisms and phenomena increasingly rely on imaging devices for their research. These scientists have many tools to collect their data, but few resources for automated analysis. In this paper, we report on discussions with diverse stakeholders to identify community needs and develop a set of functional requirements for the ongoing development of ocean science-specific analysis tools. We conducted 36 in-depth interviews with individuals working in the Blue Economy space, revealing four central issues inhibiting the development of effective imaging analysis monitoring tools for marine science. We also identified twelve user archetypes that will engage with these services. Additionally, we held a workshop with 246 participants from 35 countries centered around FathomNet, a web-based open-source annotated image database for marine research. Findings from these discussions are being used to define the feature set and interface design of Ocean Vision AI, a suite of tools and services to advance observational capabilities of life in the ocean.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {535},
numpages = {16},
keywords = {machine learning-enabled interfaces, citizen science, sustainability, human-centered design, ocean science, data portals},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581245,
author = {Jain, Eakta and Gardner-McCune, Christina},
title = {Horse as Teacher: How Human-Horse Interaction Informs Human-Robot Interaction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581245},
doi = {10.1145/3544548.3581245},
abstract = {Robots are entering our lives and workplaces as companions and teammates. Though much research has been done on how to interact with robots, teach robots and improve task performance, an open frontier for HCI/HRI research is how to establish a working relationship with a robot in the first place. Studies that explore the early stages of human-robot interaction are an emerging area of research. Simultaneously, there is resurging interest in how human-animal interaction could inform human-robot interaction. We present a first examination of early stage human-horse interaction through the lens of human-robot interaction, thus connecting these two areas. Following Strauss’ approach, we conduct a thematic analysis of data from three sources gathered over a year of field work: observations, interviews and journal entries. We contribute design guidelines based on our analyses and findings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {536},
numpages = {13},
keywords = {Qualitative Methods, Human Robot Interaction, Human Animal Interaction, Design Guidelines},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581104,
author = {Vella, Kellie},
title = {Pick Me Up Before You Go-Go: Sociotechnical Strategies for Waste in Music Festival Campsites},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581104},
doi = {10.1145/3544548.3581104},
abstract = {Multi-day music festivals have a waste problem with much of it centred around patron campgrounds. Interviews and co-design workshops were conducted with festival patrons (N = 19) and professionals (N = 9). The interviews indicated the factors impacting festival campground waste including the proliferation of cheap items, the continuity of management decisions, highly social camping practices, the land, and interactions between these. Co-design workshops explored these to produce sociotechnical strategies using the festival timeline as a frame, with one of these, a patron planning tool chosen for further development. This paper contributes new insights on how information and communication technologies might enhance sustainable practices by facilitating relational change through better organisation, evaluation, and feedback. It concludes with examination of the challenges and opportunities for Sustainable HCI, including how to carve out a design response to a wicked problem by situating relations, meaning making, telling invisible stories, and finding leverage points.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {537},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580663,
author = {Rigby, Jacob M and Preist, Chris},
title = {Towards User-Centred Climate Services: The Role of Human-Computer Interaction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580663},
doi = {10.1145/3544548.3580663},
abstract = {Climate services are systems that provide climate and climate-related information to inform decision making around the world. Despite these systems featuring diverse interactions between technologies and a variety of user groups, and frequent calls in the literature for more a more user-centred focus, HCI researchers do not appear to have engaged much with this active research area. In this paper, we demonstrate this lack of interaction via a systematic literature search and offer possible explanations for this. We also map out opportunities for how HCI researchers can use their highly relevant skillsets to contribute to this research and aid climate change adaptation, notably around the user-facing elements of climate services. Finally, we offer some reasons why HCI researchers might want to engage, such as furthering existing HCI research avenues, and creating new ones through collaborations with researchers in disciplines such as climate science, development, and policy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {538},
numpages = {14},
keywords = {climate adaptation, Climate change, decision making, development.},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581389,
author = {Nagassa, Ruth G and Butler, Matthew and Holloway, Leona and Goncu, Cagatay and Marriott, Kim},
title = {3D Building Plans: Supporting Navigation by People Who Are Blind or Have Low Vision in Multi-Storey Buildings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581389},
doi = {10.1145/3544548.3581389},
abstract = {Independent travel and navigation in new environments, in particular multi-storey buildings, is a major challenge for people who are blind or have low vision (BLV). Using tactile maps as part of orientation and mobility (O&amp;M) training, BLV people can build a cognitive map of an environment before visiting. Tactile maps of multi-level environments, however, have received little attention. We investigated the usefulness of 3D printed models of buildings, through a user study with nine BLV adults. Three designs were evaluated: flat, overlapped-sliding and overlapped-rotating. All three designs were reported to be useful, usable, engaging and allowed participants to build a cognitive map of the building. There was a strong user preference for the overlapped presentations, which were reported to be more effective in supporting cross-floor spatial knowledge. This exploration of the design space of 3D building plans demonstrates their value and we hope will encourage their provision in O&amp;M training.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {539},
numpages = {19},
keywords = {3D printed maps, indoor accessibility, multi-level representation, spatial cognition},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581304,
author = {Sargsyan, Elen and Oriola, Bernard and Mac\'{e}, Marc J-M and Serrano, Marcos and Jouffrais, Christophe},
title = {3D Printed Interactive Multi-Storey Model for People with Visual Impairments},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581304},
doi = {10.1145/3544548.3581304},
abstract = {The understanding of multi-level spatial topologies is a difficult and frequent challenge in people with visual impairments daily life, impacting their independent mobility. Using the tools of the “maker” movement, and following an iterative co-design process with Orientation and Mobility instructors, we created an innovative tool (3D printed interactive model of a train station) for teaching complex spatial knowledge. Then, we did a comparative study with end users between the 3D interactive model that we designed and two 2D interactive tactile maps representing the same location. Our results show that the 3D interactive model is useful and usable, provides better satisfaction and is preferred to 2D tactile maps. In addition, complex spatial notions are better understood with the 3D model. Altogether, these results suggest that the “maker movement” may empower special education teachers with adapted and innovative tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {540},
numpages = {15},
keywords = {Verticality, Visual Impairment, Interactive 3D Model., Spatial Knowledge},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581220,
author = {Kayukawa, Seita and Sato, Daisuke and Murata, Masayuki and Ishihara, Tatsuya and Takagi, Hironobu and Morishima, Shigeo and Asakawa, Chieko},
title = {Enhancing Blind Visitor’s Autonomy in a Science Museum Using an Autonomous Navigation Robot},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581220},
doi = {10.1145/3544548.3581220},
abstract = {Enabling blind visitors to explore museum floors while feeling the facility’s atmosphere and increasing their autonomy and enjoyment are imperative for giving them a high-quality museum experience. We designed a science museum exploration system for blind visitors using an autonomous navigation robot. Blind users can control the robot to navigate them toward desired exhibits while playing short audio descriptions along the route. They can also browse detailed explanations on their smartphones and call museum staff if interactive support is needed. Our real-world user study at a science museum during its opening hour revealed that blind participants could explore the museum safely and independently at their own pace. The study also showed that the sighted visitors who saw the participants walking with the robot accepted the assistive robot well. We finally conducted focus group sessions with the blind participants and discussed further requirements toward a more independent museum experience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {541},
numpages = {14},
keywords = {Visual impairment, autonomous navigation robot, blind navigation, museum},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580884,
author = {Zhang, Yan and Li, Ziang and Guo, Haole and Wang, Luyao and Chen, Qihe and Jiang, Wenjie and Fan, Mingming and Zhou, Guyue and Gong, Jiangtao},
title = {"I Am the Follower, Also the Boss": Exploring Different Levels of Autonomy and Machine Forms of Guiding Robots for the Visually Impaired},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580884},
doi = {10.1145/3544548.3580884},
abstract = {Guiding robots, in the form of canes or cars, have recently been explored to assist blind and low vision (BLV) people. Such robots can provide full or partial autonomy when guiding. However, the pros and cons of different forms and autonomy for guiding robots remain unknown. We sought to fill this gap. We designed autonomy-switchable guiding robotic cane and car. We conducted a controlled lab-study (N=12) and a field study (N=9) on BLV. Results showed that full autonomy received better walking performance and subjective ratings in the controlled study, whereas participants used more partial autonomy in the natural environment as demanding more control. Besides, the car robot has demonstrated abilities to provide a higher sense of safety and navigation efficiency compared with the cane robot. Our findings offered empirical evidence about how the BLV community perceived different machine forms and autonomy, which can inform the design of assistive robots.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {542},
numpages = {22},
keywords = {control, level of autonomy, safety, machine form, trust, navigation, visual impairment, guiding robot},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581359,
author = {Holloway, Leona and Butler, Matthew and Marriott, Kim},
title = {TactIcons: Designing 3D Printed Map Icons for People Who Are Blind or Have Low Vision},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581359},
doi = {10.1145/3544548.3581359},
abstract = {Visual icons provide immediate recognition of features on print maps but do not translate well for touch reading by people who are blind or have low vision due to the low fidelity of tactile perception. We explored 3D printed icons as an equivalent to visual icons for tactile maps addressing these problems. We designed over 200 tactile icons (TactIcons) for street and park maps. These were touch tested by blind and sighted people, resulting in a corpus of 33 icons that can be recognised instantly and a further 34 icons that are easily learned. Importantly, this work has informed the creation of detailed guidelines for the design of TactIcons and a practical methodology for touch testing new TactIcons. It is hoped that this work will contribute to the creation of more inclusive, user-friendly tactile maps for people who are blind or have low vision.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {543},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581415,
author = {Rahman, Adil and Azim, Md Aashikur Rahman and Heo, Seongkook},
title = {Take My Hand: Automated Hand-Based Spatial Guidance for the Visually Impaired},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581415},
doi = {10.1145/3544548.3581415},
abstract = {Tasks that involve locating objects and then moving hands to those specific locations, such as using touchscreens or grabbing objects on a desk, are challenging for the visually impaired. Over the years, audio guidance and haptic feedback have been a staple in hand navigation based assistive technologies. However, these methods require the user to interpret the generated directional cues and then manually perform the hand motions. In this paper, we present automated hand-based spatial guidance to bridge the gap between guidance and execution, allowing visually impaired users to move their hands between two points automatically, without any manual effort. We implement this concept through FingerRover, an on-finger miniature robot that carries the user’s finger to target points. We demonstrate the potential applications that can benefit from automated hand-based spatial guidance. Our user study shows the potential of our technique in improving the interaction capabilities of people with visual impairments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {544},
numpages = {16},
keywords = {visual impairment, automated guidance, accessibility, spatial guidance, miniature guiding robot},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580846,
author = {Juneja, Prerna and Bhuiyan, Md Momen and Mitra, Tanushree},
title = {Assessing Enactment of Content Regulation Policies: A Post Hoc Crowd-Sourced Audit of Election Misinformation on YouTube},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580846},
doi = {10.1145/3544548.3580846},
abstract = {With the 2022 US midterm elections approaching, conspiratorial claims about the 2020 presidential elections continue to threaten users’ trust in the electoral process. To regulate election misinformation, YouTube introduced policies to remove such content from its searches and recommendations. In this paper, we conduct a 9-day crowd-sourced audit on YouTube to assess the extent of enactment of such policies. We recruited 99 users who installed a browser extension that enabled us to collect up-next recommendation trails and search results for 45 videos and 88 search queries about the 2020 elections. We find that YouTube’s search results, irrespective of search query bias, contain more videos that oppose rather than support election misinformation. However, watching misinformative election videos still lead users to a small number of misinformative videos in the up-next trails. Our results imply that while YouTube largely seems successful in regulating election misinformation, there is still room for improvement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {545},
numpages = {22},
keywords = {misinformation, algorithm audit, fairness, voter fraud, recommendations, elections},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580758,
author = {Choe, Youjin and Tomko, Martin and Kalantari, Mohsen},
title = {Assessing Mapper Conflict in OpenStreetMap Using the Delphi Survey Method},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580758},
doi = {10.1145/3544548.3580758},
abstract = {Studies of mapper conflict in OpenStreetMap (OSM) have focused exclusively on cartographic vandalism and its effect on data quality. This paper takes a broader view on mapper conflict in OSM. Using a Delphi survey method, we collect qualitative data on perceived conflict from long-time OSM mappers. We ask mappers about four aspects of conflict in OSM: (1) topic of conflict, (2) factors leading to conflict, (3) effects of conflict, and (4) potential conflict management methods. Our results show that conflict in OSM can be explained by clashing values and opinions within and across different mapper subgroups and can be exacerbated by negative mapper behaviors. The boundaries of these subgroups, while implicit, are often defined by gender, mappers’ geographic location, level of expertise, and mappers’ professional affiliation. Based on these results, we discuss design options for OSM’s existing public communication channels that often become foci of mapper conflict management.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {546},
numpages = {17},
keywords = {OpenStreetMap, Mapper conflict, Delphi survey},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581078,
author = {Turk, Kieron Ivy and Hutchings, Alice},
title = {Click Here to Exit: An Evaluation of Quick Exit Buttons},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581078},
doi = {10.1145/3544548.3581078},
abstract = {Accessing online support services can be dangerous for some users, such as domestic abuse survivors. Many support service websites contain “quick exit” buttons that provide an easy way for users to escape the site. We investigate where exit buttons and other escape mechanisms are currently in use (country and type of site) and how they are implemented. We analyse both the security and usability of exit mechanisms on 323 mobile and 404 desktop sites. We find exit buttons typically replace the current page with another site, occasionally opening additional tabs. Some exit buttons also remove the page from the browser history. When analysing the design choices and shortcomings of exit button implementations, common problems include cookie notices covering the buttons, and buttons not remaining on the screen when scrolling. We provide recommendations for designers of support websites who want to add or improve this feature on their website.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {547},
numpages = {15},
keywords = {Security, Privacy, Usability Study, HCI for Development},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581244,
author = {Bhuiyan, Md Momen and Lee, Sang Won and Goyal, Nitesh and Mitra, Tanushree},
title = {NewsComp: Facilitating Diverse News Reading through Comparative Annotation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581244},
doi = {10.1145/3544548.3581244},
abstract = {To support efficient, balanced news consumption, merging articles from diverse sources into one, potentially through crowdsourcing, could alleviate some hurdles. However, the merging process could also impact annotators’ attitudes towards the content. To test this theory, we propose comparative news annotation; that is, annotating similarities and differences between a pair of articles. By developing and deploying NewsComp—a prototype system—we conducted a between-subjects experiment (N&nbsp;=&nbsp;109) to examine how users’ annotations compare to experts’, and how comparative annotation affects users’ perceptions of article credibility and quality. We found that comparative annotation can marginally impact users’ credibility perceptions in certain cases; it did not impact perceptions of quality. While users’ annotations were not on par with experts’, they showed greater precision in finding similarities than in identifying disparate important statements. The comparison process also led users to notice differences in information placement and depth, degree of factuality/opinion, and empathetic/inflammatory language use. We discuss implications for the design of future comparative annotation tasks.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {548},
numpages = {17},
keywords = {Comparison, Design, News Reading, Annotation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580644,
author = {Papakyriakopoulos, Orestis and Engelmann, Severin and Winecoff, Amy},
title = {Upvotes? Downvotes? No Votes? Understanding the Relationship between Reaction Mechanisms and Political Discourse on Reddit},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580644},
doi = {10.1145/3544548.3580644},
abstract = {A significant share of political discourse occurs online on social media platforms. Policymakers and researchers try to understand the role of social media design in shaping the quality of political discourse around the globe. In the past decades, scholarship on political discourse theory has produced distinct characteristics of different types of prominent political rhetoric such as deliberative, civic, or demagogic discourse. This study investigates the relationship between social media reaction mechanisms (i.e., upvotes, downvotes) and political rhetoric in user discussions by engaging in an in-depth conceptual analysis of political discourse theory. First, we analyze 155 million user comments in 55 political subforums on Reddit between 2010 and 2018 to explore whether users’ style of political discussion aligns with the essential components of deliberative, civic, and demagogic discourse. Second, we perform a quantitative study that combines confirmatory factor analysis with difference in differences models to explore whether different reaction mechanism schemes (e.g., upvotes only, upvotes and downvotes, no reaction mechanisms) correspond with political user discussion that is more or less characteristic of deliberative, civic, or demagogic discourse. We produce three main takeaways. First, despite being “ideal constructs of political rhetoric,” we find that political discourse theories describe political discussions on Reddit to a large extent. Second, we find that discussions in subforums with only upvotes, or both up- and downvotes are associated with user discourse that is more deliberate and civic. Third, and perhaps most strikingly, social media discussions are most demagogic in subreddits with no reaction mechanisms at all. These findings offer valuable contributions for ongoing policy discussions on the relationship between social media interface design and respectful political discussion among users.1},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {549},
numpages = {28},
keywords = {reaction mechanisms, political discourse, voting, political communication, platform design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580946,
author = {Aghajari, Zhila and Baumer, Eric P. S. and DiFranzo, Dominic},
title = {What’s the Norm Around Here? Individuals’ Responses Can Mitigate the Effects of Misinformation Prevalence in Shaping Perceptions of a Community},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580946},
doi = {10.1145/3544548.3580946},
abstract = {Social norms play a significant role in how conspiratorial content and related misinformation impact online communities. However, less is understood about the mechanisms by which particular aspects of a community may drive perceptions of social norms in the community. Using anti-vaccine conspiracies as a testbed, this paper experimentally examines three such features and their relationships : prevalence of conspiratorial content, community response, and explicit community rules. Results show that prevalence of content has a significant effect on norm perceptions, while the results did not support the effects of explicit rule on norm perceptions. However, these effects can be mitigated by the way a community responds to such content. Furthermore, perceived norms also influence other expectations about the community, from escalated behaviors to belief in other conspiracy theories. The paper concludes by highlighting the implications of these findings for online platform design, for community governance, and for future research about the relationships among conspiratorial content and norm perceptions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {550},
numpages = {27},
keywords = {Misleading Content, Conspiracy Theories, Online Communities, Perceived Norms, Misinformation, Anti-vaccine, Social Norms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581173,
author = {Fan, Sizheng and Min, Tian and Wu, Xiao and Cai, Wei},
title = {Altruistic and Profit-Oriented: Making Sense of Roles in Web3 Community from Airdrop Perspective},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581173},
doi = {10.1145/3544548.3581173},
abstract = {Regardless of which community, incentivizing users is a necessity for well-sustainable operations. In the blockchain-backed Web3 communities, known for their transparency and security, airdrop serves as a widespread incentive mechanism for allocating capital and power. However, it remains a controversy on how to justify airdrop to incentive and empower the decentralized governance. In this paper, we use ParaSwap as an example to propose a role taxonomy methodology through a data-driven study to understand the characteristic of community members and the effectiveness of airdrop. We find that users receive more rewards tend to take positive actions towards the community. We summarize several arbitrage patterns and confirm the current detection is not sufficient in screening out airdrop hunters. In conjunction with the results, we discuss from the aspects of interaction, financialization, and system design to conclude the challenges and possible research directions for decentralized communities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {551},
numpages = {16},
keywords = {Unsupervised learning, Decentralized community, Network analysis, Airdrop},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581317,
author = {Qiu, Huilian Sophie and Lieb, Anna and Chou, Jennifer and Carneal, Megan and Mok, Jasmine and Amspoker, Emily and Vasilescu, Bogdan and Dabbish, Laura},
title = {Climate Coach: A Dashboard for Open-Source Maintainers to Overview Community Dynamics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581317},
doi = {10.1145/3544548.3581317},
abstract = {Open-source software projects have become an integral part of our daily life, supporting virtually every software we use today. Since open-source software forms the digital infrastructure, maintaining them is of utmost importance. We present Climate Coach, a dashboard that helps open-source project maintainers monitor the health of their community in terms of team climate and inclusion. Through a literature review and an exploratory survey (N=18), we identified important signals that can reflect a project’s health, and display them on a dashboard. We evaluated and refined our dashboard through two rounds of think-aloud studies (N=19). We then conducted a two-week longitudinal diary study (N=10) to test the usefulness of our dashboard. We found that displaying signals that are related to a project’s inclusion help improve maintainers’ management strategies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {552},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580994,
author = {Haug, Saskia and Benke, Ivo and Fischer, Daniel and Maedche, Alexander},
title = {CrowdSurfer: Seamlessly Integrating Crowd-Feedback Tasks into Everyday Internet Surfing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580994},
doi = {10.1145/3544548.3580994},
abstract = {Crowd feedback overcomes scalability issues of feedback collection on interactive website designs. However, collecting feedback on crowdsourcing platforms decouples the feedback provider from the context of use. This creates more effort for crowdworkers to immerse into such context in crowdsourcing tasks. In this paper, we present CrowdSurfer, a browser extension that seamlessly integrates design feedback collection in crowdworkers’ everyday internet surfing. This enables the scalable collection of in situ feedback and, in parallel, allows crowdworkers to flexibly integrate their work into their daily activities. In a field study, we compare the CrowdSurfer against traditional feedback collection. Our qualitative and quantitative results reveal that, while in situ feedback with the CrowdSurfer is not necessarily better, crowdworkers appreciate the effortless, enjoyable, and innovative method to conduct feedback tasks. We contribute with our findings on in situ feedback collection and provide recommendations for the integration of crowdworking tasks in everyday internet surfing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {553},
numpages = {16},
keywords = {design feedback, Crowd-feedback system, browser extension, crowdsourcing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581177,
author = {Claisse, Caroline and Durrant, Abigail C},
title = {‘Keeping Our Faith Alive’: Investigating Buddhism Practice during COVID-19 to Inform Design for the Online Community Practice of Faith},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581177},
doi = {10.1145/3544548.3581177},
abstract = {Supportive digital technologies for the community practice of Faith remain relatively under-explored in Human Computer Interaction (HCI). We report on interviews with 12 members of a Buddhist community in the UK who self-organized and used video-conferencing tools to remain connected to their faith&nbsp;community&nbsp;during the COVID-19 pandemic, aiming to understand how they adopted online tools for their practice while shaping new collective experiences. Findings from Reflexive Thematic Analysis were combined with autoethnographic insights from the first author, also a community member. We evidence qualities of the practice that were valued by participants&nbsp;before and during the pandemic, and the limitations of existing tools and screen-based interactions. We contribute empirical insights on mediated religious and spiritual practice, advancing HCI discourses on Techno-Spirituality, Tangible Embodied Interaction, Soma Design and More-than-Human Worlds. We further develop design considerations for enriching spiritual experiences that are meaningful to practitioners in communities of faith.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {554},
numpages = {19},
keywords = {Buddhism, Spirituality, Video-mediated communication, Community practice of Faith},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581310,
author = {Wang, Yucheng and Lu, Zhicong},
title = {Making Sense of Post-Match Fan Behaviors in the Online Football Communities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581310},
doi = {10.1145/3544548.3581310},
abstract = {Professional sports have large fan bases that congregate in online sports fan communities. The sports community is suitable to be a sandbox for studying offline context’s effects on online community behavior. By now, prior works did not present a detailed study on the offline-online connection by examining detailed community discussion content. To fill this gap, this work presents a comprehensive study of online communities’ comments about football (soccer) matches, grounded in the data from Premier League teams’ Reddit online communities during the 2020-2021 season. We propose a metric “gap score” to quantify offline events’ effects by measuring the gap between fans’ prematch expectations and actual match results. Using this metric, we investigated how team performance impacted comments’ sentiment, discussion topics, and the pattern of comments’ votes. The findings highlight the close connection that exists between offline events and online discussions and reveals both theoretical and practical implications for online communities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {555},
numpages = {17},
keywords = {England Premier League, Fan Behaviors, Soccer, Professional Sports, Topic Modeling, Football, Online Communities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581054,
author = {Guo, Qingyu and Zhang, Chao and Lyu, Hanfang and Peng, Zhenhui and Ma, Xiaojuan},
title = {What Makes Creators Engage with Online Critiques? Understanding the Role of Artifacts’ Creation Stage, Characteristics of Community Comments, and Their Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581054},
doi = {10.1145/3544548.3581054},
abstract = {Online critique communities (OCCs) provide a convenient space for creators to solicit feedback on their artifacts and improve skills. Creators’ behavioral, emotional, and cognitive engagement with comments on their works contribute to their skill development. However, what kinds of critique creators feel engaging may change with the creation stage of their shared artifacts. In this paper, we first model three dimensions of engagement expressed in creators’ replies to peer comments. Then we quantitatively examine how their engagement is affected by artifacts’ stage and feedback characteristics via regression analysis. Results show that creators sharing works-in-progress tend to exhibit lower behavioral and emotional engagement, but higher cognitive engagement than those sharing complete works. The increase in the valence of the feedback is associated with a stronger increase in behavior engagement for seekers sharing complete works than works-in-progress. Finally, we discuss how our insights could benefit OCCs and other online help-seeking platforms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {556},
numpages = {17},
keywords = {online community, emotional engagement, Critique, cognitive engagement, behavioral engagement},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580756,
author = {Bezabih, Alemitu and Gerling, Kathrin and Abebe, Workeabeba and Vanden Abeele, Vero},
title = {Challenges and Opportunities for Interactive Technology to Support Parents of HIV-Positive Children in Ethiopia in the Disclosure Process},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580756},
doi = {10.1145/3544548.3580756},
abstract = {Fearing stigma, parents often hide their children's HIV diagnosis from them, and postpone disclosure, in turn negatively impacting children's well-being. Our work explores whether interactive technology can support disclosure. In the first study, we examine disclosure experiences and the role of interactive technology from the perspective of HIV-positive children and parents. Through Thematic Analysis, we highlight how disclosure is linked with parents’ own experience of HIV, and that disclosure needs to be viewed as a process. On this basis, we contribute an experience prototype that guides parents through an incremental disclosure process using interactive storytelling. In a second study, we evaluate the prototype through interviews with six parents. Leveraging Interpretative Phenomenological Analysis, we show that the prototype has potential to transform how parents understand and approach disclosure. Based on our results, we present further design directions, and discuss the (limitations of the) role that technology can play in this context.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {17},
keywords = {interactive technology, children, parents, storytelling, ongoing disclosure, HIV, Ethiopia},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581216,
author = {Stefanidi, Evropi and Sch\"{o}ning, Johannes and Rogers, Yvonne and Niess, Jasmin},
title = {Children with ADHD and Their Care Ecosystem: Designing Beyond Symptoms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581216},
doi = {10.1145/3544548.3581216},
abstract = {Designing for children with ADHD has been of increasing interest to the HCI community. However, current approaches do not adequately involve all relevant stakeholders, and primarily focus on addressing symptoms, following a medical model of disability that is extrinsic to neurodivergent interests. To address this, we employed a multi-step, multi-stakeholder approach (N=31). First, we conducted 1) interviews with children with ADHD and their care ecosystem followed by 2) a co-design pilot with one child with ADHD and his therapists and an interview with a UX designer and an occupational therapist. We then employed 3) co-design sessions with neurotypical children and children with ADHD, and 4) a focus group with their therapists. We identified communication and reflection as key concepts for empowering and promoting the well-being of children with ADHD and their care ecosystem. We contribute design implications for future systems aiming to promote the overall well-being of this population.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {558},
numpages = {17},
keywords = {neurodivergent, co-design, interviews, ADHD, neurodiversity, children, well-being, participatory design, reflection, empowerment, assistive technologies},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580901,
author = {James, Sam and Armstrong, Miranda and Abdallah, Zahraa and O'Kane, Aisling Ann},
title = {Chronic Care in a Life Transition: Challenges and Opportunities for Artificial Intelligence to Support Young Adults With Type 1 Diabetes Moving to University},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580901},
doi = {10.1145/3544548.3580901},
abstract = {Self-managing a chronic condition involves adapting management strategies to life’s continual change. Among these changes, moments of significant life transition can render routine self-management practices obsolete without significant modification to the new context. In this study, we examine one significant life transition for young adults living with Type 1 Diabetes, the move from home to university, to understand how near future AI-enhanced technologies might provide opportunities and challenges for supporting care. From interviews with 24 students in the UK who had moved away from their childhood homes, we used sensemaking literature to frame the process of initial disruption to the rebuilding of self-care practices around a new lifestyle and support networks. By studying a significant life transition, we uncover implications for the design of T1D technology, particularly closed-loop systems, through AI enhancements and human-centred design approaches, then extrapolate for other significant life transitions and chronic conditions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {559},
numpages = {16},
keywords = {Qualitative Study, Type 1 Diabetes, Life Transitions, Health, Artificial Intelligence, University},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580674,
author = {Siddiqui, Farheen and Varghese, Delvin and Singh, Pushpendra and Bayyavarapu, Sunita Bapuji and Lindsay, Stephen and Chandrasekara, Dharshani and Kulkarni, Pranav and Wu, Ling and Alshehri, Taghreed and Olivier, Patrick},
title = {Exploring the Digital Support Needs of Caregivers of People with Serious Mental Illness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580674},
doi = {10.1145/3544548.3580674},
abstract = {In low-and middle-income countries like India, people with severe mental illness (PSMI) rely on their families as a primary source of care, given the lack of support from healthcare systems. The demanding nature of caregiving places significant physical and mental demands on caregivers, who are the primary source of support to PSMI. We explore how caregivers in under-resourced settings can be better supported through everyday digital technologies. We conducted interviews with caregivers (from urban and rural India), as well as workshops with professionals from Indian NGOs that work directly with PSMIs. We found that technology has the potential to (1) provide carer-centred support that empowers carers who experience stigma and issues with existing support networks; (2) provide support for carers to overcome barriers and progress in the recovery of the PSMI. We conclude with design considerations, proposing how an online peer community can leverage carers’ expertise to actualise support provision.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {560},
numpages = {16},
keywords = {peer support, caregivers, India, mhealth, HCI4D, online communities, empowerment, mental health},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580657,
author = {Ding, Xianghua(Sharon) and Tran, Linda and Liu, Yanling and O'Neill, Conor and Lindsay, Stephen},
title = {Infrastructural Work Behind The Scene: A Study of Formalized Peer-Support Practices for Mental Health},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580657},
doi = {10.1145/3544548.3580657},
abstract = {Peer-support has long been recognized as valuable for mental health, and has been commonly practiced online over the Internet. However, it is often reported that peer exchange online can have harmful effects, and there has been limited research on how to ensure its effectiveness and safety. Our ethnographic study of formalized mental health peer-support practices in Scotland uncovers the infrastructural work involved when setting up and managing conditions upon which peer-support can take place in an effective and safe way. We illustrate that peer-support for mental health is not only about bringing peers together to interact with each other, but also about ensuring availability, timeliness, proactive care, positivity and safety of peer-support as a service, by weaving various social, spatial and technical elements together and managing groups and their boundaries. Our findings illuminate the work behind these peer-support practices, and suggest design implications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {561},
numpages = {14},
keywords = {infrastructural work, mental health, Peer-support},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581311,
author = {Progga, Farhat Tasnim and Senthil Kumar, Avanthika and Rubya, Sabirat},
title = {Understanding the Online Social Support Dynamics for Postpartum Depression},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581311},
doi = {10.1145/3544548.3581311},
abstract = {Postpartum depression (PPD) is one of the most prevalent mental health disorder following childbirth. Mothers utilize social media and online forums throughout postpartum to seek mental health support. In this paper, we aim to gain a comprehensive understanding of the topics of naturally occurring online discussions and the online social support dynamics associated with PPD. We qualitatively analyze posts and comments from three postpartum depression support communities corresponding to well-known online social platforms (Reddit, What to expect, and Babycenter). We discovered that the three communities share common themes of discussion that include the causes, stressors, symptoms, and coping mechanisms for PPD. Seeking both informational and emotional support through venting and storytelling was prevalent, and emotional support seeking was more common in Reddit than the other two communities. We provide recommendations for future postpartum depression research and design considerations based on pervasive help-seeking approaches.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {562},
numpages = {17},
keywords = {social support, postpartum depression, online health communities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581257,
author = {Register, Yim and Qin, Lucy and Baughan, Amanda and Spiro, Emma S.},
title = {Attached to “The Algorithm”: Making Sense of Algorithmic Precarity on Instagram},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581257},
doi = {10.1145/3544548.3581257},
abstract = {This work explores how users navigate the opaque and ever-changing algorithmic processes that dictate visibility on Instagram through the lens of Attachment Theory. We conducted thematic analysis on 1,100 posts and comments on r/Instagram to understand how users engage in collective sensemaking with regards to Instagram’s algorithms, user-perceived punishments, and strategies to counteract algorithmic precarity. We found that the unpredictability in how Instagram rewards or punishes a user can lead to distress, hypervigilance, and a need to appease “the algorithm’’. We therefore frame these findings through Attachment Theory, drawing upon the metaphor of Instagram as an unreliable paternalistic figure that inconsistently rewards users [74]. User experiences are then contextualized through the lens of anxious, avoidant, disorganized, and secure attachment. We conclude by making suggestions for fostering secure attachment towards the Instagram algorithm, by suggesting potential strategies to help users successfully cope with uncertainty.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {563},
numpages = {15},
keywords = {content moderation, algorithmic transparency, thematic analysis, folk theorization, social media algorithms, Attachment Theory, Instagram, algorithmic precarity, social media and mental health},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581386,
author = {Choi, Yoonseo and Kang, Eun Jeong and Lee, Min Kyung and Kim, Juho},
title = {Creator-Friendly Algorithms: Behaviors, Challenges, and Design Opportunities in Algorithmic Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581386},
doi = {10.1145/3544548.3581386},
abstract = {In many creator economy platforms, algorithms significantly impact creators’ practices and decisions about their creative expression and monetization. Emerging research suggests that the opacity of the algorithm and platform policies often distract creators from their creative endeavors. To study how algorithmic platforms can be more ‘creator-friendly,’ we conducted a mixed-methods study: interviews (N=14) and a participatory design workshop (N=12) with YouTube creators. Through the interviews, we found how creators’ folk theories of the curation algorithm impact their work strategies — whether they choose to work with or against the algorithm — and the associated challenges in the process. In the workshop, creators explored solution ideas to overcome the aforementioned challenges, such as fostering diverse and creative expressions, achieving success as a creator, and motivating creators to continue their job. Based on these findings, we discuss design opportunities for how algorithmic platforms can support and motivate creators to sustain their creative work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {564},
numpages = {22},
keywords = {Folk theories, Gig economy, Creator economy, Creative labor, Algorithmic experience, Algorithmic platform, Participatory design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581227,
author = {Ashktorab, Zahra and Hoover, Benjamin and Agarwal, Mayank and Dugan, Casey and Geyer, Werner and Yang, Hao Bang and Yurochkin, Mikhail},
title = {Fairness Evaluation in Text Classification: Machine Learning Practitioner Perspectives of Individual and Group Fairness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581227},
doi = {10.1145/3544548.3581227},
abstract = {Mitigating algorithmic bias is a critical task in the development and deployment of machine learning models. While several toolkits exist to aid machine learning practitioners in addressing fairness issues, little is known about the strategies practitioners employ to evaluate model fairness and what factors influence their assessment, particularly in the context of text classification. Two common approaches of evaluating the fairness of a model are group fairness and individual fairness. We run a study with Machine Learning practitioners (n=24) to understand the strategies used to evaluate models. Metrics presented to practitioners (group vs. individual fairness) impact which models they consider fair. Participants focused on risks associated with underpredicting / overpredicting and model sensitivity relative to identity token manipulations. We discover fairness assessment strategies involving personal experiences or how users form groups of identity tokens to test model fairness. We provide recommendations for interactive tools for evaluating fairness in text classification.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {565},
numpages = {20},
keywords = {human-AI interaction, AI fairness, individual fairness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580709,
author = {Sharma, Vishal and Bray, Kirsten and Kumar, Neha and Grinter, Rebecca E.},
title = {It Takes (at Least) Two: The Work to Make Romance Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580709},
doi = {10.1145/3544548.3580709},
abstract = {Digitalization has motivated romance novelists to move from traditional to self-publishing online. However, engagement with flexible and responsive, yet precarious and biased algorithmic systems online pose challenges for novelists. Through surveying and interviewing the novelists, and using the lens of feminist political economy, we investigate how digitalization has impacted the novelists’ work practices. Our findings detail the increased agency afforded by self-publishing online, which comes at the expense of performing new forms of work individually, collectively, and with assistance, otherwise performed by publishing houses. We focus on the immaterial, invisible, and unpaid work that the novelists and the ecology of workers surrounding them conducted. We make recommendations for designing digital labor platforms that support the work practices of self-employed digital workers toward a more sustainable, collective, and inclusive future(s) of work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {566},
numpages = {17},
keywords = {Romance, Political Economy, Marginalization, Immaterial Labor, Publishing, HCI, Post-Capitalist, Labor, CSCW, Future of Work, Work, Feminist Theory, Intermediation, Algorithms, Unpaid Labor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3582074,
author = {Li, Rena and Kingsley, Sara and Fan, Chelsea and Sinha, Proteeti and Wai, Nora and Lee, Jaimie and Shen, Hong and Eslami, Motahhare and Hong, Jason},
title = {Participation and Division of Labor in User-Driven Algorithm Audits: How Do Everyday Users Work Together to Surface Algorithmic Harms?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3582074},
doi = {10.1145/3544548.3582074},
abstract = {Recent years have witnessed an interesting phenomenon in which users come together to interrogate potentially harmful algorithmic behaviors they encounter in their everyday lives. Researchers have started to develop theoretical and empirical understandings of these user-driven audits, with a hope to harness the power of users in detecting harmful machine behaviors. However, little is known about users’ participation and their division of labor in these audits, which are essential to support these collective efforts in the future. Through collecting and analyzing 17,984 tweets from four recent cases of user-driven audits, we shed light on patterns of users’ participation and engagement, especially with the top contributors in each case. We also identified the various roles users’ generated content played in these audits, including hypothesizing, data collection, amplification, contextualization, and escalation. We discuss implications for designing tools to support user-driven audits and users who labor to raise awareness of algorithm bias.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {19},
keywords = {Portrait AI, content labor, Twitter image cropping, user-generated content, racism, ImageNet Roulette, content creators, Twitter, bias, user-driven auditing, Apple Card, gender, algorithm auditing, user-driven audit},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581517,
author = {Dalal, Samantha and Chiem, Ngan and Karbassi, Nikoo and Liu, Yuhan and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Understanding Human Intervention in the Platform Economy: A Case Study of an Indie Food Delivery Service},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581517},
doi = {10.1145/3544548.3581517},
abstract = {This paper examines the sociotechnical infrastructure of an “indie” food delivery platform. The platform, Nosh, provides an alternative to mainstream services, such as Doordash and Uber Eats, in several communities in the Western United States. We interviewed 28 stakeholders including restauranteurs, couriers, consumers, and platform administrators. Drawing on infrastructure literature, we learned that the platform is a patchwork of disparate technical systems held together by human intervention. Participants join this platform because they receive greater agency, financial security, and local support. We identify human intervention’s key role in making food delivery platform users feel respected. This study provides insights into the affordances, limitations, and possibilities of food delivery platforms designed to prioritize local contexts over transnational scales.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {568},
numpages = {16},
keywords = {infrastructure, scalability, gig economy, food delivery},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581116,
author = {Cimolino, Gabriele and Chen, Renee (Xinyu) and Gutwin, Carl and Graham, T.C. Nicholas},
title = {Automation Confusion: A Grounded Theory of Non-Gamers’ Confusion in Partially Automated Action Games},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581116},
doi = {10.1145/3544548.3581116},
abstract = {Partial automation makes digital games simpler by performing game actions for players. It may simplify gameplay for non-gamers who have difficulty controlling and understanding games. However, the automation may make players confused about what they control and what the automation controls. To describe and explain non-gamers’ experiences of automation confusion, we analyzed gameplay, think-aloud, and interview data from ten non-gamer participants who played two partially automated games. Our results demonstrate how incorrect mental models, behaviours resulting from those models, and players’ attitudes towards the games led to different levels and types of confusion.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {569},
numpages = {19},
keywords = {one-switch, shared control, automation, digital games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580939,
author = {Dunham, John and Papangelis, Konstantinos and Boulanger, Cati and Lalone, Nicolas and Nika, Evangelia [Lina and Saker, Michael and Schwartz, David},
title = {Building Positively Affective Location-Based Advertising: A Study of Pok\'{e}mon GO Players},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580939},
doi = {10.1145/3544548.3580939},
abstract = {With the expanding popularity of Location-Based Games and the rise of advertising therein, there exists a need to comprehend the impact of Location-Based Game Advertising (LGA). This paper seeks to identify what makes positively affective LGA, leveraging Pok\'{e}mon GO as a probe. Researchers conducted twenty-seven (n=27) semi-structured interviews with Pok\'{e}mon GO players to reveal lived experiences regarding LGA. Our findings highlight the following direct implications for LGA: (1) LGA act as a digital billboard, conveying qualitative alongside locative information, and (2) well-received LGA enhances the player’s agency. We additionally identify findings that have auxiliary implications to LGA: (3) positive memorability occurs when points of interest match physical reality, and (4) ludic engagement is a mediating factor in the memorability of locations. This research demonstrates that LGA in Location-Based Games is surprisingly well-received. However, developers must provide extra consideration to the player’s agency for such techniques to be effective.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {570},
numpages = {19},
keywords = {Pok\'{e}mon GO, COVID-19, Advertising, Location-based Games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581409,
author = {Flint, Alex and Denisova, Alena and Bowman, Nick},
title = {Comparing Measures of Perceived Challenge and Demand in Video Games: Exploring the Conceptual Dimensions of CORGIS and VGDS},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581409},
doi = {10.1145/3544548.3581409},
abstract = {Measuring perceived challenge and demand in video games is crucial as these player experiences are essential to creating enjoyable games. Two recent measures that identified seemingly distinct structures of challenge (Challenge Originating from Recent Gameplay Interaction Scale (CORGIS) - cognitive, emotional, performative, decision-making) and demand (Video Game Demand Scale (VGDS) - cognitive, emotional, controller, exertional, social) have been theorised to overlap, reflecting the five-factor demand structure. To investigate the overlap between these two scales we compared a five (complete overlap) and nine-factor (no overlap) model by surveying 1,101 players asking them to recall their last gaming experience before completing CORGIS and VGDS. After failing to confirm both models, we conducted an exploratory factor analysis. Our findings reveal seven dimensions, where the five-factor VGDS model holds alongside two additional CORGIS dimensions of performative and decision-making, ultimately providing a more holistic understanding of the concepts whilst highlighting unique aspects of each approach.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {571},
numpages = {19},
keywords = {challenge, questionnaires, demand, player experience, Video games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581348,
author = {Milani, Stephanie and Juliani, Arthur and Momennejad, Ida and Georgescu, Raluca and Rzepecki, Jaroslaw and Shaw, Alison and Costello, Gavin and Fang, Fei and Devlin, Sam and Hofmann, Katja},
title = {Navigates Like Me: Understanding How People Evaluate Human-Like AI in Video Games},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581348},
doi = {10.1145/3544548.3581348},
abstract = {We aim to understand how people assess human likeness in navigation produced by people and artificially intelligent (AI) agents in a video game. To this end, we propose a novel AI agent with the goal of generating more human-like behavior. We collect hundreds of crowd-sourced assessments comparing the human-likeness of navigation behavior generated by our agent and baseline AI agents with human-generated behavior. Our proposed agent passes a Turing Test, while the baseline agents do not. By passing a Turing Test, we mean that human judges could not quantitatively distinguish between videos of a person and an AI agent navigating. To understand what people believe constitutes human-like navigation, we extensively analyze the justifications of these assessments. This work provides insights into the characteristics that people consider human-like in the context of goal-directed video game navigation, which is a key step for further improving human interactions with AI agents.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {572},
numpages = {18},
keywords = {navigation, human subject study, games, believable AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580665,
author = {Liu, Shengmei and Kuwahara, Atsuo and Scovell, James J and Claypool, Mark},
title = {The Effects of Frame Rate Variation on Game Player Quality of Experience},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580665},
doi = {10.1145/3544548.3580665},
abstract = {For gamers, high frame rates are important for a smooth visual display and good quality of experience (QoE). However, high frame rates alone are not enough as variations in the frame display times can degrade QoE even as the average frame rate remains high. While the impact of steady frame rates on player QoE is fairly well-studied, the effects of frame rate variation is not. This paper presents a 33-person user study that evaluates the impact of frame rate variation on users playing three different computer games. Analysis of the results shows average frame rate alone is a poor predictor of QoE, and frame rate variation has a significant impact on player QoE. While the standard deviation of frame times is promising as a general predictor for QoE, frame time standard deviation may not be accurate for all individual games. However, 95% frame rate floor -– the bottom 5% of frame rates the player experiences –- appears to be an effective predictor of both QoE overall and for the individual games tested.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {573},
numpages = {10},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581097,
author = {Ma, Renkai and Li, Yao and Kou, Yubo},
title = {Transparency, Fairness, and Coping: How Players Experience Moderation in Multiplayer Online Games},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581097},
doi = {10.1145/3544548.3581097},
abstract = {Multiplayer online games seek to address toxic behaviors such as trolling and griefing through behavior moderation, where penalties such as chat restriction or account suspension are issued against toxic players in the hope that punishments create a teachable moment for punished players to reflect and improve future behavior. While punishments impact player experience (PX) in profound ways, little is known regarding how players experience behavior moderation. In this study, we conducted a survey of 291 players to understand their experiences with punishments in online multiplayer games. Through several statistical analyses, we found that moderation explanation plays a critical role in improving players’ perceived transparency and fairness of moderation; and these perceptions significantly affect what players do after punishments. We discuss moderation experience as an important facet of PX, bridge the game and moderation literature, and provide design implications for behavior moderation in multiplayer online games.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {574},
numpages = {21},
keywords = {behavior moderation, toxicity, Multiplayer online games, moderation design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580891,
author = {Janaka, Nuwan Nanayakkarawasam Peru Kandage and Zhao, Shengdong and Sapkota, Shardul},
title = {Can Icons Outperform Text? Understanding the Role of Pictograms in OHMD Notifications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580891},
doi = {10.1145/3544548.3580891},
abstract = {Optical see-through head-mounted displays (OHMDs) can provide just-in-time digital assistance to users while they are engaged in ongoing tasks. However, given users’ limited attentional resources when multitasking, there is a need to concisely and accurately present information in OHMDs. Existing approaches for digital information presentation involve using either text or pictograms. While pictograms have enabled rapid recognition and easier use in warning messages and traffic signs, most studies using pictograms for digital notifications have exhibited unfavorable results. We thus conducted a series of four iterative studies to understand how we can support effective notification presentation on OHMDs during multitasking scenarios. We find that while icon-augmented notifications can outperform text-only notifications, their effectiveness depends on icon familiarity, encoding density, and environmental brightness. We reveal design implications when using icon-augmented notifications in OHMDs and present plausible reasons for the observed disparity in literature.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {575},
numpages = {23},
keywords = {notification, OST HMD, OHMD, interruption, smart glasses, icon, pictogram, distraction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580928,
author = {Vatavu, Radu-Daniel},
title = {IFAD Gestures: Understanding Users’ Gesture Input Performance with Index-Finger Augmentation Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580928},
doi = {10.1145/3544548.3580928},
abstract = {We examine gestures performed with a class of input devices with distinctive quality properties in the wearables landscape, which we call “index-Finger Augmentation Devices” (iFADs). We introduce a four-level taxonomy to characterize the diversity of iFAD gestures, evaluate iFAD gesture articulation on a dataset of 6,369 gestures collected from 20 participants, and compute recognition accuracy rates. Our findings show that iFAD gestures are fast (1.84s on average), easy to articulate (1.52 average rating on a difficulty scale from 1 to 5), and socially acceptable (81% willingness to use them in public places). We compare iFAD gestures with gestures performed using other devices (styli, touchscreens, game controllers) from several public datasets (39,263 gestures, 277 participants), and report that iFAD gestures are two times faster than whole-body gestures and as fast as stylus and finger strokes performed on touchscreens.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {576},
numpages = {17},
keywords = {gesture recognition, gesture input, Index finger, gesture analysis, finger augmentation devices, taxonomy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581011,
author = {Yu, Difeng and Syiem, Brandon Victor and Irlitti, Andrew and Dingler, Tilman and Velloso, Eduardo and Goncalves, Jorge},
title = {Modeling Temporal Target Selection: A Perspective from Its Spatial Correspondence},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581011},
doi = {10.1145/3544548.3581011},
abstract = {Temporal target selection requires users to wait and trigger the selection input within a bounded time window, with a selection cursor that is expected to be delayed. This task conceptualizes, for example, a variety of game scenarios such as determining the timing of shooting a projectile towards a moving object. In this work, we explore models that predict “when” users typically perform a selection (i.e., user selection distribution) and their selection error rates in such tasks. We hypothesize that users react to temporal factors including “distance”, “width”, and “delay” as how they treat the corresponding variables in spatial target selection. The derived models are evaluated in a controlled experiment and an MTurk-based online study. Our research contributes new knowledge on user behavior in temporal target selection tasks and its potential connection with its spatial correspondence. Our models and conclusions can benefit both users and designers of relevant interactive applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {577},
numpages = {14},
keywords = {modeling, Timing, moving target, object selection, game.},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581071,
author = {Gori, Julien and Bellut, Quentin},
title = {Positional Variance Profiles (PVPs): A New Take on the Speed-Accuracy Trade-Off},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581071},
doi = {10.1145/3544548.3581071},
abstract = {Fitts’ law is a behavioral model, used to design protocols and analyze data from pointing experiments. These are usually conducted in HCI to evaluate input performance. We recently proposed an alternative method to characterize input performance, called the method of PVPs in 1D, based on 1) a dual-minimization protocol, and 2) an analysis of the variability of entire trajectories. We extend the method in 2D; our contributions include new metrics, a new protocol, and a Python library. We also present the results of a controlled experiment where the new method is validated using three devices (mouse, touchpad, controller): effect sizes in the 2D case replicate those previously found. We also propose a comparison between Fitts’ law and our novel evaluation: the method of PVPs provides more information than Fitts’ law, and can predict its parameters. We discuss how this new method may relieve open problems of Fitts’ law.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {578},
numpages = {16},
keywords = {Fitts’ law, pointing, evaluation, PVP},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580746,
author = {Yamanaka, Shota and Usuba, Hiroki},
title = {Tuning Endpoint-Variability Parameters by Observed Error Rates to Obtain Better Prediction Accuracy of Pointing Misses},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580746},
doi = {10.1145/3544548.3580746},
abstract = {Error rates (ERs) in target-pointing tasks are typically modelled in two steps: predicting the click-point variability (σ) based on target sizes and then computing the probability that a click falls outside a target. This is an indirect approach if the researcher’s purpose is to achieve the accurate prediction of ERs because the model coefficients are optimized to predict σ accurately in the first step. We compared the prediction accuracies of this method with a more direct technique in which the coefficients used for σ are determined in such a way as to optimize the closeness between observed and predicted ERs. Our re-analysis of eight datasets from mouse- and touch-based pointing studies showed that the latter approach consistently outperforms the conventional one if the starting values for the parameter search are appropriate (which can be achieved by hyperparameter optimization), thus enabling the interface configuration on the basis of accurately predicted ERs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {579},
numpages = {18},
keywords = {Human motor performance, endpoint distribution, error rate prediction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580920,
author = {Sch\"{a}fer, Ren\'{e} and Nowak, Oliver and Suchmann, Lovis Bero and Schr\"{o}der, S\"{o}ren and Borchers, Jan},
title = {What’s That Shape? Investigating Eyes-Free Recognition of Textile Icons},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580920},
doi = {10.1145/3544548.3580920},
abstract = {Textile surfaces, such as on sofas, cushions, and clothes, offer promising alternative locations to place controls for digital devices. Textiles are a natural, even abundant part of living spaces, and support unobtrusive input. While there is solid work on technical implementations of textile interfaces, there is little guidance regarding their design—especially their haptic cues, which are essential for eyes-free use. In particular, icons easily communicate information visually in a compact fashion, but it is unclear how to adapt them to the haptics-centric textile interface experience. Therefore, we investigated the recognizability of 84 haptic icons on fabrics. Each combines a shape, height profile (raised, recessed, or flat), and affected area (filled or outline). Our participants clearly preferred raised icons, and identified them with the highest accuracy and at competitive speeds. We also provide insights into icons that look very different, but are hard to distinguish via touch alone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {580},
numpages = {12},
keywords = {Eyes-free Interaction, Haptic Recognition, Textile Icons, Design Recommendations, Textile Interfaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581496,
author = {Hasan, Rakibul and Weil, Rebecca and Siegel, Rudolf and Krombholz, Katharina},
title = {A Psychometric Scale to Measure Individuals’ Value of Other People’s Privacy (VOPP)},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581496},
doi = {10.1145/3544548.3581496},
abstract = {Researchers invested enormous efforts to understand and mitigate the concerns of users as technologies collect their private data. However, users often undermine other people’s privacy when, e.g., posting other people’s photos online, granting mobile applications to access contacts, or using technologies that continuously sense the surrounding. Research to understand technology adoption and behaviors related to collecting and sharing data about non-users has been severely lacking. An essential step to progress in this direction is to identify and quantify factors that affect technology’s use. Toward this goal, we propose and validate a psychometric scale to measure how much an individual values other people’s privacy. We theoretically grounded the appropriateness and relevance of the construct and empirically demonstrated the scale’s internal consistency and validity. This scale will advance the field by enabling researchers to predict behaviors, design adaptive privacy-enhancing technologies, and develop interventions to raise awareness and mitigate privacy risks.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {581},
numpages = {14},
keywords = {Privacy, Other people, Data tracking, Technology adoption, Scale development},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581410,
author = {Herbert, Franziska and Becker, Steffen and Schaewitz, Leonie and Hielscher, Jonas and Kowalewski, Marvin and Sasse, Angela and Acar, Yasemin and D\"{u}rmuth, Markus},
title = {A World Full of Privacy and Security (Mis)Conceptions? Findings of a Representative Survey in 12 Countries},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581410},
doi = {10.1145/3544548.3581410},
abstract = {Misconceptions about digital security and privacy topics in the general public frequently lead to insecure behavior. However, little is known about the prevalence and extent of such misconceptions in a global context. In this work, we present the results of the first large-scale survey of a global population on misconceptions: We conducted an online survey with n = 12, 351&nbsp;participants in 12&nbsp;countries on four continents. By investigating influencing factors of misconceptions around eight common security and privacy topics (including E2EE, Wi-Fi, VPN, and malware), we find the country of residence to be the strongest estimate for holding misconceptions. We also identify differences between non-Western and Western countries, demonstrating the need for region-specific research on user security knowledge, perceptions, and behavior. While we did not observe many outright misconceptions, we did identify a lack of understanding and uncertainty about several fundamental privacy and security topics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {582},
numpages = {23},
keywords = {Online Survey, Human-Centered Security, Security Misconceptions, Co-variance Analysis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580637,
author = {Kyi, Lin and Ammanaghatta Shivakumar, Sushil and Santos, Cristiana Teixeira and Roesner, Franziska and Zufall, Frederike and Biega, Asia J.},
title = {Investigating Deceptive Design in GDPR’s Legitimate Interest},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580637},
doi = {10.1145/3544548.3580637},
abstract = {Legitimate interest is one of the six grounds for processing data under the European Union’s General Data Protection Regulation (GDPR). The flexibility and ambiguity of the term "legitimate interests" can be problematic; coupled with the lack of enforcement from legal authorities and different interpretations from the various data protection authorities, legitimate interests can be taken advantage of as a loophole to collect more user data. Drawing insights from multiple disciplines, we ran two studies to empirically investigate the deceptive designs being used when legitimate interests are applied in privacy notices, and how user perceptions line up with these practices. We identified six deceptive designs, and found that the ways legitimate interest is applied in practice does not match user expectations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {583},
numpages = {16},
keywords = {Dark Patterns, GDPR, Privacy Notice, Consent, Legitimate Interest, Deceptive Design, Human-Computer Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581537,
author = {H\"{a}ring, Maximilian and Gerlitz, Eva and Smith, Matthew and Tiefenau, Christian},
title = {Less About Privacy: Revisiting a Survey about the German COVID-19 Contact Tracing App},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581537},
doi = {10.1145/3544548.3581537},
abstract = {The release of COVID-19 contact tracing apps was accompanied by a heated public debate with much focus on privacy concerns, e.g., possible government surveillance. Many papers studied people’s intended behavior to research potential features and uptake of the apps. Studies in Germany conducted before the app’s release, such as that by H\"{a}ring et al., showed that privacy was an important factor in the intention to install the app. We conducted a follow-up study two months post-release to investigate the intention-behavior-gap, see how attitudes changed after the release, and capture reported behavior. Analyzing a quota sample (n=837) for Germany, we found that fewer participants mentioned privacy concerns post-release, whereas utility now plays a greater role. We provide further evidence that the results of intention-based studies should be handled with care when used for prediction purposes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {16},
keywords = {contact tracing, survey, privacy, intention-behavior-gap},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580909,
author = {Windl, Maximiliane and Winterhalter, Verena and Schmidt, Albrecht and Mayer, Sven},
title = {Understanding and Mitigating Technology-Facilitated Privacy Violations in the Physical World},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580909},
doi = {10.1145/3544548.3580909},
abstract = {We are constantly surrounded by technology that collects and processes sensitive data, paving the way for privacy violations. Yet, current research investigating technology-facilitated privacy violations in the physical world is scattered and focused on specific scenarios or investigates such violations purely from an expert’s perspective. Informed through a large-scale online survey, we first construct a scenario taxonomy based on user-experienced privacy violations in the physical world through technology. We then validate our taxonomy and establish mitigation strategies using interviews and co-design sessions with privacy and security experts. In summary, this work contributes (1) a refined scenario taxonomy for technology-facilitated privacy violations in the physical world, (2) an understanding of how privacy violations manifest in the physical world, (3) a decision tree on how to inform users, and (4) a design space to create notices whenever adequate. With this, we contribute a conceptual framework to enable a privacy-preserving technology-connected world.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {16},
keywords = {smart environments, privacy policies, privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581164,
author = {G\'{o}mez Ortega, Alejandra and Bourgeois, Jacky and Kortuem, Gerd},
title = {What is Sensitive About (Sensitive) Data? Characterizing Sensitivity and Intimacy with Google Assistant Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581164},
doi = {10.1145/3544548.3581164},
abstract = {Digital technologies have increasingly integrated into people’s lives, continuously capturing their behavior through potentially sensitive data. In the context of voice assistants, there is a misalignment between experts, regulators, and users on whether and what data is ‘sensitive’, partly due to how data is presented to users; as single interactions. We investigate users’ perspectives on the sensitivity and intimacy of their Google Assistant speech records, introduced comprehensively as single interactions, patterns, and inferences. We collect speech records through data donation and explore them in collaboration with 17 users during interviews based on predefined data-sharing scenarios. Our results indicate a tipping point in perceived sensitivity and intimacy as participants delve deeper into their data and the information derived from it. We propose a conceptualization of sensitivity and intimacy that accounts for the fuzzy nature of data and must disentangle from it. We discuss the implications of our findings and provide recommendations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {586},
numpages = {16},
keywords = {Intimate Data;, Sensitive Data, Personal Data, Voice Assistants},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581232,
author = {Peng, Xiaolan and Xie, Xurong and Huang, Jin and Jiang, Chutian and Wang, Haonian and Denisova, Alena and Chen, Hui and Tian, Feng and Wang, Hongan},
title = {ChallengeDetect: Investigating the Potential of Detecting In-Game Challenge Experience from Physiological Measures},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581232},
doi = {10.1145/3544548.3581232},
abstract = {Challenge is the core element of digital games. The wide spectrum of physical, cognitive, and emotional challenge experiences provided by modern digital games can be evaluated subjectively using a questionnaire, the CORGIS, which allows for a post hoc evaluation of the overall experience that occurred during game play. Measuring this experience dynamically and objectively, however, would allow for a more holistic view of the moment-to-moment experiences of players. This study, therefore, explored the potential of detecting perceived challenge from physiological signals. For this, we collected physiological responses from 32 players who engaged in three typical game scenarios. Using perceived challenge ratings from players and extracted physiological features, we applied multiple machine learning methods and metrics to detect challenge experiences. Results show that most methods achieved a detection accuracy of around 80%. We discuss in-game challenge perception, challenge-related physiological indicators and AI-supported challenge detection to inform future work on challenge evaluation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {587},
numpages = {29},
keywords = {machine learning, video games, player experience, physiological signals, perceived challenge},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580950,
author = {Roemmich, Kat and Schaub, Florian and Andalibi, Nazanin},
title = {Emotion AI at Work: Implications for Workplace Surveillance, Emotional Labor, and Emotional Privacy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580950},
doi = {10.1145/3544548.3580950},
abstract = {Workplaces are increasingly adopting emotion AI, promising benefits to organizations. However, little is known about the perceptions and experiences of workers subject to emotion AI in the workplace. Our interview study with (n=15) US adult workers addresses this gap, finding that (1) participants viewed emotion AI as a deep privacy violation over the privacy of workers’ sensitive emotional information; (2) emotion AI may function to enforce workers’ compliance with emotional labor expectations, and that workers may engage in emotional labor as a mechanism to preserve privacy over their emotions; (3) workers may be exposed to a wide range of harms as a consequence of emotion AI in the workplace. Findings reveal the need to recognize and define an individual right to what we introduce as emotional privacy, as well as raise important research and policy questions on how to protect and preserve emotional privacy within and beyond the workplace.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {588},
numpages = {20},
keywords = {workplace, emotion AI, emotional labor, emotional AI, emotion recognition, future of work, passive sensing, privacy, surveillance, affective computing, artificial emotional intelligence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581425,
author = {Wang, Yuntao and Cheng, Zirui and Yi, Xin and Kong, Yan and Wang, Xueyang and Xu, Xuhai and Yan, Yukang and Yu, Chun and Patel, Shwetak and Shi, Yuanchun},
title = {Modeling the Trade-off of Privacy Preservation and Activity Recognition on Low-Resolution Images},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581425},
doi = {10.1145/3544548.3581425},
abstract = {A computer vision system using low-resolution image sensors can provide intelligent services (e.g., activity recognition) but preserve unnecessary visual privacy information from the hardware level. However, preserving visual privacy and enabling accurate machine recognition have adversarial needs on image resolution. Modeling the trade-off of privacy preservation and machine recognition performance can guide future privacy-preserving computer vision systems using low-resolution image sensors. In this paper, using the at-home activity of daily livings (ADLs) as the scenario, we first obtained the most important visual privacy features through a user survey. Then we quantified and analyzed the effects of image resolution on human and machine recognition performance in activity recognition and privacy awareness tasks. We also investigated how modern image super-resolution techniques influence these effects. Based on the results, we proposed a method for modeling the trade-off of privacy preservation and activity recognition on low-resolution images.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {589},
numpages = {15},
keywords = {low-resolution image., Privacy, privacy preserving, visual privacy, activities of daily living, ADLs},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581183,
author = {Mendel, Tamir and Toch, Eran},
title = {Social Support for Mobile Security: Comparing Close Connections and Community Volunteers in a Field Experiment},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581183},
doi = {10.1145/3544548.3581183},
abstract = {People regularly rely on social support from family, friends, and the public when mitigating security and privacy risks, even if mainstream technologies hardly support these interactions. In this paper, we evaluated Meerkat, a mobile application that allows users to receive support through screenshot capturing, marking, and messaging. In a field experiment (n = 65), we tested how Meerkat helps users face phishing attempts and examined it by receiving help from close social connections and community volunteers. Our findings show that while users could learn from both types of helpers, they were significantly more willing to rely on advice from close connections. We evaluate several criteria for successful support interactions, showing that learning is significantly correlated with specific properties of the support interaction, such as the length of the messages. We conclude the paper by discussing how our findings can be used to design community-based applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {590},
numpages = {18},
keywords = {security, phishing, Social support, mobile, collective efficacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581387,
author = {Ul Haque, Ehsan and Khan, Mohammad Maifi Hasan and Fahim, Md Abdullah Al},
title = {The Nuanced Nature of Trust and Privacy Control Adoption in the Context of Google},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581387},
doi = {10.1145/3544548.3581387},
abstract = {This paper investigates how trust towards service providers and the adoption of privacy controls belonging to two specific purposes (control over “sharing” vs. “usage” of data) vary based on users’ technical literacy. Towards that, we chose Google as the context and conducted an online survey across 209 Google users. Our results suggest that integrity and benevolence perceptions toward Google are significantly lower among technical participants than non-technical participants. While trust perceptions differ between non-technical adopters and non-adopters of privacy controls, no such difference is found among the technical counterparts. Notably, among the non-technical participants, the direction of trust affecting privacy control adoption is observed to be reversed based on the purpose of the controls. Using qualitative analysis, we extract trust-enhancing and dampening factors contributing to users’ trusting beliefs towards Google’s protection of user privacy. The implications of our findings for the design and promotion of privacy controls are discussed in the paper.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {591},
numpages = {23},
keywords = {Privacy Choices, Privacy Control Adoption, Trust, Privacy Controls, Privacy, Technical Literacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580777,
author = {Chanenson, Jake and Sloane, Brandon and Rajan, Navaneeth and Morril, Amy and Chee, Jason and Huang, Danny Yuxing and Chetty, Marshini},
title = {Uncovering Privacy and Security Challenges In K-12 Schools},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580777},
doi = {10.1145/3544548.3580777},
abstract = {Increased use of technology in schools raises new privacy and security challenges for K-12 students—and harms such as commercialization of student data, exposure of student data in security breaches, and expanded tracking of students—but the extent of these challenges is unclear. In this paper, first, we interviewed 18 school officials and IT personnel to understand what educational technologies districts use and how they manage student privacy and security around these technologies. Second, to determine if these educational technologies are frequently endorsed across United States (US) public schools, we compiled a list of linked educational technology websites scraped from 15,573 K-12 public school/district domains and analyzed them for privacy risks. Our findings suggest that administrators lack resources to properly assess privacy and security issues around educational technologies even though they do pose potential privacy issues. Based on these findings, we make recommendations for policymakers, educators, and the CHI research community.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {592},
numpages = {28},
keywords = {EdTech, K-12, educational technologies, student data privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581390,
author = {Hayatpur, Devamardeep and Wigdor, Daniel and Xia, Haijun},
title = {CrossCode: Multi-Level Visualization of Program Execution},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581390},
doi = {10.1145/3544548.3581390},
abstract = {Program visualizations help to form useful mental models of how programs work, and to reason and debug code. But these visualizations exist at a fixed level of abstraction, e.g., line-by-line. In contrast, programmers switch between many levels of abstraction when inspecting program behavior. Based on results from a formative study of hand-designed program visualizations, we designed CrossCode, a web-based program visualization system for JavaScript that leverages structural cues in syntax, control flow, and data flow to aggregate and navigate program execution across multiple levels of abstraction. In an exploratory qualitative study with experts, we found that CrossCode enabled participants to maintain a strong sense of place in program execution, was conducive to explaining program behavior, and helped track changes and updates to the program state.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {593},
numpages = {13},
keywords = {programming, program visualization, debugging},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581403,
author = {Jiang, Peiling and Sun, Fuling and Xia, Haijun},
title = {Log-It: Supporting Programming with Interactive, Contextual, Structured, and Visual Logs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581403},
doi = {10.1145/3544548.3581403},
abstract = {Logging is a widely used technique for inspecting and understanding programs. However, the presentation of logs still often takes its ancient form of a linear stream of text that resides in a terminal, console, or log file. Despite its simplicity, interpreting log output is often challenging due to the large number of textual logs that lack structure and context. We conducted content analysis and expert interviews to understand the practices and challenges inherent in logging. These activities demonstrated that the current representation of logs does not provide the rich structures programmers need to interpret them or the program’s behavior. We present Log-it, a logging interface that enables programmers to interactively structure and visualize logs in situ. A user study with novices and experts showed that Log-it’s syntax and interface have a minimal learning curve, and the interactive representations and organizations of logs help programmers easily locate, synthesize, and understand logs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {594},
numpages = {16},
keywords = {Programming support, Visualization, Program comprehension},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580785,
author = {Beckmann, Tom and Rein, Patrick and Ramson, Stefan and Bergsiek, Joana and Hirschfeld, Robert},
title = {Structured Editing for All: Deriving Usable Structured Editors from Grammars},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580785},
doi = {10.1145/3544548.3580785},
abstract = {Structured editing can show benefits in learnability, tool building, and editing efficiency in programming. However, creating a usable structured editor is laborious and demanding, typically requiring tool builders to manually create or adjust editing interactions. We present Sandblocks, a system that allows users to automatically generate structured editors for every language with a formal grammar available. Our system’s input reconciliation process acts on arbitrary syntax trees to provides consistent interactions across our generated editors. Our editors’ editing experience is designed to be familiar to users from textual editing but, compared to previous work, requires no manual annotation in the grammars. We demonstrate our editors’ usability across languages through a user study (N=18). Compared to conventional text editors, even with minimal training, participants only took on average 21% (JS), 34% (Clojure), and 95% (RegExp) longer and reported that editing felt natural with a score of 6/7.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {595},
numpages = {16},
keywords = {text-like editing, structured editing, grammars},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581516,
author = {Zhang, Ashley Ge and Chen, Yan and Oney, Steve},
title = {VizProg: Identifying Misunderstandings By Visualizing Students’ Coding Progress},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581516},
doi = {10.1145/3544548.3581516},
abstract = {Programming instructors often conduct in-class exercises to help them identify students that are falling behind and surface students’ misconceptions. However, as we found in interviews with programming instructors, monitoring students’ progress during exercises is difficult, particularly for large classes. We present VizProg, a system that allows instructors to monitor and inspect students’ coding progress in real-time during in-class exercises. VizProg represents students’ statuses as a 2D Euclidean spatial map that encodes the students’ problem-solving approaches and progress in real-time. VizProg allows instructors to navigate the temporal and structural evolution of students’ code, understand relationships between code, and determine when to provide feedback. A comparison experiment showed that VizProg helped to identify more students’ problems than a baseline system. VizProg also provides richer and more comprehensive information for identifying important student behavior. By managing students’ activities at scale, this work presents a new paradigm for improving the quality of live learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {596},
numpages = {16},
keywords = {code visualization, programming education at scale},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581436,
author = {Krings, Kevin and Bohn, Nino S. and Hille, Nora Anna Luise and Ludwig, Thomas},
title = {“What If Everyone is Able to Program?” – Exploring the Role of Software Development in Science Fiction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581436},
doi = {10.1145/3544548.3581436},
abstract = {For decades, research around emerging technologies has been inspired by science fiction and vice versa. While so far almost only the technologies themselves have been considered, we explore the underlying software development and programming approaches. We therefore conduct a detailed media content analysis of twenty-seven movies that examines the role of software development in science fiction by identifying and investigating new approaches to programming and how software development is conceptualized portrayed within science fiction scenes. With the additional analysis of eighteen design fiction stories exploring the scenario “What if everyone is able to program?”, we envision potential impacts of the democratization of software development on business and society. Our study opens new discussions and perspectives, by investigating the current vision of the future of programming and uncovers new approaches to software development which can serve as a starting point for further research in the HCI community.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {13},
keywords = {Software Development, Content Analysis, End-User Development (EUD), Design Fiction, Science Fiction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580817,
author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
title = {“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580817},
doi = {10.1145/3544548.3580817},
abstract = {Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {598},
numpages = {31},
keywords = {Natural Language Programming, Human-AI Interaction, Spreadsheets, Large Language Models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581080,
author = {Almqvist, Andreas and Hedman, Anders and Clear, Adrian K and Comber, Rob},
title = {Different Together: Design for Radical Placemaking},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581080},
doi = {10.1145/3544548.3581080},
abstract = {This work responds to isolating urban places, and contributes new ways for thinking about placemaking. Progressing through autoethnography and prototyping, we critique design proposals with Lefebvre’s theory of utopia. There inhabitants can enjoy and shape their place together without risking depletion of their abilities and motivations to do so. The critique produces political sensibilities that help us make sense of common tensions among inhabitants, landowners, and visitors, and generate possible responses. The critique process itself illustrates how designing through critique with theory can help us think in new ways. This paper contributes a display of how design with critical theory can happen, ultimately to support our abilities and motivations to envision and make places of social flourishing that can respond to our socio-environmental crises.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {16},
keywords = {design critique, critical theory, utopia, sustainable HCI, right to the city, making place},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580996,
author = {Robertson, Samantha and Nguyen, Tonya and Hu, Cathy and Albiston, Catherine and Nikzad, Afshin and Salehi, Niloufar},
title = {Expressiveness, Cost, and Collectivism: How the Design of Preference Languages Shapes Participation in Algorithmic Decision-Making},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580996},
doi = {10.1145/3544548.3580996},
abstract = {Emerging methods for participatory algorithm design have proposed collecting and aggregating individual stakeholders’ preferences to create algorithmic systems that account for those stakeholders’ values. Drawing on two years of research across two public school districts in the United States, we study how families and school districts use students’ preferences for schools to meet their goals in the context of algorithmic student assignment systems. We find that the design of the preference language, i.e. the structure in which participants must express their needs and goals to the decision-maker, shapes the opportunities for meaningful participation. We define three properties of preference languages – expressiveness, cost, and collectivism – and discuss how these factors shape who is able to participate, and the extent to which they are able to effectively communicate their needs to the decision-maker. Reflecting on these findings, we offer implications and paths forward for researchers and practitioners who are considering applying a preference-based model for participation in algorithmic decision making.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {600},
numpages = {16},
keywords = {Participatory design, preference elicitation, algorithmic systems, preference language},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581194,
author = {Lupetti, Maria Luce and Cavalcante Siebert, Luciano and Abbink, David},
title = {Steering Stories: Confronting Narratives of Driving Automation through Contestational Artifacts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581194},
doi = {10.1145/3544548.3581194},
abstract = {In this paper, we problematize popular narratives of driving automation. Whether positive or negative, these propagate simplistic assumptions about human abilities and reinforce technocratic approaches to mobility innovation. We build on narrative approaches to participatory research and adversarial design, to explore how design-led confrontation can create opportunities for reflection on implicit assumptions and narratives that stakeholders may refer to when discussing and making decisions about automated driving technologies. Specifically, we discuss the results of four focus groups where we used contestational artifacts to promote critical discussions and confront taken-for-granted beliefs among stakeholders. We reflect on the results to distill methodological insight and design recommendations for conducting adversarial participatory design research as a way towards confronting dominant narratives. Together with the methodological approach, the main contribution of this work, we also provide a set of narrative tensions that can be used to question common beliefs surrounding automated driving futures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {601},
numpages = {20},
keywords = {Adversarial Design, Critical Design, Automated Driving, Narratives of Technology, Political Design.},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581347,
author = {Do, Kimberly and Pang, Rock Yuren and Jiang, Jiachen and Reinecke, Katharina},
title = {“That’s Important, but...”: How Computer Science Researchers Anticipate Unintended Consequences of Their Research Innovations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581347},
doi = {10.1145/3544548.3581347},
abstract = {Computer science research has led to many breakthrough innovations but has also been scrutinized for enabling technology that has negative, unintended consequences for society. Given the increasing discussions of ethics in the news and among researchers, we interviewed 20 researchers in various CS sub-disciplines to identify whether and how they consider potential unintended consequences of their research innovations. We show that considering unintended consequences is generally seen as important but rarely practiced. Principal barriers are a lack of formal process and strategy as well as the academic practice that prioritizes fast progress and publications. Drawing on these findings, we discuss approaches to support researchers in routinely considering unintended consequences, from bringing diverse perspectives through community participation to increasing incentives to investigate potential consequences. We intend for our work to pave the way for routine explorations of the societal implications of technological innovations before, during, and after the research process.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {602},
numpages = {16},
keywords = {Computer Ethics, Unintended Consequences},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581280,
author = {Sum, Cella M and Tran, Anh-Ton and Lin, Jessica and Kuo, Rachel and Bennett, Cynthia L and Harrington, Christina and Fox, Sarah E},
title = {Translation as (Re)Mediation: How Ethnic Community-Based Organizations Negotiate Legitimacy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581280},
doi = {10.1145/3544548.3581280},
abstract = {Ethnic community-based organizations (CBOs) play an essential role in supporting the wellbeing of immigrants and refugees. CBO workers often act as linguistic and cultural translators between communities, government, and health and social service systems. However, resource constraints, technological barriers, and pressures to be data-driven require workers to perform additional forms of translation to ensure their organizations’ survival. Drawing on 16 interviews with members of 7 Asian American and Pacific Islander CBOs, we examine opportunities and barriers concerning their technology-mediated work practices. We identify two circumstances where CBO workers perform translation: (1) as legitimacy work to build trust with funders and communities, and (2) as (re)mediation in attending to technological barriers and resisting hegemonic systems that treat their communities as “other.” By unpacking the politics of translation work across these sites, we position CBO workers as a critical source for HCI research and practice as it seeks to support community wellbeing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {603},
numpages = {14},
keywords = {ethnic community-based organizations, migrant, AAPI, legitimacy work, Translation work, remediation, diaspora},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581412,
author = {Sabie, Samar and Soden, Robert and Jackson, Steven and Parikh, Tapan},
title = {Unmaking as Emancipation: Lessons and Reflections from Luddism},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581412},
doi = {10.1145/3544548.3581412},
abstract = {Emancipation is fundamentally a work of unmaking, as it entails undermining, dissolving, and undoing oppressive structures. This paper offers an account of a frequently misunderstood unmaking movement, Luddism. The Luddites were a loosely organized collective of nineteenth century English textile makers who destroyed machines that were replacing their skilled labor and leading to deteriorating working conditions. In this account, we show that the goals and tactics of Luddism have significant alignments with current HCI work in the areas of unmaking and social justice. Through articulation of six characteristics of unmaking in Luddism - practical and symbolic, community-engaged, emancipatory, selective, antagonistic, and enduring - we identify potential limits and opportunities in HCI research and design practice, as currently construed. In doing so, we build upon and extend prior HCI research to suggest unmaking as emancipation, a new category of unmaking around issues of social justice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {604},
numpages = {15},
keywords = {unmaking, design, emancipation, Luddism},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581541,
author = {Alharbi, Rahaf and Tang, John and Henderson, Karl},
title = {Accessibility Barriers, Conflicts, and Repairs: Understanding the Experience of Professionals with Disabilities in Hybrid Meetings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581541},
doi = {10.1145/3544548.3581541},
abstract = {Workplaces around the globe are beginning to rapidly adopt hybrid meetings to conduct, plan, and organize their work. While previous literature explores the benefits and drawbacks of hybrid meetings, the experiences of professionals with disabilities are largely missing. With an orientation towards an accessible future of work, we interviewed 21 professionals with disabilities to unpack the accessibility barriers, opportunities, and conflicts of hybrid meetings. We highlight the creative ways professionals with disabilities developed workarounds and repairs to these accessibility tensions. Our paper expands the understanding of accessibility in hybrid meetings by identifying how the visibility of access labor may be affected by being in the room together with other colleagues or joining remotely. We also observed how hybrid configurations can require navigating accessibility conflicts specific to the location site of each participant. Building from our analysis, we offer practical suggestions and design directions to make hybrid meetings accessible.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {605},
numpages = {15},
keywords = {disability, future of work, hybrid meetings, remote work, accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581261,
author = {Rocha, Filipa and Correia, Filipa and Neto, Isabel and Pires, Ana Cristina and Guerreiro, Jo\~{a}o and Guerreiro, Tiago and Nicolau, Hugo},
title = {Coding Together: On Co-Located and Remote Collaboration between Children with Mixed-Visual Abilities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581261},
doi = {10.1145/3544548.3581261},
abstract = {Collaborative coding environments foster learning, social skills, computational thinking training, and supportive relationships. In the context of inclusive education, these environments have the potential to promote inclusive learning activities for children with mixed-visual abilities. However, there is limited research focusing on remote collaborative environments, despite the opportunity to design new modes of access and control of content to promote more equitable learning experiences. We investigated the tradeoffs between remote and co-located collaboration through a tangible coding kit. We asked ten pairs of mixed-visual ability children to collaborate in an interdependent and asymmetric coding game. We contribute insights on six dimensions - effectiveness, computational thinking, accessibility, communication, cooperation, and engagement - and reflect on differences, challenges, and advantages between collaborative settings related to communication, workspace awareness, and computational thinking training. Lastly, we discuss design opportunities of tangibles, audio, roles, and tasks to create inclusive learning activities in remote and co-located settings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {606},
numpages = {14},
keywords = {Visually impaired, Computational thinking, Mixed-visual ability, Accessible, Tangible, Collaboration, Children, Robot},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581481,
author = {Mack, Kelly and Hsu, Rai Ching Ling and Monroy-Hern\'{a}ndez, Andr\'{e}s and Smith, Brian A. and Liu, Fannie},
title = {Towards Inclusive Avatars: Disability Representation in Avatar Platforms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581481},
doi = {10.1145/3544548.3581481},
abstract = {Digital avatars are an important part of identity representation, but there is little work on understanding how to represent disability. We interviewed 18 people with disabilities and related identities about their experiences and preferences in representing their identities with avatars. Participants generally preferred to represent their disability identity if the context felt safe and platforms supported their expression, as it was important for feeling authentically represented. They also utilized avatars in strategic ways: as a means to signal and disclose current abilities, access needs, and to raise awareness. Some participants even found avatars to be a more accessible way to communicate than alternatives. We discuss how avatars can support disability identity representation because of their easily customizable format that is not strictly tied to reality. We conclude with design recommendations for creating platforms that better support people in representing their disability and other minoritized identities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {607},
numpages = {13},
keywords = {disability, identity, inclusion, avatars},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580810,
author = {Desai, Aashaka and Mankoff, Jennifer and Ladner, Richard E.},
title = {Understanding and Enhancing The Role of Speechreading in Online d/DHH Communication Accessibility},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580810},
doi = {10.1145/3544548.3580810},
abstract = {Speechreading is the art of using visual and contextual cues in the environment to support listening. Often used by d/Deaf and Hard-of-Hearing (d/DHH) individuals, it highlights nuances of rich communication. However, lived experiences of speechreaders are underdocumented in HCI literature, and the impact of online environments and interactions of captioning with speechreading has not been explored in depth. We bridge these gaps through a three-part study consisting of formative interviews, design probes, and design sessions with 12 d/DHH individuals who speechread. Our primary contribution is to understand the lived experience of speechreading in online communication, and thus to better understand the richness and variety of techniques d/DHH individuals use to provision access. We highlight technical, environmental and sociocultural factors that impact communication accessibility, explore the design space of speechreading supports and share considerations for the design future of speechreading technology.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {17},
keywords = {d/Deaf and Hard-of-Hearing, Speechreading, Accessible Video Calls},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580937,
author = {Yildiz, Zeynep and Subasi, Ozge},
title = {Virtual Collaboration Tools for Mixed-Ability Workspaces: A Cross Disability Solidarity Case from Turkey},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580937},
doi = {10.1145/3544548.3580937},
abstract = {A growing body of literature on mixed-ability teams within HCI investigates how disabled and non-disabled people collaborate. Still, how different disabilities can interact in a mixed-ability team is underexplored, especially for long commitments and in non-western contexts. As an emerging perspective in accessibility studies in HCI, disability justice emphasizes the importance of cross-disability collaborations. Collaborative access, interdependence, and cross-disability dialogue are keys to building accessible mixed-ability interactions. We conducted ten in-depth interviews with the members of a unique mixed-ability team (which includes people with different physical disabilities) using the same workspace with cross-disability interactions in Turkey. We aim to understand the requirements for an accessible mixed-ability virtual workspace and to identify practical design considerations for cross-disability solidarity-oriented virtual collaboration tools. To ensure equal access in virtual workspaces, we suggest implications for centering collective access, balancing external power dynamics, and supporting language and cultural diversities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {609},
numpages = {11},
keywords = {Collaborative accessibility, Disability justice, Mixed-Ability Teams, Cross-Disability Solidarity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581151,
author = {Kim, Yeon Soo and Im, Hyeonjeong and Lee, Sunok and Cho, Haena and Lee, Sangsu},
title = {“We Speak Visually”: User-Generated Icons for Better Video-Mediated Mixed-Group Communications Between Deaf and Hearing Participants},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581151},
doi = {10.1145/3544548.3581151},
abstract = {Since the outbreak of the COVID-19 pandemic, videoconferencing technology has been widely adopted as a convenient, powerful, and fundamental tool that has simplified many day-to-day tasks. However, video communication is dependent on audible conversation and can be strenuous for those who are Hard of Hearing. Communication methods used by the Deaf and Hard of Hearing community differ significantly from those used by the hearing community, and a distinct language gap is evident in workspaces that accommodate workers from both groups. Therefore, we integrated users in both groups to explore ways to alleviate obstacles in mixed-group videoconferencing by implementing user-generated icons. A participatory design methodology was employed to investigate how the users overcome language differences. We observed that individuals utilized icons within video-mediated meetings as a universal language to reinforce comprehension. Herein, we present design implications from these findings, along with recommendations for future icon systems to enhance and support mixed-group conversations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {610},
numpages = {16},
keywords = {Deaf and Hard of hearing, Videoconferencing, Accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581141,
author = {Mok, Lillio and Sun, Lu and Sen, Shilad and Sarrafzadeh, Bahareh},
title = {Challenging but Connective: Large-Scale Characteristics of Synchronous Collaboration Across Time Zones},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581141},
doi = {10.1145/3544548.3581141},
abstract = {Organizations are becoming increasingly distributed and many need to collaborate synchronously over great geographical distances. Despite a rich body of literature on spatially-distanced meetings, gaps remain in our understanding of temporally-distanced meetings. Here, we characterize cross time zone collaborations by analyzing 20 million meetings scheduled at a multinational corporation, Microsoft, supported by a survey on how 130 employees perceive their scheduling needs. We find that cross time zone meetings are closely associated with scheduling patterns around early morning and late evening hours, which are challenging and discordant with employees’ stated temporal preferences. Additionally, the burdens of meeting across time boundaries are asymmetrically distributed among workers at different levels of the organization and different geolocations. Nonetheless, we further observe evidence that cross time zone attendees are organizationally distant and diverse, suggesting that addressing these challenges by limiting meetings would disafford employees the opportunities to connect. We conclude by sharing opportunities for facilitating cross time zone meetings that foster healthier global collaborations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {611},
numpages = {17},
keywords = {remote work, connectivity, time zones, Collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580899,
author = {Duckert, Melanie and Barkhuus, Louise and Bj\o{}rn, Pernille},
title = {Collocated Distance: A Fundamental Challenge for the Design of Hybrid Work Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580899},
doi = {10.1145/3544548.3580899},
abstract = {After the pandemic, it is urgently important to explore the special challenges which arise with hybrid work. Through cross-case analyses of published papers, we propose collocated distance as a design challenge uniquely relevant for hybrid cooperative technologies. We identify and conceptualize collocated distance as a design challenge that arises in hybrid work situations, where at least three actors are mutually dependent in their work while being located within fewer contexts than the number of actors. Collocated distance reminds us that when designing hybrid technologies, we must not only focus on creating technologies that support the work across geographical locations but equally pay attention to the relations and possible disconnections which exist locally between collocated actors. When designing cooperative technologies supporting distributed work, often focus is on the boundaries between geographical contexts – however, in hybrid work, we must not forget to pay attention to the collocated boundaries within the same context.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {612},
numpages = {16},
keywords = {cooperative work, distributed work, hybrid work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580930,
author = {Shin, Donghoon and Kim, Soomin and Shang, Ruoxi and Lee, Joonhwan and Hsieh, Gary},
title = {IntroBot: Exploring the Use of Chatbot-Assisted Familiarization in Online Collaborative Groups},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580930},
doi = {10.1145/3544548.3580930},
abstract = {Many people gather online and form teams with strangers to collaborate on tasks. However, while intrateam trust and cohesion are critical for team performance, such characteristics take time to establish and are harder to build up through computer-mediated communication. Building on prior research that has shown that enhancing familiarity between members can help, we hypothesized that the use of a chatbot to support the familiarization of ad hoc teammates can help their collaboration. As such, we designed IntroBot, a chatbot that builds on an online discussion facilitator framework and leverages the social media data of users to assist their familiarization process. Through a between-subjects study (N=60), we found that participants who used IntroBot reported higher levels of trust, cohesion, and interaction quality, as well as generated more ideas in a collaborative brainstorming task. We discuss insights gained from our study, and present opportunities for the future of chatbot-assisted collaboration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {613},
numpages = {13},
keywords = {AI-mediated communication, familiarization, chatbot, computer-mediated communication, collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580796,
author = {Bali, Shreya and Khadpe, Pranav and Kaufman, Geoff and Kulkarni, Chinmay},
title = {Nooks: Social Spaces to Lower Hesitations in Interacting with New People at Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580796},
doi = {10.1145/3544548.3580796},
abstract = {Initiating conversations with new people at work is often intimidating because of uncertainty about their interests. People worry others may reject their attempts to initiate conversation or that others may not enjoy the conversation. We introduce a new system, Nooks, built on Slack, that reduces fear of social evaluation by enabling individuals to initiate any conversation as a nook—a conversation room that identifies its topic, but not its creator. Automatically convening others interested in the nook, Nooks further reduces fears of social evaluation by guaranteeing individuals in advance that others they are about to interact with are interested in the conversation. In a multi-month deployment with participants in a summer research program, Nooks provided participants with non-threatening and inclusive interaction opportunities, and ambient awareness, leading to new interactions online and offline. Our results demonstrate how intentionally designed social spaces can reduce fears of social evaluation and catalyze new workplace connections.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {614},
numpages = {18},
keywords = {Computer Mediated Communication, Prototyping/Implementation, Artifact or System, Workplaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580989,
author = {Augstein, Mirjam and Neumayr, Thomas and Sch\"{o}nb\"{o}ck, Johannes and Kovacs, Carrie},
title = {Remote Persons Are Closer Than They Appear: Home, Team and a Lockdown},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580989},
doi = {10.1145/3544548.3580989},
abstract = {Since 2020, worldwide COVID-19-related lockdowns have led to a rapid increase of remote collaboration, particularly in the domain of knowledge work. This has undoubtedly brought challenges (e.g., work-life boundary management, social isolation), but also opportunities. Practices that have proven successful (e.g., through increased task performance, efficiency or satisfaction) are worth retaining in future. In this qualitative empirical study, we analyzed four teams’ (14 participants in total) mandatory remote collaboration over a period of several days to several months during a nationally imposed lockdown. We report results derived from questionnaires, logbooks, group interviews, and meeting recordings. We identify possible factors influencing quality of task outcome as well as subjective aspects like satisfaction, motivation, and team atmosphere. As a basis for our conclusions, we provide a scheme for categorizing effects of remote collaboration based on an exhaustive literature review on pandemic-induced mandatory remote work and collaboration.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {25},
keywords = {remote collaboration, work from home, mandatory remote collaboration, mandatory remote work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581345,
author = {Park, So Yeon and Lee, Sang Won},
title = {Why “why”? The Importance of Communicating Rationales for Edits in Collaborative Writing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581345},
doi = {10.1145/3544548.3581345},
abstract = {Collaborative writing is prevalent, yet is rife with issues of discomfort and miscommunication among others despite access to limitless text. Editing, one key activity in collaborative writing, is prone to such issues, and providing rationales could be a promising solution. To understand the efficacy of rationales in this context, we conducted an online experiment pairing 40 participants to co-write two essays on Google Docs—one without rationales (control) and another with rationales (treatment)—followed by post-experiment surveys (N=40) and interviews (N=11) with participants who received edits with and without rationales. Despite no significant differences between conditions in survey results, interviews revealed that most people preferred collaborating with those who provided rationales and perceived them more favorably. All interviewees deemed rationales important in collaborative writing and felt the pros outweighed the cons. We contribute design recommendations with illustrative examples for effective collaborative writing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {616},
numpages = {25},
keywords = {Online collaboration, Collaborative writing, Mixed-methods investigation, Change awareness, Design recommendations},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581275,
author = {Stokes, Jackson and August, Tal and Marver, Robert A and Czeskis, Alexei and Roesner, Franziska and Kohno, Tadayoshi and Reinecke, Katharina},
title = {How Language Formality in Security and Privacy Interfaces Impacts Intended Compliance},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581275},
doi = {10.1145/3544548.3581275},
abstract = {Strong end-user security practices benefit both the user and hosting platform, but it is not well understood how companies communicate with their users to encourage these practices. This paper explores whether web companies and their platforms use different levels of language formality in these communications and tests the hypothesis that higher language formality leads to users’ increased intention to comply. We contribute a dataset and systematic analysis of 1,817 English language strings in web security and privacy interfaces across 13 web platforms, showing strong variations in language. An online study with 512 participants further demonstrated that people perceive differences in the language formality across platforms and that a higher language formality is associated with higher self-reported intention to comply. Our findings suggest that formality can be an important factor in designing effective security and privacy prompts. We discuss implications of these results, including how to balance formality with platform language style. In addition to being the first piece of work to analyze language formality in user security, these findings provide valuable insights into how platforms can best communicate with users about account security.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {617},
numpages = {12},
keywords = {Privacy, Language, Formality, Security},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581038,
author = {Ganesh, Anirudh and Ndulue, Chinenye and Orji, Rita},
title = {Tailoring a Persuasive Game to Promote Secure Smartphone Behaviour},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581038},
doi = {10.1145/3544548.3581038},
abstract = {The use of smartphones has become an integral part of everyone's lives. Due to the ubiquitous nature and multiple functionalities of smartphones, the data handled by these devices are sensitive in nature. Despite the measures companies take to protect users’ data, research has shown that people do not take the necessary actions to stay safe from security and privacy threats. Persuasive games have been implemented across various domains to motivate people towards a positive behaviour change. Even though persuasive games could be effective, research has shown that the one-size-fits-all approach to designing persuasive games might not be as effective as the tailored versions of the game. This paper presents the design and evaluation of a persuasive game to improve user awareness about smartphone security and privacy tailored to the user's motivational orientation using Regulatory Focus Theory. From the results of our mixed-methods in-the-wild study of 102 people followed by a one-on-one interview of 25 people, it is evident that the tailored version of the persuasive game performed better than the non-tailored version of the game towards improving users’ secure smartphone behaviour. We contribute to the broader HCI community by offering design suggestions and the benefits of tailoring persuasive games.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {618},
numpages = {18},
keywords = {Secure Smartphone Behaviour, Smartphone Security Game, Tailoring Persuasive Game, Protection Motivation Theory, Regulatory Focus Theory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581170,
author = {Distler, Verena},
title = {The Influence of Context on Response to Spear-Phishing Attacks: An In-Situ Deception Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581170},
doi = {10.1145/3544548.3581170},
abstract = {In today’s digitized societies, phishing attacks are a security threat with damaging consequences. Organizations remain vulnerable to phishing attacks, and it is not clear how the work context influences people’s perceptions and behaviors related to phishing attempts. I investigate (1) how contextual factors influence reactions to a spear-phishing attempt, (2) why people report or do not report phishing attempts, (3) which opportunities for security-enhancing interventions people identify. I use an in-situ deception methodology to observe participants (N=14) in their realistic work environment. I triangulate observational and self-reported data to obtain rich qualitative insights into participants’ emotions, thoughts, and actions when receiving a targeted phishing email. I find that task, IT, internal and social context play an important role. The email’s request being aligned with expectations and perceived time pressure when responding to emails were associated with insecure behavior. The social context positively influenced phishing detection, but “phished” participants did not tell anyone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {619},
numpages = {18},
keywords = {Human-computer interaction, Empirical research, Phishing, Usable privacy and security, Qualitative research methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580985,
author = {Marin, Ioana Andreea and Burda, Pavlo and Zannone, Nicola and Allodi, Luca},
title = {The Influence of Human Factors on the Intention to Report Phishing Emails},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580985},
doi = {10.1145/3544548.3580985},
abstract = {Phishing attacks are a main threat to organizations and individuals. Current widespread defenses based on spam filters and domain blacklisting are unfortunately insufficient. Prior work identifies phishing reporting as a key, largely untapped resource to mitigate phishing threats. Yet, its practice suffers from very low reporting rates and generally too low an uptake from users. Whereas it is known that phishing reporting behavior is affected by a number of ‘human factors’, a comprehensive view of the different theories and their effects on (intent to) report is not yet developed. To address this gap, we evaluate theories and factors analyzed in the extant literature, build a cohesive theoretical view of their effects and constructs, and develop, model, and empirically evaluate (by means of an online questionnaire, n=284) the resulting hypothesis structure. We discuss both theoretical implications of our findings and research directions for practice at a research and organizational level.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {620},
numpages = {18},
keywords = {Information Security, Personality traits., Organizational citizenship behaviors, Cyber security behaviors},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580650,
author = {Tally, Anne Clara and Abbott, Jacob and Bochner, Ashley M and Das, Sanchari and Nippert-Eng, Christena},
title = {Tips, Tricks, and Training: Supporting Anti-Phishing Awareness among Mid-Career Office Workers Based on Employees’ Current Practices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580650},
doi = {10.1145/3544548.3580650},
abstract = {Preventing workplace phishing depends on the actions of every employee, regardless of cybersecurity expertise. Based on 24 semi-structured interviews with mid-career office workers (70.8% women, averaging 44 years old) at two U.S. universities, we found that less than 21% of our participants had any formal anti-phishing training. Much of what our participants know about phishing comes from informal sources that emphasize “tips” and "tricks" like those found in conversations with friends, news stories, newsletters, social media, and podcasts. These informal channels provide opportunities for IT professionals wishing to enhance employees’ anti-phishing awareness by better aligning the delivery of expert advice with employees’ current practices and desires. We provide four recommendations designed to embrace "guerrilla learning" by distributing anti-phishing educational resources across the workplace and workday in part to encourage the delivery of more accurate information in more informal and incidental ways, and greater dialogue between anti-phishing training instructors and learners.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {621},
numpages = {13},
keywords = {phishing, guerrilla learning, security, informal learning, cybersecurity, workplace, human factors, qualitative user studies, work context, organizations, anti-phishing training, IT departments, phishing education, organizational security},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581046,
author = {Glas, Magdalena and Vielberth, Manfred and Pernul, Guenther},
title = {Train as You Fight: Evaluating Authentic Cybersecurity Training in Cyber Ranges},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581046},
doi = {10.1145/3544548.3581046},
abstract = {Humans can play a decisive role in detecting and mitigating cyber attacks if they possess sufficient cybersecurity skills and knowledge. Realizing this potential requires effective cybersecurity training. Cyber range exercises (CRXs) represent a novel form of cybersecurity training in which trainees can experience realistic cyber attacks in authentic environments. Although evaluation is undeniably essential for any learning environment, it has been widely neglected in CRX research. Addressing this issue, we propose a taxonomy-based framework to facilitate a comprehensive and structured evaluation of CRXs. To demonstrate the applicability and potential of the framework, we instantiate it to evaluate Iceberg CRX, a training we recently developed to improve cybersecurity education at our university. For this matter, we conducted a user study with 50 students to identify both strengths and weaknesses of the CRX.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {622},
numpages = {19},
keywords = {cybersecurity exercise, cyber range, cyber defense exercise, evaluation method},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581300,
author = {Li, Richard and Seyed, Teddy and Marquardt, Nicolai and Ofek, Eyal and Hodges, Steve and Sinclair, Mike and Romat, Hugo and Pahud, Michel and Sharma, Jatin and Buxton, William A.S. and Hinckley, Ken and Riche, Nathalie},
title = {AdHocProx: Sensing Mobile, Ad-Hoc Collaborative Device Formations Using Dual Ultra-Wideband Radios},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581300},
doi = {10.1145/3544548.3581300},
abstract = {We present AdHocProx, a system that uses device-relative, inside-out sensing to augment co-located collaboration across multiple devices, without recourse to externally-anchored beacons – or even reliance on WiFi connectivity. AdHocProx achives this via sensors including dual ultra-wideband (UWB) radios for sensing distance and angle to other devices in dynamic, ad-hoc arrangements; plus capacitive grip to determine where the user’s hands hold the device, and to partially correct for the resulting UWB signal attenuation. All spatial sensing and communication takes place via the side-channel capability of the UWB radios, suitable for small-group collaboration across up to four devices (eight UWB radios). Together, these sensors detect proximity and natural, socially meaningful device movements to enable contextual interaction techniques. We find that AdHocProx can obtain 95% accuracy recognizing various ad-hoc device arrangements in an offline evaluation, with participants particularly appreciative of interaction techniques that automatically leverage proximity-awareness and relative orientation amongst multiple devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {623},
numpages = {18},
keywords = {inside-out tracking, multi-device collaboration, ultra-wideband sensing, proximity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581549,
author = {Albaugh, Lea and Hudson, Scott E and Yao, Lining},
title = {An Augmented Knitting Machine for Operational Assistance and Guided Improvisation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581549},
doi = {10.1145/3544548.3581549},
abstract = {Computational mediation can unlock access to existing creative fabrication tools. By outfitting an otherwise purely mechanical hand-operated knitting machine with lightweight sensing capabilities, we produced a system which provides immediate feedback about the state and affordances of the underlying knitting machine. We describe our technical implementation, show modular interface applications which center the particular patterning capabilities of this kind of machine knitting, and discuss user experiences with interactive hybrid computational/mechanical systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {624},
numpages = {15},
keywords = {hybrid fabrication, soft materials., computational crafts, Interactive fabrication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581471,
author = {Yang, Yue and Ren, Lei and Chen, Chuang and Wang, Xinyue and Fan, Yitao and Shao, Yilin and Zhu, Kuangqi and Li, Jiaji and Wang, Qi and Sun, Lingyun and Tao, Ye and Wang, Guanyun},
title = {E-Orthosis: Augmenting Off-the-Shelf Orthoses with Electronics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581471},
doi = {10.1145/3544548.3581471},
abstract = {Orthoses with electronic functions have emerged as a promising medical product in response to the increasing demand for rehabilitation training, therapy assistance, and health monitoring. However, fabricating this “smart orthosis” often requires long development cycles and exorbitant prices. We introduce E-Orthosis, an integrated fabrication approach with construction toolkits for healthcare professionals to quickly embed electronics in off-the-shelf orthoses with customized functions cost-effectively and time-efficiently. Specifically, we develop components with magnets and pogo pins to support rapid attachment and sustainable use, and textile-based electrodes with snap installation to improve the wearing experience. We also provide a circuit iron tool to apply circuit traces on complex surfaces of orthoses directly and a hot punch tool to embed magnet ports and electrodes. Three application examples, technical evaluations, and expert reviews demonstrate the functionality of E-Orthosis and the potential for democratizing rapid-developed and low-cost smart orthoses for patients.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {625},
numpages = {15},
keywords = {Electronic construction kit, Smart orthosis, Personal fabrication, Health monitoring},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581361,
author = {Alalawi, Marwa and Pacik-Nelson, Noah and Zhu, Junyi and Greenspan, Ben and Doan, Andrew and Wong, Brandon M and Owen-Block, Benjamin and Mickens, Shanti Kaylene and Schoeman, Wilhelm Jacobus and Wessely, Michael and Danielescu, Andreea and Mueller, Stefanie},
title = {MechSense: A Design and Fabrication Pipeline for Integrating Rotary Encoders into 3D Printed Mechanisms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581361},
doi = {10.1145/3544548.3581361},
abstract = {We introduce MechSense, 3D-printed rotary encoders that can be fabricated in one pass alongside rotational mechanisms, and report on their angular position, direction of rotation, and speed. MechSense encoders utilize capacitive sensing by integrating a floating capacitor into the rotating element and three capacitive sensor patches in the stationary part of the mechanism. Unlike existing rotary encoders, MechSense does not require manual assembly but can be seamlessly integrated during design and fabrication. Our MechSense editor allows users to integrate the encoder with a rotating mechanism and exports files for 3D-printing. We contribute a sensor topology and a computational model that can compensate for print deviations. Our technical evaluation shows that MechSense can detect the angular position (mean error: 1.4°) across multiple prints and rotations, different spacing between sensor patches, and different sizes of sensors. We demonstrate MechSense through three application examples on 3D-printed tools, tangible UIs, and gearboxes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {626},
numpages = {14},
keywords = {capacitive sensing., printed electronics, 3D printed mechanisms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581295,
author = {Guo, Zengrong and Liang, Rong-Hao},
title = {TexonMask: Facial Expression Recognition Using Textile Electrodes on Commodity Facemasks},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581295},
doi = {10.1145/3544548.3581295},
abstract = {This paper presents TexonMask, a facial expression recognition system using lightweight electrode-augmented commodity facemasks. With a matrix of textile electrodes carefully deployed on a commodity mask, our edge computing system recognizes the wearer’s facial expressions with machine learning based on the capacitive sensor readings, provides a wearable affective display and communicates with external devices using low bandwidth. Results from user studies show that the system is effective and efficient at recognizing five or ten facial expressions with an accuracy of around , using a personalized classifier trained with only six data points per expression. The system’s performance is stable across the use sessions and further improves when more data points are collected. We further developed two LiveEmoji applications for facilitating online and face-to-face communication of facemask wearers, demonstrated them in user interviews, and obtained positive participant feedback. Based on the results and findings of the study, we discuss implications and future research directions for facilitating emotional communication between facemask wearers and others.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {627},
numpages = {15},
keywords = {facemasks, wearable, embedded interaction, capacitive sensing, facial expression recognition, edge computing, textile electrodes},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580692,
author = {Yu, Tianhong Catherine and Arakawa, Riku and McCann, James and Goel, Mayank},
title = {UKnit: A Position-Aware Reconfigurable Machine-Knitted Wearable for Gestural Interaction and Passive Sensing Using Electrical Impedance Tomography},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580692},
doi = {10.1145/3544548.3580692},
abstract = {A scarf is inherently reconfigurable: wearers often use it as a neck wrap, a shawl, a headband, a wristband, and more. We developed uKnit, a scarf-like soft sensor with scarf-like reconfigurability, built with machine knitting and electrical impedance tomography sensing. Soft wearable devices are comfortable and thus attractive for many human-computer interaction scenarios. While prior work has demonstrated various soft wearable capabilities, each capability is device- and location-specific, being incapable of meeting users’ various needs with a single device. In contrast, uKnit explores the possibility of one-soft-wearable-for-all. We describe the fabrication and sensing principles behind uKnit, demonstrate several example applications, and evaluate it with 10-participant user studies and a washability test. uKnit achieves 88.0%/78.2% accuracy for 5-class worn-location detection and 80.4%/75.4% accuracy for 7-class gesture recognition with a per-user/universal model. Moreover, it identifies respiratory rate with an error rate of 1.25 bpm and detects binary sitting postures with an average accuracy of 86.2%.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {628},
numpages = {17},
keywords = {Reconfigurable Wearable, Electrical Impedance Tomography, Smart Textile, Gestural Interaction, Machine Knitting},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581504,
author = {Berger, Arne and Kurze, Albrecht and Bischof, Andreas and Benjamin, Jesse Josua and Wong, Richmond Y. and Merrill, Nick},
title = {Accidentally Evil: On Questionable Values in Smart Home Co-Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581504},
doi = {10.1145/3544548.3581504},
abstract = {An ongoing mystery of HCI is how do well-intentioned designers consistently enable products with unintentionally evil consequences. Using “questionable values” as a lens, we retell and analyze four design scenarios for smart homes that were created by participants with an IoT toolkit we designed. The selected design scenarios reveal practices that violate principles of responsible smart home design. Through our analysis we show (1) how participants explore sensor-driven objectification of the home then leverage data for surveillance, nudging, and control over others; (2) how the dominant technosolutionist narratives of efficiency and productivity ground such questionable values; (3) and how the materiality of mass-produced sensors pre-mediates questionable design scenarios. We discuss how to attend to and utilize questionable values in design: Making space for questionable values will empower design researchers to better “look around corners”, anticipating tomorrow's concerns and forestalling the worst of their harms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {629},
numpages = {14},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581140,
author = {Zhong, Ce and Wakkary, Ron and Odom, William and Wiberg, Mikael and Chen, Amy Yo Sue and Oogjes, Doenja and White, Jordan and Yoo, Minyoung},
title = {Exploring Long-Term Mediated Relations with a Shape-Changing Thing: A Field Study of CoMorphing Stool},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581140},
doi = {10.1145/3544548.3581140},
abstract = {This paper presents a long-term field study of the coMorphing stool: a computational thing that can change shape in response to the surrounding light. We deployed 5 coMorphing stools to 5 participants' homes over 9 months. As co-speculators, the participants reflected on their mediated relations with the coMorphing stool. Findings suggest that they perceived the subtle transformations of the coMorphing stool in the early days of the deployment. After becoming familiar with these features, they interpreted their daily entanglements with the coMorphing stool in diverse personalized ways. Over time, the co-speculators accepted the coMorphing stool as part of their homes. These findings contribute new empirical insights to the shape-changing research field in HCI and enrich discussions on higher-level concepts in postphenomenology. Reflecting on these experiences promotes further HCI explorations on computational things.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {630},
numpages = {14},
keywords = {Shape-changing things, Research through design, The Materiality of Interaction, Technological mediation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581012,
author = {Chen, Amy Yo Sue and Odom, William and Neustaedter, Carman and Zhong, Ce and Lin, Henry},
title = {Exploring Memory-Oriented Interactions with Digital Photos In and Across Time: A Field Study of Chronoscope},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581012},
doi = {10.1145/3544548.3581012},
abstract = {We describe a field study of Chronoscope, a tangible photo viewer that lets people revisit and explore their digital photos with the support of temporal metadata. Chronoscope offers different temporal modalities for organizing one's personal digital photo archive, and for exploring possible connections in and across time, and among photos and memories. We deployed four Chronoscopes in four households for three months to understand participants’ experiences over time. Our goals are to investigate the reflective potential of temporal modalities as an alternative design approach for supporting memory-oriented photo exploration, and empirically explore conceptual propositions related to slow technology. Findings revealed that Chronoscope catalyzed a range of reflective experiences on their respective life histories and life stories. It opened up alternative ways of considering time and the potential longevity of personal photo archives. We conclude with implications to present opportunities for future HCI research and practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {631},
numpages = {20},
keywords = {Interaction Design, Digital Photos, Memories, Temporality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581215,
author = {Kim, Wooseok and Jun, Jian and Lee, Minha and Lee, Sangsu},
title = {“I Won’t Go Speechless”: Design Exploration on a Real-Time Text-To-Speech Speaking Tool for Videoconferencing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581215},
doi = {10.1145/3544548.3581215},
abstract = {The COVID-19 pandemic has shifted many business activities to non-face-to-face activities, and videoconferencing has become a new paradigm. However, conference spaces isolated from surrounding interferences are not always readily available. People frequently participate in public places with unexpected crowds or acquaintances, such as caf\'{e}s, living rooms, and shared offices. These environments have surrounding limitations that potentially cause challenges in speaking up during videoconferencing. To alleviate these issues and support the users in speaking-restrained spatial contexts, we propose a text-to-speech (TTS) speaking tool as a new speaking method to support active videoconferencing participation. We derived the possibility of a TTS speaking tool and investigated the empirical challenges and user expectations of a TTS speaking tool using a technology probe and participatory design methodology. Based on our findings, we discuss the need for a TTS speaking tool and suggest design considerations for its application in videoconferencing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {632},
numpages = {20},
keywords = {Videoconferencing, Augmentative and alternative communication, Text-to-speech, User experience},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580807,
author = {Gaver, William and Gaver, Frances},
title = {Living with Light Touch: An Autoethnography of a Simple Communication Device in Long-Term Use},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580807},
doi = {10.1145/3544548.3580807},
abstract = {We are a mother and son who have been using a pair of simple, self-build communication devices to maintain a feeling of connection while separated by over 5,000 miles. The devices, called Light Touch, only allow us to send one another slowly-fading, coloured lights, yet we have been surprised by how much our ongoing interaction with them means to us. This paper contributes an autoethnographical account of our experiences over the last two years, including our initial experiences with the devices, and focusing on various aspects of our day-to-day use. Based on our observations, we discuss the features that have proven important in mediating our feelings of connection. We point out, however, that their success is contingent on our context of use and the nature of our bond, and suggest that simple systems like Light Touch may support emotional communication, but only if they are well-matched to settings and relationships.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {633},
numpages = {14},
keywords = {autoethnography, self-build, IoT, emotional communication, open source, research through design, autobiographical design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581363,
author = {Rajcic, Nina and McCormack, Jon},
title = {Message Ritual: A Posthuman Account of Living with Lamp},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581363},
doi = {10.1145/3544548.3581363},
abstract = {As we become increasingly entangled with digital technologies, the boundary between human and machine is progressively blurring. Adopting a performative, posthumanist perspective resolves this ambiguity by proposing that such boundaries are not predetermined, rather they are enacted within a certain material configuration. Using this approach, dubbed ‘Entanglement HCI’, this paper presents Message Ritual – a novel, integrated AI system that encourages the re-framing of memory through machine generated poetics. Embodied within a domestic table lamp, the system listens in on conversations occurring within the home, drawing out key topics and phrases of the day and reconstituting them through machine generated poetry, delivered to household members via SMS upon waking each morning. Participants across four households were asked to live with the lamp over a two week period. We present a diffractive analysis exploring how the lamp becomes with participants and discuss the implications of this method for future HCI research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {634},
numpages = {16},
keywords = {narrative, Augmented memory, diffractive analysis, poetry, generative networks, posthumanism},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581539,
author = {Liu, Guanhong and Ding, Xianghua(Sharon) and Cai, Jinghe and Wang, Weiyun and Wang, Xinyue and Diao, Yuting and Chen, Jin and Yu, Tianyu and Xu, Haiqing and Mi, Haipeng},
title = {Digital Making for Inheritance and Enlivening Intangible Cultural Heritage: A Case of Hairy Monkey Handicrafts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581539},
doi = {10.1145/3544548.3581539},
abstract = {Digital technologies can conduct an important role in preserving intangible cultural heritage (ICH). Nonetheless, existing work tends to be limited to digital storage, presentation, dissemination, and education, with comparatively little concentrating on production and reproduction of the craft, the key to revitalizing ICH. In this paper, we explore digital making as an approach for both the inheritance and innovation of ICH handicrafts. Taking Hairy Monkey craftsmanship as an instance, we conducted a workshop with 15 groups of makers, teaching them the traditional Hairy Monkey craft and subsequently enabling them to create innovative works with digital technologies in their own time. As revealed by our interviews with these participants, ICH brings cultural inspiration to digital making, and digital making rejuvenates ICH through innovative art forms and its positive influence on participants. As demonstrated in this paper, digital technologies can be deeply integrated with ICH through making to revitalize ICH from the core through living transmission.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {635},
numpages = {17},
keywords = {digital making, intangible culture heritage},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581497,
author = {Wo\'{z}niak, Miko\l{}aj P. and V\"{o}ge, Sarah and Kr\"{u}ger, Ronja and M\"{u}ller, Heiko and Koelle, Marion and Boll, Susanne},
title = {Inhabiting Interconnected Spaces: How Users Shape and Appropriate Their Smart Home Ecosystems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581497},
doi = {10.1145/3544548.3581497},
abstract = {Over the last decade, smart home technology (SHT) has become an integral part of modern households. As a result, smart home ecosystems blend with daily social life, appropriated and integrated into personalised domestic environments. The lived experience of inhabiting smart home ecosystems, however, is not yet understood, resulting in a mismatch between ecosystem design and inhabitants’ needs. Drawing on contextual inquiry methods, we conducted an explorative interview study (N=20) with SHT users in their homes. Our thematic analysis reveals how users shape their smart home ecosystems (SHEs), considering social relationships at home, perceived ownership of SHTs, and expected key benefits. Notably, our analysis shows that household members consciously choose ‘their’ level of SHT interconnectedness, reflecting social, spatial and functional affinities between systems. Following our findings, we formulate five implications for designing future SHTs. Our work contributes insights on the dynamics and appropriation of smart home ecosystems by their inhabitants.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {636},
numpages = {18},
keywords = {interconnectedness, smart home ecosystem, interactive spaces, smart home},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581234,
author = {Chau, Connie W. and Gerber, Elizabeth M.},
title = {On Hackathons: A Multidisciplinary Literature Review},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581234},
doi = {10.1145/3544548.3581234},
abstract = {The number of hackathon events worldwide has nearly quadrupled in the last five years. Despite exponential growth across diverse industries and increasing interest across academic disciplines, our integrated understanding of the phenomena of hackathons is limited. We conduct the first multidisciplinary literature review of publications from 1999 to 2022 to understand the conceptualization of the phenomena over time. We find that hackathon research can be categorized into 4 core areas (purpose, format, processes, and outcomes). Research was first driven by a purpose (innovation, learning, and collaboration), followed by an examination of how formats adjust to purpose to influence what happens (processes) and what is produced (outcomes), and critical reviews of the hackathon phenomena. We contribute a unifying framework with these four core areas to inform future directions of hackathon research and practice, as well as a discussion of the need for longitudinal and multidisciplinary research of hackathons.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {637},
numpages = {21},
keywords = {hackathons, literature review, multidisciplinary},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581462,
author = {Yun, Sojeong and Lim, Youn-Kyung},
title = {Potential and Challenges of DIY Smart Homes with an ML-Intensive Camera Sensor},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581462},
doi = {10.1145/3544548.3581462},
abstract = {Sensors and actuators are crucial components of a do-it-yourself (DIY) smart home system that enables users to construct smart home features successfully. In addition, machine learning (ML) (e.g., ML-intensive camera sensors) can be applied to sensor technology to increase its accuracy. Although camera sensors are often utilized in homes, research on user experiences with DIY smart home systems employing camera sensors is still in its infancy. This research investigates novel user experiences while constructing DIY smart home features using an ML-intensive camera sensor in contrast to commonly used IoT sensors. Thus, we conducted a seven-day field diary study with 12 families who were given a DIY smart home kit. Here, we assess the five characteristics of the camera sensor as well as the potential and challenges of utilizing the camera sensor in the DIY smart home and discuss the opportunities to address existing DIY smart home issues.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {638},
numpages = {19},
keywords = {camera sensor, machine learning, user experience, home sensor, DIY, smart home},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580684,
author = {Chang, Ruei-Che and Yong, Seraphina and Liao, Fang-Ying and Tsao, Chih-An and Chen, Bing-Yu},
title = {Understanding (Non-)Visual Needs for the Design of Laser-Cut Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580684},
doi = {10.1145/3544548.3580684},
abstract = {Laser-cutting is a promising fabrication method that empowers makers, including blind or visually-impaired (BVI) creators, to create technologies that fit their needs. Existing work on laser-cut accessibility has facilitated easier assembly as a workaround for existing models. However, laser-cut models are still not designed to accommodate the needs of BVI users. Integrating BVI needs can enrich the greater maker community by enabling cross-group discourse on laser-cut making. To investigate how laser-cut model design can be more accessible overall, we study laser-cut assembly as a process deeply intertwined with the fundamental design of laser-cut models. We present a study with seven sighted and seven BVI participants to compare their usage of laser-cut model affordances during assembly. Data for the BVI participants in this study originate from a previous work [13]. We identify assembly cues common or unique to sighted and BVI users, and discuss implications to improve general accessibility in laser-cut design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {639},
numpages = {20},
keywords = {Laser-cut Model Design, Assembling, Haptic Exploration, Making, Accessibility, Laser cutting, Prototyping},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581256,
author = {Margariti, Eleni and Vlachokyriakos, Vasilis and Kirk, David},
title = {Understanding Occupants’ Experiences in Quantified Buildings: Results from a Series of Exploratory Studies.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581256},
doi = {10.1145/3544548.3581256},
abstract = {Quantified smart buildings increasingly utilise data-rich technologies (such as embedded sensors and personal wearables). Research and development however, rarely addresses occupants’ experiences and expectations in such environments, which is critical for designing ethical and occupant-centred workspaces. To support the design of human-centred smart buildings, a series of 4 workshops was conducted with a total of 27 participants, over 2 months, with occupants of a smart office building. Workshops used discursive (focus group) and projective (design fiction) techniques to qualitatively explore occupants’ perceptions of and concerns around the collection, processing and use of data within the building. Workshop data was thematically analysed, resulting in design implications for improving occupant experience in current smart workplaces, while also contributing implications for increasing the perceivability, accessibility and usability of data in such buildings. Contributing to discourses around Human-Building Interaction the paper concludes with discussion of future research challenges for occupant-centred development of quantified buildings.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {640},
numpages = {15},
keywords = {Qualitative Methods, Human-Building Interaction, Workplaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581062,
author = {Ginosar, Eyal and Cauchard, Jessica R.},
title = {At First Light: Expressive Lights in Support of Drone-Initiated Communication},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581062},
doi = {10.1145/3544548.3581062},
abstract = {Drones are increasingly used in situations where they can assist a person. However, people are not familiar with drones approaching them. We propose an expressive light system embedded on a drone to convey its intention to initiate communication, which we present as a four-stage process: Drone-Initiated Engagement Model (DIEM). We then describe the design and development of an LED-based prototype divided in two configurations with a total of 26 light animations, and report their evaluation in an online survey (N = 156). We describe the suitability of different configurations, animations, and colors to convey each stage of DIEM. We finally validate our system in a user study (N = 45) that showed that participants can perceive all four stages of approach via the drone movement and that expressive lights provide a more nuanced user experience. We contribute insights into the design of expressive light systems, as a stepping stone towards machine-initiated communication.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {641},
numpages = {17},
keywords = {Human-Drone Interaction, Expressive lights, UAV, Non-verbal communication, Machine-initiated communication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581189,
author = {Wei\ss{}, Sebastian and Heuten, Wilko},
title = {Don’t Panic! - Influence of Virtual Stressor Representations from the ICU Context on Perceived Stress Levels},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581189},
doi = {10.1145/3544548.3581189},
abstract = {Intensive care nurses are prone to suffering from chronic stress due to constant exposure to two main profession-related stressors: interruption and time pressure. These stressors have detrimental effects on the well-being of the nursing staff and, by proxy, the patients. To alleviate stress, increase safety, and support the training of stressful scenarios, we investigate the impact these stressors have on subjective and objective stress levels in a virtual environment. We designed an intensive care unit in which participants (n=26, 18 healthcare professionals) perform common tasks, e.g. refilling an infusion pump, whilst being exposed to interruptions and time pressure. Results from our between-subjects study provide data indicating stress increase in both stressor conditions, suggesting that artificially evoking work-related stressors for stress inoculation training (SIT) is a possible extension to simulation training during nursing education. This knowledge is helpful for designing training scenarios of safety-critical situations early in the professional apprenticeship.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {642},
numpages = {15},
keywords = {Stress, Virtual Reality, Nursing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581293,
author = {Schneider, Adrian L. Jessup and Graham, T.C. Nicholas},
title = {Supporting Aim Assistance Algorithms through a Rapidly Trainable, Personalized Model of Players’ Spatial and Temporal Aiming Ability},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581293},
doi = {10.1145/3544548.3581293},
abstract = {Multiplayer digital games can use aim assistance to help people with different levels of aiming ability to play together. To dynamically provide each player with the right amount of assistance, an aim assistance algorithm needs a model of the player’s ability that can be measured and updated during gameplay. The model must be based on difficulty parameters such as target speed, size, and duration, that can be adjusted in-game to change aiming difficulty, and must account for player’s spatial and temporal aiming abilities. To satisfy these requirements, we present the novel dynamic spatiotemporal model of a player’s aiming ability, based on difficulty parameters that can be manipulated in a game. In a crowdsourced experiment with 72 participants, the model was found to accurately predict how close to a target a player can aim and to converge rapidly with a small set of observations of aiming tasks.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {643},
numpages = {17},
keywords = {personalization, dynamic difficulty adjustment, aim assistance, game balancing, dynamic player balancing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580877,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {SurfAirs: Surface&nbsp;+&nbsp;Mid-Air Input for Large Vertical Displays},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580877},
doi = {10.1145/3544548.3580877},
abstract = {Large vertical surfaces such as wall displays allow users to work with a very large and high-resolution workspace. Such displays promote physical navigation: users can step close to the display to see details, but also move away to get a wider view of the workspace. In terms of input, current solutions usually combine direct touch on the wall with input on a handheld device, disconnecting close and distant input rather than treating it as a continuum. We present SurfAirs, which are physical controllers that users can manipulate on screen (surface input), in the air (mid-air input), and transition from the surface to the air during a single manipulation (hybrid input). We report on two user studies that compare SurfAirs’ performance with bare-hand input for both mid-air and hybrid input. Participants prefer and perform better with SurfAirs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {644},
numpages = {15},
keywords = {Bare-hand input., Wall Displays, Tangible Input, Remote Controllers},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581263,
author = {Dai, Jiaxin and Zhang, Chao and Aliakseyeu, Dzmitry and Peeters, Samantha and Ijsselsteijn, Wijnand A},
title = {The Effect of Explanation Design on User Perception of Smart Home Lighting Systems: A Mixed-Method Investigation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581263},
doi = {10.1145/3544548.3581263},
abstract = {It has been shown that providing explanations about AI-based systems’ decisions can be an effective way to increase users’ trust and acceptance. The effect of explanation design in smart home systems on users’ acceptance and perceptions is however less known. We therefore explored the effect of different explanation designs on acceptance in the context of the Philips Hue smart home lighting system. We conducted interviews (N = 10) and an online experiment (N = 452) using three everyday smart home lighting scenarios with different explanation types. The results showed that although participants indicated a positive attitude towards explanations, receiving an explanation can potentially reduce the perceived control of the lighting system. Furthermore, participants preferred system-based explanations rather than user-based explanations. Our study also provides recommendations for the design of explanations in smart home systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {645},
numpages = {14},
keywords = {Empirical study that tells us about people, Home, Ambient Devices / Internet of Things, Smart Environments / Connected Home},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581154,
author = {Xygkou, Anna and Siriaraya, Panote and Covaci, Alexandra and Prigerson, Holly Gwen and Neimeyer, Robert and Ang, Chee Siang and She, Wan-Jou},
title = {The "Conversation" about Loss: Understanding How Chatbot Technology Was Used in Supporting People in Grief.},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581154},
doi = {10.1145/3544548.3581154},
abstract = {While conversational agents have traditionally been used for simple tasks such as scheduling meetings and customer service support, recent advancements have led researchers to examine their use in complex social situations, such as to provide emotional support and companionship. For mourners who could be vulnerable to the sense of loneliness and disruption of self-identity, such technology offers a unique way to help them cope with grief. In this study, we explore the potential benefits and risks of such a practice, through semi-structured interviews with 10 mourners who actively used chatbots at different phases of their loss. Our findings indicated seven approaches in which chatbots were used to help people cope with grief, by taking the role of listener, acting as a simulation of the deceased, romantic partner, friend and emotion coach. We then highlight how interacting with the chatbots impacted mourners’ grief experience, and conclude the paper with further research opportunities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {646},
numpages = {15},
keywords = {Grief/Prolonged Grief, Chatbot, Thanatechnology, Virtual Human, Digital Grieving, Conversational AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580689,
author = {Chen, Yu-Chun and Lee, Yu-Jen and Kao, Kuei-Chun and Tsai, Jie and Liang, En-Chi and Chiu, Wei-Chen and Shih, Faye and Chang, Yung-Ju},
title = {Are You Killing Time? Predicting Smartphone Users’ Time-Killing Moments via Fusion of Smartphone Sensor Data and Screenshots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580689},
doi = {10.1145/3544548.3580689},
abstract = {Time-killing on smartphones has become a pervasive activity, and could be opportune for delivering content to their users. This research is believed to be the first attempt at time-killing detection, which leverages the fusion of phone-sensor and screenshot data. We collected nearly one million user-annotated screenshots from 36 Android users. Using this dataset, we built a deep-learning fusion model, which achieved a precision of 0.83 and an AUROC of 0.72. We further employed a two-stage clustering approach to separate users into four groups according to the patterns of their phone-usage behaviors, and then built a fusion model for each group. The performance of the four models, though diverse, yielded better average precision of 0.87 and AUROC of 0.76, and was superior to that of the general/unified model shared among all users. We investigated and discussed the features of the four time-killing behavior clusters that explain why the models’ performance differ.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {647},
numpages = {19},
keywords = {Time-killing, Mobile Devices, Screenshot, Opportune Moment, Deep Learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580828,
author = {Han, Guhyun and Jung, Jaehun and Kim, Young-Ho and Seo, Jinwook},
title = {DataHalo: A Customizable Notification Visualization System for Personalized and Longitudinal Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580828},
doi = {10.1145/3544548.3580828},
abstract = {People struggle with the overflow of smartphone notifications but often face two challenges: (1) prioritizing the informative notifications as they wish and (2) retaining the delivered information as long as they want to utilize it. In this paper, we present DataHalo, a customizable notification visualization system that represents notifications as prolonged ambient visualizations on the home screen. DataHalo supports keyword-based filtering and categorization, and draws graphical marks based on time-varying importance model to enable longitudinal interaction with the notifications. We evaluated DataHalo through a usability study (N = 17), from which we improved the interface. We then conducted a three-week deployment study (N = 12) to assess how people use DataHalo in their domestic contexts. Our study revealed that people generated various visualization settings for different kinds of apps. Drawing on both quantitative and qualitative findings, we discussed implications for supporting effective notification management through customizable ambient visualizations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {648},
numpages = {21},
keywords = {ambient information visualization, smartphone notifications, personalization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580731,
author = {Tseng, Fang-Ching and Chiou, Zih-Yun and Chuang, Ho-Hsuan and Su, Li-Ting and Lin, Yong-Han and Lin, Yu-Rou and Lee, Yi-Chi and Wang, Peng-Jui and Chen, Uei-Dar and Chang, Yung-Ju},
title = {Multiple Device Users’ Actual and Ideal Cross-Device Usage for Multi-Stage Notification-Interactions: An ESM Study Addressing the Usage Gap and Impacts of Device Context},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580731},
doi = {10.1145/3544548.3580731},
abstract = {People nowadays can use multiple devices to interact with notifications, whether via noticing, glancing, reading, or acting upon them. Prior research has focused on actual usage or on device preferences. However, users’ ideal experience of cross-device notification-interaction might differ from their current practices (due to situational limitations) and/or across the four notification-interaction stages. We therefore conducted an experience-sampling method study with multi-device users to investigate these gaps and the influence of device context. Our results reveal that nearly half of the time, the non-phone devices the participants had ranked as their top preferences for notification-interaction were not actually used, due to the devices’ context. Beyond device context, the participants’ choices of devices for notification-interaction were heavily determined by 1) their preferences that particular notification-interaction stages to take place (or not) on particular devices; and 2) the device on which they had undertaken the former stage.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {15},
keywords = {Multi-Device, Experience Sampling Method, Notifications},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581146,
author = {Chang, Xi-Jing and Hsu, Fang-Hsin and Liang, En-Chi and Chiou, Zih-Yun and Chuang, Ho-Hsuan and Tseng, Fang-Ching and Lin, Yu-Hsin and Chang, Yung-Ju},
title = {Not Merely Deemed as Distraction: Investigating Smartphone Users’ Motivations for Notification-Interaction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581146},
doi = {10.1145/3544548.3581146},
abstract = {Notifications are commonly considered a distraction when they arrive during a task, and consequently, prior research has consistently sought effective ways of deferring their arrival until task transitions. However, many smartphone users still interact with notifications during tasks. In our qualitative study combining diary study and semi-structured interviews, we examined 34 research participants’ motivations for interacting with smartphone notifications at different times, including during tasks. Our findings resulted in a human-notification interaction framework comprised of 12 unique motivations frequently associated with three activity timings for interacting with notifications, including before-task, during-task, and after-task. Notably, participants frequently perceived interaction with notifications as a tool for improving task performance, making the most of their time, and promoting personal well-being, rather than only as a distraction. The before-the-task timing, in particular, has received little attention in previous research and deserves more attention as it was related to specific user motivations for notification interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {650},
numpages = {17},
keywords = {Opportune Moment, Attention Management, Multitasking, Interruptions, Notifications},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581052,
author = {Avgustis, Iuliia},
title = {Respecifying Phubbing: Video-Based Analysis of Smartphone Use in Co-Present Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581052},
doi = {10.1145/3544548.3581052},
abstract = {The concept of phubbing (generally defined as a practice of ignoring co-present others by focusing on one's mobile device) is now widely used in studies aiming to understand the effects of smartphone use on co-present interactions. However, most of these studies are quantitative in nature and fail to grasp the interactional context of smartphone use. Drawing on video recordings and utilizing multimodal interaction analysis, the present study examines phubbing in naturally occurring interactions among young adults. Contrary to most previous research, the analysis reveals that disengagement often precedes self-initiated smartphone use rather than follows it. The study identifies factors that affect whether phubbing is reciprocated and whether it is oriented to as problematic. As a result of the analysis, an alternative conceptualization of phubbing is offered. By reflecting on participants’ ways of managing phubbing and its consequences, we discuss design solutions for supporting them in this task.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {15},
keywords = {Smartphone use, Multiactivity, Disengagement, Video-based research, Face-to-face interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581163,
author = {Sergeeva, Anastasia and Rohles, Bj\"{o}rn and Distler, Verena and Koenig, Vincent},
title = {“We Need a Big Revolution in Email Advertising”: Users’ Perception of Persuasion in Permission-Based Advertising Emails},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581163},
doi = {10.1145/3544548.3581163},
abstract = {Persuasive tactics intend to encourage users to open advertising emails. However, these tactics can overwhelm users, which makes them frustrated and leads to lower open rates. This paper intends to understand which persuasive tactics are used and how they are perceived by users. We first developed a categorization of inbox-level persuasive tactics in permission-based advertising emails. We then asked participants to interact with an email inbox prototype, combined with interviews (N=32), to investigate their opinions towards advertising emails and underlying persuasive tactics. Our qualitative findings reveal poor user experience with advertising emails, which was related to feeling surveilled by companies, forced subscription, high prior knowledge about persuasive tactics, and a desire for more agency. We also found that using certain persuasive tactics on the inbox level is perceived as ethically inappropriate. Based on these insights, we provide design recommendations to improve advertising communication and make such emails more valuable to users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {652},
numpages = {21},
keywords = {Attitude, Subject Line, Reactance Theory, Persuasion, Email Advertising},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581480,
author = {Williams, Rua Mae and Boyd, Louanne and Gilbert, Juan E.},
title = {Counterventions: A Reparative Reflection on Interventionist HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581480},
doi = {10.1145/3544548.3581480},
abstract = {Research in HCI applied to clinical interventions relies on normative assumptions about which bodies and minds are healthy, valuable, and desirable. To disrupt this normalizing drive in HCI, we define a “counterventional approach” to intervention technology design informed by critical scholarship and community perspectives. This approach is meant to unsettle normative assumptions of intervention as urgent, necessary, and curative. We begin with a historical overview of intervention in HCI and its critics. Then, through reparative readings of past HCI projects in autism intervention, we illustrate the emergent principles of a counterventional approach and how it may manifest research outcomes that are fundamentally divergent from dominant approaches. We then explicate characteristics of “counterventions” – projects that aim to contest dominant sociotechnical paradigms through privileging community and participants in research inquiry, interaction design, and analysis of outcomes. These divergent research imaginaries have transformative implications for how interventionist HCI might be conducted in future.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {653},
numpages = {11},
keywords = {Critical Design, Critical Disability Studies, Crip HCI, Queer Theory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580885,
author = {Jones, Mirabelle and Neumayer, Christina and Shklovski, Irina},
title = {Embodying the Algorithm: Exploring Relationships with Large Language Models Through Artistic Performance},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580885},
doi = {10.1145/3544548.3580885},
abstract = {Despite the proliferation of research on how people engage with and experience algorithmic systems, the materiality and physicality of these experiences is often overlooked. We tend to forget about bodies. The Embodying the Algorithm1 project worked with artists to explore the experience of translating algorithmically produced performance instructions through human bodies. As performers interpreted the rules of engagement produced by GPT-3, they struggled with the lack of consideration the rules showed for the limits of the human body. Performers made sense of their experience through personification, reflexivity, and interpretation, which gave rise to three modes of relating with the algorithm – agonistic, perfunctory, and agreeable. We demonstrate that collaboration with algorithmic systems is ultimately impossible as people can only relate to algorithmic systems (a one-way relation) due to the material limitations of algorithmic systems for reciprocity, understanding, and consideration for the human body.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {654},
numpages = {24},
keywords = {Human-Computer Interaction, GPT-3, Embodiment, Algorithms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580717,
author = {Krysztoforska, Magdalena and Docherty, Niall and Biega, Asia J.},
title = {Integrative Objects in Sociotechnical Contexts: Constructing Digital Well-Being with Generic Epistemology},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580717},
doi = {10.1145/3544548.3580717},
abstract = {This paper presents a generative approach to interdisciplinary collaboration based on generic epistemology. Informed by the work of philosopher Anne-Fran\c{c}oise Schmid, we introduce the concept of the integrative object as a means to reorient interdisciplinary collaboration toward the requirements of the object of research itself, rather than via the requirements of particular disciplinary languages, methods, or operative logics. We show how such an approach is useful for research into sociotechnical phenomena that exceed the boundaries of discrete disciplines and their convergence. We introduce digital well-being as a case study, drawing on the authors’ own interdisciplinary collaborative experiences in this area as its empirical matter. From this, and in order to aid future research into similarly complex sociotechnical objects, we then provide practical tools to help those in the HCI community prepare and conduct interdisciplinary research in a similarly generative, non-dogmatic, and non-hierarchical manner.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {655},
numpages = {17},
keywords = {generic epistemology, interdisciplinarity, collaborative practice, critical theory, digital well-being, integrative objects, sociotechnical objects},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581505,
author = {Homewood, Sarah},
title = {Self-Tracking to Do Less: An Autoethnography of Long COVID That Informs the Design of Pacing Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581505},
doi = {10.1145/3544548.3581505},
abstract = {Long COVID is a post-viral illness where symptoms are still experienced more than three months after an infection of COVID 19. In line with a recent shift within HCI and research on self-tracking towards first-person methodologies, I present the results of an 18-month long autoethnographic study of using a Fitbit fitness tracker whilst having long COVID. In contrast to its designed intentions, I misused my Fitbit to do less in order to pace and manage my illness. My autoethnography illustrates three modes of using fitness tracking technologies to do less and points to the new design space of technologies for reducing, rather than increasing, activity in order to manage chronic illnesses where over-exertion would lead to a worsening of symptoms. I propose that these “pacing technologies” should acknowledge the interoceptive and fluctuating nature of the user's body and support user's decision-making when managing long-term illness and maintaining quality of life.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {656},
numpages = {14},
keywords = {COVID 19, autoethnography, Self-Tracking, Long COVID, Fitbit, fitness tracking technologies, Phenomenology, Heart-rate monitor, pacing technologies, Step counting, Post COVID-19 syndrome},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580823,
author = {Choi, Adrian and D'Ignazio, Catherine and Foucault Welles, Brooke and Parker, Andrea G},
title = {Social Media as a Critical Pedagogical Tool: Examining the Relationship between Youths’ Online Sociopolitical Engagements and Their Critical Consciousness},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580823},
doi = {10.1145/3544548.3580823},
abstract = {Social injustices are commonly discussed on social media, presenting opportunities for youth to engage with this content and develop into engaged citizens. While much has been written about youths’ online activism, less is known about how engaging with sociopolitical content may build their capacity for activist work. We explore the extent to which youths’ engagement with sociopolitical content on various social media platforms is associated with critical consciousness—an awareness of inequities, the motivation to address them, and action that combats injustice. To investigate this relationship, we conducted a survey with 339 high school-aged youths. While sociopolitical engagement on some platforms was positively associated with youths’ critical consciousness measures, sociopolitical engagement on other platforms was negatively associated. Qualitative post-hoc analysis was used to suggest reasons for possible differences. In light of our findings, we discuss the relationship between online sociopolitical engagement and critical consciousness and suggest directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {657},
numpages = {25},
keywords = {political participation, participatory politics, critical consciousness, civic engagement, youth, sociopolitical issues, social media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581450,
author = {Reime, Lara and Tsaknaki, Vasiliki and Cohn, Marisa Leavitt},
title = {Walking Through Normativities of Reproductive Bodies: A Method for Critical Analysis of Tracking Applications},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581450},
doi = {10.1145/3544548.3581450},
abstract = {Menstruation and fertility tracking applications are of increasing concern in HCI research, as their use becomes more widespread. Methods are needed to understand how such applications become entangled in everyday practices. While these apps promise increased self-knowledge of reproductive potential by collecting intimate data about reproductive bodies, they also restrict the knowledge produced about users’ bodies and embed normative understandings of reproduction and gender. In this paper, we scrutinize&nbsp;the normativities of reproductive bodies by deploying the “walkthrough method” to uncover sociotechnical entanglements of the menstruation and fertility apps Clue, Tilly, and Drip. We discuss how the walkthrough method contributes to HCI's methodological repertoire for studying intimate bodily tracking apps and unpacking their normativities. We offer suggestions for using this method to critically analyze existing apps and extend approaches to design with and for a plurality of in/fertile bodies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {658},
numpages = {15},
keywords = {methods, fertility, self-tracking, reproductive health},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580943,
author = {Nissen, Anika and Conrad, Colin and Newman, Aaron},
title = {Are You Human? Investigating the Perceptions and Evaluations of Virtual Versus Human Instagram Influencers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580943},
doi = {10.1145/3544548.3580943},
abstract = {Virtual influencers (VI) are on the rise on Instagram, and companies increasingly cooperate with them for marketing campaigns. This has motivated an increasing number of studies, which investigate our perceptions of these influencers. Most studies propose that VI are often rated lower in perceived trust and higher in uncanniness. Yet, we still lack a deeper understanding as to why this is the case. We conduct 2 studies: 1) a questionnaire with 150 participants to get the general perception for the included influencers, and 2) an electroencephalography (EEG) study to get insights into the underlying neural mechanisms of influencer perception. Our results support findings from related works regarding lower trust and higher uncanniness associated with VI. Interestingly, the EEG components N400 and LPP did not modulate perceived trust, but rather perceived humanness, uncanniness, and intentions to follow recommendations. This provides a fruitful beginning for future research on virtual humans.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {14},
keywords = {virtual influencers, social media, uncanny, avatars, trust, EEG},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581202,
author = {Scott, Lauren and Coventry, Lynne and Cecchinato, Marta E. and Warner, Mark},
title = {“I Figured Her Feeling a Little Bit Bad Was Worth It to Not Spread That Kind of Hate”: Exploring How UK Families Discuss and Challenge Misinformation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581202},
doi = {10.1145/3544548.3581202},
abstract = {Misinformation has become a regular occurrence in our lives with many different approaches being sought to address it. One effective way to combat misinformation is for trusted individuals (e.g., family members) to challenge the misinformed person. However, less is known about how these conversations between trusted individuals occur, and how they may impact on relationships. We look to address this gap by conducting semi-structured interviews with family members in the UK who have experienced misinformation within their family networks. We identify several barriers individuals face when challenging misinformed family members, such as the misinformed person’s personality and the extent that pre-conceptions influence beliefs. We also find individuals developing strategies to overcome these barriers, and to cope with difficulties that arise through these conversations. Despite technology being the main driver for misinformation spread, we find it has limitations when used to facilitate or mediate conversations for challenging misinformation between family members.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {660},
numpages = {15},
keywords = {Disinformation, Family, Propaganda, Misinformation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580773,
author = {Im, Jane and Wang, Ruiyi and Lyu, Weikun and Cook, Nick and Habib, Hana and Cranor, Lorrie Faith and Banovic, Nikola and Schaub, Florian},
title = {Less is Not More: Improving Findability and Actionability of Privacy Controls for Online Behavioral Advertising},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580773},
doi = {10.1145/3544548.3580773},
abstract = {Tech companies that rely on ads for business argue that users have control over their data via ad privacy settings. However, these ad settings are often hidden. This work aims to inform the design of findable ad controls and study their impact on users’ behavior and sentiment. We iteratively designed ad control interfaces that varied in the setting’s (1) entry point (within ads, at the feed’s top) and (2) level of actionability, with high actionability directly surfacing links to specific advertisement settings, and low actionability pointing to general settings pages (which is reminiscent of companies’ current approach to ad controls). We built a Chrome extension that augments Facebook with our experimental ad control interfaces and conducted a between-subjects online experiment with 110 participants. Results showed that entry points within ads or at the feed’s top, and high actionability interfaces, both increased Facebook ad settings’ findability and discoverability, as well as participants’ perceived usability of them. High actionability also reduced users’ effort in finding ad settings. Participants perceived high and low actionability as equally usable, which shows it is possible to design more actionable ad controls without overwhelming users. We conclude by emphasizing the importance of regulation to provide specific and research-informed requirements to companies on how to design usable ad controls.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {661},
numpages = {33},
keywords = {advertising, user interface, ad settings, Privacy, consent., social media, usability, social platforms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581328,
author = {Hassoun, Amelia and Beacock, Ian and Consolvo, Sunny and Goldberg, Beth and Kelley, Patrick Gage and Russell, Daniel M.},
title = {Practicing Information Sensibility: How Gen Z Engages with Online Information},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581328},
doi = {10.1145/3544548.3581328},
abstract = {Assessing the trustworthiness of information online is complicated. Literacy-based paradigms are both widely used to help and widely critiqued. We conducted a study with 35 Gen Zers from across the U.S. to understand how they assess information online. We found that they tended to encounter—rather than search for—information, and that those encounters were shaped more by social motivations than by truth-seeking queries. For them, information processing is fundamentally a social practice. Gen Zers interpreted online information together, as aspirational members of social groups. Our participants sought information sensibility: a socially-informed awareness of the value of information encountered online. We outline key challenges they faced and practices they used to make sense of information. Our findings suggest that like their information sensibility practices, solutions and strategies to address misinformation should be embedded in social contexts online.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {662},
numpages = {17},
keywords = {misinformation, social media, youth, teens, disinformation, information sensibility, information literacy, Gen Z, rumors, search},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581498,
author = {Sharma, Tanusree and Kaushik, Smirity and Yu, Yaman and Ahmed, Syed Ishtiaque and Wang, Yang},
title = {User Perceptions and Experiences of Targeted Ads on Social Media Platforms: Learning from Bangladesh and India},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581498},
doi = {10.1145/3544548.3581498},
abstract = {While people’s perceptions of targeted ads have been studied extensively from a Western perspective&nbsp;(e.g., North America, Europe), we know little about users’ perceptions in the South Asian region. We interviewed 40 participants from two South Asian countries, Bangladesh and India, to explore their perceptions and practices regarding targeted ads on social media platforms. Participants identified emerging ad types, such as influencer-based ads and soft ads, through articles. In addition, participants often outweighed discounts over product quality when viewing ads. We also observed novel user mental models of targeted ads based on mobile app permissions and excessive AI usage. Participants often preferred ad control over transparency. While most participants rarely used ad settings, some controlled ads by changing mobile app permissions or muting ads on social media platforms. Participants also raised concerns about fraudulent targeted ads and privacy violations due to device sharing. We present potential design ideas to mitigate these concerns.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {663},
numpages = {15},
keywords = {Targeted Advertisement, Privacy, South Asia},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580826,
author = {Tanaka, Yuko and Inuzuka, Miwa and Arai, Hiromi and Takahashi, Yoichi and Kukita, Minao and Inui, Kentaro},
title = {Who Does Not Benefit from Fact-Checking Websites? A Psychological Characteristic Predicts the Selective Avoidance of Clicking Uncongenial Facts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580826},
doi = {10.1145/3544548.3580826},
abstract = {Fact-checking messages are shared or ignored subjectively. Users tend to seek like-minded information and ignore information that conflicts with their preexisting beliefs, leaving like-minded misinformation uncontrolled on the Internet. To understand the factors that distract fact-checking engagement, we investigated the psychological characteristics associated with users’ selective avoidance of clicking uncongenial facts. In a pre-registered experiment, we measured participants’ (N = 506) preexisting beliefs about COVID-19-related news stimuli. We then examined whether they clicked on fact-checking links to false news that they believed to be accurate. We proposed an index that divided participants into fact-avoidance and fact-exposure groups using a mathematical baseline. The results indicated that 43% of participants selectively avoided clicking on uncongenial facts, keeping 93% of their false beliefs intact. Reflexiveness is the psychological characteristic that predicts selective avoidance. We discuss susceptibility to click bias that prevents users from utilizing fact-checking websites and the implications for future design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {664},
numpages = {17},
keywords = {Fact-checking, Click bias, Psychological factor, Misinformation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581331,
author = {Shusas, Erica and Skeba, Patrick and Baumer, Eric P. S. and Forte, Andrea},
title = {Accounting for Privacy Pluralism: Lessons and Strategies from Community-Based Privacy Groups},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581331},
doi = {10.1145/3544548.3581331},
abstract = {The emergent, dynamic nature of privacy concerns in a shifting sociotechnical landscape creates a constant need for privacy-related resources and education. One response to this need is community-based privacy groups. We studied privacy groups that host meetings in diverse urban communities and interviewed the meeting organizers to see how they grapple with potentially varied and changeable privacy concerns. Our analysis identified three features of how privacy groups are organized to serve diverse constituencies: situating (finding the right venue for meetings), structuring (finding the right format/content for the meeting), and providing support (offering varied dimensions of assistance). We use these findings to inform a discussion of “privacy pluralism” as a perennial challenge for the HCI privacy research community, and we use the practices of privacy groups as an anchor for reflection on research practices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {665},
numpages = {12},
keywords = {privacy resources, privacy, privacy groups, meetup, community organizations, privacy pluralism},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580730,
author = {Hamilton, Vaughn and Soneji, Ananta and Mcdonald, Allison and Redmiles, Elissa M.},
title = {“Nudes? Shouldn’t I Charge for These?”: Motivations of New Sexual Content Creators on OnlyFans},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580730},
doi = {10.1145/3544548.3580730},
abstract = {With over 1.5 million content creators, OnlyFans is one of the fastest growing subscription-based social media platforms. The platform is primarily associated with sexual content. Thus, OnlyFans creators are uniquely positioned at the intersection of professional social media content creation and sex work. While the motivations of experienced sex workers to adopt OnlyFans have been studied, in this work we seek to understand the motivations of creators who had not previously done sex work. Through a qualitative interview study of 22 U.S.-based OnlyFans creators, we find that beyond the typical motivations for pursuing gig work (e.g., flexibility, autonomy), our participants were motivated by three key factors: (1) societal visibility and mainstream acceptance of OnlyFans; (2) platform design and affordances such as boundary-setting with clients, privacy from the public, and content archives; and (3) the pandemic, as OnlyFans provided an enormous opportunity to overcome lockdown-related issues.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {666},
numpages = {14},
keywords = {pandemic, digital labor, OnlyFans, computer-supported cooperative work, sexual expression, digital sex work, gig work, platform labour, informal labor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581036,
author = {Choe, Youjin and Tomko, Martin and Kalantari, Mohsen},
title = {Producer Conflict Management Approaches in Online Peer Production Communities – Case Study of OpenStreetMap},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581036},
doi = {10.1145/3544548.3581036},
abstract = {Producers of online peer-production communities (OPPCs) regularly experience conflicts with other producers. A deeper understanding of the producer conflict management approaches employed by community members could help OPPCs improve their conflict management tools. In this paper, we analyze the effectiveness of conflict management approaches employed by producers. Using OpenStreetMap (OSM) as a case study, we manually annotate OSM mappers’ conflict management approaches from 384 online discussion threads contained in one of OSM’s public communication channels. We investigate the effectiveness of conflict management by verifying whether producer discussions led to a solution. Our results show that online producer conflict management approaches with empathetic and proactive listening behaviors were more likely to reach a productive solution, whereas those approaches with negative online behaviors were less likely to do so. Based on these results, we reflect on how the user interface of OSM’s public online communication channels could better support producers to manage conflict behaviors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {667},
numpages = {12},
keywords = {OpenStreetMap, Conflict management approach, user interface design, online discussion},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581476,
author = {Zhang, Yu and He, Changyang and Wang, Huanchen and Lu, Zhicong},
title = {Understanding Communication Strategies and Viewer Engagement with Science Knowledge Videos on Bilibili},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581476},
doi = {10.1145/3544548.3581476},
abstract = {As a popular form of online media, videos have been widely used to communicate scientific knowledge on video-sharing platforms. These science knowledge videos take advantage of rich and multi-modality information which has the potential to provoke public engagement with science knowledge and promote self-learning. However, how communicators strategically make science knowledge videos to engage viewers, and how specific communication strategies correlate with viewer engagement remain under-explored. In this paper, we first established a taxonomy of communication strategies currently used in science knowledge videos on Bilibili and then examined the correlations between communication strategies and viewers’ behavioral, emotional, and cognitive engagements measured by post-video comments. Our findings revealed the landscape of rich science communication strategies in science knowledge videos and further uncovered the correlations between these strategies and viewer engagements. We situated our results within prior research on science communication and HCI, and provided design implications for video-sharing platforms to support effective science communication.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {668},
numpages = {18},
keywords = {Science communication, Online video platforms},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580982,
author = {Cai, Jie and Wohn, Donghee Yvette},
title = {Understanding Moderators’ Conflict and Conflict Management Strategies with Streamers in Live Streaming Communities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580982},
doi = {10.1145/3544548.3580982},
abstract = {As each micro community centered around the streamer attempts to set its own guidelines in live streaming communities, it is common for volunteer moderators (mods) and the streamer to disagree on how to handle various situations. In this study, we conducted an online survey (N=240) with live streaming mods to explore their commitment to the streamer to grow the micro community and the different styles in which they handle conflicts with the streamer. We found that 1) mods apply more active and cooperative styles than passive and assertive styles to manage conflicts, but they might be forced to do so, and 2) mods with strong commitments to the streamer would like to apply styles showing either high concerns for the streamer or low concerns for themselves. We reflect on how these results can affect micro community development and recommend designs to mitigate conflict and strengthen commitment.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {669},
numpages = {12},
keywords = {Conflict, Live Streaming Moderator, Streamer-Moderator Relationship, Conflict Management, Content Moderation, Commitment},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581019,
author = {Zhang, Yixuan and Gaggiano, Joseph D and Yongsatianchot, Nutchanon and Suhaimi, Nurul M and Kim, Miso and Sun, Yifan and Griffin, Jacqueline and Parker, Andrea G},
title = {What Do We Mean When We Talk about Trust in Social Media? A Systematic Review},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581019},
doi = {10.1145/3544548.3581019},
abstract = {Do people trust social media? If so, why, in what contexts, and how does that trust impact their lives? Researchers, companies, and journalists alike have increasingly investigated these questions, which are fundamental to understanding social media interactions and their implications for society. However, trust in social media is a complex concept, and there is conflicting evidence about the antecedents and implications of trusting social media content, users, and platforms. More problematic is that we lack basic agreement as to what trust means in the context of social media. Addressing these challenges, we conducted a systematic review to identify themes and challenges in this field. Through our analysis of 70 papers, we contribute a synthesis of how trust in social media is defined, conceptualized, and measured, a summary of trust antecedents in social media, an understanding of how trust in social media impacts behaviors and attitudes, and directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {670},
numpages = {22},
keywords = {social media, trust, systematic review},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581074,
author = {Seth, Agrima and Cao, Jiyin and Shi, Xiaolin and Dotsch, Ron and Liu, Yozen and Bos, Maarten W.},
title = {Cultural Differences in Friendship Network Behaviors: A Snapchat Case Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581074},
doi = {10.1145/3544548.3581074},
abstract = {Culture shapes people’s behavior, both online and offline. Surprisingly, there is sparse research on how cultural context affects network formation and content consumption on social media. We analyzed the friendship networks and dyadic relations between content producers and consumers across 73 countries through a cultural lens in a closed-network setting. Closed networks allow for intimate bonds and self-expression, providing a natural setting to study cultural differences in behavior. We studied three theoretical frameworks of culture - individualism, relational mobility, and tightness. We found that friendship networks formed across different cultures differ in egocentricity, meaning the connectedness between a user’s friends. Individualism, mobility, and looseness also significantly negatively impact how tie strength affects content consumption. Our findings show how culture affects social media behavior, and we outline how researchers can incorporate this in their work. Our work has implications for content recommendations and can improve content engagement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {671},
numpages = {14},
keywords = {relationship modeling, tie strength, Cross-cultural analysis, Social media platforms, Social ties, User Behavior Modeling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581333,
author = {Sannon, Shruti and Young, Jordyn and Shusas, Erica and Forte, Andrea},
title = {Disability Activism on Social Media: Sociotechnical Challenges in the Pursuit of Visibility},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581333},
doi = {10.1145/3544548.3581333},
abstract = {Activism efforts have played a central role in advancing the rights of disabled people in the United States. Social media offers new opportunities for people with disabilities to engage in activism while bypassing the accessibility issues involved in traditional activism. At the same time, disabled people face various forms of social and technical exclusion that may also complicate their use of social media for disability activism. To understand how disabled activists advocate for social change online, we interviewed 20 disabled content creators about their goals, strategies, and challenges around posting activism content on social media. We find that visibility is essential for successful online activism, but that the pursuit of visibility requires disabled content creators to navigate additional challenges including social stigma, algorithmic suppression, accessibility issues, and a heightened risk of harassment. We identify three main types of disability-related harassment faced by disabled activists, along with six ways in which they respond to such harassment. We examine the sociotechnical nature of the strategies disabled activists use to gain visibility, and identify key trade-offs involved in mitigating harassment while engaging in activism on social media.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {672},
numpages = {15},
keywords = {activism, risk, stigma, harassment, algorithms, accessibility, marginalization, disability, visibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581324,
author = {Sackitey, Darley and O'Leary, Teresa K. and Paasche-Orlow, Michael and Bickmore, Timothy and Parker, Andrea G},
title = {"Everyone is Covered": Exploring the Role of Online Interactions in Facilitating Connection and Social Support in Black Churches},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581324},
doi = {10.1145/3544548.3581324},
abstract = {Faith institutions provide social support and community care for many in the United States (U.S.). Notably, churches with predominantly Black populations have served as a site for social change and care provision, historically and in contemporary society. However, the pandemic has emphasised how localising these care networks in physical spaces can limit access to social support. Information and communication technologies offer opportunities for expanding access to care in these communities. However, integrating care networks into online contexts remains a challenge for many churches, and the potential for technology to expand these networks is not well understood. Through interviews and focus groups with nine church members, we explore how hybrid faith communities that bridge offline and online contexts can enable social support and care provision. Our findings highlight care network structures in Black churches, barriers to embedding these networks online and strategies for building more seamless hybrid support systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {673},
numpages = {17},
keywords = {online communities, techno-spirituality, faith-based technology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580898,
author = {Chou, Yu-Ling and Lee, Hsuan-Jen and Tsai, Jie and Liang, En-Chi and Chang, Yung-Ju},
title = {I Like Their Autonomy and Closeness to Me: Uncovering the Perceived Appeal of Social-Media Influencers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580898},
doi = {10.1145/3544548.3580898},
abstract = {The proliferation of influencers on social-media platforms has drawn considerable research attention, particularly in the field of marketing. Nevertheless, there is limited understanding among HCI and communication researchers of what leads these social-media influencers’ (SMIs’) audiences to favor and choose their content over traditional media. To fill this gap, we conducted semi-structured interviews with 45 SMI audience members. Our findings revealed a total of eight categories of SMIs’ appeals, i.e., factors that made the interviewees favor their content over traditional media. These appeals can further be grouped into three categories: content, presentation, and closeness. In particular, we identified the key role of SMIs’ perceived high autonomy and independence, which led both their content and their presentation styles to be seen as distinct from and more appealing than traditional media. Likewise, four closeness appeals made our participants feel emotionally attached to SMIs, resulting in sustained engagement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {674},
numpages = {19},
keywords = {social media influencer, traditional media, appeal, qualitative},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580990,
author = {Jiang, Julie and Dotsch, Ron and Triguero Roura, Mireia and Liu, Yozen and Silva, V\'{\i}tor and Bos, Maarten W. and Barbieri, Francesco},
title = {Reciprocity, Homophily, and Social Network Effects in Pictorial Communication: A Case Study of Bitmoji Stickers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580990},
doi = {10.1145/3544548.3580990},
abstract = {Pictorial emojis and stickers are commonly used in online social communications. We analyzed social communications using Bitmoji stickers, which are expressive pictorial stickers made from avatars resembling actual users. We collect a large-scale dataset of 3 billion Bitmoji stickers’ metadata, shared among 300 million Snapchat users. We find that individual Bitmoji sticker usage patterns can be characterized jointly on dimensions of reciprocity and selectivity. Generally speaking, users are either both reciprocal and selective about whom they use Bitmoji stickers with or neither reciprocal nor selective. We additionally demonstrate network homophily by showing that friends use Bitmoji stickers at similar rates. Finally, using a quasi-experimental approach, we show that receiving Bitmoji stickers from a friend encourages future Bitmoji sticker usage and overall Snapchat engagement. Our work carries implications for a better understanding of online pictorial communication behaviors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {675},
numpages = {14},
keywords = {reciprocity, pictorial, stickers, homophily, non-verbal, Bitmoji, Snapchat, social networks, behavioral contagion, social contagion},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581102,
author = {Shakeri, Hanieh and Geiskkovitch, Denise Y. and Garg, Radhika and Neustaedter, Carman},
title = {Sensing Their Presence: How Emerging Adults And Their Parents Connect After Moving Apart},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581102},
doi = {10.1145/3544548.3581102},
abstract = {When emerging adults move out of their parents’ homes for the first time, their needs for togetherness and connection evolve, as do their parents’. In co-located homes, people often experience togetherness passively by sensing one another’s presence in their environment. However, when no longer living together, methods of experiencing togetherness change. Thus, we conducted an interview and co-design study with 16 pairs of parents and emerging adults that explores this concept across distance. The study uncovered differences in the connection needs of emerging adults and their parents, including their goals in connecting, the amount of communication they needed, and their needs for privacy and transparency. We additionally found that passive connecting factors included ambient sounds of the home, visual shared experiences and traces of one another in the home, ambient home smellscapes and smell memories, touching left-behind objects or gifted objects, and the taste of family recipes and the ambience of family mealtimes. We discuss suggestions for designing for passive co-presence based on this new knowledge.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {676},
numpages = {18},
keywords = {young adults, passive togetherness, codesign study, emerging adults, sensing presence, parents},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580968,
author = {Krath, Jeanine and Altmeyer, Maximilian and Tondello, Gustavo F. and Nacke, Lennart E.},
title = {Hexad-12: Developing and Validating a Short Version of the Gamification User Types Hexad Scale},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580968},
doi = {10.1145/3544548.3580968},
abstract = {The Hexad scale is a crucial tool for personalized gamification in user experience (UX) design. However, completing a 24-item questionnaire can increase dropout rates and screen fatigue within online surveys. When included in larger surveys, scale brevity makes a difference. To reduce the time required for the assessment process, we developed and validated a 12-item version of the Hexad scale. To create it, we carried out an exploratory factor analysis on an existing data set to identify appropriate items (n = 882). To validate the 12-item version, we conducted a confirmatory factor analysis on a new data set (n = 1, 101). Our results show that Hexad-12 outperforms the original Hexad scale regarding model fit, reliability, convergent, and discriminant validity. Therefore, Hexad-12 resolves issues found in studies using the original Hexad scale and provides a suitable and swift instrument for concisely assessing Hexad user types in tailored gamification design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {677},
numpages = {18},
keywords = {Gamification, User Types, Personalization, Player Types, Hexad, Adaptive Gamification, Tailored Gamification},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581428,
author = {Schade, Eve and Savino, Gian-Luca and Niess, Jasmin and Sch\"{o}ning, Johannes},
title = {MapUncover: Fostering Spatial Exploration through Gamification in Mobile Map Apps},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581428},
doi = {10.1145/3544548.3581428},
abstract = {Getting from A to B has never been easier. Mobile navigation systems allow universal access to spatial information. However, following detailed route instructions leads to a decrease in spatial exploration behaviour and therefore a reduction of spatial knowledge acquisition. Facilitating spatial exploration has the potential to counteract this negative effect. This paper investigates how we can support people in re-discovering their surroundings. We designed and evaluated a mobile application to promote spatial exploration through gamification. The app requires active exploration behaviour to uncover a map. Gamification elements such as quests, statistics, and social competition are used to encourage exploration. We conducted an exploratory field study (n = 22). Our results show a significant increase in familiarity with the environment and a variety of exploration patterns. Based on our findings, we propose modifications to current mapping applications by limiting the visible cartographic elements and alternating routes to improve spatial knowledge acquisition.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {678},
numpages = {13},
keywords = {navigation, field-study, mobile, mobile spatial gamification, exploration, wayfinding},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581375,
author = {Mutalova, Renata and Sarrazin-Gendron, Roman and Cai, Eddie and Richard, Gabriel and Ghasemloo Gheidari, Parham and Caisse, S\'{e}bastien and Knight, Rob and Blanchette, Mathieu and Szantner, Attila and Waldisp\"{u}hl, J\'{e}r\^{o}me},
title = {Playing the System: Can Puzzle Players Teach Us How to Solve Hard Problems?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581375},
doi = {10.1145/3544548.3581375},
abstract = {With nearly three billion players, video games are more popular than ever. Casual puzzle games are among the most played categories. These games capitalize on the players’ analytical and problem-solving skills. Can we leverage these abilities to teach ourselves how to solve complex combinatorial problems? In this study, we harness the collective wisdom of millions of players to tackle the classical NP-hard problem of multiple sequence alignment, relevant to many areas of biology and medicine. We show that Borderlands Science players propose solutions to multiple sequence alignment tasks that perform as well or better than standard approaches, while exploring a much larger area of the Pareto-optimal solution space. We also show the strategies of the players, although highly heterogeneous, follow a collective logic that can be mimicked with Behavioral Cloning with minimal performance loss, allowing the players’ collective wisdom to be leveraged for alignment of any sequences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {679},
numpages = {15},
keywords = {video games, transformers, reinforcement learning, multiple sequence alignment, fully convolutional networks, behavioural cloning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581142,
author = {Mills, Chelsea and Geiskkovitch, Denise Y. and Neustaedter, Carman and Odom, William and Axtell, Benett},
title = {Remote Wavelength: Design and Evaluation of a System for Social Connectedness Through Distributed Tabletop Gameplay},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581142},
doi = {10.1145/3544548.3581142},
abstract = {Playing remote tabletop games is a fun way to connect with distant friends. Yet most systems for remote tabletop gaming lack support for tangible and social interaction, two important aspects of gameplay for most players. We are interested in how to better design systems for remote tangible gameplay that support social connection. We investigate this topic through the design and evaluation of a prototype system for playing the board game Wavelength across two locations. First, we describe the design goals that informed our prototype: “Remote Wavelength”. Then, we discuss the results of a qualitative user study in which ten friend groups played Remote Wavelength. Our findings indicate that a synchronized, tangible gameboard benefits player engagement, communication, and awareness. Our results also illustrate the value of integration across communication and gameplay systems. We conclude by offering considerations for the design of both digital and remote tangible gameplay systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {680},
numpages = {19},
keywords = {Tangible, Prototype, Social connection, Design, Distributed, Tabletop games, Remote, Friends},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581544,
author = {Xu, Jiangnan and Papangelis, Konstantinos and Dunham, John and Boulanger, Cati and Lee, Jin Ha and Lalone, Nicolas and Saker, Michael},
title = {Understanding Social Interactions in Location-Based Games as Hybrid Spaces: Coordination and Collaboration in Raiding in Pok\'{e}mon GO},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581544},
doi = {10.1145/3544548.3581544},
abstract = {The overlaying of physical spaces with digital information produces hybrid spaces, redefining people’s experience of social interactions. Location-based games (LBGs) with social components are a good case. Yet, the impact LBGs have on sociability remains under-researched. In April 2020, the new in-person/remote raiding format in the LBG Pok\'{e}mon GO provided a lens to explore people’s social interactions in hybrid spaces. We interviewed 41 Pok\'{e}mon GO players to understand how players coordinate and collaborate for in-person/remote raids and other social patterns. Our findings demonstrate that new social dynamics occurred: participants’ social interactions highly rely on external social media groups bridging cyberspace and the physical world. In such external social media groups, spontaneously formed leadership roles and mentor-mentee relationships demonstrate autonomy among players in the hybrid space. However, we observed that the interoperability issue challenges people’s experience. Overall, this work sheds light on the social interactions in LBGs as hybrid spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {681},
numpages = {19},
keywords = {location-based games, social interaction, interoperability, hybrid spaces},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580664,
author = {Kleinman, Erica and Villareale, Jennifer and Shergadwala, Murtuza N. and Teng, Zhaoqing and Bryant, Andy and Zhu, Jichen and El-Nasr, Magy Seif},
title = {"What Else Can I Do?" Examining the Impact of Community Data on Adaptation and Quality of Reflection in an Educational Game},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580664},
doi = {10.1145/3544548.3580664},
abstract = {Adaptation, or ability and willingness to consider an alternative approach, is a critical component of learning through reflection, especially in educational games, where there are often multiple avenues to success. As a domain, educational games have shown increased interest in using retrospective visualizations to promote and support reflection. Such visualizations, which can facilitate comparison with peer data, may also have an impact on adaptation in educational games. This has, however, not been empirically examined within the domain. In this work, we examine how comparison with other players’ data influenced adaptation, a part of reflection, in the context of a game that teaches parallel programming. Our results indicate that comparison with peers does significantly impact willingness to try a different approach, but suggest that there may also be other ways. We discuss what these results mean for future use of retrospective visualizations in educational games and present opportunities for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {682},
numpages = {12},
keywords = {community data, reflection, adaptation, learning, educational games, retrospective visualization, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580722,
author = {Luft, Yoav and Karpashevich, Pavel and H\"{o}\"{o}k, Kristina},
title = {Boards Hit Back: Reflecting on Martial Arts Practices Through Soma Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580722},
doi = {10.1145/3544548.3580722},
abstract = {There is an increasing interest in the HCI community in designing for bodily practices. We report on a soma design process for martial arts and the resulting artifact – an interactive wooden dummy. Through a detailed account of the design process, we show how it enriched and revamped the bodily practice, but also how it changed the martial arts expert in the design team. Based on a phenomenological account of his experiences, we argue that the estrangement methods in soma design may allow practitioners engaging as soma designers, to cultivate and create new artistic habits fused with thought and feeling, changing themselves and their practice in directions they seek.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {683},
numpages = {18},
keywords = {Martial Arts, Embodied Interaction, Design, Soma Design, Bodily Practices},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581543,
author = {Bang, Tove Grimstad and Fdili Alaoui, Sarah and Schwartz, Elisabeth},
title = {Designing in Conversation With Dance Practice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581543},
doi = {10.1145/3544548.3581543},
abstract = {We present a long-term collaboration between dancers and designers, centred around the transmission of the century-old repertoire of modern dance pioneer Isadora Duncan. We engaged in a co-design process with a Duncanian dancer consisting of conversations and participation in her transmission of Duncan’s choreographies and technique. We then articulated experiential qualities central to Duncan’s repertoire and used them to guide the design of the probes, the sounding scarfs. Our probes sonify dancers’ movements using temporal sensors embedded in the fabric of the scarfs, with the goal of evoking Duncan’s work and legacy. We shared the probes with our Duncan dance community and found that they deepen the dancers’ engagement with the repertoire. Finally, we discuss how co-designing with slowness and humility were key to the dialogue created between the practitioners, allowing for seamless integration of design research and dance practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {684},
numpages = {16},
keywords = {longitudinal study, Dance, co-design, sonification, first-person perspectives, soma design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580977,
author = {N\'{u}\~{n}ez-Pacheco, Claudia and Frid, Emma},
title = {Sharing Earthquake Narratives: Making Space for Others in Our Autobiographical Design Process},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580977},
doi = {10.1145/3544548.3580977},
abstract = {As interaction designers are venturing to design for others based on autobiographical experiences, it becomes particularly relevant to critically distinguish the designer’s voice from others’ experiences. However, few reports go into detail about how self and others mutually shape the design process and how to incorporate external evaluation into these designs. We describe a one-year process involving the design and evaluation of a prototype combining haptics and storytelling, aiming to materialise and share somatic memories of earthquakes experienced by a designer and her partner. We contribute with three strategies for bringing others into our autobiographical processes, avoiding the dilution of first-person voices while critically addressing design flaws that might hinder the representation of our stories.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {685},
numpages = {18},
keywords = {HCI, autobiographical design, first-person research, soma design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581502,
author = {Karlgren, Kasper and Mcmillan, Donald},
title = {Sleep Planning with Awari: Uncovering the Materiality of Body&nbsp;Rhythms Using Research through Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581502},
doi = {10.1145/3544548.3581502},
abstract = {With the increasing adoption of body tracking technology, users are able to collect bio-data which designers struggle to make legible or actionable. This work focused on increasing this technology-mediated bodily understanding through exploring the material properties of the body rhythms that govern the sleep behaviours being tracked. Building from a workshop with non-normative sleepers, we reframe sleep tracking to be about understanding and manipulating body rhythms. We explore these rhythms through the RtD process of designing the Awari alertness-forecast and scheduling application in four iterations. This resulted in three non-exclusive categories of rhythmic influence: Slow &amp; Cyclical, Pressure &amp; Release, and Anchored. Through a better understanding of how they interact, their inertia, and their material properties for interaction we encourage the design of technology to shape, and be shaped, by the complex rhythms of life. We discuss ways in which this can democratise medical-models, and make actionable complex bodily processes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {686},
numpages = {17},
keywords = {Health Informatics, Self-tracking, Personal Informatics, Research Through Design, Sleep, Speculative Design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581488,
author = {Bang, Tove Grimstad and Fdili Alaoui, Sarah},
title = {Suspended Circles: Soma Designing a Musical Instrument},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581488},
doi = {10.1145/3544548.3581488},
abstract = {We present a soma design process of a digital musical instrument grounded in the designer’s first-person perspective of practicing Dalcroze eurhythmics, a pedagogical approach to learning music through movement. Our goal is to design an instrument that invites musicians to experience music as movement. The designer engaged in the soma design process, by first sensitising her body through Dalcroze training. Subsequently, she articulated her bodily experiences into experiential design qualities that guided the making of the instrument. The process resulted in the design of a large suspended mobile played by touching it with bare skin. We shared our instrument with 7 professional musicians and observed how it inspires a variety of approaches to musical meaning-making, ranging from exploring sound, to choreographing the body. Finally, we discuss how engaging with Dalcroze eurhythmics can be generative to the design of music–movement interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {687},
numpages = {15},
keywords = {soma design, first-person perspectives, Music–movement interaction, Dalcroze eurhythmics, DMIs},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581356,
author = {Sabnis, Nihar and Wittchen, Dennis and Vega, Gabriela and Reed, Courtney N. and Strohmeier, Paul},
title = {Tactile Symbols with Continuous and Motion-Coupled Vibration: An Exploration of Using Embodied Experiences for Hermeneutic Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581356},
doi = {10.1145/3544548.3581356},
abstract = {With most digital devices, vibrotactile feedback consists of rhythmic patterns of continuous vibration. In contrast, when interacting with physical objects, we experience many of their material properties through vibration which is not continuous, but dynamically coupled to our actions. We assume the first style of vibration to lead to hermeneutic mediation, while the second style leads to embodied mediation. What if both types of mediation could be used to design tactile symbols? To investigate this, five haptic experts designed tactile symbols using continuous and motion-coupled vibration. Experts were interviewed to understand their symbols and design approach. A thematic analysis revealed themes showing that lived experience and affective qualities shaped design choices, that experts optimized for passive or active symbols, and that they considered context as part of the design. Our study suggests that adding embodied experiences as a design resource changes how participants think of tactile symbol design, thus broadening the scope of the symbol by design for context, and expanding their affective repertoire as changing the type of vibration influences perceived valence and arousal.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {688},
numpages = {19},
keywords = {symbol design, embodied interaction, vibrotactile feedback, postphenomenology, tactons},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581440,
author = {Li, Jiaji and Li, Mingming and Ji, Junzhe and Pan, Deying and Fan, Yitao and Zhu, Kuangqi and Yang, Yue and Yan, Zihan and Sun, Lingyun and Tao, Ye and Wang, Guanyun},
title = {All-in-One Print: Designing and 3D Printing Dynamic Objects Using Kinematic Mechanism Without Assembly},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581440},
doi = {10.1145/3544548.3581440},
abstract = {The field of Human-Computer-Interaction (HCI) has been consistently utilizing kinematic mechanisms to create tangible dynamic interfaces and objects. However, the design and fabrication of these mechanisms are challenging due to complex spatial structures, step-by-step assembly processes, and unstable joint connections resulting from the inevitable matching errors within separated parts. In this paper, we propose an integrated fabrication method for one-step FDM 3D printing (FDM3DP) kinematic mechanisms to create dynamic objects without additional post-processing. We describe the Arch-printing and Support-bridges method, which we call All-in-One Print, that compiles given arbitrary solid 3D models into printable kinematic models as G-Code for FDM3DP. To expand the design space, we investigate a series of motion structures (e.g., rotate, slide, and screw) with multi-stabilities and develop a design tool to help users quickly design such dynamic objects. We also demonstrate various application cases, including physical interfaces, toys with interactive aesthetics and daily items with internalized functions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {689},
numpages = {15},
keywords = {Prototyping/Implementation, Fabrication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581214,
author = {Sturdee, Miriam and Kara, Hayat and Alexander, Jason},
title = {Exploring Co-Located Interactions with a Shape-Changing Bar Chart},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581214},
doi = {10.1145/3544548.3581214},
abstract = {Data-physicalizations encode data and meaning through geometry or material properties, providing a non-planar view of data, offering novel opportunities for interrogation, discovery and presentation. This field has explored how single users interact with complex 3D data, but the challenges in the application of this technology to collaborative situations have not been addressed. We describe a study exploring interactions and preferences among co-located individuals using a dynamic data-physicalization in the form of a shape-changing bar chart, and compare this to previous work with single participants. Results suggest that co-located interactions with physical data prompt non-interactive hand gestures, a mirroring of physicalizations, and novel hand gestures in comparison to single participant studies. We also note that behavioural similarities in participants between interactive tabletop studies and data-physicalizations may be capitalised upon for further development of these dynamic representations. Finally, we consider the implications and challenges for the adoption of these types of platforms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {690},
numpages = {13},
keywords = {Bar-Graph, Tangible Interaction, Data-physicalization, Shape-changing interfaces, Co-Location},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580914,
author = {Katakura, Shohei and Taraz, Martin and Abdullah, Muhammad and Methfessel, Paul and Rambold, Lukas and Kovacs, Robert and Baudisch, Patrick},
title = {Kerfmeter: Automatic Kerf Calibration for Laser Cutting},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580914},
doi = {10.1145/3544548.3580914},
abstract = {We present Kerfmeter, a hardware + software device that automatically determines how much material the laser cutter burns off, also known as kerf. Its knowledge about kerf allows Kerfmeter to make the joints of laser cut 3D models fit together with just the right tension, i.e., loose enough to allow for comfortable assembly, yet tight enough to hold parts together without glue—all this without user interaction. Kerfmeter attaches to the head of a laser cutter and works as follows: when users send a model to the laser cutter, Kerfmeter intercepts the job, injects a brief calibration routine that determines kerf, dilates the cutting plan according to this kerf, and then proceeds to fabricate the cutting plan. During the calibration routine, Kerfmeter cuts a 2cm Archimedean spiral and uses a motor to rotate it in place until it jams against the surrounding material; the angle at which the spiral jams allows Kerfmeter to infer kerf. The calibration process takes about 20s, which is &gt;10x faster than traditional, manual kerf calibration, while also eliminating the need for expertise. In our technical evaluation, Kerfmeter produced functioning press fit joints reliably at a precision comparable to traditional manual kerf strips. Kerfmeter makes it easy to sample repeatedly; we demonstrate how this allows boosting precision past any traditional kerf strip.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {691},
numpages = {13},
keywords = {laser cutting, rapid prototyping, personal fabrication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580849,
author = {Kim, Daekun and Joshi, Nikhita and Vogel, Daniel},
title = {Perspective and Geometry Approaches to Mouse Cursor Control in Spatial Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580849},
doi = {10.1145/3544548.3580849},
abstract = {Spatial augmented reality (SAR) can extend desktop computing out of the monitor and into our surroundings, but extending the standard style of mouse input is challenging due to real-world geometry irregularity, gaps, and occlusion. We identify two general approaches for controlling a mouse cursor in SAR: perspective-based approaches based on raycasting, such as Nacenta et. al’s Perspective Cursor, and geometry-based approaches that closely associate cursor movement with surface topology. For the latter, we introduce Everywhere Cursor, a geometry-based approach for indirect mouse cursor control for complex 3D surface geometry in SAR. A controlled experiment compares approaches. Results show the geometry-based Everywhere Cursor improves accuracy and precision by 29% to 60% on average in a tracing task, but when traversing long distances, the perspective-based Perspective Cursor and Raycasting techniques are 22% to 49% faster, albeit with 4% to 10% higher error rates.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {692},
numpages = {19},
keywords = {Empirical Study, Interaction Techniques},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580923,
author = {Wang, Guanyun and Zhu, Kuangqi and Zhou, Lingchuan and Guo, Mengyan and Chen, Haotian and Yan, Zihan and Pan, Deying and Yang, Yue and Li, Jiaji and Wu, Jiang and Tao, Ye and Sun, Lingyun},
title = {PneuFab: Designing Low-Cost 3D-Printed Inflatable Structures for Blow Molding Artifacts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580923},
doi = {10.1145/3544548.3580923},
abstract = {Access to computer-aided fabrication tools, such as 3D printing, empowers various craft techniques to democratize the creation of artifacts. To afford new blow molding techniques in the field of Human-Computer Interaction, we make efforts to simplify this challenging handy fabrication and enrich the design space of blow molding by taking advantage of the thermoformability and heat deformability of 3D printed thermoplastics. We propose a novel and democratized blow molding technique, PneuFab, enabled by FDM 3D-printed custom structures and temporal triggering methods. Then we implement and evaluate a design tool that allows users to play with parameters and preview the resulting forms until achieving their desired shapes. Showcasing design spaces including artifacts with complex geometries and tunable stiffness, we hope to expand access and dive into what more the digital blow molding fabrication can be.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {693},
numpages = {17},
keywords = {Blow Molding, Shape Changing, 3D Printing, Hybrid Fabrication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581267,
author = {Lin, Ting-Han and Yang, Willa Yunqi and Nakagaki, Ken},
title = {ThrowIO: Actuated TUIs That Facilitate “Throwing and Catching” Spatial Interaction with Overhanging Mobile Wheeled Robots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581267},
doi = {10.1145/3544548.3581267},
abstract = {We introduce ThrowIO, a novel style of actuated tangible user interface that facilitates throwing and catching spatial interaction powered by mobile wheeled robots on overhanging surfaces. In our approach, users throw and stick objects that are embedded with magnets to an overhanging ferromagnetic surface where wheeled robots can move and drop them at desired locations, allowing users to catch them. The thrown objects are tracked with an RGBD camera system to perform closed-loop robotic manipulations. By computationally facilitating throwing and catching interaction, our approach can be applied in many applications including kinesthetic learning, gaming, immersive haptic experience, ceiling storage, and communication. We demonstrate the applications with a proof-of-concept system enabled by wheeled robots, ceiling hardware design, and software control. Overall, ThrowIO opens up novel spatial, dynamic, and tangible interaction for users via overhanging robots, which has great potential to be integrated into our everyday space.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {694},
numpages = {17},
keywords = {Swarm User Interface, Actuated Tangible User Interface, Spatial Interaction, Human-Computer Interaction, Human-Robot Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580775,
author = {Jingu, Arata and Tanaka, Yudai and Lopes, Pedro},
title = {LipIO: Enabling Lips as Both Input and Output Surface},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580775},
doi = {10.1145/3544548.3580775},
abstract = {Abstract. We engineered LipIO, a novel device enabling the lips to be used simultaneously as an input and output surface. LipIO comprises two overlapping flexible electrode arrays: an outward-facing array for capacitive touch and a lip-facing array for electrotactile stimulation. While wearing LipIO, users feel the interface's state via lip stimulation and respond by touching their lip with their tongue or opposing lip. More importantly, LipIO provides co-located tactile feedback that allows users to feel where in the lip they are touching—this is key to enabling eyes- and hands-free interactions. Our three studies verified participants perceived electrotactile output on their lips and subsequently touched the target location with their tongue with an average accuracy of 93%, while wearing LipIO with five I/O electrodes with co-located feedback. Finally, we demonstrate the potential of LipIO in four exemplary applications that illustrate how it enables new types of eyes- and hands-free micro-interactions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {695},
numpages = {14},
keywords = {Haptics, on-skin interface, lips, tongue},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581465,
author = {Su, Zixiong and Fang, Shitao and Rekimoto, Jun},
title = {LipLearner: Customizable Silent Speech Interactions on Mobile Devices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581465},
doi = {10.1145/3544548.3581465},
abstract = {Silent speech interface is a promising technology that enables private communications in natural language. However, previous approaches only support a small and inflexible vocabulary, which leads to limited expressiveness. We leverage contrastive learning to learn efficient lipreading representations, enabling few-shot command customization with minimal user effort. Our model exhibits high robustness to different lighting, posture, and gesture conditions on an in-the-wild dataset. For 25-command classification, an F1-score of 0.8947 is achievable only using one shot, and its performance can be further boosted by adaptively learning from more data. This generalizability allowed us to develop a mobile silent speech interface empowered with on-device fine-tuning and visual keyword spotting. A user study demonstrated that with LipLearner, users could define their own commands with high reliability guaranteed by an online incremental learning scheme. Subjective feedback indicated that our system provides essential functionalities for customizable silent speech interactions with high usability and learnability.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {696},
numpages = {21},
keywords = {Few-shot Learning, Lipreading, Customization, Silent Speech Interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581210,
author = {Xiao, Xiao and Kuhnert, Barbara and Audibert, Nicolas and Locqueville, Gr\'{e}goire and Pillot-Loiseau, Claire and Zhang, Haohan and D'Alessandro, Christophe},
title = {Performative Vocal Synthesis for Foreign Language Intonation Practice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581210},
doi = {10.1145/3544548.3581210},
abstract = {Typical foreign language (L2) pronunciation training focuses mainly on individual sounds. Intonation, the patterns of pitch change across words or phrases is often neglected, despite its key role in word-level intelligibility and in the expression of attitudes and affect. This paper examines hand-controlled real-time vocal synthesis, known as Performative Vocal Synthesis (PVS), as an interaction technique for practicing L2 intonation in computer aided pronunciation training (CAPT). We evaluate a tablet-based interface where users gesturally control the pitch of a pre-recorded utterance by drawing curves on the touchscreen. 24 subjects (12 French learners, 12 British controls) imitated English phrases with their voice and the interface. Results of an acoustic analysis and expert perceptive evaluation showed that learners’ gestural imitations yielded more accurate results than vocal imitations of the fall-rise intonation pattern typically difficult for francophones, suggesting that PVS can help learners produce intonation patterns beyond the capabilities of their natural voice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {697},
numpages = {9},
keywords = {vocal synthesis, prosody, language learning, performative vocal synthesis, intonation, gesture, CAPT},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580723,
author = {Matthews, Brandon J and Thomas, Bruce H and Von Itzstein, G Stewart and Smith, Ross T},
title = {Towards Applied Remapped Physical-Virtual Interfaces: Synchronization Methods for Resolving Control State Conflicts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580723},
doi = {10.1145/3544548.3580723},
abstract = {User interfaces in virtual reality enable diverse interactions within the virtual world, though they typically lack the haptic cues provided by physical interface controls. Haptic retargeting enables flexible mapping between dynamic virtual interfaces and physical controls to provide real haptic feedback. This investigation aims to extend these remapped interfaces to support more diverse control types. Many interfaces incorporate sliders, switches, and knobs. These controls hold fixed states between interactions creating potential conflicts where a virtual control has a different state from the physical control. This paper presents two methods, “manual” and “automatic”, for synchronizing physical and virtual control states and explores the effects of these methods on the usability of remapped interfaces. Results showed that interfaces without retargeting were the ideal configuration, but they lack the flexibility that remapped interfaces provide. Automatic synchronization was faster and more usable; however, manual synchronization is suitable for a broader range of physical interfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {698},
numpages = {18},
keywords = {haptic retargeting, user interfaces, remapped interfaces, interaction, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580724,
author = {Park, Chaeyong and Kim, Jeongwoo and Choi, Seungmoon},
title = {Visuo-Haptic Crossmodal Shape Perception Model for Shape-Changing Handheld Controllers Bridged by Inertial Tensor},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580724},
doi = {10.1145/3544548.3580724},
abstract = {We present a visuo-haptic crossmodal model of shape perception designed for shape-changing handheld controllers. The model uses the inertia tensor of an object to bridge the two senses. The model was constructed from the results of three perceptual experiments. In the first two experiments, we validate that the primary moment and product of inertia (MOI and POI) in the inertia tensor have critical effects on the haptic perception of object length and asymmetry. Then, we estimate a haptic-to-visual shape matching model using MOI and POI as two link variables from the results of the third experiment for crossmodal magnitude production. Finally, we validate in a summative user study that the inverse of the shape matching model is effective for pairing a perceptually-congruent haptic object from a virtual object—the functionality we need for shape-changing handheld interfaces to afford perceptually-fulfilling sensory experiences in virtual reality.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {699},
numpages = {18},
keywords = {Perception Model, Dynamic Touch, Handheld Controller, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580706,
author = {Rekimoto, Jun},
title = {WESPER: Zero-Shot and Realtime Whisper to Normal Voice Conversion for Whisper-Based Speech Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580706},
doi = {10.1145/3544548.3580706},
abstract = {Recognizing whispered speech and converting it to normal speech creates many possibilities for speech interaction. Because the sound pressure of whispered speech is significantly lower than that of normal speech, it can be used as a semi-silent speech interaction in public places without being audible to others. Converting whispers to normal speech also improves the speech quality for people with speech or hearing impairments. However, conventional speech conversion techniques do not provide sufficient conversion quality or require speaker-dependent datasets consisting of pairs of whispered and normal speech utterances. To address these problems, we propose WESPER, a zero-shot, real-time whisper-to-normal speech conversion mechanism based on self-supervised learning. WESPER consists of a speech-to-unit (STU) encoder, which generates hidden speech units common to both whispered and normal speech, and a unit-to-speech (UTS) decoder, which reconstructs speech from the encoded speech units. Unlike the existing methods, this conversion is user-independent and does not require a paired dataset for whispered and normal speech. The UTS decoder can reconstruct speech in any target speaker’s voice from speech units, and it requires only an unlabeled target speaker’s speech data. We confirmed that the quality of the speech converted from a whisper was improved while preserving its natural prosody. Additionally, we confirmed the effectiveness of the proposed approach to perform speech reconstruction for people with speech or hearing disabilities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {700},
numpages = {12},
keywords = {neural networks, self-supervised learning, whispered voice, whispered voice conversion, artificial intelligence, silent speech, speech interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581322,
author = {Sato, Arissa J. and Sramek, Zefan and Yatani, Koji},
title = {Groupnamics: Designing an Interface for Overviewing and Managing Parallel Group Discussions in an Online Classroom},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581322},
doi = {10.1145/3544548.3581322},
abstract = {Instructors facilitating online classes have a limited ability to see and hear interactions of student groups working in parallel, which prevents them from interacting with students effectively. In this work, we explore interface design for providing an overview of parallel group discussions in online classrooms. We derive design considerations through a participatory design process and instantiate them in our visualization interface, Groupnamics. Groupnamics visualizes recent vocal activities and discussion statuses of each group in a one-page view, facilitating identification of groups where intervention may be needed. Our user study with 16 instructors confirmed that Groupnamics can successfully provide cues for when instructors should join group discussions and improvements on the perceived usefulness and ease of use over the baseline interface representing existing videoconferencing tools. Our qualitative results suggest future research directions in interface design for online parallel group discussions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {701},
numpages = {18},
keywords = {parallel group discussions, online classroom, Group visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581255,
author = {Sterman, Sarah and Nicholas, Molly Jane and Vivrekar, Janaki and Mindel, Jessica R and Paulos, Eric},
title = {Kaleidoscope: A Reflective Documentation Tool for a User Interface Design Course},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581255},
doi = {10.1145/3544548.3581255},
abstract = {Documentation can support design work and create opportunities for learning and reflection. We explore how a novel documentation tool for a remote interaction design course provides insight into design process and integrates strategies from expert practice to support studio-style collaboration and reflection. Using Research through Design, we develop and deploy Kaleidoscope, an online tool for documenting design process, in an upper-level HCI class during the COVID-19 pandemic, iteratively developing it in response to student feedback and needs. We discuss key themes from the real-world deployment of Kaleidoscope, including: tensions between documentation and creation; effects of centralizing discussion; privacy and visibility in shared spaces; balancing evidence of achievement with feelings of overwhelm; and the effects of initial perceptions and incentives on tool usage. These successes and challenges provide insights to guide future tools for design documentation and HCI education that scaffold learning process as an equal partner to execution.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {702},
numpages = {19},
keywords = {online learning, studio, reflection, documentation, HCI education},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581029,
author = {Hui, Julie and Sprouse, Michelle L.},
title = {Lettersmith: Scaffolding Written Professional Communication Among College Students},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581029},
doi = {10.1145/3544548.3581029},
abstract = {Professional writing is critical for job search and performance, but many – especially those without work experience – struggle to write well. We introduce an instructional approach called ‘scaffolded annotation’ as a way to guide students in creating initial drafts of professional writing, like client emails and cover letters. We studied the implementation of scaffolded annotation in a digital platform called Lettersmith. First, we performed a quasi-experimental study and found that students applying scaffolded annotation in Lettersmith were more likely to include key components of professional writing. We also interviewed instructors and students who used Lettersmith and found that scaffolded annotation helped students in guiding structure, content, and tone. Instructors found the approach useful for articulating writing task expectations, pinpointing student gaps in understanding, and scaling instructional support for early-stage drafting. We provide implications for writing instruction and HCI researchers developing writing support tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {703},
numpages = {17},
keywords = {Reflection, Workplace Communication, Scaffolding, Annotation, Writing, Learning, Modeling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581153,
author = {Tanprasert, Thitaree and Fels, Sidney S and Sinnamon, Luanne and Yoon, Dongwook},
title = {Scripted Vicarious Dialogues: Educational Video Augmentation Method for Increasing Isolated Students’ Engagement},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581153},
doi = {10.1145/3544548.3581153},
abstract = {Videos are convenient resources for asynchronous learning, but they lack interpersonal interactions found in synchronous classrooms. Due to missed social connectedness, the isolated video-based learners experience low emotional, behavioral, and cognitive engagement. This work presents "Scripted Vicarious Dialogues" (SVD), a technique for engaging students in a pseudo-social experience of witnessing scripted dialogues between virtual characters (teaching assistants and students) around a video. We conducted a participatory design study to derive design guidelines for SVD. The findings indicate the need to distinguish the virtual components and to give students control of the dialogue’s pace. We then implemented an interactive prototype of SVD and evaluated it (N=40) against a non-social, direct-learning baseline. The results show that the preference for SVD versus the baseline is polarized (25 of 40 preferred SVD; no neutral preferences), and those who preferred SVD had significantly higher emotional and behavioral engagement with SVD compared to the baseline.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {704},
numpages = {25},
keywords = {augmented learning environment, learner engagement, video-based learning, vicarious learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581374,
author = {Risha, Zak and Sonmez Unal, Deniz and Walker, Erin},
title = {Soliloquy: Fostering Poetry Comprehension Using an Interactive Think-Aloud Visualization},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581374},
doi = {10.1145/3544548.3581374},
abstract = {Complex texts like poetry are distinct from informative texts, requiring additional subprocesses to decode and interpret. Approaching a poem without knowledge of these cognitive strategies can result in confusion and frustration—rather than comprehension. In this work, we explore how interfaces can surface and demonstrate these cognitive processes to novice readers. We introduce Soliloquy, an interface that visualizes the thoughts of an expert as they read and interpret a poem by using animations of text and pop-up tooltips. We evaluate the interface in a five-condition Mechanical Turk study (n=254) by varying the detail of thoughts, including audio, and substituting a static text control. Our study detected a significant difference in comprehension between the detail of thoughts, but not between the Soliloquy interface and static text control. We further investigate this finding in a think-aloud study (n=13), revealing the impact individual differences, experience, and cognitive load could have on Soliloquy’s effectiveness.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {705},
numpages = {16},
keywords = {think-aloud, worked example, reading comprehension, poetry},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581143,
author = {Rhim, Jungwook and Kim, Jiwon and Gweon, Gahgene},
title = {Using Geometric Features of Drag-and-Drop Trajectories to Understand Students’ Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581143},
doi = {10.1145/3544548.3581143},
abstract = {Herein, we present two studies on how students’ Psychological State of Decision difficulty (PSD) relates to two aspects of learning, i.e., guessing behavior and learning achievement. To measure PSD, we extracted geometric features from trajectories of drag-and-drop touch interactions collected while students aged 7–10 played a math game on a tablet device. In the first study, we explored whether eight geometric features extracted from 97,303 trial trajectories could be grouped to understand students’ PSD. In the second study, we examined whether the two aspects of learning could be predicted using the data collected from 187 students with geometric features indicating their PSD. This work provides empirical evidence that geometric features can be grouped into two types of PSD in the context of learning, including conflict and uncertainty. Moreover, our results demonstrate that data on students’ PSD collected from drag-and-drop trajectories can be used to predict learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {706},
numpages = {14},
keywords = {Decision difficulty, Drag-and-drop trajectory, Guessing behavior, Learning achievement},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581059,
author = {Emsenhuber, Gerlinde and Langlotz, Tobias and Kalkofen, Denis and Sutton, Jonathan and Tatzgern, Markus},
title = {Eye-Perspective View Management for Optical See-Through Head-Mounted Displays},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581059},
doi = {10.1145/3544548.3581059},
abstract = {Optical see-through (OST) head-mounted displays (HMDs) enable users to experience Augmented Reality (AR) support in the form of helpful real-world annotations. Unfortunately, the blend of the environment with virtual augmentations due to semitransparent OST displays often deteriorates the contrast and legibility of annotations. View management algorithms adapt the annotations’ layout to improve legibility based on real-world information, typically captured by built-in HMD cameras. However, the camera views are different from the user’s view through the OST display which decreases the final layout quality. We present eye-perspective view management that synthesizes high-fidelity renderings of the user’s view to optimize annotation placement. Our method significantly improves over traditional camera-based view management in terms of annotation placement and legibility. Eye-perspective optimizations open up opportunities for further research on use cases relying on the user’s true view through OST HMDs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {707},
numpages = {16},
keywords = {optical see-through, label placement, augmented reality, head-mounted displays, legibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580721,
author = {Nazari, Ahmadreza and Shahidi, Ali and Kaufman, Kate M. and Bondi, Julia E and Alabood, Lorans and Jaswal, Vikram K. and Krishnamurthy, Diwakar and Wang, Mea},
title = {Interactive AR Applications for Nonspeaking Autistic People? - A Usability Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580721},
doi = {10.1145/3544548.3580721},
abstract = {About one-third of autistic people are nonspeaking, and most are never provided access to an effective alternative to speech. Thoughtfully designed AR applications could provide members of this population with structured learning opportunities, including training on skills that underlie alternative forms of communication. A fundamental step toward creating such opportunities, however, is to investigate nonspeaking autistic people’s ability to tolerate a head-mounted AR device and to interact with virtual objects. We present the first study to examine the usability of an interactive AR-based application by this population. We recruited 17 nonspeaking autistic subjects to play a HoloLens 2 game we developed that involved holographic animations and buttons. Almost all subjects tolerated the device long enough to begin the game, and most completed increasingly challenging tasks that involved pressing holographic buttons. Based on the results, we discuss best practice design and process recommendations. Our findings contradict prevailing assumptions about nonspeaking autistic people and thus open up exciting possibilities for AR-based solutions for this understudied and underserved population.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {708},
numpages = {15},
keywords = {assistive technology, nonspeaking autistic people, usability study, augmented reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580904,
author = {Hofmann, Megan and Auradkar, Nayha and Birchfield, Jessica and Cao, Jerry and Hughes, Autumn G and Kim, Gene S-H and Kurpad, Shriya and Lum, Kathryn J and Mack, Kelly and Nilakantan, Anisha and Seehorn, Margaret Ellen and Warnock, Emily and Mankoff, Jennifer and Hudson, Scott E},
title = {OPTIMISM: Enabling Collaborative Implementation of Domain Specific Metaheuristic Optimization},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580904},
doi = {10.1145/3544548.3580904},
abstract = {For non-technical domain experts and designers it can be a substantial challenge to create designs that meet domain specific goals. This presents an opportunity to create specialized tools that produce optimized designs in the domain. However, implementing domain-specific optimization methods requires a rare combination of programming and domain expertise. Creating flexible design tools with re-configurable optimizers that can tackle a variety of problems in a domain requires even more domain and programming expertise. We present OPTIMISM, a toolkit which enables programmers and domain experts to collaboratively implement an optimization component of design tools. OPTIMISM supports the implementation of metaheuristic optimization methods by factoring them into easy to implement and reuse components: objectives that measure desirable qualities in the domain, modifiers which make useful changes to designs, design and modifier selectors which determine how the optimizer steps through the search space, and stopping criteria that determine when to return results. Implementing optimizers with OPTIMISM shifts the burden of domain expertise from programmers to domain experts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {709},
numpages = {19},
keywords = {optimization, metaheuristic, toolkit, generative design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581413,
author = {Kumaran, Radha and Kim, You-Jin and Milner, Anne E and Bullock, Tom and Giesbrecht, Barry and H\"{o}llerer, Tobias},
title = {The Impact of Navigation Aids on Search Performance and Object Recall in Wide-Area Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581413},
doi = {10.1145/3544548.3581413},
abstract = {Head-worn augmented reality (AR) is a hotly pursued and increasingly feasible contender paradigm for replacing or complementing smartphones and watches for continual information consumption. Here, we compare three different AR navigation aids (on-screen compass, on-screen radar and in-world vertical arrows) in a wide-area outdoor user study (n=24) where participants search for hidden virtual target items amongst physical and virtual objects. We analyzed participants’ search task performance, movements, eye-gaze, survey responses and object recall. There were two key findings. First, all navigational aids enhanced search performance relative to a control condition, with some benefit and strongest user preference for in-world arrows. Second, users recalled fewer physical objects than virtual objects in the environment, suggesting reduced awareness of the physical environment. Together, these findings suggest that while navigational aids presented in AR can enhance search task performance, users may pay less attention to the physical environment, which could have undesirable side-effects.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {710},
numpages = {17},
keywords = {Wide-Area, Mobile Augmented Reality, Navigation Aids, Perception, Lighting Conditions, Behavior, User Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581211,
author = {Chauvergne, Edwige and Hachet, Martin and Prouzeau, Arnaud},
title = {User Onboarding in Virtual Reality: An Investigation of Current Practices},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581211},
doi = {10.1145/3544548.3581211},
abstract = {Explaining to novice users how to interact in immersive VR applications may be challenging. This is in particular due to the fact that the learners are isolated from the real world, and they are asked to manipulate hardware and software objects they are not used to. Consequently, the onboarding phase, which consists in teaching the user how to interact with the application is particularly crucial. In this paper, we aim at giving a better understanding of current VR onboarding methods, their benefits and challenges. We performed 21 VR tutorial ergonomic reviews and 15 interviews with VR experts with experience in VR onboarding. Building on the results, we propose a conceptual framework for VR onboarding and discuss important research directions to explore the design of future efficient onboarding solutions adapted to VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {711},
numpages = {15},
keywords = {computer assisted, virtual reality, user onboarding, learning, human assisted},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580966,
author = {P\"{o}hlmann, Katharina Margareta Theresa and Li, Gang and Mcgill, Mark and Markoff, Reuben and Brewster, Stephen Anthony},
title = {You Spin Me Right Round, Baby, Right Round: Examining the Impact of Multi-Sensory Self-Motion Cues on Motion Sickness During a VR Reading Task},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580966},
doi = {10.1145/3544548.3580966},
abstract = {Motion sickness is a problem for many in everyday travel and will become more prevalent with the rise of automated vehicles. Virtual Reality (VR) headsets have shown significant promise in-transit, enabling passengers to engage in immersive entertainment and productivity experiences. In a controlled multi-session motion sickness study using an actuated rotating chair, we examine the potential of multi-sensory visual and auditory motion cues, presented during a VR reading task, for mitigating motion sickness. We found that visual cues are most efficient in reducing symptoms, with auditory cues showing some beneficial effects when combined with the visual. Motion sickness had negative effects on presence as well as task performance, and despite the cognitive demand and multi-sensory cues, motion sickness still reached problematic levels. Our work emphasises the need for effective mitigations and the design of stronger multi-sensory motion cues if VR is to fulfil its potential for passengers.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {712},
numpages = {16},
keywords = {rotation, virtual reality, automated vehicles, motion sickness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581395,
author = {Jin, Qiao and Liu, Yu and Sun, Ruixuan and Chen, Chen and Zhou, Puqi and Han, Bo and Qian, Feng and Yarosh, Svetlana},
title = {Collaborative Online Learning with VR Video: Roles of Collaborative Tools and Shared Video Control},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581395},
doi = {10.1145/3544548.3581395},
abstract = {Virtual Reality (VR) has a noteworthy educational potential by providing immersive and collaborative environments. As an alternative but cost-effective way of delivering realistic environments in VR, using 360-degree videos in immersive VR (VR videos) received more attention. Although many studies reported positive learning experiences with VR videos, little is known about how collaborative learning performs on VR video viewing systems. In this study, we implemented two collaborative VR video viewing modes based on the way of group video control, synchronized or shared (Sync mode) and non-synchronized or individual (Non-sync mode) video control, against a conventional VR video viewing setting (Basic mode). We conducted a within-subject study (N = 54) in a lab-simulated remote learning environment. Our results show that collaborative VR video modes (Sync and Non-sync mode) improve users’ learning experiences and collaboration quality, especially with shared video control. Our findings provide directions for designing and employing collaborative VR video tools in online learning environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {713},
numpages = {18},
keywords = {collaborative learning, educational VR, Virtual Reality, 360-degree video, social VR},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580944,
author = {Fitton, Isabel and Clarke, Christopher and Dalton, Jeremy and Proulx, Michael J and Lutteroth, Christof},
title = {Dancing with the Avatars: Minimal Avatar Customisation Enhances Learning in a Psychomotor Task},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580944},
doi = {10.1145/3544548.3580944},
abstract = {Virtual environments can support psychomotor learning by allowing learners to observe instructor avatars. Instructor avatars that look like the learner hold promise in enhancing learning; however, it is unclear whether this works for psychomotor tasks and how similar avatars need to be. We investigated ‘minimal’ customisation of instructor avatars, approximating a learner’s appearance by matching only key visual features: gender, skin-tone, and hair colour. These avatars can be created easily and avoid problems of highly similar avatars. Using modern dancing as a skill to learn, we compared the effects of visually similar and dissimilar avatars, considering both learning on a screen (n=59) and in VR (n=38). Our results indicate that minimal avatar customisation leads to significantly more vivid visual imagery of the dance moves than dissimilar avatars. We analyse variables affecting interindividual differences, discuss the results in relation to theory, and derive design implications for psychomotor training in virtual environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {714},
numpages = {16},
keywords = {Virtual Reality, Avatar Customisation, Virtual Environments, Skills Training, Psychomotor},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581100,
author = {Clarke, Christopher and Xu, Jingnan and Zhu, Ye and Dharamshi, Karan and McGill, Harry and Black, Stephen and Lutteroth, Christof},
title = {FakeForward: Using Deepfake Technology for Feedforward Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581100},
doi = {10.1145/3544548.3581100},
abstract = {Videos are commonly used to support learning of new skills, to improve existing skills, and as a source of motivation for training. Video self-modelling (VSM) is a learning technique that improves performance and motivation by showing a user a video of themselves performing a skill at a level they have not yet achieved. Traditional VSM is very data and labour intensive: a lot of video footage needs to be collected and manually edited in order to create an effective self-modelling video. We address this by presenting FakeForward – a method which uses deepfakes to create self-modelling videos from videos of other people. FakeForward turns videos of better-performing people into effective, personalised training tools by replacing their face with the user’s. We investigate how FakeForward can be effectively applied and demonstrate its efficacy in rapidly improving performance in physical exercises, as well as confidence and perceived competence in public speaking.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {715},
numpages = {17},
keywords = {Videos, Deepfake, Physical Exercise, Skill Acquisition, Training, Fitness, Feedforward, Public Speaking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581572,
author = {Zegura, Cass and Shapiro, Ben Rydal and MacDonald, Robert and Borenstein, Jason and Zegura, Ellen},
title = {“Moment to Moment”: A Situated View of Teaching Ethics from the Perspective of Computing Ethics Teaching Assistants},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581572},
doi = {10.1145/3544548.3581572},
abstract = {The HCI research community has long centered ethics in HCI research and practice. This interest has persisted as scholars highlight the need for more situated understandings and deeper integration of ethics into HCI. In parallel, HCI scholars and students have become increasingly involved in teaching computing ethics across many different university contexts, bringing in valuable perspectives informed by the connections between HCI and the socio-technical subject matter of computing ethics. Yet explicitly bringing these two threads together – examining the teaching of ethics through an HCI research lens – remains nascent. This paper integrates work in HCI and computing education to focus on the role and experience of computing ethics teaching assistants (CETAs), who are increasingly involved in ethics instruction and whose perspectives are predominantly missing in existing literature spanning HCI and computing education. Drawing on HCI theories and methods, our qualitative study of eleven CETAs at two American universities makes three contributions to the HCI literature. First, we build an understanding of who these TAs are with respect to the unique position of teaching computing ethics. Second, we characterize how CETAs’ teaching and learning is situated and shaped within different communities and institutional contexts. Finally, we suggest several implications for the design of ethics instruction within undergraduate computing programs. More broadly, our work can be viewed as a call to action, encouraging HCI scholars to play a more significant role in studying and designing the teaching and learning of computing ethics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {716},
numpages = {15},
keywords = {Teaching assistants, Community of practice, Computing ethics, Situated teaching and learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580892,
author = {Amores Fernandez, Judith and Mehra, Nirmita and Rasch, Bjoern and Maes, Pattie},
title = {Olfactory Wearables for Mobile Targeted Memory Reactivation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580892},
doi = {10.1145/3544548.3580892},
abstract = {This paper investigates how a smartphone-controlled olfactory wearable might improve memory recall. We conducted a within-subjects experiment with 32 participants using the device and without (control). In the experimental condition, bursts of odor were released during visuo-spatial memory navigation tasks, and replayed during sleep the following night in the subjects’ home. We found that compared to control, there was an improvement in memory performance when using the scent wearable in memory tasks that involved walking in a physical space. Furthermore, participants recalled more objects and translations when re-exposed to the same scent during the recall test, in addition to during sleep. These effects were statistically significant, and, in the object recall task, they also persisted for more than one week. This experiment demonstrates a potential practical application of olfactory interfaces that can interact with a user during wake as well as sleep to support memory.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {717},
numpages = {20},
keywords = {sleep, Targeted Memory Reactivation, learning, olfaction, wearables, well-being, olfactory interfaces, Memory},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581364,
author = {Rong, Ethan Z. and Zhou, Mo Morgana and Gao, Ge and Lu, Zhicong},
title = {Understanding Personal Data Tracking and Sensemaking Practices for Self-Directed Learning in Non-Classroom and Non-Computer-Based Contexts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581364},
doi = {10.1145/3544548.3581364},
abstract = {Self-directed learning is becoming a significant skill for learners. However, learners may suffer from difficulties such as distractions, a lack of motivation, and so on. While self-tracking technologies have the potential to address these challenges, existing tools and systems mainly focused on tracking computer-based learning data in classroom contexts. Little is known about how students track and make sense of their learning data from non-classroom learning activities and which types of learning data are personally meaningful for learners. In this paper, we conducted a qualitative study with 24 users of Timing, a mobile learning tracking application in China. Our findings indicated that users tracked a variety of qualitative learning data (e.g., videos, photos of learning materials, and emotions) and made sense of this data using different strategies such as observing behavioral and contextual details in videos. We then provided implications for designing non-classroom and non-computer-based personal learning tracking tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {718},
numpages = {16},
keywords = {self-directed learning, behavior change, non-classroom-based learning, personal informatics, self-tracking, non-computer-based learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581269,
author = {Cui, Wenzhe and Liu, Rui and Li, Zhi and Wang, Yifan and Wang, Andrew and Zhao, Xia and Rashidian, Sina and Baig, Furqan and Ramakrishnan, IV and Wang, Fusheng and Bi, Xiaojun},
title = {GlanceWriter: Writing Text by Glancing Over Letters with Gaze},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581269},
doi = {10.1145/3544548.3581269},
abstract = {Writing text with eye gaze only is an appealing hands-free text entry method. However, existing gaze-based text entry methods introduce eye fatigue and are slow in typing speed because they often require users to dwell on letters of a word, or mark the starting and ending positions of a gaze path with extra operations for entering a word. In this paper, we propose GlanceWriter, a text entry method that allows users to enter text by glancing over keys one by one without any need to dwell on any keys or specify the starting and ending positions of a gaze path when typing a word. To achieve so, GlanceWriter probabilistically determines the letters to be typed based on the dynamics of gaze movements and gaze locations. Our user studies demonstrate that GlanceWriter significantly improves the text entry performance over EyeSwipe, a dwell-free input method using “reverse crossing” to identify the starting and ending keys. GlanceWriter also outperforms the dwell-free gaze input method of Tobii’s Communicator 5, a commercial eye gaze-based communication system. Overall, GlanceWriter achieves dwell-free and crossing-free text entry by probabilistically decoding gaze paths, offering a promising gaze-based text entry method.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {719},
numpages = {13},
keywords = {gesture input, word gesture, eye gaze, text input},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581430,
author = {Zhou, Chen and Fennedy, Katherine and Tan, Felicia Fang-Yi and Zhao, Shengdong and Shao, Yurui},
title = {Not All Spacings Are Created Equal: The Effect of Text Spacings in On-the-Go Reading Using Optical See-Through Head-Mounted Displays},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581430},
doi = {10.1145/3544548.3581430},
abstract = {The emergent Optical Head-Mounted Display (OHMD) platform has made mobile reading possible by superimposing digital text onto users’ view of the environment. However, mobile reading through OHMD needs to be effectively balanced with the user’s environmental awareness. Hence, a series of studies were conducted to explore how text spacing strategies facilitate such balance. Through these studies, it was found that increasing spacing within the text can significantly enhance mobile reading on OHMDs in both simple and complex navigation scenarios and that such benefits mainly come from increasing the inter-line spacing, but not inter-word spacing. Compared with existing positioning strategies, increasing inter-line spacing improves mobile OHMD information reading in terms of reading speed (11.9% faster), walking speed (3.7% faster), and switching between reading and navigation (106.8% more accurate and 33% faster).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {720},
numpages = {19},
keywords = {Inter-line Spacing, Smart Glasses, Text Spacing, Inter-word Spacing, Mobile Reading, OHMD, Reading on-the-go, Heads-up Computing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581065,
author = {Cai, Runze and Janaka, Nuwan Nanayakkarawasam Peru Kandage and Zhao, Shengdong and Sun, Minghui},
title = {ParaGlassMenu: Towards Social-Friendly Subtle Interactions in Conversations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581065},
doi = {10.1145/3544548.3581065},
abstract = {Interactions with digital devices during social settings can reduce social engagement and interrupt conversations. To overcome these drawbacks, we designed ParaGlassMenu, a semi-transparent circular menu that can be displayed around a conversation partner’s face on Optical See-Through Head-Mounted Display (OHMD) and interacted subtly using a ring mouse. We evaluated ParaGlassMenu with several alternative approaches (Smartphone, Voice assistant, and Linear OHMD menus) by manipulating Internet-of-Things (IoT) devices in a simulated conversation setting with a digital partner. Results indicated that the ParaGlassMenu offered the best overall performance in balancing social engagement and digital interaction needs in conversations. To validate these findings, we conducted a second study in a realistic conversation scenario involving commodity IoT devices. Results confirmed the utility and social acceptance of the ParaGlassMenu. Based on the results, we discuss implications for designing attention-maintaining subtle interaction techniques on OHMDs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {721},
numpages = {21},
keywords = {ring interaction, HMD, smart glasses, Internet-of-Things, conversation, IoT manipulation, social interaction, circular menu},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581055,
author = {Li, Zhuojun and Yu, Chun and Gu, Yizheng and Shi, Yuanchun},
title = {ResType: Invisible and Adaptive Tablet Keyboard Leveraging Resting Fingers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581055},
doi = {10.1145/3544548.3581055},
abstract = {Text entry on tablet touchscreens is a basic need nowadays. Tablet keyboards require visual attention for users to locate keys, thus not supporting efficient touch typing. They also take up a large proportion of screen space, which affects the access to information. To solve these problems, we propose ResType, an adaptive and invisible keyboard on three-state touch surfaces (e.g. tablets with unintentional touch prevention). ResType allows users to rest their hands on it and automatically adapts the keyboard to the resting fingers. Thus, users do not need visual attention to locate keys, which supports touch typing. We quantitatively explored users’ resting finger patterns on ResType, based on which we proposed an augmented Bayesian decoding algorithm for ResType, with 96.3% top-1 and 99.0% top-3 accuracies. After a 5-day evaluation, ResType achieved 41.26 WPM, outperforming normal tablet keyboards by 13.5% and reaching 86.7% of physical keyboards. It solves the occlusion problem while maintaining comparable typing speed with current methods on visible tablet keyboards.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {722},
numpages = {14},
keywords = {text entry, touch typing, adaptive keyboard, invisible keyboard},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580915,
author = {Faleel, Shariff AM and Liu, Yishuo and Cody, Roya A and Rey, Bradley and Du, Linghao and Yu, Jiangyue and Huang, Da-Yuan and Irani, Pourang and Li, Wei},
title = {T-Force: Exploring the Use of Typing Force for Three State Virtual Keyboards},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580915},
doi = {10.1145/3544548.3580915},
abstract = {Three state virtual keyboards which differentiate contact events between released, touched, and pressed states have the potential to improve overall typing experience and reduce the gap between virtual keyboards and physical keyboards. Incorporating force sensitivity, three-state virtual keyboards can utilize a force threshold to better classify a contact event. However, our limited knowledge of how force plays a role during typing on virtual keyboards limits further progress. Through a series of studies we observe that using a uniform threshold is not an optimal approach. Furthermore, the force being applied while typing varies significantly across the keys and among participants. As such, we propose three different approaches to further improve the uniform threshold. We show that a carefully selected non-uniform threshold function could be sufficient in delineating typing events on a three-state keyboard. Finally, we conclude our work with lessons learned, suggestion for future improvements, and comparisons with current methods available.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {723},
numpages = {15},
keywords = {10-finger typing, force sensitive touch interactions, three-state Virtual keyboard},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581248,
author = {Iftikhar, Zainab and Ma, Yumeng and Huang, Jeff},
title = {“Together but Not Together”: Evaluating Typing Indicators for Interaction-Rich Communication},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581248},
doi = {10.1145/3544548.3581248},
abstract = {Messaging is a ubiquitous digital communication medium. It is also a minimal medium of communication because of its inability to convey immediate feedback, tone, facial expressions, hesitations, and pauses, or follow the train of the other person’s thoughts. This paper combines quantitative and qualitative approaches for analyzing richer forms of typing indicators in messaging interfaces, such as showing text as it is typed. By assessing users’ subjective workload and interpreting these findings in the context of users’ experiences, we found that more expressive typing indicators were perceived as “rich in communication”, as they helped people communicate more allowing for closer connections. These indicators also increased users’ perceived co-presence. In addition, our research suggests there may be benefits of designing customized typing indicators for relationship maintenance and task-based communication.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {724},
numpages = {12},
keywords = {typing indicators, computer-mediated communication, social presence, media richness theory, texting, online interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581171,
author = {Aufheimer, Maria and Gerling, Kathrin and Graham, T.C. Nicholas and Naaris, Mari and Konings, Marco J. and Monbaliu, Elegast and Hallez, Hans and Ortibus, Els},
title = {An Examination of Motivation in Physical Therapy Through the Lens of Self-Determination Theory: Implications for Game Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581171},
doi = {10.1145/3544548.3581171},
abstract = {While it is widely assumed that games can engage patients in therapy through their inherent ‘motivational pull’, relatively little attention has been paid to what HCI games research can learn from strategies employed by therapists. We address this gap by leveraging Self-Determination Theory (SDT) and its mini-theories Basic Psychological Needs Theory and Organismic Integration Theory as a theoretical lens on physical therapy for children and adolescents. Results from in-depth interviews with twelve therapists show that they carefully adjust sessions to allow patients to experience competence, making more comprehensive adjustments than currently offered by games. Additionally, we highlight how therapists leverage their relationship with patients to support motivation, but struggle to reconcile meaningful experiences of autonomy with therapeutic goals. On this basis, we reflect on implications for researchers and designers who create games for physical therapy, and the potential of SDT to provide a foundation for game design and therapeutic practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {725},
numpages = {16},
keywords = {Self-Determination Theory, Motivation, Games, Physical Therapy, Rehabilitation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581342,
author = {Inie, Nanna and Westh, Bj\o{}rn Hjorth and Muller, John Henrik and Lungu, Mircea Filip},
title = {Challenges and Opportunities of Using Redirection of Activity for Self-Regulation Online},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581342},
doi = {10.1145/3544548.3581342},
abstract = {This paper explores redirection of activity as an intervention strategy for self-regulation online. We conducted an explorative study (N = 19) of the browser extension Aiki, which redirects a user from a self-defined ‘time-wasting’ website to an online platform for learning programming (Sololearn, Codecademy, or Udemy). Based on quantitative measures alone, using Aiki decreased the participants’ time spent on time-wasting websites on average, and increased programming knowledge. However, several users ended up avoiding their time-wasting websites entirely when Aiki was active, or they discontinued the use of the extension after ‘the novelty wore off’. Based on these effects, we qualitatively explored the user experiences and identified four challenges and four opportunities for using redirection of activity as an intervention strategy for self-regulation of time management in a browser. Our results suggest that this intervention strategy is promising, but careful design is necessary to strike an optimal balance between independence and regulation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {726},
numpages = {19},
keywords = {user experience evaluation, productivity management, self-regulation, procrastination, self-control, microlearning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581156,
author = {McQuillan, Holly and Karana, Elvin},
title = {Conformal, Seamless, Sustainable: Multimorphic Textile-Forms as a Material-Driven Design Approach for HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581156},
doi = {10.1145/3544548.3581156},
abstract = {Technology embeddedness in HCI textiles has great potential for enabling novel interactions and enriched experiences, but unless carefully designed, could inadvertently worsen HCI’s sustainability problem. In an attempt to bridge sustainable debates and practical material-driven scholarship in HCI, we propose Multimorphic Textile-forms (MMTF), as a design approach developed through a lens of multiplicity and extended life cycles, that facilitate change in both design/production and use-time via the simultaneous thinking of the qualities and behaviour of material and form. We provide a number of cases, textile-form methods and vocabulary to enable exploration in this emerging design space. MMTF grants insights into textiles as complex material systems whose behaviour can be tuned across material, interaction and ecological scales for conformal, seamless, and sustainable outcomes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {727},
numpages = {19},
keywords = {Material-driven design, Materials experience., Textile-form, HCI textiles, Multimorphic textile-forms, Sustainability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581404,
author = {Pfau, Johannes and Seif El-Nasr, Magy},
title = {Player-Driven Game Analytics: The Case of Guild Wars 2},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581404},
doi = {10.1145/3544548.3581404},
abstract = {Video game analytics are widely adopted within academia and industrial development – yet, the player’s perspective is rarely considered as a driving factor, even though vast communities are interested in self-regulated learning, cross-comparisons and empirical trends or insights. In this work, we propose to empower the role of the player as the central impulse for analytics, collect requirements and data from the community of one of the most popular MMORPGs (Guild Wars 2), establish a tool over a 18-month period of participatory development and discuss the co-created features. With analytics for in-game logs from (n = 175, 099) unique players and atomic game actions of over 2 million hours played, we contribute a large-scale, long-term iterative implementation and evaluation of a player-driven instrument to quantify popularity, viability and hierarchical inspection between classes or individual performances. This tool found frequent usage among the actual game community, delivering game data science to the very player.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {728},
numpages = {14},
keywords = {Game Analytics, Participatory Research, Massively Multiplayer Online Role Playing Games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581570,
author = {Mohaddesi, Omid and Chicoine, Noah and Gong, Min and Ergun, Ozlem and Griffin, Jacqueline and Kaeli, David and Marsella, Stacy and Harteveld, Casper},
title = {Thought Bubbles: A Proxy into Players’ Mental Model Development},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581570},
doi = {10.1145/3544548.3581570},
abstract = {Studying mental models has recently received more attention, aiming to understand the cognitive aspects of human-computer interaction. However, there is not enough research on the elicitation of mental models in complex dynamic systems. We present Thought Bubbles as an approach for eliciting mental models and an avenue for understanding players’ mental model development in interactive virtual environments. We demonstrate the use of Thought Bubbles in two experimental studies involving 250 participants playing a supply chain game. In our analyses, we rely on Situation Awareness (SA) levels, including perception, comprehension, and projection, and show how experimental manipulations such as disruptions and information sharing shape players’ mental models and drive their decisions depending on their behavioral profile. Our results provide evidence for the use of thought bubbles in uncovering cognitive aspects of behavior by indicating how disruption location and availability of information affect people’s mental model development and influence their decisions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {729},
numpages = {21},
keywords = {dynamic decision-making, mental model elicitation, thought bubble, mental model development, supply chain},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581072,
author = {Hirzle, Teresa and M\"{u}ller, Florian and Draxler, Fiona and Schmitz, Martin and Knierim, Pascal and Hornb\ae{}k, Kasper},
title = {When XR and AI Meet - A Scoping Review on Extended Reality and Artificial Intelligence},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581072},
doi = {10.1145/3544548.3581072},
abstract = {Research on Extended Reality (XR) and Artificial Intelligence (AI) is booming, which has led to an emerging body of literature in their intersection. However, the main topics in this intersection are unclear, as are the benefits of combining XR and AI. This paper presents a scoping review that highlights how XR is applied in AI research and vice versa. We screened 2619 publications from 203 international venues published between 2017 and 2021, followed by an in-depth review of 311 papers. Based on our review, we identify five main topics at the intersection of XR and AI, showing how research at the intersection can benefit each other. Furthermore, we present a list of commonly used datasets, software, libraries, and models to help researchers interested in this intersection. Finally, we present 13 research opportunities and recommendations for future work in XR and AI research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {730},
numpages = {45},
keywords = {artificial intelligence, scoping review, extended reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581321,
author = {Tao, Ye and Wang, Shuhong and Ji, Junzhe and Cai, Linlin and Xia, Hongmei and Wang, Zhiqi and He, Jinghai and Fan, Yitao and Pan, Shengzhang and Xu, Jinghua and Yang, Cheng and Sun, Lingyun and Wang, Guanyun},
title = {4Doodle: 4D Printing Artifacts Without 3D Printers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581321},
doi = {10.1145/3544548.3581321},
abstract = {4D printing encodes transformability over time, which empowers users to create artifacts by on-demand deformation. The creative process of 4D printing shape-changing artifacts can be challenging because of its discontinuous fabrication steps, such as digital designing, specific path planning, automatic printing and manual triggering. We hypothesize that switching from typical 4D printing reliant on 3D printers to a more “handcrafted” method can allow users to understand and continuously reflect upon the artifact and its transformability. Towards this vision, we introduce 4Doodle, a hybrid craft approach that integrates unique deformation controllability and five techniques for freehand 4D printing, using a 3D pen. To tackle the shape-changing challenges of uncertain hands-on fabrication, we develop a mixed reality system to help novices master the manual skills of 4D printing. We also demonstrate a series of 4D printed artifacts with fully human intervention. Finally, our user study shows that 4Doodle lowers the skill-acquisition barrier associated with handcrafting 4D printed artifacts, and it has great potential for creative production and spatial ability.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {731},
numpages = {16},
keywords = {4D printing, Shape-changing behavior, Hybrid craft, 3D pens},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581408,
author = {Jeong, Yunwoo and Cho, Hyungjun and Kim, Taewan and Nam, Tek-Jin},
title = {AutomataStage: An AR-Mediated Creativity Support Tool for Hands-on Multidisciplinary Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581408},
doi = {10.1145/3544548.3581408},
abstract = {The creativity support tools can enhance the hands-on multidisciplinary learning experience by drawing interest in the process of creating the outcome. We present AutomataStage, an AR-mediated creativity support tool for hands-on multidisciplinary learning. AutomataStage utilizes a video see-through interface to support the creation of Interactive Automata. The combination of building blocks and low-cost materials increases the expressiveness. The generative design method and one-to-one guide support the idea development process. It also provides a hardware see-through feature with which inside parts and circuits can be seen and an operational see-through feature that shows the operation in real-time. The visual programming method with a state transition diagram supports the iterative process during the creation process. A user study shows that AutomataStage enabled the students to create diverse Interactive Automata within 40-minute sessions. By creating Interactive Automata, the participants could learn the basic concepts of components. See-through features allowed active exploration with interest while integrating the components. We discuss the implications of hands-on tools with interactive and kinetic content beyond multidisciplinary learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {732},
numpages = {16},
keywords = {creativity support tool, hands-on learning, learning tool, video see-through system, Interactive Automata, STEAM, Multidisciplinary learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580748,
author = {Ko, Donghyeon and Kim, Yoonji and Zhu, Junyi and Wessely, Michael and Mueller, Stefanie},
title = {FlexBoard: A Flexible Breadboard for Interaction Prototyping on Curved and Deformable Surfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580748},
doi = {10.1145/3544548.3580748},
abstract = {We present FlexBoard, an interaction prototyping platform that enables rapid prototyping with interactive components such as sensors, actuators and displays on curved and deformable objects. FlexBoard offers the rapid prototyping capabilities of traditional breadboards but is also flexible to conform to different shapes and materials. FlexBoard’s bendability is enabled by replacing the rigid body of a breadboard with a flexible living hinge that holds the metal strips from a traditional breadboard while maintaining the standard pin spacing. In addition, FlexBoards are also shape-customizable as they can be cut to a specific length and joined together to form larger prototyping areas. We discuss FlexBoard’s mechanical design and present a technical evaluation of its bendability, adhesion to curved and deformable surfaces, and holding force of electronic components. Finally, we show the usefulness of FlexBoard through 3 application scenarios with interactive textiles, curved tangible user interfaces, and VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {733},
numpages = {13},
keywords = {deformable user interfaces., electronic prototyping, breadboards},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580691,
author = {Pourjafarian, Narjes and Mjaku, Fjolla and Koelle, Marion and Schmitz, Martin and Borchers, Jan and Steimle, J\"{u}rgen},
title = {Handheld Tools Unleashed: Mixed-Initiative Physical Sketching with a Robotic Printer},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580691},
doi = {10.1145/3544548.3580691},
abstract = {Personal fabrication has mostly focused on handheld tools as embodied extensions of the user, and machines like laser cutters and 3D printers automating parts of the process without intervention. Although interactive digital fabrication has been explored as a middle ground, existing systems have a fixed allocation of user intervention vs. machine autonomy, limiting flexibility, creativity, and improvisation. We explore a new class of devices that combine the desirable properties of a handheld tool and an autonomous fabrication robot, offering a continuum from manual and assisted to autonomous fabrication, with seamless mode transitions. We exemplify the concept of mixed-initiative physical sketching with a working robotic printer that can be handheld for free-hand sketching, can provide interactive assistance during sketching, or move about for computer-generated sketches. We present interaction techniques to seamlessly transition between modes, and sketching techniques benefitting from these transitions to, e.g., extend (upscale, repeat) or revisit (refine, color) sketches. Our evaluation with seven sketchers illustrates that RoboSketch successfully leverages each mode’s strengths, and that mixed-initiative physical sketching makes computer-supported sketching more flexible.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {734},
numpages = {14},
keywords = {mixed-initiative fabrication, robotic printer, fabrication, prototyping, sketching interfaces, Sketching},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581002,
author = {Feng, Shuyue and Yao, Cheng and Lin, Weijia and Yao, Jiayu and Zhang, Chao and Jia, Zhongyu and Liu, Lijuan and Bokola, Masulani and Chen, Hangyue and Ying, Fangtian and Wang, Guanyun},
title = {MechCircuit: Augmenting Laser-Cut Objects with Integrated Electronics, Mechanical Structures and Magnets},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581002},
doi = {10.1145/3544548.3581002},
abstract = {Laser cutting revolutionizes the creation of personal-fabricated prototypes. These objects can have transformable properties by adopting different materials and be interactive by integrating electronic circuits. However, circuits in laser-cut objects always have limited movements, which refrains laser cutting from achieving interactive prototypes with more complex movable functions like mechanisms. We propose MechCircuit, a design and fabrication pipeline for making mechanical-electronical objects with laser cutting. We leverage the neodymium magnet’s natures of magnetism and conductivity to integrate electronics and mechanical structure joints into prototypes. We conduct the evaluation to explore technological parameters and assess the practical feasibility of the fabrication pipeline. And we organized a user-observing workshop for non-expert users. Through the outcoming prototypes, the result demonstrates the feasibility of MechCircuit as a useful and inspiring prototyping method.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {735},
numpages = {15},
keywords = {Digital fabrication;, Prototyping, Movable electronics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581434,
author = {Albaugh, Lea and Hudson, Scott E and Yao, Lining},
title = {Physically Situated Tools for Exploring a Grain Space in Computational Machine Knitting},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581434},
doi = {10.1145/3544548.3581434},
abstract = {We propose an approach to enabling exploratory creativity in digital fabrication through the use of grain spaces. In material processes, “grain” describes underlying physical properties like the orientation of cellulose fibers in wood that, in aggregate, affect fabrication concerns (such as directional cutting) and outcomes (such as axes of strength and visual effects). Extending this into the realm of computational fabrication, grain spaces define a curated set of mid-level material properties as well as the underlying low-level fabrication processes needed to produce them. We specify a grain space for computational brioche knitting, use it to guide our production of a set of hybrid digital/physical tools to support quick and playful exploration of this space’s unique design affordances, and reflect on the role of such tools in creative practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {736},
numpages = {14},
keywords = {Machine Knitting, Casual Creativity., Textiles},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580847,
author = {Chang, Joseph Chee and Zhang, Amy X. and Bragg, Jonathan and Head, Andrew and Lo, Kyle and Downey, Doug and Weld, Daniel S.},
title = {CiteSee: Augmenting Citations in Scientific Papers with Persistent and Personalized Historical Context},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580847},
doi = {10.1145/3544548.3580847},
abstract = {When reading a scholarly article, inline citations help researchers contextualize the current article and discover relevant prior work. However, it can be challenging to prioritize and make sense of the hundreds of citations encountered during literature reviews. This paper introduces CiteSee, a paper reading tool that leverages a user’s publishing, reading, and saving activities to provide personalized visual augmentations and context around citations. First, CiteSee connects the current paper to familiar contexts by surfacing known citations a user had cited or opened. Second, CiteSee helps users prioritize their exploration by highlighting relevant but unknown citations based on saving and reading history. We conducted a lab study that suggests CiteSee is significantly more effective for paper discovery than three baselines. A field deployment study shows CiteSee helps participants keep track of their explorations and leads to better situational awareness and increased paper discovery via inline citation when conducting real-world literature reviews.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {737},
numpages = {15},
keywords = {reading interfaces, scientific papers, personalization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581371,
author = {Kang, Hyeonsu B and Soliman, Nouran and Latzke, Matt and Chang, Joseph Chee and Bragg, Jonathan},
title = {ComLittee: Literature Discovery with Personal Elected Author Committees},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581371},
doi = {10.1145/3544548.3581371},
abstract = {In order to help scholars understand and follow a research topic, significant research has been devoted to creating systems that help scholars discover relevant papers and authors. Recent approaches have shown the usefulness of highlighting relevant authors while scholars engage in paper discovery. However, these systems do not capture and utilize users’ evolving knowledge of authors. We reflect on the design space and introduce ComLittee, a literature discovery system that supports author-centric exploration. In contrast to paper-centric interaction in prior systems, ComLittee’s author-centric interaction supports curating research threads from individual authors, finding new authors and papers using combined signals from a paper recommender and the curated authors’ authorship graphs, and understanding them in the context of those signals. In a within-subjects experiment that compares to a paper-centric discovery system with author-highlighting, we demonstrate how ComLittee improves author and paper discovery.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {738},
numpages = {20},
keywords = {interactive machine learning, author-augmented literature discovery, interpretable relevance explanations, paper and author recommendations, Scholarly discovery systems},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580741,
author = {Song, Da and Wang, Zhijie and Huang, Yuheng and Ma, Lei and Zhang, Tianyi},
title = {DeepLens: Interactive Out-of-Distribution Data Detection in NLP Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580741},
doi = {10.1145/3544548.3580741},
abstract = {Machine Learning (ML) has been widely used in Natural Language Processing (NLP) applications. A fundamental assumption in ML is that training data and real-world data should follow a similar distribution. However, a deployed ML model may suffer from out-of-distribution (OOD) issues due to distribution shifts in the real-world data. Though many algorithms have been proposed to detect OOD data from text corpora, there is still a lack of interactive tool support for ML developers. In this work, we propose DeepLens, an interactive system that helps users detect and explore OOD issues in massive text corpora. Users can efficiently explore different OOD types in DeepLens with the help of a text clustering method. Users can also dig into a specific text by inspecting salient words highlighted through neuron activation analysis. In a within-subjects user study with 24 participants, participants using DeepLens were able to find nearly twice more types of OOD issues accurately with 22% more confidence compared with a variant of DeepLens that has no interaction or visualization support.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {739},
numpages = {17},
keywords = {Out-of-distribution Detection, NLP, Interactive Visualization, Machine Learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580852,
author = {Wang, Zhijie and Huang, Yuheng and Song, Da and Ma, Lei and Zhang, Tianyi},
title = {DeepSeer: Interactive RNN Explanation and Debugging via State Abstraction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580852},
doi = {10.1145/3544548.3580852},
abstract = {Recurrent Neural Networks (RNNs) have been widely used in Natural Language Processing (NLP) tasks given its superior performance on processing sequential data. However, it is challenging to interpret and debug RNNs due to the inherent complexity and the lack of transparency of RNNs. While many explainable AI (XAI) techniques have been proposed for RNNs, most of them only support local explanations rather than global explanations. In this paper, we present DeepSeer, an interactive system that provides both global and local explanations of RNN behavior in multiple tightly-coordinated views for model understanding and debugging. The core of DeepSeer is a state abstraction method that bundles semantically similar hidden states in an RNN model and abstracts the model as a finite state machine. Users can explore the global model behavior by inspecting text patterns associated with each state and the transitions between states. Users can also dive into individual predictions by inspecting the state trace and intermediate prediction results of a given input. A between-subjects user study with 28 participants shows that, compared with a popular XAI technique, LIME, participants using DeepSeer made a deeper and more comprehensive assessment of RNN model behavior, identified the root causes of incorrect predictions more accurately, and came up with more actionable plans to improve the model performance.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {740},
numpages = {20},
keywords = {Recurrent Neural Networks, Model Debugging, Explainable AI, Visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581290,
author = {Lam, Michelle S. and Ma, Zixian and Li, Anne and Freitas, Izequiel and Wang, Dakuo and Landay, James A. and Bernstein, Michael S.},
title = {Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581290},
doi = {10.1145/3544548.3581290},
abstract = {Machine learning practitioners often end up tunneling on low-level technical details like model architectures and performance metrics. Could early model development instead focus on high-level questions of which factors a model ought to pay attention to? Inspired by the practice of sketching in design, which distills ideas to their minimal representation, we introduce model sketching: a technical framework for iteratively and rapidly authoring functional approximations of a machine learning model’s decision-making logic. Model sketching refocuses practitioner attention on composing high-level, human-understandable concepts that the model is expected to reason over (e.g., profanity, racism, or sarcasm in a content moderation task) using zero-shot concept instantiation. In an evaluation with 17 ML practitioners, model sketching reframed thinking from implementation to higher-level exploration, prompted iteration on a broader range of model designs, and helped identify gaps in the problem formulation—all in a fraction of the time ordinarily required to build a model.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {741},
numpages = {24},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580841,
author = {Palani, Srishti and Naik, Aakanksha and Downey, Doug and Zhang, Amy X. and Bragg, Jonathan and Chang, Joseph Chee},
title = {Relatedly: Scaffolding Literature Reviews with Existing Related Work Sections},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580841},
doi = {10.1145/3544548.3580841},
abstract = {Scholars who want to research a scientific topic must take time to read, extract meaning, and identify connections across many papers. As scientific literature grows, this becomes increasingly challenging. Meanwhile, authors summarize prior research in papers’ related work sections, though this is scoped to support a single paper. A formative study found that while reading multiple related work paragraphs helps overview a topic, it is hard to navigate overlapping and diverging references and research foci. In this work, we design a system, Relatedly, that scaffolds exploring and reading multiple related work paragraphs on a topic, with features including dynamic re-ranking and highlighting to spotlight unexplored dissimilar information, auto-generated descriptive paragraph headings, and low-lighting of redundant information. From a within-subjects user study (n=15), we found that scholars generate more coherent, insightful, and comprehensive topic outlines using Relatedly compared to a baseline paper list.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {742},
numpages = {20},
keywords = {Sensemaking, Scientific Discovery, Literature Review, Exploratory Search},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581192,
author = {Niijima, Arinobu and Kubo, Yuki},
title = {Assisting with Fingertip Force Control by Active Bio-Acoustic Sensing and Electrical Muscle Stimulation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581192},
doi = {10.1145/3544548.3581192},
abstract = {Fingertip force control plays an important role in learning motor skills. Exoskeleton gloves have been developed to assist with fingertip force control, but having the equipment on the fingers interferes with finger motion control and tactile sensation. Thus, we present a system for assisting with voluntary fingertip force control that does not require any devices to be worn on the fingers. In this study, we focused particularly on lateral pinch force, which is grip force achieved with the pad of the thumb and the lateral surface of the index finger to grasp objects. We use active bio-acoustic sensing to estimate voluntary pinch force with piezo elements attached to the back of the hand and electrical muscle stimulation (EMS) to the forearm to control involuntary pinch force in a closed-loop system. We developed three prototypes and conducted user studies to investigate whether our system can assist with pinch force control under several target forces, from weak to strong. Our user studies showed that the combination of active bio-acoustic sensing and EMS can assist users in maintaining the pinch force closer to the target force.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {743},
numpages = {13},
keywords = {fingertip force, electrical muscle stimulation, closed-loop control, active bio-acoustic sensing, pinch force},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580638,
author = {Zhong, Ke and Fernandes Minori, Adriane and Wu, Di and Yang, Humphrey and Islam, Mohammad F. and Yao, Lining},
title = {EpoMemory: Multi-State Shape Memory for Programmable Morphing Interfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580638},
doi = {10.1145/3544548.3580638},
abstract = {Smart shape-changing materials can be adapted to different usages, which have been leveraged for dynamic affordances and on-demand haptic feedback in HCI. However, the applicability of these materials is often bottlenecked by their complex fabrication and the challenge of programming localized and individually addressable responses. In this work, we propose a toolkit for designing and fabricating programmable morphing objects using off-the-shelf epoxies. Our method involves varying the crosslinker to epoxy resin ratio to control morphing temperatures from 40 ℃ to 90 ℃, either across different regions of a shape memory device or across devices. Functional components (e.g., conductive fabric, magnetic particles) are also incorporated with the epoxy for sensing and active reconfiguration. A toolbox of fabrication methods and a primitive design library are introduced to support design ideation and programmable morphing. Finally, we demonstrate application examples, including morphing toys, a shape-changing input device, and an active window shutter.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {744},
numpages = {15},
keywords = {Tangible interfaces, reconfigurable devices, shape memory polymer},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581547,
author = {Shultz, Craig and Harrison, Chris},
title = {Flat Panel Haptics: Embedded Electroosmotic Pumps for Scalable Shape Displays},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581547},
doi = {10.1145/3544548.3581547},
abstract = {Flat touch interfaces, with or without screens, pervade the modern world. However, their haptic feedback is minimal, prompting much research into haptic and shape-changing display technologies which are self-contained, fast acting, and offer millimeters of displacement while only being only millimeters thick. We present a new, miniaturizable type of shape-changing display using embedded electroosmotic pumps (EEOPs). Our pumps, controlled and powered directly by applied voltage, are 1.5mm in thickness, and allow complete stackups under 5mm. Nonetheless, they can move their entire volume’s worth of fluid in 1 second, and generate pressures of +/-50kPa, enough to create dynamic, millimeter-scale tactile features on a surface that can withstand typical interaction forces (&lt;1N). These are the requisite technical ingredients to enable, for example, a pop-up keyboard on a flat smartphone. We experimentally quantify the mechanical and psychophysical performance of our displays and conclude with a set of example interfaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {745},
numpages = {16},
keywords = {Shape-changing displays, Microfluidics, Haptics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581064,
author = {Herbst, Yair and Wolf, Alon and Zelnik-Manor, Lihi},
title = {HUGO, a High-Resolution Tactile Emulator for Complex Surfaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581064},
doi = {10.1145/3544548.3581064},
abstract = {Many of our activities rely on tactile feedback perceived through mechanoreceptors in our skin. While visual and auditory devices provide immersive experiences, cutaneous feedback devices are typically limited in the range of sensations they provide and are hence usually used and tested on relatively simple synthetic surfaces. We present a device designed in a human-centered process, triggering the mechanoreceptors sensitive to pressure, low-frequency vibrations, and high-frequency vibrations, enabling one to experience touch of complex real-world surfaces. The device is based on a parallel manipulator and a pin-array, that operate simultaneously at 200Hz and emulate coarse and fine geometrical features, respectively. The decomposition into coarse and fine features, alongside the high operation frequency, enable simulation of virtual surfaces. This was corroborated via experiments on complex real-world surfaces via both a quantitative recognition test and a usability questionnaire. We believe that this design can be incorporated in numerous applications.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {746},
numpages = {15},
keywords = {Haptics, High-Resolution Haptics, Human Computer Interface, User Study, Haptic Textures},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581179,
author = {Fan, Zhuzhi and Coutrix, C\'{e}line},
title = {Impact of Softness on Users’ Perception of Curvature for Future Soft Curvature-Changing UIs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581179},
doi = {10.1145/3544548.3581179},
abstract = {Soft (compliant) curvature-changing UIs provide haptic feedback through changes in softness and curvature. Different softness can impact the deformation of UIs when worn and touched, and thus impact the users’ perception of the curvature. To investigate how softness impacts users’ perception of curvature, we measured participants’ curvature perception accuracy and precision in different softness conditions. We found that participants perceived the curviest surfaces with similar precision in all different softness conditions. Participants lost half the precision of the rigid material when touching the flattest surfaces with the softest material. Participants perceived all curvatures with similar accuracy in all softness conditions. The results of our experiment lay the foundation for soft curvature perception and provide guidelines for the future design of curvature- and softness-changing UIs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {747},
numpages = {19},
keywords = {Shape-changing UIs, Just Noticeable difference., Psychophysics, Soft UIs},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581254,
author = {Li, Jiasheng and Yan, Zeyu and Shah, Arush and Lazar, Jonathan and Peng, Huaishu},
title = {Toucha11y: Making Inaccessible Public Touchscreens Accessible},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581254},
doi = {10.1145/3544548.3581254},
abstract = {Despite their growing popularity, many public kiosks with touchscreens are inaccessible to blind people. Toucha11y is a working prototype that allows blind users to use existing inaccessible touchscreen kiosks independently and with little effort. Toucha11y consists of a mechanical bot that can be instrumented to an arbitrary touchscreen kiosk by a blind user and a companion app on their smartphone. The bot, once attached to a touchscreen, will recognize its content, retrieve the corresponding information from a database, and render it on the user’s smartphone. As a result, a blind person can use the smartphone’s built-in accessibility features to access content and make selections. The mechanical bot will detect and activate the corresponding touchscreen interface. We present the system design of Toucha11y along with a series of technical evaluations. Through a user study, we found out that Toucha11y could help blind users operate inaccessible touchscreen devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {748},
numpages = {13},
keywords = {accessibility, visual impairments, touchscreen appliances, robotic},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581518,
author = {Bhat, Avinash and Coursey, Austin and Hu, Grace and Li, Sixian and Nahar, Nadia and Zhou, Shurui and K\"{a}stner, Christian and Guo, Jin L.C.},
title = {Aspirations and Practice of ML Model Documentation: Moving the Needle with Nudging and Traceability},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581518},
doi = {10.1145/3544548.3581518},
abstract = {The documentation practice for machine-learned (ML) models often falls short of established practices for traditional software, which impedes model accountability and inadvertently abets inappropriate or misuse of models. Recently, model cards, a proposal for model documentation, have attracted notable attention, but their impact on the actual practice is unclear. In this work, we systematically study the model documentation in the field and investigate how to encourage more responsible and accountable documentation practice. Our analysis of publicly available model cards reveals a substantial gap between the proposal and the practice. We then design a tool named DocML aiming to (1) nudge the data scientists to comply with the model cards proposal during the model development, especially the sections related to ethics, and (2) assess and manage the documentation quality. A lab study reveals the benefit of our tool towards long-term documentation quality and accountability.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {749},
numpages = {17},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581003,
author = {Rakotonarivo, Balita Heriniaina and Drougard, Nicolas and Conversy, St\'{e}phane and Garcia, J\'{e}r\'{e}mie},
title = {Cleared for Safe Take-off? Improving the Usability of Mission Preparation to Mitigate the Safety Risks of Drone Operations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581003},
doi = {10.1145/3544548.3581003},
abstract = {Drone operations such as power line inspection, automated deliveries, or crowd control are becoming more widespread. For flights that present serious risks to human safety, operators must conduct safety assessments and get authorizations from the regulators. These preparation tasks are complex and time-consuming but few previous works addressed them. We interviewed 14 professional drone operators, safety study consultants, and 2 regulators to better understand the needs for these tasks. The result is a workable model of the tasks which includes defining the concept of operation, assessing operational risks, and negotiating for authorization. We devised 9 recommendations to inform the design of future mission preparation tools, and consolidated them with a follow-up questionnaire. The recommendations include systematically describing a mission with operational parameters, showing their estimated impact on mission safety, or enabling awareness of the application’s status among all stakeholders. We conclude with design concerns and opportunities to inform future research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {750},
numpages = {17},
keywords = {Policy/Politics/Legal Issues, Survey, Empirical study that tells us about people, Interview, Collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581391,
author = {Lee, Hsinju and Hsu, Fang-Hsin and Li, Wei-Ko and Tsai, Jie and Chen, Ying-Yu and Chang, Yung-Ju},
title = {Get Distracted or Missed the Stop? Investigating Public Transit Passengers’ Travel-Based Multitasking Behaviors, Motives, and Challenges},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581391},
doi = {10.1145/3544548.3581391},
abstract = {Mobile users commonly multitask during travel, but doing so on public transit can be challenging due to the dynamic nature of the environment as well as long-standing lack of infrastructural support. Nevertheless, HCI scholars and practitioners have devoted relatively little attention to developing technology for enhancing travel multitasking. To facilitate such development, we sought to understand travel multitaskers’ practices and challenges while on public transit, and to that end, conducted a multi-methods study that involved shadowing and interviewing 30 of them. We identified four travel-multitasking patterns, characterized by distinct motives that affected these travelers’ multitasking practices, receptivity to environmental stimuli, and task persistence. The two main challenges they encountered during travel multitasking resulted from mutual interference from their tasks and from the dynamic nature of transit environments. Based on these findings, design recommendations for public-transit agencies and mobile services are also provided.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {751},
numpages = {14},
keywords = {HCI, Public Transit, Travel-Based Multitasking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581241,
author = {Zhang-Kennedy, Leah and Aziz, Saira and Oluwadare, Oluwafunminitemi (Temi) and Pan, Lyndon and Wu, Zeyu and Lamorea, Sydney E.C. and Li, Soda and Sun, Michael and M\"{a}kel\"{a}, Ville},
title = {Passenger Perceptions, Information Preferences, and Usability of Crowding Visualizations on Public Displays in Transit Stations and Vehicles},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581241},
doi = {10.1145/3544548.3581241},
abstract = {Large crowds in public transit stations and vehicles introduce obstacles for wayfinding, hygiene, and physical distancing. Public displays that currently provide on-site transit information could also provide critical crowdedness information. Therefore, we examined people’s crowd perceptions and information preferences before and during the pandemic, and designs for visualizing crowdedness to passengers. We first report survey results with public transit users (n = 303), including the usability results of three crowdedness visualization concepts. Then, we present two animated crowd simulations on public displays that we evaluated in a field study (n = 44). We found that passengers react very positively to crowding information, especially before boarding a vehicle. Visualizing the exact physical spaces occupied on transit vehicles was most useful for avoiding crowded areas. However, visualizing the overall fullness of vehicles was the easiest to understand. We discuss design implications for communicating crowding information to support decision-making and promote a sense of safety.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {752},
numpages = {15},
keywords = {crowding, covid-19, visualization, public transit, public displays},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581564,
author = {Chu, Mengdi and Zong, Keyu and Shu, Xin and Gong, Jiangtao and Lu, Zhicong and Guo, Kaimin and Dai, Xinyi and Zhou, Guyue},
title = {Work with AI and Work for AI: Autonomous Vehicle Safety Drivers’ Lived Experiences},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581564},
doi = {10.1145/3544548.3581564},
abstract = {The development of Autonomous Vehicle (AV) has created a novel job, the safety driver, recruited from experienced drivers to supervise and operate AV in numerous driving missions. Safety drivers usually work with non-perfect AV in high-risk real-world traffic environments for road testing tasks. However, this group of workers is under-explored in the HCI community. To fill this gap, we conducted semi-structured interviews with 26 safety drivers. Our results present how safety drivers cope with defective algorithms and shape and calibrate their perceptions while working with AV. We found that, as front-line workers, safety drivers are forced to take risks accumulated from the AV industry upstream and are also confronting restricted self-development in working for AV development. We contribute the first empirical evidence of the lived experience of safety drivers, the first passengers in the development of AV, and also the grassroots workers for AV, which can shed light on future human-AI interaction research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {753},
numpages = {16},
keywords = {autonomous driving, responsible AI, AI perception, AI labor, human-AI interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581075,
author = {Sivaraman, Venkatesh and Bukowski, Leigh A and Levin, Joel and Kahn, Jeremy M. and Perer, Adam},
title = {Ignore, Trust, or Negotiate: Understanding Clinician Acceptance of AI-Based Treatment Recommendations in Health Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581075},
doi = {10.1145/3544548.3581075},
abstract = {Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term “negotiation.” These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {754},
numpages = {18},
keywords = {visualization, healthcare, human-AI interaction, interpretability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581197,
author = {Wischnewski, Magdalena and Kr\"{a}mer, Nicole and M\"{u}ller, Emmanuel},
title = {Measuring and Understanding Trust Calibrations for Automated Systems: A Survey of the State-Of-The-Art and Future Directions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581197},
doi = {10.1145/3544548.3581197},
abstract = {Trust has been recognized as a central variable to explain the resistance to using automated systems (under-trust) and the overreliance on automated systems (over-trust). To achieve appropriate reliance, users’ trust should be calibrated to reflect a system’s capabilities. Studies from various disciplines have examined different interventions to attain such trust calibration. Based on a literature body of 1000+ papers, we identified 96 relevant publications which aimed to calibrate users’ trust in automated systems. To provide an in-depth overview of the state-of-the-art, we reviewed and summarized measurements of the trust calibration, interventions, and results of these efforts. For the numerous promising calibration interventions, we extract common design choices and structure these into four dimensions of trust calibration interventions to guide future studies. Our findings indicate that the measurement of the trust calibration often limits the interpretation of the effects of different interventions. We suggest future directions for this problem.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {755},
numpages = {16},
keywords = {warranted trust, automation, trust calibration, survey, empirical studies},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581253,
author = {Cheng, Lingwei and Chouldechova, Alexandra},
title = {Overcoming Algorithm Aversion: A Comparison between Process and Outcome Control},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581253},
doi = {10.1145/3544548.3581253},
abstract = {Algorithm aversion occurs when humans are reluctant to use algorithms despite their superior performance. Studies show that giving users outcome control by providing agency over how models’ predictions are incorporated into decision-making mitigates algorithm aversion. We study whether algorithm aversion is mitigated by process control, wherein users can decide what input factors and algorithms to use in model training. We conduct a replication study of outcome control, and test novel process control study conditions on Amazon Mechanical Turk (MTurk) and Prolific. Our results partly confirm prior findings on the mitigating effects of outcome control, while also forefronting reproducibility challenges. We find that process control in the form of choosing the training algorithm mitigates algorithm aversion, but changing inputs does not. Furthermore, giving users both outcome and process control does not reduce algorithm aversion more than outcome or process control alone. This study contributes to design considerations around mitigating algorithm aversion.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {756},
numpages = {27},
keywords = {customization, model design, algorithm aversion},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581550,
author = {Sidji, Matthew and Smith, Wally and Rogerson, Melissa J.},
title = {The Hidden Rules of Hanabi: How Humans Outperform AI Agents},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581550},
doi = {10.1145/3544548.3581550},
abstract = {Games that feature multiple players, limited communication, and partial information are particularly challenging for AI agents. In the cooperative card game Hanabi, which possesses all of these attributes, AI agents fail to achieve scores comparable to even first-time human players. Through an observational study of three mixed-skill Hanabi play groups, we identify the techniques used by humans that help to explain their superior performance compared to AI. These concern physical artefact manipulation, coordination play, role establishment, and continual rule negotiation. Our findings extend previous accounts of human performance in Hanabi, which are purely in terms of theory-of-mind reasoning, by revealing more precisely how this form of collective decision-making is enacted in skilled human play. Our interpretation points to a gap in the current capabilities of AI agents to perform cooperative tasks.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {757},
numpages = {16},
keywords = {Human-Computer Interaction, boardgames, Human-AI Interaction, Human-AI Teaming, social roles, teaming, theory of mind},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581366,
author = {Wang, Xinru and Yin, Ming},
title = {Watch Out for Updates: Understanding the Effects of Model Explanation Updates in AI-Assisted Decision Making},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581366},
doi = {10.1145/3544548.3581366},
abstract = {AI explanations have been increasingly used to help people better utilize AI recommendations in AI-assisted decision making. While AI explanations may change over time due to updates of the AI model, little is known about how these changes may affect people’s perceptions and usage of the model. In this paper, we study how varying levels of similarity between the AI explanations before and after a model update affects people’s trust in and satisfaction with the AI model. We conduct randomized human-subject experiments on two decision making contexts where people have different levels of domain knowledge. Our results show that changes in AI explanation during the model update do not affect people’s tendency to adopt AI recommendations. However, they may change people’s subjective trust in and satisfaction with the AI model via changing both their perceived model accuracy and perceived consistency of AI explanations with their prior knowledge.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {758},
numpages = {19},
keywords = {Human-subject experiments, AI updates, Explainable AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581058,
author = {Ma, Shuai and Lei, Ying and Wang, Xinru and Zheng, Chengbo and Shi, Chuhan and Yin, Ming and Ma, Xiaojuan},
title = {Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581058},
doi = {10.1145/3544548.3581058},
abstract = {In AI-assisted decision-making, it is critical for human decision-makers to know when to trust AI and when to trust themselves. However, prior studies calibrated human trust only based on AI confidence indicating AI’s correctness likelihood (CL) but ignored humans’ CL, hindering optimal team decision-making. To mitigate this gap, we proposed to promote humans’ appropriate trust based on the CL of both sides at a task-instance level. We first modeled humans’ CL by approximating their decision-making models and computing their potential performance in similar instances. We demonstrated the feasibility and effectiveness of our model via two preliminary studies. Then, we proposed three CL exploitation strategies to calibrate users’ trust explicitly/implicitly in the AI-assisted decision-making process. Results from a between-subjects experiment (N=293) showed that our CL exploitation strategies promoted more appropriate human trust in AI, compared with only using AI confidence. We further provided practical implications for more human-compatible AI-assisted decision-making.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {759},
numpages = {19},
keywords = {AI-Assisted Decision-making, Trust Calibration, Human-AI Collaboration, Trust in AI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581108,
author = {Cao, Hancheng and Lu, Yujie and Deng, Yuting and Mcfarland, Daniel and Bernstein, Michael S.},
title = {Breaking Out of the Ivory Tower: A Large-Scale Analysis of Patent Citations to HCI Research},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581108},
doi = {10.1145/3544548.3581108},
abstract = {What is the impact of human-computer interaction research on industry? While it is impossible to track all research impact pathways, the growing literature on translational research impact measurement offers patent citations as one measure of how industry recognizes and draws on research in its inventions. In this paper, we perform a large-scale measurement study primarily of 70, 000 patent citations to premier HCI research venues, tracing how HCI research are cited in United States patents over the last 30 years. We observe that 20.1% of papers from these venues, including 60–80% of papers at UIST and 13% of papers in a broader dataset of SIGCHI-sponsored venues overall, are cited by patents—far greater than premier venues in science overall (9.7%) and NLP (11%). However, the time lag between a patent and its paper citations is long (10.5 years) and getting longer, suggesting that HCI research and practice may not be efficiently connected.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {760},
numpages = {24},
keywords = {Industry impact, citation analysis, technology transfer, patent, translational science},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581006,
author = {Lin, Georgianna and Li, Jin Yi and Fazly, Afsaneh and Pavlovic, Vladimir and Truong, Khai},
title = {Identifying Multimodal Context Awareness Requirements for Supporting User Interaction with Procedural Videos},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581006},
doi = {10.1145/3544548.3581006},
abstract = {Following along how-to videos requires alternating focus between understanding procedural video instructions and performing them. Examining how to support these continuous context switches for the user has been largely unexplored. In this paper, we describe a user study with thirty participants who performed an hour-long cooking task while interacting with a wizard-of-oz hands-free interactive system that is aware of both their cooking progress and environment contexts. Through analysis of the session scripts, we identify a dichotomy between participant query differences and workflow alignment similarities, under-studied interactions that require AI functionality beyond video navigation alone, and queries that call for multimodal sensing of a user’s environment. By understanding the assistant experience through the participants’ interactions, we identify design implications for a smart assistant that can discern a user’s task completion flow and personal characteristics, accommodate requests within and external to the task domain, and support nonvoice-based queries.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {761},
numpages = {17},
keywords = {Context Aware Assistants, Alternating Task, Procedural How-to Videos},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580661,
author = {Rayed, Mohammad and Elahi, Tawfique and Arefin Shimon, Shaikh Shawon and Ahmed, Nova},
title = {MFS Design in Appstore-Enabled Smart Featurephones for Low-Literate, Marginalized Communities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580661},
doi = {10.1145/3544548.3580661},
abstract = {Mobile Financial Services (MFS) has gained significant popularity during the COVID-19 pandemic, especially among marginalized and low-income, low-literate communities around the world. Such communities have not been traditionally considered while designing MFS services via smartphone apps or USSD services in featurephones. Financial constraints limit such end-users towards basic featurephones, where recent appstore support has made it possible to deploy app-based MFS solutions beyond USSD. This new featurephone platform is a relatively underexplored area in terms of addressing design issues related to aforementioned end-users while developing MFS solutions. Our work addresses this gap by presenting qualitative findings on barriers to technology access focused on MFS solutions in marginal communities. We present a prototype non-USSD, app-based solution on an appstore-supported featurephone platform designed via a human-centered approach. This work has the potential to increase the financial inclusivity of marginalized communities in cashless MFS transactions via low-cost, appstore-enabled featurephones.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {762},
numpages = {19},
keywords = {User Experience Design, Mobile Devices: Phones/Tablets, HCI for Development, Finance/Money},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581077,
author = {Ford, Corey and Bryan-Kinns, Nick},
title = {Towards a Reflection in Creative Experience Questionnaire},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581077},
doi = {10.1145/3544548.3581077},
abstract = {Reflection is underexplored in Creativity Support Tool (CST) research, partly due to its ambiguous nature. We suggest that researchers could benefit from a measure of a CST’s capacity to support reflection. To this end, we detail the first stages of development of the Reflection in Creative Experience Questionnaire (RiCE) – a lightweight questionnaire for differentiating between creative user experiences which exhibit more or less moments of reflection. We develop RiCE through i) an expert review of questionnaire items (n=10) and ii) an exploratory factor analysis (n=300) of the reviewed items. We also present a user study testing RiCE (n=58) across two time points (one week apart) with novel interfaces designed for creative writing and music making. Although we do not confirm validity, we identify four factors for RiCE which we suggest are interpretable in a conceptually meaningful way. Our formative studies contribute towards supporting future explorations on reflection with CSTs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {763},
numpages = {16},
keywords = {reflection, psychometrics, reflective practice, metrics, evaluation, factor analysis, creativity support tools, creativity, creative process},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581273,
author = {Feng, K. J. Kevin and Li, Tony W and Zhang, Amy X.},
title = {Understanding Collaborative Practices and Tools of Professional UX Practitioners in Software Organizations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581273},
doi = {10.1145/3544548.3581273},
abstract = {User experience (UX) has undergone a revolution in collaborative practices, due to tools that enable quick feedback and continuous collaboration with a varied team across a design’s lifecycle. However, it is unclear how this shift in collaboration has been received in professional UX practice, and whether new pain points have arisen. To this end, we conducted a survey (N = 114) with UX practitioners at software organizations based in the U.S. to better understand their collaborative practices and tools used throughout the design process. We found that while an increase in collaborative activity enhanced many aspects of UX work, some long-standing challenges—such as handing off designs to developers—still persist. Moreover, we observed new challenges emerging from activities enabled by collaborative tools such as design system management. Based on our findings, we discuss how UX practices can improve collaboration moving forward and provide concrete design implications for collaborative UX tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {764},
numpages = {20},
keywords = {user experience, design practice, collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580712,
author = {Hsieh, Gary and Halperin, Brett A. and Schmitz, Evan and Chew, Yen Nee and Tseng, Yuan-Chi},
title = {What is in the Cards: Exploring Uses, Patterns, and Trends in Design Cards},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580712},
doi = {10.1145/3544548.3580712},
abstract = {Card-based design tools–design cards–increasingly present opportunities to support practitioners. However, the breadth and depth of the design card landscape remain underexplored. In this work, we surveyed 103 design practitioners to assess current usages and associated barriers. Additionally, we analyzed and classified 161 decks of design cards from 1952-2020. We held a workshop with four experienced practitioners to generate initial categories, and then coded the remaining decks. We found that the cards contain seven different types of design knowledge: Creative Inspiration; Human Insights; Material &amp; Domain; Methods &amp; Tooling; Problem Definition; Team Building; and Values in Practice. The content of these cards can support designers across design stages; however, most are intended to support the early stages of design (e.g., research and ideation) rather than later design stages (e.g., prototyping and implementation). We share additional patterns uncovered and provide recommendations to support the future development and adoption of these tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {765},
numpages = {18},
keywords = {Design Cards, Card-based Design Tools},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580971,
author = {Porcheron, Martin and Clark, Leigh and Nicholson, Stuart Alan and Jones, Matt},
title = {Cyclists’ Use of Technology While on Their Bike},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580971},
doi = {10.1145/3544548.3580971},
abstract = {Cycling continues to grow in popularity, both as a means to commute and for exercise. While there is a plethora of research studying technology use in vehicular travel, cycling remains a relatively understudied area—especially within HCI. We conducted an ethnography, adopting an ethnomethodological lens, to study cyclists as they use their bicycles for routine purposes. Through the use of a handlebar-mounted 360-degree action video camera, we conducted our study longitudinally with participants over a number of weeks. Our analysis explicates our participants accountable use of different electronic technologies while on the go and in this paper we present four fragments of their use of different technologies as exemplars from our corpus. Our paper offers insights into the use of technology on bicycles, including how cyclists select moments of opportunity to use technology for different purposes. We conclude by offering design implications for the design of interactive technologies for cyclists.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {766},
numpages = {15},
keywords = {cycling, video ethnography, smartphone, earphones, ethnomethodology, smartwatch, mobile interaction, bike computer},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580862,
author = {Hwang, Seokhyun and Lee, Jieun and Kim, Youngin and Seo, Youngseok and Kim, Seungjun},
title = {Electrical, Vibrational, and Cooling Stimuli-Based Redirected Walking: Comparison of Various Vestibular Stimulation-Based Redirected Walking Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580862},
doi = {10.1145/3544548.3580862},
abstract = {Redirected walking (RDW) is a technology that enables users to walk seamlessly in an enormous virtual space within a narrow real space while avoiding collisions with physical elements. Although RDW provides accurate proprioceptive sensations, redirection performance is limited by visual–vestibular inconsistencies. This study aims to support seamless walking in a VR environment by alleviating inconsistencies using four vestibular stimulations: noisy and directional galvanic vestibular stimulation, bone-conduction vibration, and caloric vestibular stimulation. The user study demonstrated that the stimulations successfully enable spatial expansion without impairing immersion and presence. Non-electrical stimulations (bone-conduction vibration and caloric vestibular stimulation) expanded the detection threshold, making them alternatives to electrical stimulations, and direction-based stimulation (directional galvanic vestibular stimulation) improved the user’s gait stability in RDW. Finally, the findings suggested improving the user experience for vestibular stimulation RDW either by lowering audio interference or increasing the synchronization between the RDW gain and the stimulation intensity.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {767},
numpages = {18},
keywords = {Locomotion, Vestibular Stimulation, Gait Stability, Virtual Reality, Haptic Device, Redirected Walking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581303,
author = {Lanzer, Mirjam and Koniakowsky, Ina and Colley, Mark and Baumann, Martin},
title = {Interaction Effects of Pedestrian Behavior, Smartphone Distraction and External Communication of Automated Vehicles on Crossing and Gaze Behavior},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581303},
doi = {10.1145/3544548.3581303},
abstract = {External communication of automated vehicles is proposed to replace driver-pedestrian communication in ambiguous crossing situations. So far, research has focused on simpler scenarios with one attentive pedestrian and one automated vehicle. This virtual reality study (N=115) investigates a more complex scenario with other crossing pedestrians, a distracting task on the smartphone, and external communication by the automated vehicle. Interaction effects were found for crossing duration, gaze behavior, and subjective measures. For attentive pedestrians, the external communication resulted in shorter crossing durations, higher perceived safety, as well as lower perceived criticality, cognitive workload, and effort. These positive effects were not found when pedestrians were distracted. Instead, distracted pedestrians benefited from other crossing pedestrians because they looked less at the stopping vehicle, felt safer, perceived the situation as less critical, and reported lower cognitive workload and effort. Pedestrians initiated crossings earlier with a group or external communication and later with a smartphone.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {768},
numpages = {18},
keywords = {smartphone distraction, eye tracking, pedestrian group, automated vehicles, unsignalized crossing, eHMI, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581049,
author = {Al-Taie, Ammar and Abdrabou, Yasmeen and Macdonald, Shaun Alexander and Pollick, Frank and Brewster, Stephen Anthony},
title = {Keep It Real: Investigating Driver-Cyclist Interaction in Real-World Traffic},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581049},
doi = {10.1145/3544548.3581049},
abstract = {Cyclists encounter drivers in many traffic scenarios; good communication is key to avoiding collisions. Little is known about everyday driver-cyclist interaction and communication. This is important in designing Automated Vehicles (AVs) that must drive safely around cyclists. We explored driver-cyclist interaction across diverse scenarios through in-the-wild observations (N = 414) and a naturalistic study involving cyclists wearing eye-trackers (N = 12). Results showed cyclists attended to road markings and traffic signs in controlled traffic scenarios but to vehicle sides and windows in uncontrolled encounters. Interactions were unlikely at controlled intersections, but various techniques were used to negotiate right-of-way in uncontrolled scenarios, e.g. cyclists used arm gestures and shoulder checks to communicate their intent and awareness when lane merging. Drivers communicated these through on-vehicle signals and head movements at roundabouts. We discuss the implications of driver-cyclist interaction behaviour on AV interaction design and offer insights into system requirements to support cyclists riding in traffic.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {769},
numpages = {15},
keywords = {Observations, Cyclists, Autonomous Vehicle-Cyclist Interaction, Vulnerable Road Users, Field Study, Eye-Tracking, Naturalistic Study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581469,
author = {Shi, Chuhan and Hu, Yicheng and Wang, Shenan and Ma, Shuai and Zheng, Chengbo and Ma, Xiaojuan and Luo, Qiong},
title = {RetroLens: A Human-AI Collaborative System for Multi-Step Retrosynthetic Route Planning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581469},
doi = {10.1145/3544548.3581469},
abstract = {Multi-step retrosynthetic route planning (MRRP) is the core task in synthetic chemistry, in which chemists recursively deconstruct a target molecule to find a set of reactants that make up the target. MRRP is challenging in that the search space is vast, and chemists are often lost in the process. Existing AI models can achieve automatic MRRP fast, but they only work on relatively simple targets, which leaves complex molecules under chemists’ expertise. To facilitate MRRP of complex molecules, we proposed a human-AI collaborative system, RetroLens, through a participatory design process. AI can contribute by two approaches: joint action and algorithm-in-the-loop. Deconstruction steps are allocated to chemists or AI based on their capabilities and AI recommends candidate revision steps to fix problems along the way. A within-subjects study (N=18) showed that chemists who used RetroLens reported faster MRRP, broader design space exploration, higher confidence in their planning, and lower cognitive load.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {770},
numpages = {20},
keywords = {multi-criteria decision making, Human-AI collaboration, multi-step problem solving},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581274,
author = {Bala, Paulo and Sanches, Pedro and Ces\'{a}rio, Vanessa and Le\~{a}o, Sarah and Rodrigues, Catarina and Nunes, Nuno Jardim and Nisi, Valentina},
title = {Towards Critical Heritage in the Wild: Analysing Discomfort through Collaborative Autoethnography},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581274},
doi = {10.1145/3544548.3581274},
abstract = {As we engaged in designing digital interventions for intercultural dialogues around public cultural heritage sites, we saw an opportunity to surface multiple interpretations and points of view of history and shine a critical lens on current societal issues. To do so, we present the results of a collaborative auto-ethnography of alternative tours accompanied by intercultural guides, to explore sensory and embodied engagements with cultural heritage sites in a southern European capital. By focusing on the differences in how we experienced the heritage sites, we analyse the duality of discomfort, a common concept in HCI, in that it can both be deployed as a resource for designing systems that can transform people’s understanding of history or it can be a hindrance for engagement, having an unequal effect on individuals.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {771},
numpages = {19},
keywords = {cultural heritage, intercultural dialogues, ethnography},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581483,
author = {Keurulainen, Antti and Westerlund, Isak Rafael and Keurulainen, Oskar and Howes, Andrew},
title = {Amortised Experimental Design and Parameter Estimation for User Models of Pointing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581483},
doi = {10.1145/3544548.3581483},
abstract = {User models play an important role in interaction design, supporting automation of interaction design choices. In order to do so, model parameters must be estimated from user data. While very large amounts of user data are sometimes required, recent research has shown how experiments can be designed so as to gather data and infer parameters as efficiently as possible, thereby minimising the data requirement. In the current article, we investigate a variant of these methods that amortises the computational cost of designing experiments by training a policy for choosing experimental designs with simulated participants. Our solution learns which experiments provide the most useful data for parameter estimation by interacting with in-silico agents sampled from the model space thereby using synthetic data rather than vast amounts of human data. The approach is demonstrated for three progressively complex models of pointing.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {772},
numpages = {17},
keywords = {parameter estimation, active inference, user models, adaptive experiment design, computational rationality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581439,
author = {Moon, Hee-Seung and Oulasvirta, Antti and Lee, Byungjoo},
title = {Amortized Inference with User Simulations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581439},
doi = {10.1145/3544548.3581439},
abstract = {There have been significant advances in simulation models predicting human behavior across various interactive tasks. One issue remains, however: identifying the parameter values that best describe an individual user. These parameters often express personal cognitive and physiological characteristics, and inferring their exact values has significant effects on individual-level predictions. Still, the high complexity of simulation models usually causes parameter inference to consume prohibitively large amounts of time, as much as days per user. We investigated amortized inference for its potential to reduce inference time dramatically, to mere tens of milliseconds. Its principle is to pre-train a neural proxy model for probabilistic inference, using synthetic data simulated from a range of parameter combinations. From examining the efficiency and prediction performance of amortized inference in three challenging cases that involve real-world data (menu search, point-and-click, and touchscreen typing), the paper demonstrates that an amortized-inference approach permits analyzing large-scale datasets by means of simulation models. It also addresses emerging opportunities and challenges in applying amortized inference in HCI.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {773},
numpages = {20},
keywords = {inverse modeling, simulation models, amortized inference},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580686,
author = {Lim, Chungman and Park, Gunhyuk},
title = {Can a Computer Tell Differences between Vibrations?: Physiology-Based Computational Model for Perceptual Dissimilarity Prediction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580686},
doi = {10.1145/3544548.3580686},
abstract = {Perceptual dissimilarities, requiring high-cost user ratings, have contributed to designing well-distinguishable vibrations for associated meaning delivery. Appropriate metrics can reduce the cost, but known metrics in vibration similarity/dissimilarity could not predict them robustly. We propose a physiology-based model (PM) that predicts the perceptual dissimilarities of a given vibration set via two parallel processes: Neural Coding (NC), mimicking the neural signal transfer, and One-dimensional Convolution (OC), capturing rhythmic features. Eight parameters were trained using six datasets published in the literature to maximize Spearman’s Rank Correlation. We validated PM and six metrics of RMSE, DTW, Spectral/Temporal Matchings, ST-SIM, and SPQI in twelve datasets: six trained and six untrained datasets including measured accelerations. In all validations, PM’s predictions showed robust correlations with user data and similar structures in perceptual spaces. Other baseline metrics showed better fit in specific datasets, but none of them robustly showed correlations and similar perceptual spaces over twelve datasets.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {774},
numpages = {15},
keywords = {Vibrotactile Perception, Computational Model, Perceptual Dissimilarity, Biomimetic Modeling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581482,
author = {Suresh, Harini and Shanmugam, Divya and Chen, Tiffany and Bryan, Annie G and D'Amour, Alexander and Guttag, John and Satyanarayan, Arvind},
title = {Kaleidoscope: Semantically-Grounded, Context-Specific ML Model Evaluation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581482},
doi = {10.1145/3544548.3581482},
abstract = {Desired model behavior often differs across contexts (e.g., different geographies, communities, or institutions), but there is little infrastructure to facilitate context-specific evaluations key to deployment decisions and building trust. Here, we present Kaleidoscope, a system for evaluating models in terms of user-driven, domain-relevant concepts. Kaleidoscope’s iterative workflow enables generalizing from a few examples into a larger, diverse set representing an important concept. These example sets can be used to test model outputs or shifts in model behavior in semantically-meaningful ways. For instance, we might construct a “xenophobic comments” set and test that its examples are more likely to be flagged by a content moderation model than a “civil discussion” set. To evaluate Kaleidoscope, we compare it against template- and DSL-based grouping methods, and conduct a usability study with 13 Reddit users testing a content moderation model. We find that Kaleidoscope facilitates iterative, exploratory hypothesis testing across diverse, conceptually-meaningful example sets.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {775},
numpages = {13},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580767,
author = {Gonzalez, Eric J and Follmer, Sean},
title = {Sensorimotor Simulation of Redirected Reaching Using Stochastic Optimal Feedback Control},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580767},
doi = {10.1145/3544548.3580767},
abstract = {Illusory VR interaction techniques such as hand redirection work because humans use vision to adjust their motor commands during movement (e.g., reaching). Existing simulations of redirected reaching are limited, however, and have not yet incorporated important stochastic characteristics like sensorimotor noise, nor captured redirection’s effect on movement duration. In this work, we propose adapting a stochastic optimal feedback control (SOFC) model of normal reach to simulate redirection by augmenting sensory feedback at run-time. We present a summary of our simulation and validate it against user data gathered in multiple redirection conditions. We also evaluate the impacts of visual attention on the effectiveness of redirection in real users and replicate the effects in simulation. Our results show that an infinite-horizon SOFC model is able to reproduce key characteristics of redirected reaches and highlight the benefits of SOFC as a tool for simulating, evaluating, and gaining insights about redirection techniques.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {776},
numpages = {17},
keywords = {Optimal Control, Modeling, Stochastic Simulation, Sensorimotor Control, Virtual Reality, Hand Redirection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581217,
author = {Zhang, Hao and Huang, Jin and Tu, Huawei and Tian, Feng},
title = {Shape-Adaptive Ternary-Gaussian Model: Modeling Pointing Uncertainty for Moving Targets of Arbitrary Shapes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581217},
doi = {10.1145/3544548.3581217},
abstract = {This paper presents a Shape-Adaptive Ternary-Gaussian model for describing endpoint uncertainty when pointing at moving targets of arbitrary shapes. The basic idea of the model is to combine the uncertainty related to the target shape with the uncertainty caused by the target motion. First, we proposed a model to predict endpoint distribution on static targets based on a Dual-Space Decomposition (DUDE) algorithm. Then, we linearly combined a 2D Ternary-Gaussian model with the newly proposed DUDE-based model to make the 2D Ternary-Gaussian model adaptable to moving targets with random shapes. To verify the performance of our model, we compared it with the original 2D Ternary-Gaussian model and a recent proposed Inscribed Circle model in predicting endpoint distribution. The results show that the proposed model outperformed the two baseline models while maintaining good robustness across different shapes and moving speeds.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {777},
numpages = {18},
keywords = {Moving Target Selection, Models, Endpoint Distribution, Arbitrary Shapes, Pointing Uncertainty},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581009,
author = {Shen, Ximing and Pai, Yun Suen and Kiuchi, Dai and Bao, Kehan and Aoki, Tomomi and Meguro, Hikari and Oishi, Kanoko and Wang, Ziyue and Wakisaka, Sohei and Minamizawa, Kouta},
title = {Dementia Eyes: Co-Design and Evaluation of a Dementia Education Augmented Reality Experience for Medical Workers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581009},
doi = {10.1145/3544548.3581009},
abstract = {Dementia describes a syndrome of cognitive degeneration, and Behavioural and Psychological Symptoms of Dementia (BPSD) is the non-cognitive symptom. BPSD can be improved by care services. To aid better care service, we explore the potential of using Augmented Reality (AR) to support dementia education for medical workers in three steps: (1) We explore medical workers’ perspective on dementia care lived experience and XR, (2) we co-design an educational experience containing an AR-based application and a 5-min activity with medical workers, (3) we evaluate the effectiveness of the system through a mixed method study. Our result shows that the AR experience successfully touches participants, and motivates them to reflect on the provision of care service. On this basis, we discuss the elements and challenges of designing XR-enabled dementia education for users unfamiliar with novel technology, and the potential of using XR in clinical education.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {778},
numpages = {18},
keywords = {experience-centred design, education, augmented reality, dementia},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581262,
author = {Xu, Tong Bill and Mostafavi, Armin and Kim, Benjamin C. and Lee, Angella Anyi and Boot, Walter and Czaja, Sara and Kalantari, Saleh},
title = {Designing Virtual Environments for Social Engagement in Older Adults: A Qualitative Multi-Site Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581262},
doi = {10.1145/3544548.3581262},
abstract = {Virtual reality (VR) is increasingly used as a platform for social interaction, including as a means for elders to maintain engagement. However, not many empirical studies have been conducted to examine features of social VR that are most relevant to elders’ experiences. The current study qualitatively analyzed the behavior of older adults in a collaborative VR environment and evaluated aspects of design that affected their engagement outcomes. We paired 36 participants over the age of 60 from three diverse geographic locations to interact in collaborative VR modules. Video-based observation methods and thematic analyses were used to study their interactions. The results indicated a strong link between conversations about personal lives in VR and social engagement, highlighting the need for social VR to encourage users to create their own stories and share their life experiences. The study provides new insights into design guidelines that could improve social VR for older adults.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {779},
numpages = {15},
keywords = {social VR, older adults, social Engagement, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580809,
author = {McDonnell, Emma J and Moon, Soo Hyun and Jiang, Lucy and Goodman, Steven M. and Kushalnagar, Raja and Froehlich, Jon E. and Findlater, Leah},
title = {“Easier or Harder, Depending on Who the Hearing Person Is”: Codesigning Videoconferencing Tools for Small Groups with Mixed Hearing Status},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580809},
doi = {10.1145/3544548.3580809},
abstract = {With improvements in automated speech recognition and increased use of videoconferencing, real-time captioning has changed significantly. This shift toward broadly available but less accurate captioning invites exploration of the role hearing conversation partners play in shaping the accessibility of a conversation to d/Deaf and hard of hearing (DHH) captioning users. While recent work has explored DHH individuals’ videoconferencing experiences with captioning, we focus on established groups’ current practices and priorities for future tools to support more accessible online conversations. Our study consists of three codesign sessions, conducted with four groups (17 participants total, 10 DHH, 7 hearing). We found that established groups crafted social accessibility norms that met their relational contexts. We also identify promising directions for future captioning design, including the need to standardize speaker identification and customization, opportunities to provide behavioral feedback during a conversation, and ways that videoconferencing platforms could enable groups to set and share norms.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {780},
numpages = {15},
keywords = {Captioning, Videoconferencing, Accessibility, d/Deaf and hard of hearing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581076,
author = {Wang, Yiwen and Li, Ziming and Chelladurai, Pratheep Kumar and Dannels, Wendy and Oh, Tae and Peiris, Roshan L},
title = {Haptic-Captioning: Using Audio-Haptic Interfaces to Enhance Speaker Indication in Real-Time Captions for Deaf and Hard-of-Hearing Viewers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581076},
doi = {10.1145/3544548.3581076},
abstract = {Captions make the audio content of videos accessible and understandable for deaf or hard-of-hearing people (DHH). However, in real-time captioning scenarios, captions alone can be challenging for DHH users to identify the active speaker in a real time in multiple-speaker scenarios. To enhance the accessibility of real-time captioning, we propose Haptic-Captioning which provides real-time vibration feedback on the wrist by directly translating the sound of content into vibrations. We conducted three experiments to examine: (1) the haptic perception (Preliminary Study), (2) the feasibility of the haptic modality along with real-time and non-real-time visual captioning methods (Study 1), and (3) the user experience of using the Haptic-Captioning system in different media contexts (Study 2). Our results highlight that the Haptic-Captioning complements visual captions by improving caption readability, maintaining media engagement, enhancing understanding of emotions, and assisting speaker indication in real-time captioning scenarios. Furthermore, we discuss design implications for the future development of Haptic-Captioning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {781},
numpages = {14},
keywords = {accessibility, captioning, Haptics, deaf and hard of hearing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580788,
author = {Wu, Shaomei},
title = {“The World is Designed for Fluent People”: Benefits and Challenges of Videoconferencing Technologies for People Who Stutter},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580788},
doi = {10.1145/3544548.3580788},
abstract = {This work studies the experiences of people who stutter (PWS) with videoconferencing (VC) and VC technologies. Our interview study with 13 adults who stutter uncovers extra challenges introduced by current VC platforms to people who stutter. While some of the challenges are a direct result of the characteristics of stuttering (e.g. people/systems mistaking pauses as end of turn), a bigger yet less visible challenge comes with the significant amount of emotional and cognitive effort required to manage one’s speech and identity over VC, in which people’s existing communication strategies - such as body language and eye contact - are under-supported and their biggest discomfort - such as seeing oneself stutter - are exacerbated by preset features like self view. Overall, our work sheds light on the structural barriers and the opportunities for PWS to engage and enjoy virtual communications via VC technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {782},
numpages = {17},
keywords = {computer-mediated communication, accessibility, stuttering, speech diversity, videoconferencing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581399,
author = {Lowy, Rachel and Gao, Lan and Hall, Kaely and Kim, Jennifer G},
title = {Toward Inclusive Mindsets: Design Opportunities to Represent Neurodivergent Work Experiences to Neurotypical Co-Workers in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581399},
doi = {10.1145/3544548.3581399},
abstract = {Inclusive workplaces require mutual efforts between neurotypical (NT) and neurodivergent (ND) employees to understand one another’s viewpoints and experiences. Currently, the majority of inclusivity training places the burden of change on NDs to conform to NT social-behavioral standards. Our research examines moving toward a more equal effort distribution by exploring virtual reality (VR) design opportunities to build NTs’ understanding of ND workplace experiences. Using participatory design, including generative toolkits and design meetings, we surfaced two main themes that could bridge gaps in understanding: (1) NTs’ recognition of NDs’ strengths and efforts at work, and (2) NTs’ understanding of NDs’ differences. We present a strengths-based assessment of ND traits in the workplace, focusing on how workplaces can support NDs’ success. Finally, we propose VR simulation designs that communicate these themes to represent ND experiences, emphasizing their strengths and viewpoints so that NT co-workers can better empathize and accommodate them.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {783},
numpages = {17},
keywords = {neurodiversity, workplace, empathy-building, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581270,
author = {Kim, Minji and Lee, Kyungjin and Balan, Rajesh and Lee, Youngki},
title = {Bubbleu: Exploring Augmented Reality Game Design with Uncertain AI-Based Interaction},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581270},
doi = {10.1145/3544548.3581270},
abstract = {Object detection, while being an attractive interaction method for Augmented Reality (AR), is fundamentally error-prone due to the probabilistic nature of the underlying AI models, resulting in sub-optimal user experiences. In this paper, we explore the effect of three game design concepts, Ambiguity, Transparency, and Controllability, to provide better gameplay experiences in AR games that use error-prone object detection-based interaction modalities. First, we developed a base AR pet breeding game, called Bubbleu that uses object detection as a key interaction method. We then implemented three different variants, each according to the three concepts, to investigate the impact of each design concept on the overall user experience. Our user study results show that each design has its own strengths and can improve player experiences in different ways such as decreasing perceived errors (Ambiguity), explaining the system (Transparency), and enabling users to control the rate of uncertainties (Controllability).},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {784},
numpages = {18},
keywords = {Human-AI Interaction, computer vision, vision sensing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581259,
author = {Rasch, Julian and Rusakov, Vladislav Dmitrievic and Schmitz, Martin and M\"{u}ller, Florian},
title = {Going, Going, Gone: Exploring Intention Communication for Multi-User Locomotion in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581259},
doi = {10.1145/3544548.3581259},
abstract = {Exploring virtual worlds together with others adds a social component to the Virtual Reality (VR) experience that increases connectedness. In the physical world, joint locomotion comes naturally through implicit intention communication and subsequent adjustments of the movement patterns. In VR, however, discrete locomotion techniques such as point&amp;teleport come without prior intention communication, hampering the collective experience. Related work proposes fixed groups, with a single person controlling the group movement, resulting in the loss of individual movement capabilities. To close the gap and mediate between these two extremes, we introduce three intention communication methods and explore them with two baseline methods. We contribute the results of a controlled experiment (n=20) investigating these methods from the perspective of a leader and a follower in a dyadic locomotion task. Our results suggest shared visualizations support the understanding of movement intentions, increasing the group feeling while maintaining individual freedom of movement.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {785},
numpages = {13},
keywords = {Virtual Reality, SocialVR, Teleportation, Connectedness, Locomotion, Multi-User},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580973,
author = {Cmentowski, Sebastian and Karaosmanoglu, Sukran and Nacke, Lennart E. and Steinicke, Frank and Kr\"{u}ger, Jens Harald},
title = {Never Skip Leg Day Again: Training the Lower Body with Vertical Jumps in a Virtual Reality Exergame},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580973},
doi = {10.1145/3544548.3580973},
abstract = {Virtual Reality (VR) exergames can increase engagement in and motivation for physical activities. Most VR exergames focus on the upper body because many VR setups only track the users’ heads and hands. To become a serious alternative to existing exercise programs, VR exergames must provide a balanced workout and train the lower limbs, too. To address this issue, we built a VR exergame focused on vertical jump training to explore full-body exercise applications. To create a safe and effective training, nine domain experts participated in our prototype design. Our mixed-methods study confirms that the jump-centered exercises provided a worthy challenge and positive player experience, indicating long-term retention. Based on our findings, we present five design implications to guide future work: avoid an unintended forward drift, consider technical constraints, address safety concerns in full-body VR exergames, incorporate rhythmic elements with fluent movement patterns, adapt difficulty to players’ fitness progression status.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {786},
numpages = {18},
keywords = {serious games, health, exergame, training, dynamic difficulty, sport, virtual reality, vertical jump, VR},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580751,
author = {Tang, Kymeng and Gerling, Kathrin and Vanden Abeele, Vero and Geurts, Luc and Aufheimer, Maria},
title = {Playful Reflection: Impact of Gamification on a Virtual Reality Simulation of Breastfeeding},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580751},
doi = {10.1145/3544548.3580751},
abstract = {Gamification is a popular technique to improve task engagement, and has broadly been deployed in health and education to a point where many users now expect gameful experiences in these settings. However, gamification has been criticised for being a potential obstacle to the experience of reflection. Motivated by this tension, our work examines how the addition of gamification to a Virtual Reality simulation of breastfeeding impacts player experience and reflection. Using a within-subjects design, we invited 34 participants to take part in a mixed-methods evaluation of a gamified and non-gamified variant of the simulation that included questionnaires and semi-structured interviews. Results show that gamification improved player experience and encouraged players to reflect on goal achievement and performance. However, it also diverted players’ attention from nuances within the act of nursing. Drawing on our findings, we contribute considerations for the application of gamification in personal and sensitive settings such as breastfeeding.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {787},
numpages = {13},
keywords = {Virtual Reality, Reflection, Simulation, Breastfeeding, Gamification},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580833,
author = {Reig, Samantha and Principe Cruz, Erica and Powers, Melissa M. and He, Jennifer and Chong, Timothy and Tham, Yu Jiang and Kratz, Sven and Robinson, Ava and Smith, Brian A. and Vaish, Rajan and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Supporting Piggybacked Co-Located Leisure Activities via Augmented Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580833},
doi = {10.1145/3544548.3580833},
abstract = {Technology, especially the smartphone, is villainized for taking meaning and time away from in-person interactions and secluding people into “digital bubbles”. We believe this is not an intrinsic property of digital gadgets, but evidence of a lack of imagination in technology design. Leveraging augmented reality (AR) toward this end allows us to create experiences for multiple people, their pets, and their environments. In this work, we explore the design of AR technology that “piggybacks” on everyday leisure to foster co-located interactions among close ties (with other people and pets). We designed, developed, and deployed three such AR applications, and evaluated them through a 41-participant and 19-pet user study. We gained key insights about the ability of AR to spur and enrich interaction in new channels, the importance of customization, and the challenges of designing for the physical aspects of AR devices (e.g., holding smartphones). These insights guide design implications for the novel research space of co-located AR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {788},
numpages = {15},
keywords = {human–pet–computer interaction, everyday leisure, embodied interaction, co-located interaction, augmented/mixed reality, piggybacking},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581230,
author = {Sykownik, Philipp and Karaosmanoglu, Sukran and Emmerich, Katharina and Steinicke, Frank and Masuch, Maic},
title = {VR Almost There: Simulating Co-Located Multiplayer Experiences in Social Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581230},
doi = {10.1145/3544548.3581230},
abstract = {Consumer social virtual reality (VR) applications have recently started to enable social interactions at a distance. Yet it is still relatively unknown if and to what extent such applications provide meaningful social experiences in cases where in-person leisure activities are not feasible. To explore this, we developed a custom social VR application and conducted an exploratory lab study with 25 dyads in which we compared an in-person and a virtual version of a co-located multiplayer scenario. Our mixed-methods analysis revealed that both scenarios created a socially rich atmosphere and strengthened the social closeness between players. However, the lack of facial animations, limited body language, and a low field of view led to VR’s main social experiential limitations: a reduced mutual awareness and emotional understanding compared to the in-person scenario. We derive implications for social VR design and research as well as game user research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {789},
numpages = {19},
keywords = {player experience, social virtual reality, social interaction, social presence, multiplayer games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581107,
author = {Bartolome, Ava and Niu, Shuo},
title = {A Literature Review of Video-Sharing Platform Research in HCI},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581107},
doi = {10.1145/3544548.3581107},
abstract = {Video-sharing platforms (VSPs) such as YouTube, TikTok, and Twitch have grown rapidly in recent years and attracted millions of users. Research topics such as online communities, video interactions, and recommendation algorithms have drawn increasing attention. Group and community dynamics were also examined with live streaming and short-form videos. However, HCI literature lacks a holistic picture of video-sharing research themes, methods, and findings that summarizes the diverse topics on interaction modalities and communities. Prior reviews on VSPs were about a particular platform or reviewed as a part of social media. This paper contributes a scoping review of 106 articles on video-sharing published in HCI literature from 2012 to June 2022. We identified six research themes through grounded theory analysis and encoded five HCI research methods in VSP studies. We concluded a framework with five components to structure findings in video-sharing research, with which we reflect on future directions on this topic.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {790},
numpages = {20},
keywords = {TikTok, video-sharing, literature review, Twitch, YouTube, video},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581380,
author = {O'Toole, Katherine},
title = {Collaborative Creativity in TikTok Music Duets},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581380},
doi = {10.1145/3544548.3581380},
abstract = {On the social media platform TikTok, users are able to engage with each other’s content by using the Duet feature, which allows them to re-share another user’s video while also layering on additional content to the original video. Through this, the affordances of the Duet feature facilitate a distributed and collaborative creative process, in which we can observe the evolution of cultural artifacts through the different versions that are produced from user contributions. As a result, the open-ended nature of these collaborations positions engagement as both a creative and social act. In this paper, we identify the ways in which the Duet feature supports decentralized co-creativity and engagement between users. We find that the cumulative nature of an artifact’s creative evolution, along with the ability for multiple iterations of an artifact to develop in parallel, facilitates development of diverse creative artifacts.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {791},
numpages = {16},
keywords = {HCI, MIR, CSCW, Creativity},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581458,
author = {Saha, Manika and Bartindale, Tom and Varghese, Delvin and Lindsay, Stephen and Richardson, Dan and Ahmed, Syed Ishtiaque and Olivier, Patrick},
title = {Community Voice as Data: Affordances of Participatory Videos for International Program Development},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581458},
doi = {10.1145/3544548.3581458},
abstract = {International program development is a complex process involving many stakeholders. Current international practice affords limited, if any, opportunities for direct community-led input into the program commissioning process, resulting in programs that may not meet the specific needs of communities on the ground. Community voice is one source of data that could help focus the design of effective development programs and interventions. However, development programs are primarily formulated based on representative and often quantitative data conducted by experts from outside the community. Through a participatory video production process with disadvantaged women farmers in rural Bangladesh, we explore the opportunities for including meaningful community voices in these institutionalized processes. We present practical design implications for how community-generated voices can act as rich data, establishing confidence, community bonds and senses of accountability to inform early stages of project development, and to specifically augment and contextualize other data sources.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {792},
numpages = {16},
keywords = {qualitative methods, sustainability, audio video, HCI for development},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581013,
author = {Hu, Erzhen and Gr\o{}nb\ae{}k, Jens Emil Sloth and Houck, Austin and Heo, Seongkook},
title = {OpenMic: Utilizing Proxemic Metaphors for Conversational Floor Transitions in Multiparty Video Meetings},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581013},
doi = {10.1145/3544548.3581013},
abstract = {Turn-taking is one of the biggest interactivity challenges in multiparty remote meetings. One contributing factor is that current videoconferencing tools lack support for proxemic cues; i.e., spatial cues that humans use to enact their social relations and intentions. While more recent tools provide support for proxemic metaphors, they often focus on approach and leave-taking rather than turn-taking. In this paper, we present OpenMic, a videoconferencing system that utilizes proxemic metaphors for conversational floor management by providing 1) a Virtual Floor that serves as a fixed-feature space for users to be aware of others’ intention to talk, and 2) Malleable Mirrors, which are video and screen feeds that can be continuously moved and resized for conversational floor transitions. Our exploratory user study found that these system features can aid the conversational flow in multiparty video meetings. With this work, we show potential for embedding proxemic metaphors to support conversational floor management in videoconferencing systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {793},
numpages = {17},
keywords = {turn-taking, video conferencing, proxemics, multiparty video meeting, non-verbal cues},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581085,
author = {Hyrkas, Jeremy and Wilson, Andrew D and Tang, John and Gamper, Hannes and Sodoma, Hong and Tankelevitch, Lev and Inkpen, Kori and Chappidi, Shreya and Jones, Brennan},
title = {Spatialized Audio and Hybrid Video Conferencing: Where Should Voices Be Positioned for People in the Room and Remote Headset Users?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581085},
doi = {10.1145/3544548.3581085},
abstract = {Hybrid video calls include attendees in a conference room with loudspeakers and remote attendees using headsets, each with different options for rendering sound spatially. Two studies explored the listener experience with spatial audio in video calls. One study examined the in-room experience using loudspeakers, comparing among spatialization algorithms spreading voices out horizontally. A second study compared varying degrees of horizontal separation of binaurally rendered voices for a remote participant using a headset. In-room participants preferred the widest spatialization over monophonic, stereo, and stereo-binary audio in metrics related to intelligibility and helpfulness. Remote participants preferred different widths of the audio stage depending on the number of voices. In both studies, rendering sound spatially increased performance in speech stream identification. Results indicate spatial audio benefits for in-room and remote attendees in video calls, although the in-room attendees accepted a wider audio stage than remote users.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {794},
numpages = {14},
keywords = {hybrid meetings, spatial audio, teleconferencing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580912,
author = {Yen, Ryan and Feng, Li and Mehra, Brinda and Pang, Ching Christie and Hu, Siying and Lu, Zhicong},
title = {StoryChat: Designing a Narrative-Based Viewer Participation Tool for Live Streaming Chatrooms},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580912},
doi = {10.1145/3544548.3580912},
abstract = {Live streaming platforms and existing viewer participation tools enable users to interact and engage with an online community, but the anonymity and scale of chat usually result in the spread of negative comments. However, only a few existing moderation tools investigate the influence of proactive moderation on viewers’ engagement and prosocial behavior. To address this, we developed StoryChat, a narrative-based viewer participation tool that utilizes a dynamic graphical plot to reflect chatroom negativity. We crafted the narrative through a viewer-centered (N=65) iterative design process and evaluated the tool with 48 experienced viewers in a deployment study. We discovered that StoryChat encouraged viewers to contribute prosocial comments, increased viewer engagement, and fostered viewers’ sense of community. Viewers reported a closer connection between streamers and other viewers because of the narrative design, suggesting that narrative-based viewer engagement tools have the potential to encourage community engagement and prosocial behaviors.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {795},
numpages = {18},
keywords = {narrative, community, moderation, user engagement, intervention, live streaming},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581494,
author = {Huh, Mina and Yang, Saelyne and Peng, Yi-Hao and Chen, Xiang 'Anthony' and Kim, Young-Ho and Pavel, Amy},
title = {AVscript: Accessible Video Editing with Audio-Visual Scripts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581494},
doi = {10.1145/3544548.3581494},
abstract = {Sighted and blind and low vision (BLV) creators alike use videos to communicate with broad audiences. Yet, video editing remains inaccessible to BLV creators. Our formative study revealed that current video editing tools make it difficult to access the visual content, assess the visual quality, and efficiently navigate the timeline. We present &nbsp;AVscript, an accessible text-based video editor. &nbsp;AVscript enables users to edit their video using a script that embeds the video’s visual content, visual errors (e.g., dark or blurred footage), and speech. Users can also efficiently navigate between scenes and visual errors or locate objects in the frame or spoken words of interest. A comparison study (N=12) showed that &nbsp;AVscript significantly lowered BLV creators’ mental demands while increasing confidence and independence in video editing. We further demonstrate the potential of &nbsp;AVscript through an exploratory study (N=3) where BLV creators edited their own footage.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {796},
numpages = {17},
keywords = {accessibility, authoring tools, video},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581126,
author = {Yang, Saelyne and Kwak, Sangkyung and Lee, Juhoon and Kim, Juho},
title = {Beyond Instructions: A Taxonomy of Information Types in How-to Videos},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581126},
doi = {10.1145/3544548.3581126},
abstract = {How-to videos are rich in information—they not only give instructions but also provide justifications or descriptions. People seek different information to meet their needs, and identifying different types of information present in the video can improve access to the desired knowledge. Thus, we present a taxonomy of information types in how-to videos. Through an iterative open coding of 4k sentences in 48 videos, 21 information types under 8 categories emerged. The taxonomy represents diverse information types that instructors provide beyond instructions. We first show how our taxonomy can serve as an analytical framework for video navigation systems. Then, we demonstrate through a user study (n=9) how type-based navigation helps participants locate the information they needed. Finally, we discuss how the taxonomy enables a wide range of video-related tasks, such as video authoring, viewing, and analysis. To allow researchers to build upon our taxonomy, we release a dataset of 120 videos containing 9.9k sentences labeled using the taxonomy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {797},
numpages = {21},
keywords = {How-to Videos, Video Content Analysis, Information Type},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581525,
author = {Wang, April Yi and Head, Andrew and Zhang, Ashley Ge and Oney, Steve and Brooks, Christopher},
title = {Colaroid: A Literate Programming Approach for Authoring Explorable Multi-Stage Tutorials},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581525},
doi = {10.1145/3544548.3581525},
abstract = {Multi-stage programming tutorials are key learning resources for programmers, using progressive incremental steps to teach them how to build larger software systems. A good multi-stage tutorial describes the code clearly, explains the rationale and code changes for each step, and allows readers to experiment as they work through the tutorial. In practice, it is time-consuming for authors to create tutorials with these attributes. In this paper, we introduce Colaroid, an interactive authoring tool for creating high quality multi-stage tutorials. Colaroid tutorials are augmented computational notebooks, where snippets and outputs represent a snapshot of a project, with source code differences highlighted, complete source code context for each snippet, and the ability to load and tinker with any stage of the project in a linked IDE. In two laboratory studies, we found Colaroid makes it easy to create multi-stage tutorials, while offering advantages to readers compared to video and web-based tutorials.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {798},
numpages = {22},
keywords = {programming, computational notebooks, tutorials, instruction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581115,
author = {Nicholas, Molly Jane and Marquardt, Nicolai and Pahud, Michel and Riche, Nathalie and Romat, Hugo and Collins, Christopher and Ledo, David and Kadekodi, Rohan and Chandramouli, Badrish and Hinckley, Ken},
title = {Escapement: A Tool for Interactive Prototyping with Video via Sensor-Mediated Abstraction of Time},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581115},
doi = {10.1145/3544548.3581115},
abstract = {We present Escapement, a video prototyping tool that introduces a powerful new concept for prototyping screen-based interfaces by flexibly mapping sensor values to dynamic playback control of videos. This recasts the time dimension of video mock-ups as sensor-mediated interaction. This abstraction of time as interaction, which we dub video-escapement prototyping, empowers designers to rapidly explore and viscerally experience direct touch or sensor-mediated interactions across one or more device displays. Our system affords cross-device and bidirectional remote (tele-present) experiences via cloud-based state sharing across multiple devices. This makes Escapement especially potent for exploring multi-device, dual-screen, or remote-work interactions for screen-based applications. We introduce the core concept of sensor-mediated abstraction of time for quickly generating video-based interactive prototypes of screen-based applications, share the results of observations of long-term usage of video-escapement techniques with experienced interaction designers, and articulate design choices for supporting a reflective, iterative, and open-ended creative design process.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {799},
numpages = {14},
keywords = {video prototyping, creativity support tools, sensor-mediated interaction, cross-device interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580896,
author = {Li, Jiannan and Sousa, Maur\'{\i}cio and Mahadevan, Karthik and Wang, Bryan and Aoyagui, Paula Akemi and Yu, Nicole and Yang, Angela and Balakrishnan, Ravin and Tang, Anthony and Grossman, Tovi},
title = {Stargazer: An Interactive Camera Robot for Capturing How-To Videos Based on Subtle Instructor Cues},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580896},
doi = {10.1145/3544548.3580896},
abstract = {Live and pre-recorded video tutorials are an effective means for teaching physical skills such as cooking or prototyping electronics. A dedicated cameraperson following an instructor’s activities can improve production quality. However, instructors who do not have access to a cameraperson’s help often have to work within the constraints of static cameras. We present Stargazer, a novel approach for assisting with tutorial content creation with a camera robot that autonomously tracks regions of interest based on instructor actions to capture dynamic shots. Instructors can adjust the camera behaviors of Stargazer with subtle cues, including gestures and speech, allowing them to fluidly integrate camera control commands into instructional activities. Our user study with six instructors, each teaching a distinct skill, showed that participants could create dynamic tutorial videos with a diverse range of subjects, camera framing, and camera angle combinations using Stargazer.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {800},
numpages = {16},
keywords = {instructional videos, robots, cameras},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580772,
author = {Kim, Jeongyeon and Choi, Daeun and Lee, Nicole and Beane, Matt and Kim, Juho},
title = {Surch: Enabling Structural Search and Comparison for Surgical Videos},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580772},
doi = {10.1145/3544548.3580772},
abstract = {Video is an effective medium for learning procedural knowledge, such as surgical techniques. However, learning procedural knowledge through videos remains difficult due to limited access to procedural structures of knowledge (e.g., compositions and ordering of steps) in a large-scale video dataset. We present Surch, a system that enables structural search and comparison of surgical procedures. Surch supports video search based on procedural graphs generated by our clustering workflow capturing latent patterns within surgical procedures. We used vectorization and weighting schemes that characterize the features of procedures, such as recursive structures and unique paths. Surch enhances cross-video comparison by providing video navigation synchronized by surgical steps. Evaluation of the workflow demonstrates the effectiveness and interpretability (Silhouette score = 0.82) of our clustering for surgical learning. A user study with 11 residents shows that our system significantly improves the learning experience and task efficiency of video search and comparison, especially benefiting junior residents.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {801},
numpages = {17},
keywords = {Procedural Knowledge Representation, Video-Based Learning, Cross-Video Interaction, Structural Video Search, Surgical Learning},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581186,
author = {Thompson, John R and Martinez, Jesse J and Sarikaya, Alper and Cutrell, Edward and Lee, Bongshin},
title = {Chart Reader: Accessible Visualization Experiences Designed with Screen Reader Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581186},
doi = {10.1145/3544548.3581186},
abstract = {Even though screen readers are a core accessibility tool for blind and low vision individuals (BLVIs), most visualizations are incompatible with screen readers. To improve accessible visualization experiences, we partnered with 10 BLV screen reader users (SRUs) in an iterative co-design study to design and develop accessible visualization experiences that afford SRUs the autonomy to interactively read and understand visualizations and their underlying data. During the five-month study, we explored accessible visualization prototypes with our design partners for three one-hour sessions. Our results provide feedback on the synthesized design concepts we explored, why (or why not) they aid comprehension and exploration for SRUs, and how differing design concepts can fit into cohesive accessible visualization experiences. We contribute both Chart Reader, a web-based accessibility engine resulting from our design iterations, and our distilled study findings—organized by design dimensions—in the creation of comprehensive accessible visualization experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {802},
numpages = {18},
keywords = {iterative co-design, blind and low vision, accessible visualization experiences, data visualization, accessibility engine, screen readers, accessibility},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580669,
author = {Williams, Katy and Bigelow, Alex and Isaacs, Katherine E.},
title = {Data Abstraction Elephants: The Initial Diversity of Data Representations and Mental Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580669},
doi = {10.1145/3544548.3580669},
abstract = {Two people looking at the same dataset will create different mental models, prioritize different attributes, and connect with different visualizations. We seek to understand the space of data abstractions associated with mental models and how well people communicate their mental models when sketching. Data abstractions have a profound influence on the visualization design, yet it’s unclear how universal they may be when not initially influenced by a representation. We conducted a study about how people create their mental models from a dataset. Rather than presenting tabular data, we presented each participant with one of three datasets in paragraph form, to avoid biasing the data abstraction and mental model. We observed various mental models, data abstractions, and depictions from the same dataset, and how these concepts are influenced by communication and purpose-seeking. Our results have implications for visualization design, especially during the discovery and data collection phase.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {803},
numpages = {24},
keywords = {data abstractions, visualization theory, Human-centered computing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581204,
author = {Wu, Keke and Tran, Michelle Ho and Petersen, Emma and Koushik, Varsha and Szafir, Danielle Albers},
title = {Data, Data, Everywhere: Uncovering Everyday Data Experiences for People with Intellectual and Developmental Disabilities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581204},
doi = {10.1145/3544548.3581204},
abstract = {Data is everywhere but may not be accessible to everyone. Conventional data visualization tools and guidelines often do not actively consider the specific needs and abilities of people with Intellectual and Developmental Disabilities (IDD), leaving them excluded from data-driven activities and vulnerable to ethical issues. To understand the needs and challenges people with IDD have with data, we conducted 15 semi-structured interviews with individuals with IDD and their caregivers. Our algorithmic interview approach situated data in the lived experiences of people with IDD to uncover otherwise hidden data encounters in their everyday life. Drawing on findings and observations, we characterize how they conceptualize data, when and where they use data, and what barriers exist when they interact with data. We use our results as a lens to reimagine the role of visualization in data accessibility and establish a critical near-term research agenda for cognitively accessible visualization.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {804},
numpages = {17},
keywords = {human-subjects qualitative studies, personal visual analytics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581139,
author = {Kim, Gyeongri and Kim, Jiho and Kim, Yea-Seul},
title = {“Explain What a Treemap Is”: Exploratory Investigation of Strategies for Explaining Unfamiliar Chart to Blind and Low Vision Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581139},
doi = {10.1145/3544548.3581139},
abstract = {Visualization designers increasingly use diverse types of visualizations, but assistive technologies and education for blind and low vision people often focus on elementary chart types. We explore textual explanation as a more generalizable solution. We define three dimensions of explanation strategies based on education theories: comparing to a familiar chart type, describing how to draw one, and using a concrete example. We develop a prototype system that automatically generates text explanations from a given chart specification. We conduct an exploratory study with 24 legally blind people to observe both the effectiveness and the perceived effectiveness of the strategies. The findings include: description of visual appearance is overall more effective than instructions for drawing, effective strategies differ by each chart type and by each participant, and the user’s perceived effectiveness does not always lead to better performance. We demonstrate the feasibility of an explanation generation system and compile design considerations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {805},
numpages = {13},
keywords = {Visualization Accessibility, Explanation Strategy, Blind Users},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580765,
author = {Tandon, Sara and Abdul-Rahman, Alfie and Borgo, Rita},
title = {Visual Task Performance and Spatial Abilities: An Investigation of Artists and Mathematicians},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580765},
doi = {10.1145/3544548.3580765},
abstract = {This study builds on past research to present a domain-specific empirical investigation of artists and math &amp; computer scientists on their respective relationships to, perceptions of, and interactions with data visualization. We conducted a three-phase study utilizing mixed-methods to investigate performance on visual and text representations of data between domains. Our findings evidenced how math &amp; computer scientists are proficient utilizing text representations of data while artists benefit more from visual chart representations. Finally, we present perspectives from artists to gain an understanding of their approach to visual and mathematical tasks. Our findings indicate that artists are especially adept at statistical visual tasks and that development of cognitive skills could be fostered by individuals to potentially benefit visualization task performance.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {806},
numpages = {16},
keywords = {text representation, spatial ability, visual artists, education, bar charts, perception, Human-subjects quantitative studies, mixed-methods, domain-specific, cognitive abilities},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581086,
author = {Dhawka, Priya and He, Helen Ai and Willett, Wesley},
title = {We Are the Data: Challenges and Opportunities for Creating Demographically Diverse Anthropographics},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581086},
doi = {10.1145/3544548.3581086},
abstract = {Anthropographics are human-shaped visualizations that aim to emphasize the human importance of datasets and the people behind them. However, current anthropographics tend to employ homogeneous human shapes to encode data about diverse demographic groups. Such anthropographics can obscure important differences between groups and contemporary designs exemplify the lack of inclusive approaches for representing human diversity in visualizations. In response, we explore the creation of demographically diverse anthropographics that communicate the visible diversity of demographically distinct populations. Building on previous anthropographics research, we explore strategies for visualizing datasets about people in ways that explicitly encode diversity—illustrating these approaches with examples in a variety of visual styles. We also critically reflect on strategies for creating diverse anthropographics, identifying social and technical challenges that can result in harmful representations. Finally, we highlight a set of forward-looking research opportunities for advancing the design and understanding of diverse anthropographics.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {807},
numpages = {14},
keywords = {demographic data, diversity, anthropographics, marginalized populations},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581472,
author = {Cao, Yining and E, Jane L and Chen, Zhutian and Xia, Haijun},
title = {DataParticles: Block-Based and Language-Oriented Authoring of Animated Unit Visualizations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581472},
doi = {10.1145/3544548.3581472},
abstract = {Unit visualizations have been widely used in data storytelling within interactive articles and videos. However, authoring data stories that contain animated unit visualizations is challenging due to the tedious, time-consuming process of switching back and forth between writing a narrative and configuring the accompanying visualizations and animations. To streamline this process, we present DataParticles, a block-based story editor that leverages the latent connections between text, data, and visualizations to help creators flexibly prototype, explore, and iterate on a story narrative and its corresponding visualizations. To inform the design of DataParticles, we interviewed 6 domain experts and studied a dataset of 44 existing animated unit visualizations to identify the narrative patterns and congruence principles they employed. A user study with 9 experts showed that DataParticles can significantly simplify the process of authoring data stories with animated unit visualizations by encouraging exploration and supporting fast prototyping.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {808},
numpages = {15},
keywords = {natural language, storytelling, animation, unit visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581509,
author = {Narechania, Arpit and Du, Fan and Sinha, Atanu R and Rossi, Ryan and Hoffswell, Jane and Guo, Shunan and Koh, Eunyee and Navathe, Shamkant B and Endert, Alex},
title = {DataPilot: Utilizing Quality and Usage Information for Subset Selection during Visual Data Preparation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581509},
doi = {10.1145/3544548.3581509},
abstract = {Selecting relevant data subsets from large, unfamiliar datasets can be difficult. We address this challenge by modeling and visualizing two kinds of auxiliary information: (1) quality – the validity and appropriateness of data required to perform certain analytical tasks; and (2) usage – the historical utilization characteristics of data across multiple users. Through a design study with 14 data workers, we integrate this information into a visual data preparation and analysis tool, DataPilot. DataPilot presents visual cues about “the good, the bad, and the ugly” aspects of data and provides graphical user interface controls as interaction affordances, guiding users to perform subset selection. Through a study with 36 participants, we investigate how DataPilot helps users navigate a large, unfamiliar tabular dataset, prepare a relevant subset, and build a visualization dashboard. We find that users selected smaller, effective subsets with higher quality and usage, and with greater success and confidence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {809},
numpages = {18},
keywords = {design study, visualization, data quality, data usage, data preparation, visual data analysis, subset selection},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580754,
author = {Lee, Benjamin and Satyanarayan, Arvind and Cordeil, Maxime and Prouzeau, Arnaud and Jenny, Bernhard and Dwyer, Tim},
title = {Deimos: A Grammar of Dynamic Embodied Immersive Visualisation Morphs and Transitions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580754},
doi = {10.1145/3544548.3580754},
abstract = {We present Deimos, a grammar for specifying dynamic embodied immersive visualisation morphs and transitions. A morph is a collection of animated transitions that are dynamically applied to immersive visualisations at runtime and is conceptually modelled as a state machine. It is comprised of state, transition, and signal specifications. States in a morph are used to generate animation keyframes, with transitions connecting two states together. A transition is controlled by signals, which are composable data streams that can be used to enable embodied interaction techniques. Morphs allow immersive representations of data to transform and change shape through user interaction, facilitating the embodied cognition process. We demonstrate the expressivity of Deimos in an example gallery and evaluate its usability in an expert user study of six immersive analytics researchers. Participants found the grammar to be powerful and expressive, and showed interest in drawing upon Deimos’ concepts and ideas in their own research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {810},
numpages = {18},
keywords = {embodied interaction, Immersive Analytics, animated transitions, user study, grammar, data visualisation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580974,
author = {Shin, Sungbok and Hong, Sanghyun and Elmqvist, Niklas},
title = {Perceptual Pat: A Virtual Human Visual System for Iterative Visualization Design},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580974},
doi = {10.1145/3544548.3580974},
abstract = {Designing a visualization is often a process of iterative refinement where the designer improves a chart over time by adding features, improving encodings, and fixing mistakes. However, effective design requires external critique and evaluation. Unfortunately, such critique is not always available on short notice and evaluation can be costly. To address this need, we present Perceptual Pat, an extensible suite of AI and computer vision techniques that forms a virtual human visual system for supporting iterative visualization design. The system analyzes snapshots of a visualization using an extensible set of filters—including gaze maps, text recognition, color analysis, etc—and generates a report summarizing the findings. The web-based Pat Design Lab provides a version tracking system that enables the designer to track improvements over time. We validate Perceptual Pat using a longitudinal qualitative study involving 4 professional visualization designers that used the tool over a few days to design a new visualization.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {811},
numpages = {17},
keywords = {iterative design., simulation, visualization, virtual human visual system, Virtual human, machine learning, computer vision},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581168,
author = {Akbaba, Derya and Lange, Devin and Correll, Michael and Lex, Alexander and Meyer, Miriah},
title = {Troubling Collaboration: Matters of Care for Visualization Design Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581168},
doi = {10.1145/3544548.3581168},
abstract = {A common research process in visualization is for visualization researchers to collaborate with domain experts to solve particular applied data problems. While there is existing guidance and expertise around how to structure collaborations to strengthen research contributions, there is comparatively little guidance on how to navigate the implications of, and power produced through the socio-technical entanglements of collaborations. In this paper, we qualitatively analyze reflective interviews of past participants of collaborations from multiple perspectives: visualization graduate students, visualization professors, and domain collaborators. We juxtapose the perspectives of these individuals, revealing tensions about the tools that are built and the relationships that are formed — a complex web of competing motivations. Through the lens of matters of care, we interpret this web, concluding with considerations that both trouble and necessitate reformation of current patterns around collaborative work in visualization design studies to promote more equitable, useful, and care-ful outcomes.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {812},
numpages = {15},
keywords = {interview study, matters of care, diffraction, collaboration, maintenance, design study},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581132,
author = {Choi, Jinhan and Oh, Changhoon and Kim, Yea-Seul and Kim, Nam Wook},
title = {VisLab: Enabling Visualization Designers to Gather Empirically Informed Design Feedback},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581132},
doi = {10.1145/3544548.3581132},
abstract = {When creating a visualization, designers face various conflicting design choices. They typically rely on their hunches to deal with intricate trade-offs or resort to feedback from their colleagues. On the other hand, researchers have long used empirical methods to derive useful quantitative insights into visualization designs. Taking inspiration from this research tradition, we developed VisLab, an open-source online system to complement the existing qualitative feedback practice and help visualization practitioners run experiments to gather empirically informed design feedback. We surveyed practitioners’ perceptions of quantitative feedback and analyzed the research literature to inform VisLab’s motivation and design. VisLab operationalizes the experiment process using templates and dashboards to make empirical methods amenable for practitioners while supporting sharing and remixing experiments to aid knowledge exchange and validation. We demonstrated the validity of experiments in VisLab and evaluated the usability and potential usefulness of VisLab in visualization design practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {813},
numpages = {18},
keywords = {design feedback, empirical feedback, crowdsourcing, data visualization, citizen science},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581520,
author = {Allison, Fraser and Nansen, Bj\o{}rn and Gibbs, Martin and Arnold, Michael},
title = {Bones of Contention: Social Acceptance of Digital Cemetery Technologies},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581520},
doi = {10.1145/3544548.3581520},
abstract = {Digital technologies play an increasingly prominent role in memorialisation, but their use at cemeteries has been criticised for lack of sensitivity. Designers of digital cemetery technologies (cemtech) face a high risk of causing offence or failing to attract users due to social norms of memorial sites. To map this area of design and its pitfalls, we first developed a typology of cemtech through a review of examples from around the world. We then evaluated social acceptance of various types of cemtech through a survey of 1,053 Australian residents. Younger people were more accepting of cemtech than older people. Acceptance was highest for cemtech with three characteristics: familiarity, intimacy of user group and peacefulness. Through a reflexive thematic analysis, we identified four attitudinal dichotomies that explain divergent reactions to cemtech: Expands/Impedes, Public/Private, Lively/Restful and Pragmatic/Affective. We conclude with a discussion of how this work can assist designers of public memorialisation technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {814},
numpages = {17},
keywords = {cemetery, user experience, social acceptability, pervasive displays, graveyard, deathscapes, death},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581406,
author = {Ge, Lily W. and Cui, Yuan and Kay, Matthew},
title = {CALVI: Critical Thinking Assessment for Literacy in Visualizations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581406},
doi = {10.1145/3544548.3581406},
abstract = {Visualization misinformation is a prevalent problem, and combating it requires understanding people’s ability to read, interpret, and reason about erroneous or potentially misleading visualizations, which lacks a reliable measurement: existing visualization literacy tests focus on well-formed visualizations. We systematically develop an assessment for this ability by: (1) developing a precise definition of misleaders (decisions made in the construction of visualizations that can lead to conclusions not supported by the data), (2) constructing initial test items using a design space of misleaders and chart types, (3) trying out the provisional test on 497 participants, and (4) analyzing the test tryout results and refining the items using Item Response Theory, qualitative analysis, a wrong-due-to-misleader score, and the content validity index. Our final bank of 45 items shows high reliability, and we provide item bank usage recommendations for future tests and different use cases. Related materials are available at: https://osf.io/pv67z/.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {815},
numpages = {18},
keywords = {Measurement, Psychometrics, Visualization literacy, Information visualization, Visualization misinformation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580805,
author = {Chen, Cheng and Sundar, S. Shyam},
title = {Is This AI Trained on Credible Data? The Effects of Labeling Quality and Performance Bias on User Trust},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580805},
doi = {10.1145/3544548.3580805},
abstract = {To promote data transparency, frameworks such as CrowdWorkSheets encourage documentation of annotation practices on the interfaces of AI systems, but we do not know how they affect user experience. Will the quality of labeling affect perceived credibility of training data? Does the source of annotation matter? Will a credible dataset persuade users to trust a system even if it shows racial biases in its predictions? To find out, we conducted a user study (N = 430) with a prototype of a classification system, using a 2 (labeling quality: high vs. low) \texttimes{} 4 (source: others-as-source vs. self-as-source cue vs. self-as-source voluntary action, vs. self-as-source forced action) \texttimes{} 3 (AI performance: none vs. biased vs. unbiased) experiment. We found that high-quality labeling leads to higher perceived training data credibility, which in turn enhances users’ trust in AI, but not when the system shows bias. Practical implications for explainable and ethical AI interfaces are discussed.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {816},
numpages = {11},
keywords = {labeling source, trust in AI, algorithmic bias, training data credibility, data labeling quality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580910,
author = {Lisnic, Maxim and Polychronis, Cole and Lex, Alexander and Kogan, Marina},
title = {Misleading Beyond Visual Tricks: How People Actually Lie with Charts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580910},
doi = {10.1145/3544548.3580910},
abstract = {Data visualizations can empower an audience to make informed decisions. At the same time, deceptive representations of data can lead to inaccurate interpretations while still providing an illusion of data-driven insights. Existing research on misleading visualizations primarily focuses on examples of charts and techniques previously reported to be deceptive. These approaches do not necessarily describe how charts mislead the general population in practice. We instead present an analysis of data visualizations found in a real-world discourse of a significant global event—Twitter posts with visualizations related to the COVID-19 pandemic. Our work shows that, contrary to conventional wisdom, violations of visualization design guidelines are not the dominant way people mislead with charts. Specifically, they do not disproportionately lead to reasoning errors in posters’ arguments. Through a series of examples, we present common reasoning errors and discuss how even faithfully plotted data visualizations can be used to support misinformation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {817},
numpages = {21},
keywords = {visualization, COVID-19, misinformation, social media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581123,
author = {Sun, Yuan and Drivas, Magdalayna and Liao, Mengqi and Sundar, S. Shyam},
title = {When Recommender Systems Snoop into Social Media, Users Trust Them Less for Health Advice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581123},
doi = {10.1145/3544548.3581123},
abstract = {Recommender systems (RS) have become increasingly vital for guiding health actions. While traditional systems filter content based on either demographics, personal history of activities, or preferences of other users, newer systems use social media information to personalize recommendations, based either on the users’ own activities and/or those of their friends on social media platforms. However, we do not know if these approaches differ in their persuasiveness. To find out, we conducted a user study of a fitness plan recommender system (N = 341), wherein participants were randomly assigned to one of six personalization approaches, with half of them given a choice to switch to a different approach. Data revealed that social media-based personalization threatens users’ identity and increases privacy concerns. Users prefer personalized health recommendations based on their own preferences. Choice enhances trust by providing users with a greater sense of agency and lowering their privacy concerns. These findings provide design implications for RS, especially in the preventive health domain.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {818},
numpages = {14},
keywords = {user choice, agency, personalization, health, privacy, identity threat},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581524,
author = {Burns, Alyxander and Lee, Christiana and Chawla, Ria and Peck, Evan and Mahyar, Narges},
title = {Who Do We Mean When We Talk About Visualization Novices?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581524},
doi = {10.1145/3544548.3581524},
abstract = {As more people rely on visualization to inform their personal and collective decisions, researchers have focused on a broader range of audiences, including “novices.” But successfully applying, interrogating, or advancing visualization research for novices demands a clear understanding of what “novice” means in theory and practice. Misinterpreting who a “novice” is could lead to misapplying guidelines and overgeneralizing results. In this paper, we investigated how visualization researchers define novices and how they evaluate visualizations intended for novices. We analyzed 79 visualization papers that used “novice,” “non-expert,” “laypeople,” or “general public” in their titles or abstracts. We found ambiguity within papers and disagreement between papers regarding what defines a novice. Furthermore, we found a mismatch between the broad language describing novices and the narrow population representing them in evaluations (i.e., young people, students, and US residents). We suggest directions for inclusively supporting novices in both theory and practice.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {819},
numpages = {16},
keywords = {research methodology, data visualization, critical analyses, audience},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581349,
author = {Zeng, Zehua and Battle, Leilani},
title = {A Review and Collation of Graphical Perception Knowledge for Visualization Recommendation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581349},
doi = {10.1145/3544548.3581349},
abstract = {Selecting appropriate visual encodings is critical to designing effective visualization recommendation systems, yet few findings from graphical perception are typically applied within these systems. We observe two significant limitations in translating graphical perception knowledge into actionable visualization recommendation rules/constraints: inconsistent reporting of findings and a lack of shared data across studies. How can we translate the graphical perception literature into a knowledge base for visualization recommendation? We present a review of 59 papers that study user perception and performance across ten visual analysis tasks. Through this study, we contribute a JSON dataset that collates existing theoretical and experimental knowledge and summarizes key study outcomes in graphical perception. We illustrate how this dataset can inform automated encoding decisions with three representative visualization recommendation systems. Based on our findings, we highlight open challenges and opportunities for the community in collating graphical perception knowledge for a range of visualization recommendation scenarios.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {820},
numpages = {16},
keywords = {Visualization Design, Literature Review, Human Perception},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581320,
author = {Zhao, Yayan and Li, Mingwei and Berger, Matthew},
title = {Graphical Perception of Saliency-Based Model Explanations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581320},
doi = {10.1145/3544548.3581320},
abstract = {In recent years, considerable work has been devoted to explaining predictive, deep learning-based models, and in turn how to evaluate explanations. An important class of evaluation methods are ones that are human-centered, which typically require the communication of explanations through visualizations. And while visualization plays a critical role in perceiving and understanding model explanations, how visualization design impacts human perception of explanations remains poorly understood. In this work, we study the graphical perception of model explanations, specifically, saliency-based explanations for visual recognition models. We propose an experimental design to investigate how human perception is influenced by visualization design, wherein we study the task of alignment assessment, or whether a saliency map aligns with an object in an image. Our findings show that factors related to visualization design decisions, the type of alignment, and qualities of the saliency map all play important roles in how humans perceive saliency-based visual explanations.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {821},
numpages = {15},
keywords = {graphical perception, user study, model explanation, neural networks, saliency map},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581111,
author = {Yang, Fumeng and Ma, Yuxin and Harrison, Lane and Tompkin, James and Laidlaw, David H.},
title = {How Can Deep Neural Networks Aid Visualization Perception Research? Three Studies on Correlation Judgments in Scatterplots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581111},
doi = {10.1145/3544548.3581111},
abstract = {How deep neural networks can aid visualization perception research is a wide-open question. This paper provides insights from three perspectives—prediction, generalization, and interpretation—via training and analyzing deep convolutional neural networks on human correlation judgments in scatterplots across three studies. The first study assesses the accuracy of twenty-nine neural network architectures in predicting human judgments, finding that a subset of the architectures (e.g., VGG-19) has comparable accuracy to the best-performing regression analyses in prior research. The second study shows that the resulting models from the first study display better generalizability than prior models on two other judgment datasets for different scatterplot designs. The third study interprets visual features learned by a convolutional neural network model, providing insights about how the model makes predictions, and identifies potential features that could be investigated in human correlation perception studies. Together, this paper suggests that deep neural networks can serve as a tool for visualization perception researchers in devising potential empirical study designs and hypothesizing about perpetual judgments. The preprint, data, code, and training logs are available at https://doi.org/10.17605/osf.io/exa8m.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {822},
numpages = {17},
keywords = {scatterplots, predictive modeling, deep neural networks, perception, visualization features},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580734,
author = {Lu, Kecheng and Reda, Khairi and Deussen, Oliver and Wang, Yunhai},
title = {Interactive Context-Preserving Color Highlighting for Multiclass Scatterplots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580734},
doi = {10.1145/3544548.3580734},
abstract = {Color is one of the main visual channels used for highlighting elements of interest in visualization. However, in multi-class scatterplots, color highlighting often comes at the expense of degraded color discriminability. In this paper, we argue for context-preserving highlighting during the interactive exploration of multi-class scatterplots to achieve desired pop-out effects, while maintaining good perceptual separability among all classes and consistent color mapping schemes under varying points of interest. We do this by first generating two contrastive color mapping schemes with large and small contrasts to the background. Both schemes maintain good perceptual separability among all classes and ensure that when colors from the two palettes are assigned to the same class, they have a high color consistency in color names. We then interactively combine these two schemes to create a dynamic color mapping for highlighting different points of interest. We demonstrate the effectiveness through crowd-sourced experiments and case studies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {823},
numpages = {15},
keywords = {Multi-Class Scatterplots, Color Palettes, Highlighting, Discriminability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581416,
author = {Tseng, Chin and Quadri, Ghulam Jilani and Wang, Zeyu and Szafir, Danielle Albers},
title = {Measuring Categorical Perception in Color-Coded Scatterplots},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581416},
doi = {10.1145/3544548.3581416},
abstract = {Scatterplots commonly use color to encode categorical data. However, as datasets increase in size and complexity, the efficacy of these channels may vary. Designers lack insight into how robust different design choices are to variations in category numbers. This paper presents a crowdsourced experiment measuring how the number of categories and choice of color encodings used in multiclass scatterplots influences the viewers’ abilities to analyze data across classes. Participants estimated relative means in a series of scatterplots with 2 to 10 categories encoded using ten color palettes drawn from popular design tools. Our results show that the number of categories and color discriminability within a color palette notably impact people’s perception of categorical data in scatterplots and that the judgments become harder as the number of categories grows. We examine existing palette design heuristics in light of our results to help designers make robust color choices informed by the parameters of their data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {824},
numpages = {14},
keywords = {scatterplot, colors, category},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581119,
author = {Gutwin, Carl and Mairena, Aristides and Bandi, Venkat},
title = {Showing Flow: Comparing Usability of Chord and Sankey Diagrams},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581119},
doi = {10.1145/3544548.3581119},
abstract = {Chord and Sankey diagrams are two common techniques for visualizing flows. Chord diagrams use a radial layout with a single circular axis, and Sankey diagrams use a left-to-right layout with two vertical axes. Previous work suggests both strengths and weaknesses of the radial approach, but little is known about the usability and interpretability of these two layout styles for showing flow. We carried out a study where participants answered questions using equivalent Chord and Sankey diagrams. We measured completion time, errors, perceived effort, and preference. Our results show that participants took substantially longer to answer questions with Chord diagrams and made more errors; participants also rated Chord as requiring more effort, and strongly preferred Sankey diagrams. Our study identifies and explains limitations of the popular Chord layout, provides new understanding about radial vs. linear layouts that can help guide visualization designers, and identifies possible design improvements for both visualization types.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {825},
numpages = {10},
keywords = {radial vs. linear layout, visualization usability, Sankey diagrams, Chord diagrams, visual analytics},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581087,
author = {Hoque, Md Naimul and Ehtesham-Ul-Haque, Md and Elmqvist, Niklas and Billah, Syed Masum},
title = {Accessible Data Representation with Natural Sound},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581087},
doi = {10.1145/3544548.3581087},
abstract = {Sonification translates data into non-speech audio. Such auditory representations can make data visualization accessible to people who are blind or have low vision (BLV). This paper presents a sonification method for translating common data visualization into a blend of natural sounds. We hypothesize that people’s familiarity with sounds drawn from nature, such as birds singing in a forest, and their ability to listen to these sounds in parallel, will enable BLV users to perceive multiple data points being sonified at the same time. Informed by an extensive literature review and a preliminary study with 5 BLV participants, we designed an accessible data representation tool, Susurrus, that combines our sonification method with other accessibility features, such as keyboard interaction and text-to-speech feedback. Finally, we conducted a user study with 12 BLV participants and report the potential and application of natural sounds for sonification compared to existing sonification tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {826},
numpages = {19},
keywords = {Natural sound, Accessibility, Sonification, Data visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581337,
author = {Kamikubo, Rie and Lee, Kyungjun and Kacorri, Hernisa},
title = {Contributing to Accessibility Datasets: Reflections on Sharing Study Data by Blind People},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581337},
doi = {10.1145/3544548.3581337},
abstract = {To ensure that AI-infused systems work for disabled people, we need to bring accessibility datasets sourced from this community in the development lifecycle. However, there are many ethical and privacy concerns limiting greater data inclusion, making such datasets not readily available. We present a pair of studies where 13 blind participants engage in data capturing activities and reflect with and without probing on various factors that influence their decision to share their data via an AI dataset. We see how different factors influence blind participants’ willingness to share study data as they assess risk-benefit tradeoffs. The majority support sharing of their data to improve technology but also express concerns over commercial use, associated metadata, and the lack of transparency about the impact of their data. These insights have implications for the development of responsible practices for stewarding accessibility datasets, and can contribute to broader discussions in this area.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {827},
numpages = {18},
keywords = {datasets, disability, human-centered AI, data ownership, privacy},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581532,
author = {Kim, Jiho and Srinivasan, Arjun and Kim, Nam Wook and Kim, Yea-Seul},
title = {Exploring Chart Question Answering for Blind and Low Vision Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581532},
doi = {10.1145/3544548.3581532},
abstract = {Data visualizations can be complex or involve numerous data points, making them impractical to navigate using screen readers alone. Question answering (QA) systems have the potential to support visualization interpretation and exploration without overwhelming blind and low vision (BLV) users. To investigate if and how QA systems can help BLV users in working with visualizations, we conducted a Wizard of Oz study with 24 BLV people where participants freely posed queries about four visualizations. We collected 979 queries and mapped them to popular analytic task taxonomies. We found that retrieving value and finding extremum were the most common tasks, participants often made complex queries and used visual references, and the data topic notably influenced the queries. We compile a list of design considerations for accessible chart QA systems and make our question corpus publicly available to guide future research and development.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {828},
numpages = {15},
keywords = {Question Answering, Design Considerations, Human-Subjects Qualitative Studies, Accessibility, Visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580921,
author = {Peng, Yi-Hao and Chi, Peggy and Kannan, Anjuli and Morris, Meredith Ringel and Essa, Irfan},
title = {Slide Gestalt: Automatic Structure Extraction in Slide Decks for Non-Visual Access},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580921},
doi = {10.1145/3544548.3580921},
abstract = {Presentation slides commonly use visual patterns for structural navigation, such as titles, dividers, and build slides. However, screen readers do not capture such intention, making it time-consuming and less accessible for blind and visually impaired (BVI) users to linearly consume slides with repeated content. We present Slide Gestalt, an automatic approach that identifies the hierarchical structure in a slide deck. Slide Gestalt computes the visual and textual correspondences between slides to generate hierarchical groupings. Readers can navigate the slide deck from the higher-level section overview to the lower-level description of a slide group or individual elements interactively with our UI. We derived side consumption and authoring practices from interviews with BVI readers and sighted creators and an analysis of 100 decks. We performed our pipeline with 50 real-world slide decks and a large dataset. Feedback from eight BVI participants showed that Slide Gestalt helped navigate a slide deck by anchoring content more efficiently, compared to using accessible slides.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {829},
numpages = {14},
keywords = {Multimodal correspondence and alignment, Presentation, Accessibility, Screen reader, Slide deck},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581560,
author = {Valencia, Stephanie and Cave, Richard and Kallarackal, Krystal and Seaver, Katie and Terry, Michael and Kane, Shaun K.},
title = {“The Less I Type, the Better”: How AI Language Models Can Enhance or Impede Communication for AAC Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581560},
doi = {10.1145/3544548.3581560},
abstract = {Users of augmentative and alternative communication (AAC) devices sometimes find it difficult to communicate in real time with others due to the time it takes to compose messages. AI technologies such as large language models (LLMs) provide an opportunity to support AAC users by improving the quality and variety of text suggestions. However, these technologies may fundamentally change how users interact with AAC devices as users transition from typing their own phrases to prompting and selecting AI-generated phrases. We conducted a study in which 12 AAC users tested live suggestions from a language model across three usage scenarios: extending short replies, answering biographical questions, and requesting assistance. Our study participants believed that AI-generated phrases could save time, physical and cognitive effort when communicating, but felt it was important that these phrases reflect their own communication style and preferences. This work identifies opportunities and challenges for future AI-enhanced AAC devices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {830},
numpages = {14},
keywords = {artificial intelligence, large language models, accessibility, communication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581511,
author = {de Lacerda Pataca, Calu\~{a} and Watkins, Matthew and Peiris, Roshan and Lee, Sooyeon and Huenerfauth, Matt},
title = {Visualization of Speech Prosody and Emotion in Captions: Accessibility&nbsp;for&nbsp;Deaf&nbsp;and&nbsp;Hard-of-Hearing Users},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581511},
doi = {10.1145/3544548.3581511},
abstract = {Speech is expressive in ways that caption text does not capture, with emotion or emphasis information not conveyed. We interviewed eight Deaf and Hard-of-Hearing (dhh) individuals to understand if and how captions’ inexpressiveness impacts them in online meetings with hearing peers. Automatically captioned speech, we found, lacks affective depth, lending it a hard-to-parse ambiguity and general dullness. Interviewees regularly feel excluded, which some understand is an inherent quality of these types of meetings rather than a consequence of current caption text design. Next, we developed three novel captioning models that depicted, beyond words, features from prosody, emotions, and a mix of both. In an empirical study, 16 dhh participants compared these models with conventional captions. The emotion-based model outperformed traditional captions in depicting emotions and emphasis, with only a moderate loss in legibility, suggesting its potential as a more inclusive design for captions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {831},
numpages = {15},
keywords = {Individuals with Disabilities &amp; Assistive Technologies, Empirical study that tells us about how people use a system, Accessibility, Emotion / Affective Computing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580790,
author = {Robertson, Samantha and Wang, Zijie J. and Moritz, Dominik and Kery, Mary Beth and Hohman, Fred},
title = {Angler: Helping Machine Translation Practitioners Prioritize Model Improvements},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580790},
doi = {10.1145/3544548.3580790},
abstract = {Machine learning (ML) models can fail in unexpected ways in the real world, but not all model failures are equal. With finite time and resources, ML practitioners are forced to prioritize their model debugging and improvement efforts. Through interviews with 13 ML practitioners at Apple, we found that practitioners construct small targeted test sets to estimate an error’s nature, scope, and impact on users. We built on this insight in a case study with machine translation models, and developed Angler, an interactive visual analytics tool to help practitioners prioritize model improvements. In a user study with 7 machine translation experts, we used Angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive. Our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {832},
numpages = {20},
keywords = {visual analytics, Model evaluation, machine translation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581127,
author = {Wang, Qianwen and L'Yi, Sehi and Gehlenborg, Nils},
title = {DRAVA: Aligning Human Concepts with Machine Learning Latent Dimensions for the Visual Exploration of Small Multiples},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581127},
doi = {10.1145/3544548.3581127},
abstract = {Latent vectors extracted by machine learning (ML) are widely used in data exploration (e.g., t-SNE) but suffer from a lack of interpretability. While previous studies employed disentangled representation learning (DRL) to enable more interpretable exploration, they often overlooked the potential mismatches between the concepts of humans and the semantic dimensions learned by DRL. To address this issue, we propose Drava, a visual analytics system that supports users in 1) relating the concepts of humans with the semantic dimensions of DRL and identifying mismatches, 2) providing feedback to minimize the mismatches, and 3) obtaining data insights from concept-driven exploration. Drava provides a set of visualizations and interactions based on visual piles to help users understand and refine concepts and conduct concept-driven exploration. Meanwhile, Drava employs a concept adaptor model to fine-tune the semantic dimensions of DRL based on user refinement. The usefulness of Drava is demonstrated through application scenarios and experimental validation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {833},
numpages = {15},
keywords = {Visual exploration, small multiples, XAI, latent space, Human-AI collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581373,
author = {Ahn, Yongsu and Lin, Yu-Ru and Xu, Panpan and Dai, Zeng},
title = {ESCAPE: Countering Systematic Errors from Machine’s Blind Spots via Interactive Visual Analysis},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581373},
doi = {10.1145/3544548.3581373},
abstract = {Classification models learn to generalize the associations between data samples and their target classes. However, researchers have increasingly observed that machine learning practice easily leads to systematic errors in AI applications, a phenomenon referred to as “AI blindspots.” Such blindspots arise when a model is trained with training samples (e.g., cat/dog classification) where important patterns (e.g., black cats) are missing or periphery/undesirable patterns (e.g., dogs with grass background) are misleading towards a certain class. Even more sophisticated techniques cannot guarantee to capture, reason about, and prevent the spurious associations. In this work, we propose ESCAPE, a visual analytic system that promotes a human-in-the-loop workflow for countering systematic errors. By allowing human users to easily inspect spurious associations, the system facilitates users to spontaneously recognize concepts associated misclassifications and evaluate mitigation strategies that can reduce biased associations. We also propose two statistical approaches, relative concept association to better quantify the associations between a concept and instances, and debias method to mitigate spurious associations. We demonstrate the utility of our proposed ESCAPE system and statistical measures through extensive evaluation including quantitative experiments, usage scenarios, expert interviews, and controlled user experiments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {834},
numpages = {16},
keywords = {unknown-unknowns, concept interpretability, systematic error, blind spot, visual analytics, visualization, human-AI interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580816,
author = {Wang, Zijie J. and Wortman Vaughan, Jennifer and Caruana, Rich and Chau, Duen Horng},
title = {GAM Coach: Towards Interactive and User-Centered Algorithmic Recourse},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580816},
doi = {10.1145/3544548.3580816},
abstract = {Machine learning (ML) recourse techniques are increasingly used in high-stakes domains, providing end users with actions to alter ML predictions, but they assume ML developers understand what input variables can be changed. However, a recourse plan’s actionability is subjective and unlikely to match developers’ expectations completely. We present GAM Coach, a novel open-source system that adapts integer linear programming to generate customizable counterfactual explanations for Generalized Additive Models (GAMs), and leverages interactive visualizations to enable end users to iteratively generate recourse plans meeting their needs. A quantitative user study with 41 participants shows our tool is usable and useful, and users prefer personalized recourse plans over generic plans. Through a log analysis, we explore how users discover satisfactory recourse plans, and provide empirical evidence that transparency can lead to more opportunities for everyday users to discover counterintuitive patterns in ML models. GAM Coach is available at: https://poloclub.github.io/gam-coach/.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {835},
numpages = {20},
keywords = {Interpretability, Counterfactual Explanation, Algorithmic Recourse},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580998,
author = {Yang, Fumeng and Hedayati, Maryam and Kay, Matthew},
title = {Subjective Probability Correction for Uncertainty Representations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580998},
doi = {10.1145/3544548.3580998},
abstract = {We propose a new approach to uncertainty communication: we keep the uncertainty representation fixed, but adjust the distribution displayed to compensate for biases in people’s subjective probability in decision-making. To do so, we adopt a linear-in-probit model of subjective probability and derive two corrections to a Normal distribution based on the model’s intercept and slope: one correcting all right-tailed probabilities, and the other preserving the mode and one focal probability. We then conduct two experiments on U.S. demographically-representative samples. We show participants hypothetical U.S. Senate election forecasts as text or a histogram and elicit their subjective probabilities using a betting task. The first experiment estimates the linear-in-probit intercepts and slopes, and confirms the biases in participants’ subjective probabilities. The second, preregistered follow-up shows participants the bias-corrected forecast distributions. We find the corrections substantially improve participants’ decision quality by reducing the integrated absolute error of their subjective probabilities compared to the true probabilities. These corrections can be generalized to any univariate probability or confidence distribution, giving them broad applicability. Our preprint, code, data, and preregistration are available at https://doi.org/10.17605/osf.io/kcwxm},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {836},
numpages = {17},
keywords = {election forecasts, perception, subjective probability, uncertainty visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580819,
author = {Rogers, Jen and Crisan, Anamaria},
title = {Tracing and Visualizing Human-ML/AI Collaborative Processes through Artifacts of Data Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580819},
doi = {10.1145/3544548.3580819},
abstract = {Automated Machine Learning (AutoML) technology can lower barriers in data work yet still requires human intervention to be functional. However, the complex and collaborative process resulting from humans and machines trading off work makes it difficult to trace what was done, by whom (or what), and when. In this research, we construct a taxonomy of data work artifacts that captures AutoML and human processes. We present a rigorous methodology for its creation and discuss its transferability to the visual design process. We operationalize the taxonomy through the development of&nbsp;AutoML Trace&nbsp; a visual interactive sketch showing both the context and temporality of human-ML/AI collaboration in data work. Finally, we demonstrate the utility of our approach via a usage scenario with an enterprise software development team. Collectively, our research process and findings explore challenges and fruitful avenues for developing data visualization tools that interrogate the sociotechnical relationships in automated data work. Availability of Supplemental Materials: https://osf.io/3nmyj/?view_only=19962103d58b45d289b5c83421f48b36},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {837},
numpages = {22},
keywords = {Taxonomy, AutoML, Data Visualization, Human-Machine Collaboration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580739,
author = {Verma, Arnav and Morais, Luiz and Dragicevic, Pierre and Chevalier, Fanny},
title = {Designing Resource Allocation Tools to Promote Fair Allocation: Do Visualization and Information Framing Matter?},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580739},
doi = {10.1145/3544548.3580739},
abstract = {Studies on human decision-making focused on humanitarian aid have found that cognitive biases can hinder the fair allocation of resources. However, few HCI and Information Visualization studies have explored ways to overcome those cognitive biases. This work investigates whether the design of interactive resource allocation tools can help to promote allocation fairness. We specifically study the effect of presentation format (using text or visualization) and a specific framing strategy (showing resources allocated to groups or individuals). In our three crowdsourced experiments, we provided different tool designs to split money between two fictional programs that benefit two distinct communities. Our main finding indicates that individual-framed visualizations and text may be able to curb unfair allocations caused by group-framed designs. This work opens new perspectives that can motivate research on how interactive tools and visualizations can be engineered to combat cognitive biases that lead to inequitable decisions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {838},
numpages = {16},
keywords = {framing, donation, cognitive bias, visualization, resource allocation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581573,
author = {Mcneill, Graham and Sondag, Max and Powell, Stewart and Asplin, Phoebe and Turkay, Cagatay and Moller, Faron and Archambault, Daniel},
title = {From Asymptomatics to Zombies: Visualization-Based Education of Disease Modeling for Children},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581573},
doi = {10.1145/3544548.3581573},
abstract = {Throughout the COVID-19 pandemic, visualizations became commonplace in public communications to help people make sense of the world and the reasons behind government-imposed restrictions. Though the adult population were the main target of these messages, children were affected by restrictions through not being able to see friends and virtual schooling. However, through these daily models and visualizations, the pandemic response provided a way for children to understand what data scientists really do and provided new routes for engagement with STEM subjects. In this paper, we describe the development of an interactive and accessible visualization tool to be used in workshops for children to explain computational modeling of diseases, in particular COVID-19. We detail our design decisions based on approaches evidenced to be effective and engaging such as unplugged activities and interactivity. We share reflections and learnings from delivering these workshops to 140 children and assess their effectiveness.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {839},
numpages = {17},
keywords = {Visualization, Children, Disease spread, Teaching},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580837,
author = {Pu, Xiaoying and Kay, Matthew},
title = {How Data Analysts Use a Visualization Grammar in Practice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580837},
doi = {10.1145/3544548.3580837},
abstract = {Visualization grammars, often based on the Grammar of Graphics (GoG), have much potential for augmenting data analysis in a programming environment. However, we do not know how analysts conceptualize grammar abstractions, or how a visualization grammar works with data analysis in practice. Therefore, we qualitatively analyzed how experienced analysts (N = 6) from TidyTuesday, a social data project, wrangled and visualized data using GoG-based ggplot2 without given tasks in R Markdown. Though participants’ analysis and customization needs could mismatch with GoG component design, their analysis processes aligned with the goal of GoG to expedite visualization iteration. We also found a feedback loop and tight coupling between visualization and data transformation code, explaining both participants’ productivity and their errors. From these results, we discuss how future visualization grammars can become more practical for analysts and how visualization grammar and analysis tools can better integrate within a programming (i.e., computational notebook) environment.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {840},
numpages = {22},
keywords = {Visualization grammar, computational notebook, TidyTuesday},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581266,
author = {Chen, Zhutian and Yang, Qisen and Shan, Jiarui and Lin, Tica and Beyer, Johanna and Xia, Haijun and Pfister, Hanspeter},
title = {IBall: Augmenting Basketball Videos with Gaze-Moderated Embedded Visualizations},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581266},
doi = {10.1145/3544548.3581266},
abstract = {We present iBall, a basketball video-watching system that leverages gaze-moderated embedded visualizations to facilitate game understanding and engagement of casual fans. Video broadcasting and online video platforms make watching basketball games increasingly accessible. Yet, for new or casual fans, watching basketball videos is often confusing due to their limited basketball knowledge and the lack of accessible, on-demand information to resolve their confusion. To assist casual fans in watching basketball videos, we compared the game-watching behaviors of casual and die-hard fans in a formative study and developed iBall based on the findings. iBall embeds visualizations into basketball videos using a computer vision pipeline, and automatically adapts the visualizations based on the game context and users’ gaze, helping casual fans appreciate basketball games without being overwhelmed. We confirmed the usefulness, usability, and engagement of iBall in a study with 16 casual fans, and further collected feedback from 8 die-hard fans.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {841},
numpages = {18},
keywords = {Embedded Visualization, Video-based Visualization, Gaze Interaction, Augmented Sports Videos, Sports Visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581137,
author = {Perovich, Laura J and Rogowitz, Bernice and Crabb, Victoria and Vogelsang, Jack and Hartleben, Sara and Offenhuber, Dietmar},
title = {The Tactile Dimension: A Method for Physicalizing Touch Behaviors},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581137},
doi = {10.1145/3544548.3581137},
abstract = {Traces of touch provide valuable insight into how we interact with the physical world. Measuring touch behavior, however, is expensive and imprecise. Utilizing a fluorescent UV tracer powder, we developed a low-cost analog method to capture persistent, high-contrast touch records on arbitrary objects. We describe our process for selecting a tracer, methods for capturing, enhancing, and aggregating traces, and approaches to examining qualitative aspects of the user experience. Three user studies demonstrate key features of this method. First, we show that it provides clear and durable traces on objects representative of scientific visualization, physicalization, and product design. Second, we demonstrate how this method could be used to study touch perception, by measuring how task and narrative framing elicit different touch behaviors on the same object. Third, we demonstrate how this method can be used to evaluate data physicalizations by observing how participants touch two different physicalizations of COVID-19 time-series data.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {842},
numpages = {15},
keywords = {data physicalization, touch, materiality, design methods},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580768,
author = {Pooryousef, Vahid and Cordeil, Maxime and Besan\c{c}on, Lonni and Hurter, Christophe and Dwyer, Tim and Bassed, Richard},
title = {Working with Forensic Practitioners to Understand the Opportunities and Challenges for Mixed-Reality Digital Autopsy},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580768},
doi = {10.1145/3544548.3580768},
abstract = {Forensic practitioners analyse intrinsic 3D data daily on 2D screens. We explore novel immersive visualisation techniques that enable digital autopsy through analysis of 3D imagery. We employ a user-centred design process involving four rounds of user feedback: (1) formative interviews eliciting opportunities and requirements for mixed-reality digital autopsies; (2) a larger workshop identifying our prototype’s limitations and further use-cases and interaction ideas; (3+4) two rounds of qualitative user validation of successive prototypes of novel interaction techniques for pathologist sensemaking. Overall, we find MR holds great potential to enable digital autopsy, initially to supplement physical autopsy, but ultimately to replace it. We found that experts were able to use our tool to perform basic virtual autopsy tasks, MR setup promotes exploration and sense making of cause of death, and subject to limitations of current MR technology, the proposed system is a valid option for digital autopsies, according to experts’ feedback. – Warning: This paper contains sensitive images which are 3D visualisation of deceased people.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {843},
numpages = {15},
keywords = {pathology, mixed reality, autopsy, forensics, user-centred design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581561,
author = {Karkera, Yukta and Tandukar, Barsa and Chandra, Sowmya and Martin-Hammond, Aqueasha},
title = {Building Community Capacity: Exploring Voice Assistants to Support Older Adults in an Independent Living Community},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581561},
doi = {10.1145/3544548.3581561},
abstract = {Voice assistants (VAs) such as Siri or Amazon Alexa can benefit older adults by offering accessible and convenient information options and aiding living independently. Therefore, researchers have considered how VAs might support older adults. Yet, few studies have explored opportunities for VAs to support communities and the implications of this integration. This study investigates older adults' perceptions of VAs and the potential to extend VA capabilities to support an independent living community. We invited independent living residents to virtual community forums and interviews to discuss their experiences with VAs, expectations, and concerns for VA integration to support information exchange, wellness, and social connections in their community. We found that residents desired additional VA capabilities to address unique community needs, including building on existing community capacities to support VA adoption and use. We discuss VA design implications for independent living communities and recommendations to support VA sustainability in a community environment.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {844},
numpages = {17},
keywords = {assets, voice assistants, older adults, independent living, capacity building},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581421,
author = {Wolf, Sara and Luthe, Simon and Baumeister, Lennart and Moerike, Frauke and Janakiraman, Vyjayanthi and Hurtienne, J\"{o}rn},
title = {Designing for Uncontrollability: Drawing Inspiration from the Blessing Companion},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581421},
doi = {10.1145/3544548.3581421},
abstract = {This paper presents an inspirational concept for companion technology design, uncontrollability, and a corresponding artefact, the Blessing Companion. Both originated from a research through design project exploring companion technologies for blessing rituals. We established an exchange with Protestant theologians, explored believers’ experiences of blessings, co-speculated on potential technologies, and refined the resulting ideas through ideation, prototyping, and testing. Inspired by believers’ descriptions of blessing experiences as not plannable, predictable, controllable, or enforceable, we adopted the concept of uncontrollability, explored how it might be implemented in companion technologies, and designed the Blessing Companion. The Blessing Companion embodies uncontrollability through its ambiguous appearance and (partly) uncontrollable behaviour. It thus stands in contrast to the prevailing on-demand and user-driven interaction paradigms. We discuss how uncontrollability can be reflected in content, form, and interaction, highlight respective possibilities for companion technologies, and reflect on the Blessing Companion as an example of designing for religious rituals.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {845},
numpages = {14},
keywords = {Research through design, religion, ritual, transcendent experience, techno-spirituality, companion technology},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581007,
author = {Lewis, Brittany and Ranalli, Tina-Marie and Gourley, Alexandra and Kirupaharan, Piriyankan and Venkatasubramanian, Krishna},
title = {"I... Caught a Person Casing My House... and Scared Him off:" The Use of Security-Focused Smart Home Devices by People with Disabilities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581007},
doi = {10.1145/3544548.3581007},
abstract = {Recent years have seen a proliferation of security-focused smart home devices (SSHDs). SSHDs, such as smart locks and cameras, are designed to accomplish critical tasks, such as protecting one’s home and property. However, their use by and for people with disabilities (PwD) has not been broadly investigated. To explore the state of SSHD use by PwD, we collected 114,871 amazon.com reviews for popular SSHDs and created a data set of reviews pertaining to PwD. We performed a broad analysis of the reviews in this data set and found that the presence of SSHDs empowered PwD to secure their domiciles independently. Further, caregivers used SSHDs to monitor PwD, ostensibly for the latter’s safety, albeit without explicit consent. Moreover, we also found that SSHDs have several drawbacks that impose various barriers of use on PwD. We analyze the significance of these findings and suggest five future research opportunities for SSHD design.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {846},
numpages = {16},
keywords = {disability, home security, smart home devices, empowerment, accessibility, surveillance},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581507,
author = {Desai, Smit and Chin, Jessie},
title = {OK Google, Let's Learn: Using Voice User Interfaces for Informal Self-Regulated Learning of Health Topics among Younger and Older Adults},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581507},
doi = {10.1145/3544548.3581507},
abstract = {In this paper, we present Health Buddy, a voice agent integrated into commercially available Voice User Interfaces (VUIs) to support informal self-regulated learning (SRL) of health-related topics through multiple learning strategies and examine the efficacy of Health Buddy on learning outcomes for younger and older adults. We conducted a mixed-factorial-design experiment with 26 younger and 25 older adults, assigned to three SRL strategies (within-subjects): monologue, dialogue-based scaffolding building, and conceptual diagramming. We found that while younger adults benefit more from scaffolding building and conceptual diagramming, both younger and older adults showed equivalent learning outcomes. Furthermore, interaction fluency (operationalized by the number of conversational breakdowns) was associated with learning outcomes regardless of age. While older adults did not experience less fluent conversations, interaction fluency affected their technology acceptance toward VUIs more than younger ones. Our study discusses age-related learning differences and has implications for designing VUI-based learning programs for older adults.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {847},
numpages = {21},
keywords = {Informal Learning, Metacognition, Interaction fluency, Aging, Voice user interface(s), Health information, Technology acceptance, Conversational agent(s), Self-regulated learning, Voice assistant(s)},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580925,
author = {Upadhyay, Pooja and Heung, Sharon and Azenkot, Shiri and Brewer, Robin N.},
title = {Studying Exploration &amp; Long-Term Use of Voice Assistants by Older Adults},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580925},
doi = {10.1145/3544548.3580925},
abstract = {While past research has examined older adults’ voice assistant (VA) use, it is unclear whether VAs provide enough value to sustain use when compared to technologies such as smartphones. Research also suggests that barriers around structured command input may limit use. In order to investigate these gaps in adoption, we conducted interviews with ten older adults in a long-term care community who have adopted Alexa devices for at least one year. Participants learned to use Alexa through a training program that encouraged exploration. They used Alexa to complement their daily routines, improve their mood, engage in cognitively stimulating activities, and support socialization with others. We discuss our findings in the context of prior work, describe strategies to promote VA learning and adoption, and present design recommendations to support aging.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {848},
numpages = {11},
keywords = {voice assistants, utility, learning, exploration, speech interfaces, older adults, aging},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581447,
author = {Yu, Ja Eun and Parde, Natalie and Chattopadhyay, Debaleena},
title = {“Where is History”: Toward Designing a Voice Assistant to Help Older Adults Locate Interface Features Quickly},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581447},
doi = {10.1145/3544548.3581447},
abstract = {Older adults often struggle to locate a function quickly in feature-rich user interfaces (UIs). Mobile UIs not only pack a ton of features in a small screen but also get frequent updates to their visual layouts—thereby exacerbating the problem. This paper explores a design solution where users could search for a UI feature using spoken-word queries. We investigated: 1) what type of questions older users ask when facing interaction challenges in unfamiliar scenarios, 2) how those query types compare with younger users’ inquiries, and 3) how older adults use a voice assistant design probe in a Wizard-of-Oz (WoZ) study. Results reveal five query types when verbally articulating interaction issues: validation, directed and undirected informational, navigational, and conceptual. In the WoZ study, older users typically asked for help following a series of non-unique or off-task feature selections (n = 13/15), and in 77% of those instances, they completed the task in the next interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {849},
numpages = {19},
keywords = {voice assistant, design, accessibility, speech input, aging, older adults, mobile interface},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580813,
author = {Buechley, Leah and Ta, Ruby},
title = {3D Printable Play-Dough: New Biodegradable Materials and Creative Possibilities for Digital Fabrication},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580813},
doi = {10.1145/3544548.3580813},
abstract = {Play-dough is a brightly-colored, easy-to-make, and familiar material. We have developed and tested custom play-dough materials that can be employed in 3D printers designed for clay. This paper introduces a set of recipes for 3D printable play-dough along with an exploration of these materials’ print characteristics. We explore the design potential of play-dough as a sustainable fabrication material, highlighting its recyclability, compostability, and repairability. We demonstrate how custom-color prints can be designed and constructed and describe how play-dough can be used as a support material for clay 3D prints. We also present a set of example artifacts made from play-dough and discuss opportunities for future research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {850},
numpages = {15},
keywords = {keywords},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580958,
author = {Gough, Phillip and Perera, Praneeth Bimsara and Kertesz, Michael A. and Withana, Anusha},
title = {Design, Mould, Grow!: A Fabrication Pipeline for Growing 3D Designs Using Myco-Materials},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580958},
doi = {10.1145/3544548.3580958},
abstract = {There is a growing interest in sustainable fabrication approaches, including the exploration of material conservation and utilisation of waste materials. Particularly, recent work has applied organic myco-materials, made from fungi, to develop tangible, interactive devices. However, a systematic approach for 3D fabrication using myco-materials is under-explored. In this paper, we present a parametric design tool and a fabrication pipeline to grow 3D designs using the mycelia of edible fungi species, such as Reishi or Oyster mushrooms. The proposed tool is designed based on empirical results from a series of technical evaluations of the geometric and material qualities of 3D-grown myco-objects. Furthermore, the paper introduces an easy-to-replicate fabrication process that can recycle different organic waste material combinations such as sawdust and coffee grounds to grow mycelia. Through a series of demonstration applications, we identify the challenges and opportunities for working with myco-materials in the HCI context.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {851},
numpages = {15},
keywords = {Biological HCI, Bio-design, Design Tools, Bio-Fabrication},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580801,
author = {Zhang, Ruidong and Li, Ke and Hao, Yihong and Wang, Yufan and Lai, Zhengnan and Guimbreti\`{e}re, Fran\c{c}ois and Zhang, Cheng},
title = {EchoSpeech: Continuous Silent Speech Recognition on Minimally-Obtrusive Eyewear Powered by Acoustic Sensing},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580801},
doi = {10.1145/3544548.3580801},
abstract = {We present EchoSpeech, a minimally-obtrusive silent speech interface (SSI) powered by low-power active acoustic sensing. EchoSpeech uses speakers and microphones mounted on a glass-frame and emits inaudible sound waves towards the skin. By analyzing echos from multiple paths, EchoSpeech captures subtle skin deformations caused by silent utterances and uses them to infer silent speech. With a user study of 12 participants, we demonstrate that EchoSpeech can recognize 31 isolated commands and 3-6 figure connected digits with 4.5% (std 3.5%) and 6.1% (std 4.2%) Word Error Rate (WER), respectively. We further evaluated EchoSpeech under scenarios including walking and noise injection to test its robustness. We then demonstrated using EchoSpeech in demo applications in real-time operating at 73.3mW, where the real-time pipeline was implemented on a smartphone with only 1-6 minutes of training data. We believe that EchoSpeech takes a solid step towards minimally-obtrusive wearable SSI for real-life deployment.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {852},
numpages = {18},
keywords = {Silent Speech Recognition, Smart Glasses, Acoustic Sensing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581344,
author = {Yan, Zihan and Lin, Yuxiaotong and Wang, Guanyun and Cai, Yu and Cao, Peng and Mi, Haipeng and Zhang, Yang},
title = {LaserShoes: Low-Cost Ground Surface Detection Using Laser Speckle Imaging},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581344},
doi = {10.1145/3544548.3581344},
abstract = {Ground surfaces are often carefully designed and engineered with various textures to fit the functionalities of human environments and thus could contain rich context information for smart wearables. Ground surface detection could power a wide array of applications including activity recognition, mobile health, and context-aware computing, and potentially provide an additional channel of information for many existing kinesiology approaches such as gait analysis. To facilitate the detection of ground surfaces, we present LaserShoes, a texture-sensing-enabled system using laser speckle imaging that can be retrofitted to shoes. Our system captures videos of speckle patterns induced on ground surfaces and uses pre-processing to identify ideal images with clear speckle patterns collected when users’ feet are in contact with ground surfaces. We demonstrated our technique with a ResNet-18 model and achieved real-time inference. We conducted an evaluation in different conditions and demonstrated results that verified the feasibility.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {853},
numpages = {20},
keywords = {Smart Shoes, Laser Speckle Imaging, Context Aware Computing, Texture Identification, Surface Identification},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581098,
author = {Song, Katherine Wei and Dierk, Christine and Tung, Szu Ting and Paulos, Eric},
title = {Lotio: Lotion-Mediated Interaction with an Electronic Skin-Worn Display},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581098},
doi = {10.1145/3544548.3581098},
abstract = {Skin-based electronics are an emerging genre of interactive technologies. In this paper, we leverage the natural uses of lotions and propose them as mediators for driving novel, low-power, quasi-bistable, and bio-degradable electrochromic displays on the skin and other surfaces. We detail the design, fabrication, and evaluation of one such “Lotion Interface,” including how it can be customized using low-cost everyday materials and technologies to trigger various visual and temporal effects –&nbsp;some lasting up to fifteen minutes when unpowered. We characterize different fabrication techniques and lotions to demonstrate various visual effects on a variety of skin types and tones. We highlight the safety of our design for humans and the environment. Finally, we report findings from an exploratory user study and present a range of compelling applications for Lotion Interfaces that expand the on-skin and surface interaction landscapes to include the familiar and often habitual practice of applying lotion.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {854},
numpages = {15},
keywords = {ambient displays, wearables, skin interface, lotion},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581088,
author = {Meegahapola, Lakmal and Constantinides, Marios and Radivojevic, Zoran and Li, Hongwei and Quercia, Daniele and Eggleston, Michael S},
title = {Quantified Canine: Inferring Dog Personality From Wearables},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581088},
doi = {10.1145/3544548.3581088},
abstract = {Being able to assess dog personality can be used to, for example, match shelter dogs with future owners, and personalize dog activities. Such an assessment typically relies on experts or psychological scales administered to dog owners, both of which are costly. To tackle that challenge, we built a device called “Patchkeeper” that can be strapped on the pet’s chest and measures activity through an accelerometer and a gyroscope. In an in-the-wild deployment involving 12 healthy dogs, we collected 1300 hours of sensor activity data and dog personality test results from two validated questionnaires. By matching these two datasets, we trained ten machine learning classifiers that predicted dog personality from activity data, achieving AUCs in [0.63-0.90], suggesting the value of tracking psychological signals of pets using wearable technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {855},
numpages = {19},
keywords = {dog personality, behavior modeling, activity level, wearables, dog activity recognition, passive sensing},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581536,
author = {Wiese, Jason and Lund, John R. and Kabir, Kazi Sinthia},
title = {Adding Domain-Specific Features to a Text-Editor to Support Diverse, Real-World Approaches to Time Management Planning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581536},
doi = {10.1145/3544548.3581536},
abstract = {Many tools are designed to support users in maintaining or developing strong time management practices. Abandonment of these specialized tools is common, in favor of returning to a more general-purpose unstructured tool. How can designs leverage the familiarity of general-purpose tools and the advantages of specialized ones? We explore if applying a time-management-specific understanding of conventions and interactions within unstructured plaintext can be a successful approach to designing support for these tasks. We report the results of two field deployments (combined n=29) of “Plan” - a mobile application with a notes-application-based interface designed to support the practice of Time Management Planning. We show that modest, domain-specific modifications of general-purpose designs can facilitate users’ pre-existing workflows and nudge them towards better practices while leaving interfaces familiar and flexible. However, those with minimal planning experience desired additional structure.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {856},
numpages = {13},
keywords = {time management planning, field deployment, interviews},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581326,
author = {Das Swain, Vedant and Hernandez, Javier and Houck, Brian and Saha, Koustuv and Suh, Jina and Chaudhry, Ahad and Cho, Tenny and Guo, Wendy and Iqbal, Shamsi and Czerwinski, Mary P},
title = {Focused Time Saves Nine: Evaluating Computer–Assisted Protected Time for Hybrid Information Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581326},
doi = {10.1145/3544548.3581326},
abstract = {Information workers often struggle to balance their time for a variety of activities like focused work, communication, and caring. This study analyzes the impact of a commercially available computer-assisted time protection intervention that automatically and preemptively schedules calendar time for self-determined activities. We analyzed the behaviors and self-reports of workers in two naturalistic studies. First, we studied 27 workers who were already using Computer-Assisted Protected Time (CAP time) and found that they mainly used it for focused work. Second, we analyzed the effect of CAP time as a randomized intervention on 89 workers who never had CAP time and found that those with it self-reported an increase in performance, job resources, and immersion. In both studies, workers with CAP time exhibited a rearrangement of activities leading to an overall reduction in work activity. This study highlights new opportunities for intelligent time-management interventions and the importance of protected time at work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {857},
numpages = {18},
keywords = {time–management, behavioral intervention, information work, future of work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581528,
author = {Wong, Novia and Jackson, Victoria and Van Der Hoek, Andr\'{e} and Ahmed, Iftekhar and Schueller, Stephen M. and Reddy, Madhu},
title = {Mental Wellbeing at Work: Perspectives of Software Engineers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581528},
doi = {10.1145/3544548.3581528},
abstract = {Software engineers exhibit higher burnout and suicide rates compared to many other information workers. Consequently, mental wellbeing is a growing concern to technology organizations. To better understand the challenges of supporting mental wellbeing in the context of the work of software engineering, we conducted 14 interviews with software engineers. We examine the different aspects of their lived experiences with mental wellbeing at work, their strategies for managing mental wellbeing, the challenges they face in using these strategies, and recommendations they have for mental wellbeing technologies. We contribute to the HCI literature by discussing how mental wellbeing should be considered within the context of work across individual, team, and organization levels, and highlight the need for integrating mental wellbeing into the technologies employees use at work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {858},
numpages = {15},
keywords = {Health-wellbeing, Interview, Workplaces, Empirical study that tells us about people},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581354,
author = {Zhang, Angie and Boltz, Alexander and Lynn, Jonathan and Wang, Chun-Wei and Lee, Min Kyung},
title = {Stakeholder-Centered AI Design: Co-Designing Worker Tools with Gig Workers through Data Probes},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581354},
doi = {10.1145/3544548.3581354},
abstract = {AI technologies continue to advance from digital assistants to assisted decision-making. However, designing AI remains a challenge given its unknown outcomes and uses. One way to expand AI design is by centering stakeholders in the design process. We conduct co-design sessions with gig workers to explore the design of gig worker-centered tools as informed by their driving patterns, decisions, and personal contexts. Using workers’ own data as well as city-level data, we create probes—interactive data visuals—that participants explore to surface the well-being and positionalities that shape their work strategies. We describe participant insights and corresponding AI design considerations surfaced from data probes about: 1) workers’ well-being trade-offs and positionality constraints, 2) factors that impact well-being beyond those in the data probes, and 3) instances of unfair algorithmic management. We discuss the implications for designing data probes and using them to elevate worker-centered AI design as well as for worker advocacy.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {859},
numpages = {19},
keywords = {AI Design, Worker Well-Being, Data Probes, Co-Design, Worker-Centered Worker Tools, Gig Work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580882,
author = {Kuo, Tzu-Sheng and Shen, Hong and Geum, Jisoo and Jones, Nev and Hong, Jason I. and Zhu, Haiyi and Holstein, Kenneth},
title = {Understanding Frontline Workers’ and Unhoused Individuals’ Perspectives on AI Used in Homeless Services},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580882},
doi = {10.1145/3544548.3580882},
abstract = {Recent years have seen growing adoption of AI-based decision-support systems (ADS) in homeless services, yet we know little about stakeholder desires and concerns surrounding their use. In this work, we aim to understand impacted stakeholders’ perspectives on a deployed ADS that prioritizes scarce housing resources. We employed AI lifecycle comicboarding, an adapted version of the comicboarding method, to elicit stakeholder feedback and design ideas across various components of an AI system’s design. We elicited feedback from county workers who operate the ADS daily, service providers whose work is directly impacted by the ADS, and unhoused individuals in the region. Our participants shared concerns and design suggestions around the AI system’s overall objective, specific model design choices, dataset selection, and use in deployment. Our findings demonstrate that stakeholders, even without AI knowledge, can provide specific and critical feedback on an AI system’s design and deployment, if empowered to do so.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {860},
numpages = {17},
keywords = {public algorithms, homelessness, comicboarding, AI-based decision support},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580690,
author = {Ma, Rongjun and Lassila, Henrik and Nurgalieva, Leysan and Lindqvist, Janne},
title = {When Browsing Gets Cluttered: Exploring and Modeling Interactions of Browsing Clutter, Browsing Habits, and Coping},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580690},
doi = {10.1145/3544548.3580690},
abstract = {In this paper, we investigate browsing clutter, which refers to cluttered experiences of users due to buildup of disorganized browser elements and information. We studied what users experience as clutter, what behaviors and factors contribute to the clutter, and what users do when they experience clutter through an interview study (N = 16) and an online survey study (N = 400). Based on our studies, browsing clutter includes the amount of tabs and windows, content of the web pages and interactive elements, navigation, and search process. We identified sources of browsing clutter from task characteristics, such as importance and complexity, to user habits, such as multitasking and tab closing. To reveal the dynamics of browsing clutter, we modeled how browsing clutter is predicted by specific browsing habits and coping strategies. Our model demonstrates how individual forms of clutter are interrelated and altered by behavior. We discuss how browsing clutter relates to information overload.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {861},
numpages = {29},
keywords = {Information overload, Web browsing behavior, Browsing clutter, Coping},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581370,
author = {Ziegler, Parker and Chasins, Sarah E.},
title = {A Need-Finding Study with Users of Geospatial Data},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581370},
doi = {10.1145/3544548.3581370},
abstract = {Geospatial data is playing an increasingly critical role in the work of Earth and climate scientists, social scientists, and data journalists exploring spatiotemporal change in our environment and societies. However, existing software and programming tools for geospatial analysis and visualization are challenging to learn and difficult to use. The aim of this work is to identify the unmet computing needs of the diverse and expanding community of geospatial data users. We conducted a contextual inquiry study (n = 25) with domain experts using geospatial data in their current work. Through a thematic analysis, we found that participants struggled to (1)&nbsp;find and transform geospatial data to satisfy spatiotemporal constraints, (2)&nbsp;understand the behavior of geospatial operators, (3)&nbsp;track geospatial data provenance, and (4)&nbsp;explore the cartographic design space. These findings suggest design opportunities for developers and designers of geospatial analysis and visualization systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {862},
numpages = {16},
keywords = {need-finding, contextual inquiry, geography, geospatial data, GIS, cartography},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580997,
author = {Raghunandan, Deepthi and Roy, Aayushi and Shi, Shenzhi and Elmqvist, Niklas and Battle, Leilani},
title = {Code Code Evolution: Understanding How People Change Data Science Notebooks Over Time},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580997},
doi = {10.1145/3544548.3580997},
abstract = {Sensemaking is the iterative process of identifying, extracting, and explaining insights from data, where each iteration is referred to as the “sensemaking loop.” However, little is known about how sensemaking behavior evolves from exploration and explanation during this process. This gap limits our ability to understand the full scope of sensemaking, which in turn inhibits the design of tools that support the process. We contribute the first mixed-method to characterize how sensemaking evolves within computational notebooks. We study 2,574 Jupyter notebooks mined from GitHub by identifying data science notebooks that have undergone significant iterations, presenting a regression model that automatically characterizes sensemaking activity, and using this regression model to calculate and analyze shifts in activity across GitHub versions. Our results show that notebook authors participate in various sensemaking tasks over time, such as annotation, branching analysis, and documentation. We use our insights to recommend extensions to current notebook environments.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {863},
numpages = {12},
keywords = {data science, analysis., machine learning, sensemaking, Computational notebooks, data exploration},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580766,
author = {Ortloff, Anna-Marie and Fassl, Matthias and Ponticello, Alexander and Martius, Florin and Mertens, Anne and Krombholz, Katharina and Smith, Matthew},
title = {Different Researchers, Different Results? Analyzing the Influence of Researcher Experience and Data Type During Qualitative Analysis of an Interview and Survey Study on Security Advice},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580766},
doi = {10.1145/3544548.3580766},
abstract = {When conducting qualitative research it is necessary to decide how many researchers should be involved in coding the data: Is one enough or are more coders beneficial? To offer empirical evidence for this question, we designed a series of studies investigating qualitative coding. We replicated and extended a usable security and privacy study by Ion et al. to gather both simple survey data and complex interview data. We had a total of 65 students and seven researchers analyze different parts of this data. We analyzed the codebook creation process, similarity of outcomes, inter-rater reliability, and compared the student to the researcher outcomes. We also surveyed five years of SOUPS-PC members about their views on coding. The reviewers view on coding practices for complex and simple data are almost identical. However, our results suggest that the coding process can be different for the two types of data, with complex data benefiting more from interaction between coders.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {864},
numpages = {21},
keywords = {quality criteria, qualitative analysis, reliability},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581271,
author = {Kasica, Stephen and Berret, Charles and Munzner, Tamara},
title = {Dirty Data in the Newsroom: Comparing Data Preparation in Journalism and Data Science},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581271},
doi = {10.1145/3544548.3581271},
abstract = {The work involved in gathering, wrangling, cleaning, and otherwise preparing data for analysis is often the most time consuming and tedious aspect of data work. Although many studies describe data preparation within the context of data science workflows, there has been little research on data preparation in data journalism. We address this gap with a hybrid form of thematic analysis that combines deductive codes derived from existing accounts of data science workflows and inductive codes arising from an interview study with 36 professional data journalists. We extend a previous model of data science work to incorporate detailed activities of data preparation. We synthesize 60 dirty data issues from 16 taxonomies on dirty data and our interview data, and we provide a novel taxonomy to characterize these dirty data issues as discrepancies between mental models. We also identify four challenges faced by journalists: diachronic, regional, fragmented, and disparate data sources.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {865},
numpages = {18},
keywords = {data cleaning, data journalism, data wrangling, data science, thematic analysis},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580916,
author = {Alvarado Garcia, Adriana and Wong-Villacres, Marisol and Miceli, Milagros and Hern\'{a}ndez, Benjam\'{\i}n and Le Dantec, Christopher A},
title = {Mobilizing Social Media Data: Reflections of a Researcher Mediating between Data and Organization},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580916},
doi = {10.1145/3544548.3580916},
abstract = {This paper examines the practices involved in mobilizing social media data from their site of production to the institutional context of non-profit organizations. We report on nine months of fieldwork with a transnational and intergovernmental organization using social media data to understand the role of grassroots initiatives in Mexico, in the unique context of the COVID-19 pandemic. We show how different stakeholders negotiate the definition of problems to be addressed with social media data, the collective creation of ground-truth, and the limitations involved in the process of extracting value from data. The meanings of social media data are not defined in advance; instead, they are contingent on the practices and needs of the organization that seeks to extract insights from the analysis. We conclude with a list of reflections and questions for researchers who mediate in the mobilization of social media data into non-profit organizations to inform humanitarian action.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {866},
numpages = {19},
keywords = {NGO, humanitarian context, mobilizing data, user-generated content, organizational practices, data work, data experts, non-profit organizations, social media data},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581562,
author = {Brown, Adam and D'Angelo, Sarah and Holtz, Ben and Jaspan, Ciera and Green, Collin},
title = {Using Logs Data to Identify When Software Engineers Experience Flow or Focused Work},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581562},
doi = {10.1145/3544548.3581562},
abstract = {Beyond self-report data, we lack reliable and non-intrusive methods for identifying flow. However, taking a step back and acknowledging that flow occurs during periods of focus gives us the opportunity to make progress towards measuring flow by isolating focused work. Here, we take a mixed-methods approach to design a logs-based metric that leverages machine learning and a comprehensive collection of logs data to identify periods of related actions (indicating focus), and validate this metric against self-reported time in focus or flow using diary data and quarterly survey data. Our results indicate that we can determine when software engineers at a large technology company experience focused work which includes instances of flow. This metric speaks to engineering work, but can be leveraged in other domains to non-disruptively measure when people experience focus. Future research can build upon this work to identify signals associated with other facets of flow.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {867},
numpages = {12},
keywords = {diary study, Focus, machine learning, survey, Logs based analysis, Flow, Software Engineering},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581548,
author = {Lashkari, Mitra and Cheng, Jinghui},
title = {“Finding the Magic Sauce”: Exploring Perspectives of Recruiters and Job Seekers on Recruitment Bias and Automated Tools},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581548},
doi = {10.1145/3544548.3581548},
abstract = {Automated recruitment tools are proliferating. While having the promise of improving efficiency, various risks, including bias, challenges the potential of these tools. An in-depth understanding of the perceived risk factors and needs from the perspective of both recruiters and job seekers is needed. We address this through an interview study in the high-tech industry to compare and contrast the concerns of these two roles. We found that the importance of clarifying position requirements and assessing candidates as “whole individuals” are commonly discussed by both recruiters and job seekers. In contrast, while recruiters tended to be more aware of cognitive bias and desired more tool support during interviews, job seekers voiced more desire towards a healthy candidate-company relationship. Additionally, both roles considered the uncertainty of the current technology capability and reduced human contact as concerns for using automated tools. Based on these results, we provided design implications for automated recruitment tools and related decision-support technologies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {868},
numpages = {16},
keywords = {Hiring, automated recruitment tools, decision support system, decision making, bias},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580647,
author = {Raghunath, Ananditha and Krovetz, Laurel and Mpogole, Hosea and Mulisa, Henry and Dillon, Brian and Anderson, Richard},
title = {From Grasshoppers to Secondhand Cars: Understanding the Smartphone-Enabled Marketplace in Peri-Urban Tanzania},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580647},
doi = {10.1145/3544548.3580647},
abstract = {The evolving socio-technical landscape in peri-urban Tanzania has paved the way for a dramatic increase in smartphone-supported micro and small enterprises. We conduct surveys and focus groups with 46 such entrepreneurs, shedding light on the internal mechanisms and external networks of their businesses. We uncover the new trust dynamics encountered in online interactions, the gendered aspects of this emerging business model, and the means through which people with low capital are reclaiming economic empowerment through entrepreneurship.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {869},
numpages = {13},
keywords = {Smartphones, HCI4D, WhatsApp, Tanzania, Entrepreneurship},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581383,
author = {Akahori, Wataru and Yamashita, Naomi and Jamieson, Jack and Nakatani, Momoko and Hashimoto, Ryo and Watanabe, Masahiro},
title = {Impacts of the Strength and Conformity of Social Norms on Well-Being: A Mixed-Method Study Among Hybrid Workers in Japan},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581383},
doi = {10.1145/3544548.3581383},
abstract = {Previous studies have suggested that organizational social norms can positively affect employee well-being. However, such social norms have not been well developed during the post-COVID-19 transition to hybrid work, which combines office and remote work, and it is unclear how employees’ perceptions of social norms for hybrid work affect their well-being. In this study, we investigated the impact of social norms for hybrid work on the well-being of hybrid workers living in Japan through a mixed-method approach consisting of an online survey (n = 212) and semi-structured interviews (n = 20). The results indicate that hybrid workers who feel subject to strong social norms have lower well-being. Conversely, those who are more willing to conform to social norms have higher well-being. Given our findings, we discuss implications for the design of systems to help hybrid workers conform to organizational social norms and to improve their well-being.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {870},
numpages = {17},
keywords = {Social Norms, Well-Being, Hybrid Work},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581487,
author = {Abdulgalimov, Dinislam and Kirkham, Reuben and Nicholson, James and Bartindale, Tom and Olivier, Patrick},
title = {OurStrategy: Employee Voice In Transnational Strategy Development},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581487},
doi = {10.1145/3544548.3581487},
abstract = {The rich detail generated by qualitative research is essential for understanding workplace contexts and processes for organizational development. This can be a highly involved and extensive process, thus limiting the number of people who can normally be allowed to fully participate. This is especially problematic when it comes to workplace collaboration and development, as it means that a large number of voices are not considered and heard. In this paper, we provide and implement a novel semi-automated approach that enables large-scale qualitative research. This was done within the context of developing a new organizational strategy for a large and diverse multi-lingual international development organization. We included over 150 different stakeholders whilst enabling their views to be collected and analyzed in depth. This case study demonstrates how to effectively implement qualitative interview research at scale with an application to the employee voice setting, contributing the tools and means to achieve this.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {871},
numpages = {17},
keywords = {Qualitative research at Scale, Workplace, Organizational strategy, Employee voice},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581101,
author = {Bellini, Rosanna},
title = {Paying the Price: When Intimate Partners Use Technology for Financial Harm},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581101},
doi = {10.1145/3544548.3581101},
abstract = {Financial abuse — the control of a survivor’s access to and use of financial resources — is highly prevalent in intimate partner violence (IPV) cases. Based on the reports of 158 survivors of IPV and 16 financial advocates, we present a comprehensive investigation into how abusers exploit technologies to harm survivors financially through various technical attacks and deceptive strategies. In doing so, we identify four motivations for abusers who use these harmful attacks and how these acts exploit, monitor, restrict, and sabotage a survivor’s financial well-being and independence. As each dimension of these financial harms warrants a tailored approach, we highlight potential directions for practice and research to protect survivors from technology-enabled financial harms. Broadly, we call for the financial technology sector to consider designing for intimate threats through adversarial thinking, recommend strategies for detecting financially abusive activity and provide guidance for how customer service agents may be financially abuse aware.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {872},
numpages = {17},
keywords = {technology-enabled abuse, financial abuse, intimate partner violence},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581308,
author = {Saxena, Devansh and Moon, Erina Seh-Young and Chaurasia, Aryan and Guan, Yixin and Guha, Shion},
title = {Rethinking "Risk" in Algorithmic Systems Through A Computational Narrative Analysis of Casenotes in Child-Welfare},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581308},
doi = {10.1145/3544548.3581308},
abstract = {Risk assessment algorithms are being adopted by public sector agencies to make high-stakes decisions about human lives. Algorithms model “risk” based on individual client characteristics to identify clients most in need. However, this understanding of risk is primarily based on easily quantifiable risk factors that present an incomplete and biased perspective of clients. We conducted a computational narrative analysis of child-welfare casenotes and draw attention to deeper systemic risk factors that are hard to quantify but directly impact families and street-level decision-making. We found that beyond individual risk factors, the system itself poses a significant amount of risk where parents are over-surveilled by caseworkers and lack agency in decision-making processes. We also problematize the notion of risk as a static construct by highlighting the temporality and mediating effects of different risk, protective, systemic, and procedural factors. Finally, we draw caution against using casenotes in NLP-based systems by unpacking their limitations and biases embedded within them.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {873},
numpages = {19},
keywords = {risk work, uncertainty in decision-making, computational narrative analysis, risk prediction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580736,
author = {Tseng, Wen-Jie and Huron, Samuel and Lecolinet, Eric and Gugenheimer, Jan},
title = {FingerMapper: Mapping Finger Motions onto Virtual Arms to Enable Safe Virtual Reality Interaction in Confined Spaces},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580736},
doi = {10.1145/3544548.3580736},
abstract = {Whole-body movements enhance the presence and enjoyment of Virtual Reality (VR) experiences. However, using large gestures is often uncomfortable and impossible in confined spaces (e.g., public transport). We introduce FingerMapper, mapping small-scale finger motions onto virtual arms and hands to enable whole-body virtual movements in VR. In a first target selection study (n=13) comparing FingerMapper to hand tracking and ray-casting, we found that FingerMapper can significantly reduce physical motions and fatigue while having a similar degree of precision. In a consecutive study (n=13), we compared FingerMapper to hand tracking inside a confined space (the front passenger seat of a car). The results showed participants had significantly higher perceived safety and fewer collisions with FingerMapper while preserving a similar degree of presence and enjoyment as hand tracking. Finally, we present three example applications demonstrating how FingerMapper could be applied for locomotion and interaction for VR in confined spaces.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {874},
numpages = {14},
keywords = {Body Re-Association in VR, Confined Spaces, FingerMapper},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580988,
author = {Bonnail, Elise and Tseng, Wen-Jie and Mcgill, Mark and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
title = {Memory Manipulations in Extended Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580988},
doi = {10.1145/3544548.3580988},
abstract = {Human memory has notable limitations (e.g., forgetting) which have necessitated a variety of memory aids (e.g., calendars). As we grow closer to mass adoption of everyday Extended Reality (XR), which is frequently leveraging perceptual limitations (e.g., redirected walking), it becomes pertinent to consider how XR could leverage memory limitations (forgetting, distorting, persistence) to induce memory manipulations. As memories highly impact our self-perception, social interactions, and behaviors, there is a pressing need to understand XR Memory Manipulations (XRMMs). We ran three speculative design workshops (n=12), with XR and memory researchers creating 48 XRMM scenarios. Through thematic analysis, we define XRMMs, present a framework of their core components and reveal three classes (at encoding, pre-retrieval, at retrieval). Each class differs in terms of technology (AR, VR) and impact on memory (influencing quality of memories, inducing forgetting, distorting memories). We raise ethical concerns and discuss opportunities of perceptual and memory manipulations in XR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {875},
numpages = {20},
keywords = {Speculative Design, Extended Reality, Augmented Reality, Virtual Reality, Perceptual Manipulations, XR Memory Manipulations},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581018,
author = {O'Hagan, Joseph and Williamson, Julie R. and Mathis, Florian and Khamis, Mohamed and McGill, Mark},
title = {Re-Evaluating VR User Awareness Needs During Bystander Interactions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581018},
doi = {10.1145/3544548.3581018},
abstract = {Virtual reality (VR) users are often around bystanders, i.e. people in the real world the VR user may want to interact with. To facilitate bystander-VR user interactions, technology-mediated awareness systems have been introduced to increase a user’s awareness of bystanders. However, while prior works have found effective means of facilitating bystander-VR user interactions, it is unclear when and why one awareness system should be used over another. We reviewed, and selected, a breadth of bystander awareness systems from the literature and investigated their usability, and how they could be holistically used together to support varying awareness needs across 14 bystander-VR user interactions. Our results demonstrate VR users do not manage bystander awareness based solely on the usability of awareness systems but rather on the demands of social context weighted against desired immersion in VR (something existing evaluations fail to capture) and show the need for socially intelligent bystander awareness systems.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {876},
numpages = {17},
keywords = {Bystander-VR User Interactions, Augmented Reality, Virtual Reality, Mixed Reality, Interruptions, Context Awareness, Awareness},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580963,
author = {van Gemert, Thomas and Hornb\ae{}k, Kasper and Knibbe, Jarrod and Bergstr\"{o}m, Joanna},
title = {Towards a Bedder Future: A Study of Using Virtual Reality While Lying Down},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580963},
doi = {10.1145/3544548.3580963},
abstract = {Most contemporary Virtual Reality (VR) experiences are made for standing users. However, when a user is lying down—either by choice or necessity—it is unclear how they can walk around, dodge obstacles, or grab distant objects. We rotate the virtual coordinate space to study the movement requirements and user experience of using VR while lying down. Fourteen experienced VR users engaged with various popular VR applications for 40 minutes in a study using a think-aloud protocol and semi-structured interviews. Thematic analysis of captured videos and interviews reveals that using VR while lying down is comfortable and usable and that the virtual perspective produces a potent illusion of standing up. However, commonplace movements in VR are surprisingly difficult when lying down, and using alternative interactions is fatiguing and hampers performance. To conclude, we discuss design opportunities to tackle the most significant challenges and to create new experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {877},
numpages = {18},
keywords = {virtual reality, supine, room-scale, lying down, movement, user experience, bed},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581444,
author = {Johnson, Janet G and Sharkey, Tommy and Butarbutar, Iramuali Cynthia and Xiong, Danica and Huang, Ruijie and Sy, Lauren and Weibel, Nadir},
title = {UnMapped: Leveraging Experts’ Situated Experiences to Ease Remote Guidance in Collaborative Mixed Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581444},
doi = {10.1145/3544548.3581444},
abstract = {Collaborative Mixed Reality (MR) systems that help extend expertise for physical tasks to remote environments often situate experts in an immersive view of the task environment to bring the collaboration closer to collocated settings. In this paper, we design UnMapped, an alternative interface for remote experts that combines a live 3D view of the active space within the novice’s environment with a static 3D recreation of the expert’s own workspace to leverage their existing spatial memories within it. We evaluate the impact of this approach on single and repeated use of collaborative MR systems for remote guidance through a comparative study. Our results indicate that despite having a limited understanding of the novice’s environment, using an UnMapped interface increased performance and communication efficiency while reducing experts’ task load. We also outline the various affordances of providing remote experts with a familiar and spatially-stable environment to assist novices.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {878},
numpages = {20},
keywords = {Remote Collaboration, Augmented Reality, Physical Tasks, Virtual Reality, Mixed Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581050,
author = {Matviienko, Andrii and Hoxha, Hajris and M\"{u}hlh\"{a}user, Max},
title = {What Does It Mean to Cycle in Virtual Reality? Exploring Cycling Fidelity and Control of VR Bicycle Simulators},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581050},
doi = {10.1145/3544548.3581050},
abstract = {Creating highly realistic Virtual Reality (VR) bicycle experiences can be time-consuming and expensive. Moreover, it is unclear what hardware parts are necessary to design a bicycle simulator and whether a bicycle is needed at all. In this paper, we investigated cycling fidelity and control of VR bicycle simulators. For this, we developed and evaluated three cycling simulators: (1) cycling without a bicycle (bikeless), (2) cycling on a fixed (stationary) and (3) moving bicycle (tandem) with four levels of control (no control, steering, pedaling, and steering + pedaling). To evaluate all combinations of fidelity and control, we conducted a controlled experiment (N = 24) in indoor and outdoor settings. We found that the bikeless setup provides the highest feeling of safety, while the tandem leads to the highest realism without increasing motion sickness. Moreover, we discovered that bicycles are not essential for cycling in VR.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {879},
numpages = {15},
keywords = {cycling, virtual reality, bicycle simulators, locomotion},
location = {Hamburg, Germany},
series = {CHI '23}
}

